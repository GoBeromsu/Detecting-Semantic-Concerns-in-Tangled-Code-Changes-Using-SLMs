commit_message,diff,concern_count,shas,types
repository creation,"diff --git a/server/src/services/repository.service.ts b/server/src/services/repository.service.ts
index 3869c98..d675b30 100644
--- a/server/src/services/repository.service.ts
+++ b/server/src/services/repository.service.ts
@@ -19,6 +19,8 @@ export class RepositoryService {
       return;
     }
 
+    await this.createTeam(this.github, this.getTeamName(course), course.id);
+
     const studentRepo = getCustomRepository(StudentRepository);
     const students = await studentRepo.findActiveByCourseId(this.courseId);
 
@@ -31,8 +33,8 @@ export class RepositoryService {
         if (mentorGithubId) {
           await this.inviteMentor(mentorGithubId, course);
         }
-        await this.addTeamToRepository(this.github, course, student.githubId);
       }
+      await this.addTeamToRepository(this.github, course, student.githubId);
       if (record?.repository) {
         result.push({ repository: record.repository });
       }
",1,"[""87d5d4e55ab7149b593d29410f1fe426ba2447d4""]","[""fix""]"
update wrapping tests for v7,"diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });
",1,"[""317f4eefecddfb1392ca71d551840f446feee302""]","[""test""]"
add a branch name to Slack notifications (#14793),"diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'
",1,"[""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da""]","[""cicd""]"
increment failing test retries,"diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
",1,"[""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57""]","[""cicd""]"
print errors without stacktrace,"diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {
",1,"[""d129eaf9125a967ac86c6c7276bbae6b4d50af36""]","[""fix""]"
"assist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }
",1,"[""1269431c8a3e7549f10fcbbb4b88ff625c8898b3""]","[""build""]"
export a modal transition preset,"diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {
",1,"[""535708ae50aecb452560a23356fd396f99ef13a2""]","[""refactor""]"
"add hardware back button

Closes #5071","diff --git a/ionic/components/app/app.ts b/ionic/components/app/app.ts
index 04d8c57..08aab92 100644
--- a/ionic/components/app/app.ts
+++ b/ionic/components/app/app.ts
@@ -3,8 +3,7 @@ import {Title} from 'angular2/platform/browser';
 
 import {Config} from '../../config/config';
 import {ClickBlock} from '../../util/click-block';
-import {Nav} from '../nav/nav';
-import {Tabs} from '../tabs/tabs';
+import {Platform} from '../../platform/platform';
 
 
 /**
@@ -23,8 +22,20 @@ export class IonicApp {
 
   constructor(
     private _config: Config,
-    private _clickBlock: ClickBlock
-  ) {}
+    private _clickBlock: ClickBlock,
+    platform: Platform
+  ) {
+    platform.backButton.subscribe(() => {
+      let activeNav = this.getActiveNav();
+      if (activeNav) {
+        if (activeNav.length() === 1) {
+          platform.exitApp();
+        } else {
+          activeNav.pop();
+        }
+      }
+    });
+  }
 
   /**
    * Sets the document title.
@@ -102,7 +113,7 @@ export class IonicApp {
   /**
    * @private
    */
-  getActiveNav(): Nav | Tabs {
+  getActiveNav(): any {
     var nav = this._rootNav || null;
     var activeChildNav;
 
",1,"[""68278b00450f2679761a2999500f6d87a579376b""]","[""feat""]"
publish sdks after docs/build,"diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/
",1,"[""6c9cb638cb4d1ecc42632fcf389c24898c5b3244""]","[""cicd""]"
fixed docker link tests,"diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
",1,"[""c7b25726df94a2530c9b1c0d2b6a0acaa103822f""]","[""test""]"
"terminated tasks linger for a bit

Signed-off-by: Eliza Weisman <eliza@buoyant.io>","diff --git a/console/src/main.rs b/console/src/main.rs
index ebfa315..5328d96 100644
--- a/console/src/main.rs
+++ b/console/src/main.rs
@@ -69,6 +69,7 @@ async fn main() -> Result<(), Box<dyn std::error::Error>> {
                 .wrap(Wrap { trim: true });
             f.render_widget(header, chunks[0]);
             tasks.render(f, chunks[1]);
+            tasks.retain_active();
         })?;
     }
 
diff --git a/console/src/tasks.rs b/console/src/tasks.rs
index 7be39a4..eb41495 100644
--- a/console/src/tasks.rs
+++ b/console/src/tasks.rs
@@ -19,6 +19,7 @@ struct Task {
     fields: String,
     kind: &'static str,
     stats: Stats,
+    completed_for: usize,
 }
 
 #[derive(Default, Debug)]
@@ -28,10 +29,15 @@ struct Stats {
     idle: Duration,
     total: Duration,
 }
+
 impl State {
+    // How many updates to retain completed tasks for
+    const RETAIN_COMPLETED_FOR: usize = 6;
+
     pub(crate) fn len(&self) -> usize {
         self.tasks.len()
     }
+
     pub(crate) fn update(&mut self, update: proto::tasks::TaskUpdate) {
         let new_tasks = update.new_tasks.into_iter().filter_map(|task| {
             if task.id.is_none() {
@@ -48,6 +54,7 @@ impl State {
                 fields: task.string_fields,
                 kind,
                 stats: Default::default(),
+                completed_for: 0,
             };
             Some((id, task))
         });
@@ -60,7 +67,10 @@ impl State {
         }
 
         for proto::SpanId { id } in update.completed {
-            if self.tasks.remove(&id).is_none() {
+            if let Some(task) = self.tasks.get_mut(&id) {
+                task.kind = ""!"";
+                task.completed_for = 1;
+            } else {
                 tracing::warn!(?id, ""tried to complete a task that didn't exist"");
             }
         }
@@ -79,7 +89,7 @@ impl State {
         const DUR_PRECISION: usize = 4;
         const POLLS_LEN: usize = 5;
         let rows = self.tasks.values().map(|task| {
-            let row = Row::new(vec![
+            let mut row = Row::new(vec![
                 Cell::from(task.id_hex.as_str()),
                 // TODO(eliza): is there a way to write a `fmt::Debug` impl
                 // directly to tui without doing an allocation?
@@ -105,6 +115,9 @@ impl State {
                 Cell::from(format!(""{:>width$}"", task.stats.polls, width = POLLS_LEN)),
                 Cell::from(task.fields.as_str()),
             ]);
+            if task.completed_for > 0 {
+                row = row.style(Style::default().add_modifier(style::Modifier::DIM));
+            }
             row
         });
         let t = Table::new(rows)
@@ -126,6 +139,16 @@ impl State {
 
         frame.render_widget(t, area)
     }
+
+    pub(crate) fn retain_active(&mut self) {
+        self.tasks.retain(|_, task| {
+            if task.completed_for == 0 {
+                return true;
+            }
+            task.completed_for += 1;
+            task.completed_for <= Self::RETAIN_COMPLETED_FOR
+        })
+    }
 }
 
 impl From<proto::tasks::Stats> for Stats {
",1,"[""1bcf88670b50155b50071e707f98f30cea0b7a24""]","[""feat""]"
"upgrade to Flux v0.42.0

Skips a test that requires special dependencies to pass.","diff --git a/go.mod b/go.mod
index ea705da..8c352f7 100644
--- a/go.mod
+++ b/go.mod
@@ -38,7 +38,7 @@ require (
 	github.com/hashicorp/go-msgpack v0.0.0-20150518234257-fa3f63826f7c // indirect
 	github.com/hashicorp/raft v1.0.0 // indirect
 	github.com/hashicorp/vault/api v1.0.2
-	github.com/influxdata/flux v0.41.0
+	github.com/influxdata/flux v0.42.0
 	github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6
 	github.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368
 	github.com/jessevdk/go-flags v1.4.0
diff --git a/go.sum b/go.sum
index 4bfdf4c..634a0f1 100644
--- a/go.sum
+++ b/go.sum
@@ -206,8 +206,8 @@ github.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NH
 github.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=
 github.com/influxdata/changelog v1.0.0 h1:RstJD6H48zLQj0GdE6E6k/6RPwtUjkyzIe/T1E/xuWU=
 github.com/influxdata/changelog v1.0.0/go.mod h1:uzpGWE/qehT8L426YuXwpMQub+a63vIINhIeEI9mnSM=
-github.com/influxdata/flux v0.41.0 h1:ljbWJmE+aNx8Yoqhb04gWC4sXMV87eYUxz5vjYphLLs=
-github.com/influxdata/flux v0.41.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
+github.com/influxdata/flux v0.42.0 h1:2iEG6hLHdHEJ6LgD8OSnlHS9yoVrLO1/aM4P9ERb94U=
+github.com/influxdata/flux v0.42.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
 github.com/influxdata/goreleaser v0.97.0-influx h1:jT5OrcW7WfS0e2QxfwmTBjhLvpIC9CDLRhNgZJyhj8s=
 github.com/influxdata/goreleaser v0.97.0-influx/go.mod h1:MnjA0e0Uq6ISqjG1WxxMAl+3VS1QYjILSWVnMYDxasE=
 github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6 h1:CFx+pP90q/qg3spoiZjf8donE4WpAdjeJfPOcoNqkWo=
diff --git a/query/stdlib/testing/testing.go b/query/stdlib/testing/testing.go
index d41574a..85b0673 100644
--- a/query/stdlib/testing/testing.go
+++ b/query/stdlib/testing/testing.go
@@ -98,4 +98,6 @@ var FluxEndToEndSkipList = map[string]string{
 	""http_endpoint"": ""need ability to test side effects in e2e tests: (https://github.com/influxdata/flux/issues/1723)"",
 
 	""holt_winters_panic"": ""Expected output is an empty table which breaks the testing framework (https://github.com/influxdata/influxdb/issues/14749)"",
+
+	""secrets"": ""Cannot inject custom deps into the test framework so the secrets don't lookup correctly"",
 }
",1,"[""454003841aabeb74396d73541378bfa59c75b5db""]","[""build""]"
"only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>","diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest
",1,"[""dbb537a26e388a8d7d17faf131abc30c2f7a84e6""]","[""cicd""]"
Fix typo,"diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and
",1,"[""bf83c9155e9bee6925aa7102fab53fb803d52533""]","[""docs""]"
add getter for protocol id,"diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }
",1,"[""dc5238b2bda98a7c4f2fe9584fc3b0191a408109""]","[""feat""]"
remove ubuntu-latest from job title where that is the only os,"diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
",1,"[""74e9de5ec97dc013a52aa063dff0f40ac74c407b""]","[""cicd""]"
ensure checksum persist flushes to disk,"diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);
",1,"[""b7ce2894fd1794064bd6db4ed730bb6cb7728739""]","[""test""]"
updated react demo parcel command,"diff --git a/demo/react/package.json b/demo/react/package.json
index be28bf9..32d0952 100644
--- a/demo/react/package.json
+++ b/demo/react/package.json
@@ -12,7 +12,7 @@
   },
   ""scripts"": {
     ""start"": ""parcel serve public/index.html --no-cache --open"",
-    ""build"": ""parcel build -t browser -d dist public/index.html --no-source-maps""
+    ""build"": ""parcel build --target browser --dist-dir dist public/index.html --no-source-maps""
   },
   ""bugs"": {
     ""url"": ""https://github.com/matteobruni/tsparticles/issues""
",1,"[""32b92cfa0b74a6c25990e32ac6aab12b8496794c""]","[""build""]"
autostart feature fixed,"diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();
",1,"[""bed78248c941d57ad4cc20a455147e186e97c7a1""]","[""fix""]"
"Adjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.","diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)
",1,"[""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3""]","[""test""]"
"add numberOfLines prop to DataTableTitle (#863)

Closes #848","diff --git a/src/components/DataTable/DataTableTitle.js b/src/components/DataTable/DataTableTitle.js
index bfcf07e..d764fd5 100644
--- a/src/components/DataTable/DataTableTitle.js
+++ b/src/components/DataTable/DataTableTitle.js
@@ -27,6 +27,10 @@ type Props = React.ElementConfig<typeof TouchableWithoutFeedback> & {|
    */
   sortDirection?: 'ascending' | 'descending',
   /**
+   * The number of lines to show.
+   */
+  numberOfLines?: number,
+  /**
    * Function to execute on press.
    */
   onPress?: () => mixed,
@@ -44,6 +48,10 @@ type State = {
 class DataTableTitle extends React.Component<Props, State> {
   static displayName = 'DataTable.Title';
 
+  static defaultProps = {
+    numberOfLines: 1,
+  };
+
   state = {
     spinAnim: new Animated.Value(
       this.props.sortDirection === 'ascending' ? 0 : 1
@@ -70,6 +78,7 @@ class DataTableTitle extends React.Component<Props, State> {
       sortDirection,
       theme,
       style,
+      numberOfLines,
       ...rest
     } = this.props;
 
@@ -99,7 +108,7 @@ class DataTableTitle extends React.Component<Props, State> {
               styles.cell,
               sortDirection ? styles.sorted : { color: textColor },
             ]}
-            numberOfLines={1}
+            numberOfLines={numberOfLines}
           >
             {children}
           </Text>
",1,"[""f9a094918b62534614c47aa8a13f33aec751a1e0""]","[""feat""]"
"added changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284","diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')
",1,"[""aca23027da1295c78fdf42ba9687d8ccc88784d7""]","[""docs""]"
"docker PG version upgrade

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>","diff --git a/packages/nocodb/docker-compose.yml b/packages/nocodb/docker-compose.yml
index 7fabf79..ba2ab7b 100644
--- a/packages/nocodb/docker-compose.yml
+++ b/packages/nocodb/docker-compose.yml
@@ -1,4 +1,4 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
     # db55:
@@ -96,8 +96,8 @@ services:
     #     - 5495:5432
     #   volumes:
     #     - ./pg-sakila-db:/docker-entrypoint-initdb.d
-    pg96:
-     image: postgres:9.6
+    pg147:
+     image: postgres:14.7
      restart: always
      environment:
        POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
index 19dfab2..97d346b 100644
--- a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
+++ b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg.yml b/tests/playwright/scripts/docker-compose-pg.yml
index 0396579..9fab10e 100644
--- a/tests/playwright/scripts/docker-compose-pg.yml
+++ b/tests/playwright/scripts/docker-compose-pg.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
",1,"[""37b1cbfd3d2c462ef4f2a131e4172c38dc8d9ddf""]","[""build""]"
support use meta key select multiple element,"diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index ab68624..aeee7b7 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -277,9 +277,11 @@ export default class LogicFlow {
   }
   /**
    * 将图形选中
+   * @param id 选择元素ID
+   * @param multiple 是否允许多选，如果为true，不会将上一个选中的元素重置
    */
-  select(id: string) {
-    this.graphModel.selectElementById(id);
+  select(id: string, multiple = false) {
+    this.graphModel.selectElementById(id, multiple);
   }
   /**
    * 将图形定位到画布中心
diff --git a/packages/core/src/model/EditConfigModel.ts b/packages/core/src/model/EditConfigModel.ts
index 67e334a..83e5f16 100644
--- a/packages/core/src/model/EditConfigModel.ts
+++ b/packages/core/src/model/EditConfigModel.ts
@@ -25,6 +25,7 @@ const SilentConfig = {
   edgeTextEdit: false,
   nodeTextDraggable: false,
   edgeTextDraggable: false,
+  metaKeyMultipleSelected: false,
 };
 
 /**
@@ -42,6 +43,7 @@ export default class EditConfigModel {
   @observable edgeTextEdit = true; // 允许连线文本可以编辑
   @observable nodeTextDraggable = false; // 允许节点文本可以拖拽
   @observable edgeTextDraggable = false; // 允许连线文本可以拖拽
+  @observable metaKeyMultipleSelected = false; // 允许meta多选元素
   constructor(data) {
     const keys = [
       'stopZoomGraph',
@@ -55,6 +57,7 @@ export default class EditConfigModel {
       'edgeTextEdit',
       'nodeTextDraggable',
       'edgeTextDraggable',
+      'metaKeyMultipleSelected',
     ];
     const { isSilentMode, textEdit } = data;
     if (isSilentMode) {
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 9667f4d..310daf4 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -34,6 +34,7 @@ class GraphModel {
   height: number;
   topElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
   selectElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
+  selectElements = new Map<string, IBaseModel>(); // 多选
   @observable edgeType: string;
   @observable nodes: BaseNodeModel[] = [];
   @observable activeElement: IBaseModel;
@@ -50,7 +51,6 @@ class GraphModel {
   @observable gridSize = 1;
   @observable partial = false; // 是否开启局部渲染
   @observable fakerNode: BaseNodeModel;
-  // @observable selectElements = new Map<string, IBaseModel>(); // 多选还没有做，先不加
   constructor(config) {
     const {
       container,
@@ -456,24 +456,44 @@ class GraphModel {
   }
 
   @action
-  selectNodeById(id) {
-    this.selectElement?.setSelected(false);
+  selectNodeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.nodesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectEdgeById(id) {
-    this.selectElement?.setSelected(false);
+  selectEdgeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.edgesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectElementById(id: string) {
-    this.selectElement?.setSelected(false);
+  selectElementById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
+  }
+
+  @action
+  clearSelectElements() {
+    this.selectElements.forEach(element => {
+      element.setSelected(false);
+    });
+    this.selectElements.clear();
   }
 
   /* 修改连线类型 */
diff --git a/packages/core/src/view/edge/BaseEdge.tsx b/packages/core/src/view/edge/BaseEdge.tsx
index d45ea9e..d7c8f38 100644
--- a/packages/core/src/view/edge/BaseEdge.tsx
+++ b/packages/core/src/view/edge/BaseEdge.tsx
@@ -178,7 +178,8 @@ export default class BaseEdge extends Component<IProps> {
   handleClick = (e) => {
     const { model, graphModel, eventCenter } = this.props;
     graphModel.toFront(model.id);
-    graphModel.selectEdgeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectEdgeById(model.id, e.metaKey && metaKeyMultipleSelected);
     // 边数据
     const edgeData = model?.getData();
     const position = graphModel.getPointByClient({
diff --git a/packages/core/src/view/node/BaseNode.tsx b/packages/core/src/view/node/BaseNode.tsx
index 140889c..5ee3975 100644
--- a/packages/core/src/view/node/BaseNode.tsx
+++ b/packages/core/src/view/node/BaseNode.tsx
@@ -275,7 +275,8 @@ export default abstract class BaseNode extends Component<IProps, Istate> {
       }, 400);
     }
     graphModel.toFront(model.id);
-    graphModel.selectNodeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectNodeById(model.id, e.metaKey && metaKeyMultipleSelected);
     this.preStartTime = this.startTime;
   };
   handleContextMenu = (ev: MouseEvent) => {
diff --git a/packages/core/src/view/overlay/CanvasOverlay.tsx b/packages/core/src/view/overlay/CanvasOverlay.tsx
index ef11822..8c79fd2 100644
--- a/packages/core/src/view/overlay/CanvasOverlay.tsx
+++ b/packages/core/src/view/overlay/CanvasOverlay.tsx
@@ -104,9 +104,9 @@ class CanvasOverlay extends Component<IProps, Istate> {
     const target = ev.target as HTMLElement;
     if (target.getAttribute('name') === 'canvas-overlay') {
       const { graphModel, eventCenter } = this.props;
-      const { selectElement, textEditElement } = graphModel;
-      if (selectElement) {
-        selectElement.setSelected(false);
+      const { textEditElement, selectElements } = graphModel;
+      if (selectElements.size > 0) {
+        graphModel.clearSelectElements();
       }
       if (textEditElement) {
         textEditElement.setElementState(ElementState.DEFAULT);
diff --git a/packages/extension/examples/bpmn/index.html b/packages/extension/examples/bpmn/index.html
index 7a68d6f..f7ea87d 100644
--- a/packages/extension/examples/bpmn/index.html
+++ b/packages/extension/examples/bpmn/index.html
@@ -6,6 +6,7 @@
   <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
   <title>LOGIN FLOW</title>
   <link rel=""stylesheet"" href=""/core/dist/style/index.css"">
+  <link rel=""stylesheet"" href=""/extension/lib/style/index.css"">
   <style>
     html,body {
       padding: 0;
@@ -129,11 +130,14 @@
     </div>
   </div>
   <script src=""/core/dist/logic-flow.js""></script>
+  <!-- <script src=""http://0.0.0.0:9090/logic-flow.js""></script> -->
   <script src=""/BpmnElement.js""></script>
   <script src=""/BpmnAdapter.js""></script>
+  <script src=""/Control.js""></script>
   <script src=""/Snapshot.js""></script>
   <script>
     LogicFlow.use(BpmnElement);
+    LogicFlow.use(Control);
     LogicFlow.use(BpmnAdapter);
     LogicFlow.use(Snapshot);
   </script>
diff --git a/packages/extension/examples/bpmn/index.js b/packages/extension/examples/bpmn/index.js
index 21d2da0..6f6aa39 100644
--- a/packages/extension/examples/bpmn/index.js
+++ b/packages/extension/examples/bpmn/index.js
@@ -3,6 +3,10 @@ window.onload = function () {
     container: document.querySelector('#app'),
     // fixme: grid成为了必传的了
     edgeTextDraggable: true,
+    metaKeyMultipleSelected: true,
+    // stopScrollGraph: true,
+    // stopMoveGraph: true,
+    // stopZoomGraph: true,
     grid: {
       type: 'dot',
       size: 20,
",1,"[""e137f9fdbdb6bf3f85c3f7ac9323785e445844c8""]","[""feat""]"
verify checkpoint listeners are notified,"diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }
",1,"[""e0198f74b81da3663144cfe1d971939319f82a0f""]","[""test""]"
do not use scripts and binaries from the libcc repo,"diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |
",1,"[""45837af24a33308a70a3454f0f650f9fe728e272""]","[""cicd""]"
update `cargo-make` for `v0.35.3`,"diff --git a/CHANGELOG.md b/CHANGELOG.md
index 5e125e3..52d9b6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 * Fix: resizing/scrolling through heavily wrapped panes no longer hangs (https://github.com/zellij-org/zellij/pull/814)
 * Terminal compatibility: properly handle HOME/END keys in eg. vim/zsh (https://github.com/zellij-org/zellij/pull/815)
 * Fix: Typo (https://github.com/zellij-org/zellij/pull/821)
+* Fix: Update `cargo-make` instructions post `v0.35.3` (https://github.com/zellij-org/zellij/pull/819)
 
 ## [0.19.0] - 2021-10-20
 * Fix: Prevent text overwrite when scrolled up (https://github.com/zellij-org/zellij/pull/655)
",1,"[""0cfc5633d37ea06f645649138323f1820e18bdee""]","[""docs""]"
add tests,"diff --git a/Cargo.lock b/Cargo.lock
index 84d5d07..6ad05da 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -293,6 +293,7 @@ version = ""0.1.0""
 dependencies = [
  ""git-cliff-core"",
  ""log"",
+ ""pretty_assertions"",
  ""pretty_env_logger"",
  ""structopt"",
 ]
diff --git a/git-cliff-core/src/lib.rs b/git-cliff-core/src/lib.rs
index 3b18ba0..a560c94 100644
--- a/git-cliff-core/src/lib.rs
+++ b/git-cliff-core/src/lib.rs
@@ -1,6 +1,8 @@
 //! Highly customizable Changelog Generator
 #![warn(missing_docs, clippy::unwrap_used)]
 
+/// Export regex crate.
+pub use regex;
 /// Git commit.
 pub mod commit;
 /// Config file parser.
diff --git a/git-cliff/Cargo.toml b/git-cliff/Cargo.toml
index 41eb2e9..cc64b37 100644
--- a/git-cliff/Cargo.toml
+++ b/git-cliff/Cargo.toml
@@ -20,3 +20,6 @@ log = ""0.4.14""
 version = ""0.3""
 default-features = false
 features = [""suggestions"", ""color"", ""wrap_help""]
+
+[dev-dependencies]
+pretty_assertions = ""0.7""
diff --git a/git-cliff/src/changelog.rs b/git-cliff/src/changelog.rs
index 3f9e994..23ea186 100644
--- a/git-cliff/src/changelog.rs
+++ b/git-cliff/src/changelog.rs
@@ -115,3 +115,171 @@ impl<'a> Changelog<'a> {
 		Ok(())
 	}
 }
+
+#[cfg(test)]
+mod test {
+	use super::*;
+	use git_cliff_core::config::{
+		ChangelogConfig,
+		CommitParser,
+		GitConfig,
+	};
+	use git_cliff_core::regex::Regex;
+	use pretty_assertions::assert_eq;
+	use std::str;
+	#[test]
+	fn changelog_generator() -> Result<()> {
+		let config = Config {
+			changelog: ChangelogConfig {
+				header: Some(String::from(""# Changelog"")),
+				body:   String::from(
+					r#""{% if version %}
+				## Release [{{ version }}] - {{ timestamp | date(format=""%Y-%m-%d"") }}
+				({{ commit_id }}){% else %}
+				## Unreleased{% endif %}
+				{% for group, commits in commits | group_by(attribute=""group"") %}
+				### {{ group }}{% for group, commits in commits | group_by(attribute=""scope"") %}
+				#### {{ group }}{% for commit in commits %}
+				- {{ commit.message }}{% endfor %}
+				{% endfor %}{% endfor %}""#,
+				)
+				.replace(""				"", """"),
+				footer: Some(String::from(""------------"")),
+			},
+			git:       GitConfig {
+				conventional_commits: true,
+				commit_parsers:       Some(vec![
+					CommitParser {
+						message: Regex::new(""feat*"").ok(),
+						body:    None,
+						group:   Some(String::from(""New features"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new(""fix*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Bug Fixes"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new("".*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Other"")),
+						skip:    None,
+					},
+				]),
+				filter_commits:       Some(false),
+				tag_pattern:          String::new(),
+				skip_tags:            Regex::new(""v3.*"").ok(),
+			},
+		};
+		let test_release = Release {
+			version:   Some(String::from(""v1.0.0"")),
+			commits:   vec![
+				Commit::new(
+					String::from(""0bc123""),
+					String::from(""feat(app): add cool features""),
+				),
+				Commit::new(
+					String::from(""0werty""),
+					String::from(""style(ui): make good stuff""),
+				),
+				Commit::new(
+					String::from(""0w3rty""),
+					String::from(""fix(ui): fix more stuff""),
+				),
+				Commit::new(
+					String::from(""0jkl12""),
+					String::from(""chore(app): do nothing""),
+				),
+			],
+			commit_id: Some(String::from(""0bc123"")),
+			timestamp: 50000000,
+			previous:  None,
+		};
+		let releases = vec![
+			test_release.clone(),
+			Release {
+				version: Some(String::from(""v3.0.0"")),
+				commits: vec![Commit::new(
+					String::from(""n0thin""),
+					String::from(""feat(xyz): skip commit""),
+				)],
+				..Release::default()
+			},
+			Release {
+				version:   None,
+				commits:   vec![
+					Commit::new(
+						String::from(""abc123""),
+						String::from(""feat(app): add xyz""),
+					),
+					Commit::new(
+						String::from(""abc124""),
+						String::from(""docs(app): document zyx""),
+					),
+					Commit::new(String::from(""def789""), String::from(""merge #4"")),
+					Commit::new(
+						String::from(""qwerty""),
+						String::from(""fix(app): fix abc""),
+					),
+					Commit::new(
+						String::from(""hjkl12""),
+						String::from(""chore(ui): do boring stuff""),
+					),
+				],
+				commit_id: None,
+				timestamp: 1000,
+				previous:  Some(Box::new(test_release)),
+			},
+		];
+		let changelog = Changelog::new(releases, &config)?;
+		let mut out = Vec::new();
+		changelog.generate(&mut out)?;
+		assert_eq!(
+			String::from(
+				r#""# Changelog
+
+			## Unreleased
+
+			### Bug Fixes
+			#### app
+			- fix abc
+
+			### New features
+			#### app
+			- add xyz
+
+			### Other
+			#### app
+			- document zyx
+
+			#### ui
+			- do boring stuff
+
+			## Release [v1.0.0] - 1971-08-02
+			(0bc123)
+
+			### Bug Fixes
+			#### ui
+			- fix more stuff
+
+			### New features
+			#### app
+			- add cool features
+
+			### Other
+			#### app
+			- do nothing
+
+			#### ui
+			- make good stuff
+			------------
+			""#
+			)
+			.replace(""			"", """"),
+			str::from_utf8(&out).unwrap()
+		);
+		Ok(())
+	}
+}
",1,"[""8ee0611fbf0cd89abe7ae588f22e6ecb843598ea""]","[""test""]"
"update Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909","diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })
",1,"[""c2ee5cd5e709afd15c5565ee009a0d204403a119""]","[""docs""]"
"wrong icon reference

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/packages/nc-gui/components.d.ts b/packages/nc-gui/components.d.ts
index b7e6585..bb86478 100644
--- a/packages/nc-gui/components.d.ts
+++ b/packages/nc-gui/components.d.ts
@@ -81,7 +81,6 @@ declare module '@vue/runtime-core' {
     ClaritySuccessLine: typeof import('~icons/clarity/success-line')['default']
     EvaEmailOutline: typeof import('~icons/eva/email-outline')['default']
     IcBaselineMoreVert: typeof import('~icons/ic/baseline-more-vert')['default']
-    Icon: typeof import('~icons/ic/on')['default']
     IcOutlineInsertDriveFile: typeof import('~icons/ic/outline-insert-drive-file')['default']
     IcRoundEdit: typeof import('~icons/ic/round-edit')['default']
     IcRoundKeyboardArrowDown: typeof import('~icons/ic/round-keyboard-arrow-down')['default']
",1,"[""d1d55e787b7d07f763852602b9939a5394607fd9""]","[""fix""]"
"spring version, core version","diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 
",1,"[""c55591ba157298a9c5816693c102a89dfd058830""]","[""build""]"
"fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.","diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 
",1,"[""9be725fa3906323d4bc9788f54eccf74109d632b""]","[""fix""]"
"fix netty dependency

netty-bom 4.1.70 contains the changes from pull request
https://github.com/netty/netty/pull/11798, which moved the classes out
of the native modules to make sure the same classes don't end up on the
classpath multiple times. For us it means that we need to depend on both
the native and classes modules. However, since we don't use the native
module directly (only classes that were moved to this classes module),
we need to force the dependency plugin to consider the native module as
used.","diff --git a/atomix/cluster/pom.xml b/atomix/cluster/pom.xml
index a477873..b6db695 100644
--- a/atomix/cluster/pom.xml
+++ b/atomix/cluster/pom.xml
@@ -69,6 +69,10 @@
     </dependency>
     <dependency>
       <groupId>io.netty</groupId>
+      <artifactId>netty-transport-classes-epoll</artifactId>
+    </dependency>
+    <dependency>
+      <groupId>io.netty</groupId>
       <artifactId>netty-transport-native-epoll</artifactId>
       <classifier>linux-x86_64</classifier>
     </dependency>
@@ -278,6 +282,7 @@
             <dependency>uk.co.real-logic:sbe-tool</dependency>
             <dependency>net.jqwik:jqwik</dependency>
             <dependency>io.netty:netty-tcnative-boringssl-static</dependency>
+            <dependency>io.netty:netty-transport-native-epoll</dependency>
           </usedDependencies>
         </configuration>
       </plugin>
",1,"[""f00a4d3e307b89842250358ee432e6800bb24362""]","[""build""]"
add comments for the Handler,"diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }
",1,"[""036a0ff49a7dade0e04c9c07071a1ff49133ee24""]","[""docs""]"
add .nullif() example,"diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 
",1,"[""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21""]","[""docs""]"
restructure ClusterTopology to track completed change,"diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(
",1,"[""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2""]","[""refactor""]"
add spacing in comment fix lint (#8555),"diff --git a/src/components/nav/test/basic/app-module.ts b/src/components/nav/test/basic/app-module.ts
index 467917a..375e662 100644
--- a/src/components/nav/test/basic/app-module.ts
+++ b/src/components/nav/test/basic/app-module.ts
@@ -633,7 +633,7 @@ export class Tab3 {
   }
 
   presentModal() {
-    //this.modalCtrl.create(MyModal).present();
+    // this.modalCtrl.create(MyModal).present();
   }
 
   selectPrevious() {
",1,"[""af880ac5b4fecbc6c4f3d1eee0d95f326e8bd9d1""]","[""docs""]"
"never call ""onStart"" prop when idle","diff --git a/packages/core/src/SpringValue.ts b/packages/core/src/SpringValue.ts
index 18494a8..cbc4f27 100644
--- a/packages/core/src/SpringValue.ts
+++ b/packages/core/src/SpringValue.ts
@@ -596,11 +596,11 @@ export class SpringValue<T = any> extends AnimationValue<T> {
   /** Notify change observers */
   protected _onChange(value: T, idle = false) {
     const anim = this.animation
-    if (!anim.changed) {
+    if (!anim.changed && !idle) {
       anim.changed = true
       // The ""onStart"" prop is called on the first change after entering the
       // frameloop, but never for immediate animations.
-      if (anim.onStart && !anim.immediate) {
+      if (anim.onStart) {
         anim.onStart(this)
       }
     }
",1,"[""c8e0ae8612df3d6f2831acc004aaac332f6105e4""]","[""fix""]"
make it mode less,"diff --git a/core/src/components/slides/slides.tsx b/core/src/components/slides/slides.tsx
index 48fd53f..d5c2f75 100644
--- a/core/src/components/slides/slides.tsx
+++ b/core/src/components/slides/slides.tsx
@@ -1,7 +1,6 @@
 import { Component, Element, Event, EventEmitter, Method, Prop, Watch } from '@stencil/core';
 
 import { Mode } from '../../interface.js';
-import { createThemedClasses } from '../../utils/theme.js';
 
 import { Swiper } from './vendor/swiper.js';
 
@@ -15,6 +14,7 @@ import { Swiper } from './vendor/swiper.js';
   shadow: true
 })
 export class Slides {
+
   private container!: HTMLElement;
   private swiper: any;
 
@@ -391,12 +391,6 @@ export class Slides {
     return { ...swiperOptions, ...this.options, ...eventOptions };
   }
 
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'slides')
-    };
-  }
-
   render() {
     return (
       <div class=""swiper-container"" ref={el => this.container = el as HTMLElement }>
diff --git a/core/src/components/thumbnail/thumbnail.ios.scss b/core/src/components/thumbnail/thumbnail.ios.scss
deleted file mode 100644
index e3add45..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.ios.vars"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-ios-width};
-  --border-radius: #{$thumbnail-ios-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.ios.vars.scss b/core/src/components/thumbnail/thumbnail.ios.vars.scss
deleted file mode 100644
index 85d53e5..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.ios"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-ios-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-ios-height:                  $thumbnail-ios-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-ios-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.md.scss b/core/src/components/thumbnail/thumbnail.md.scss
deleted file mode 100644
index 0fbb2ca..0000000
--- a/core/src/components/thumbnail/thumbnail.md.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.md.vars"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-md-width};
-  --border-radius: #{$thumbnail-md-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.md.vars.scss b/core/src/components/thumbnail/thumbnail.md.vars.scss
deleted file mode 100644
index 94e48b2..0000000
--- a/core/src/components/thumbnail/thumbnail.md.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.md"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-md-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-md-height:                  $thumbnail-md-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-md-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.scss b/core/src/components/thumbnail/thumbnail.scss
index 8ac3a22..8af268d 100644
--- a/core/src/components/thumbnail/thumbnail.scss
+++ b/core/src/components/thumbnail/thumbnail.scss
@@ -9,6 +9,8 @@
    * @prop --border-radius: Border radius of the thumbnail
    * @prop --size: Size of the thumbnail
    */
+  --size: 48px;
+  --border-radius: 0;
 
   @include border-radius(var(--border-radius));
 
diff --git a/core/src/components/thumbnail/thumbnail.tsx b/core/src/components/thumbnail/thumbnail.tsx
index 50ff2c2..de76593 100644
--- a/core/src/components/thumbnail/thumbnail.tsx
+++ b/core/src/components/thumbnail/thumbnail.tsx
@@ -1,25 +1,11 @@
 import { Component } from '@stencil/core';
 
-import { Mode } from '../../interface';
-import { createThemedClasses } from '../../utils/theme';
-
 @Component({
   tag: 'ion-thumbnail',
-  styleUrls: {
-    ios: 'thumbnail.ios.scss',
-    md: 'thumbnail.md.scss'
-  },
+  styleUrl: 'thumbnail.scss',
   shadow: true
 })
 export class Thumbnail {
-  mode!: Mode;
-
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'thumbnail')
-    };
-  }
-
   render() {
     return <slot></slot>;
   }
",1,"[""771857b1df9470ebc15357e8879118a72c649d5b""]","[""refactor""]"
remove appear css animation,"diff --git a/src/popup/Popup.tsx b/src/popup/Popup.tsx
index d485bb6..2abc22a 100644
--- a/src/popup/Popup.tsx
+++ b/src/popup/Popup.tsx
@@ -269,7 +269,6 @@ export class Popup extends React.Component<{ t: TranslationFunction }, PopupStat
         <CSSTransition
           classNames='fade'
           in={!!currentTabUrl}
-          appear
           timeout={500}
           exit={false}
           mountOnEnter
",1,"[""47ef9104e4a89e80d7cc6c1950bc080841da4a7b""]","[""refactor""]"
convert `run_tag_values_test_case` to a function,"diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
",1,"[""1db13ec43727aca872a0f3836e4023ed85db665e""]","[""refactor""]"
update flushed index before truncating,"diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {
",1,"[""933ab6bb86372913c992567cf9660009900911a7""]","[""fix""]"
skip flaky test,"diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method
",1,"[""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d""]","[""test""]"
[gn] fix include_dirs ordering error,"diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)
",1,"[""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945""]","[""build""]"
add remote [skip ci],"diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 06c9003..e19c703 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -47,7 +47,10 @@ jobs:
           git config --global user.email 'ibis-squawk-bot[bot]@users.noreply.github.com'
 
       - name: fetch and rebase on top of upstream
-        run: git pull --rebase -X ours https://github.com/ibis-project/ibis master
+        run: |
+          git remote add upstream https://github.com/ibis-project/ibis
+          git fetch upstream
+          git rebase -X ours upstream/master
 
       - uses: tibdex/github-app-token@v1
         id: generate_pr_token
",1,"[""e96487ad7ce90b141219d9032fa2bed68d5dae6a""]","[""cicd""]"
[gn win] link comctl32.lib to fix component build,"diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]
",1,"[""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0""]","[""build""]"
better layout for block and segment,"diff --git a/docs/docs/config-block.md b/docs/docs/config-block.md
new file mode 100644
index 0000000..df1ee54
--- /dev/null
+++ b/docs/docs/config-block.md
@@ -0,0 +1,60 @@
+---
+id: config-block
+title: Block
+sidebar_label: Block
+---
+
+Let's take a closer look at what defines a block.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""segments"": [
+        ...
+      ]
+    }
+  ]
+}
+```
+
+- type: `prompt` | `rprompt`
+- newline: `boolean`
+- alignment: `left` | `right`
+- vertical_offset: `int`
+- horizontal_offset: `int`
+- segments: `array` of one or more `segments`
+
+### Type
+
+Tells the engine what to do with the block. There are three options:
+
+- `prompt` renders one or more segments
+- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
+Supported on [ZSH][rprompt], Bash and Powershell.
+
+### Newline
+
+Start the block on a new line. Defaults to `false`.
+
+### Alignment
+
+Tell the engine if the block should be left or right-aligned.
+
+### Vertical offset
+
+Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
+moves it up one line.
+
+### Horizontal offset
+
+Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
+but on a horizontal level where a negative number moves the block left and a positive number right.
+
+### Segments
+
+Array of one or more segments.
diff --git a/docs/docs/config-example.md b/docs/docs/config-example.md
new file mode 100644
index 0000000..c180c4f
--- /dev/null
+++ b/docs/docs/config-example.md
@@ -0,0 +1,96 @@
+---
+id: config-sample
+title: Sample
+sidebar_label: Sample
+---
+
+```json
+{
+  ""final_space"": true,
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""right"",
+      ""vertical_offset"": -1,
+      ""segments"": [
+        {
+          ""type"": ""time"",
+          ""style"": ""plain"",
+          ""foreground"": ""#007ACC"",
+          ""properties"": {
+            ""time_format"": ""15:04:05""
+          }
+        }
+      ]
+    },
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""newline"": true,
+      ""segments"": [
+        {
+          ""type"": ""session"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#ffb300"",
+          ""leading_diamond"": ""\uE0B6"",
+          ""trailing_diamond"": ""\uE0B0"",
+          ""properties"": {
+            ""postfix"": "" ""
+          }
+        },
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ""prefix"": "" \uE5FF "",
+            ""style"": ""folder"",
+            ""exclude_folders"": [
+              ""/super/secret/project""
+            ],
+            ""enable_hyperlink"": false
+          }
+        },
+        {
+          ""type"": ""git"",
+          ""style"": ""powerline"",
+          ""foreground"": ""#193549"",
+          ""foreground_templates"": [
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
+          ],
+          ""background"": ""#2e9599"",
+          ""background_templates"": [
+            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
+            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
+            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
+          ],
+          ""powerline_symbol"": ""\uE0B0"",
+          ""properties"": {
+            ""fetch_status"": true,
+            ""branch_max_length"": 25,
+            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
+          }
+        },
+        {
+          ""type"": ""exit"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#00897b"",
+          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
+          ""leading_diamond"": """",
+          ""trailing_diamond"": ""\uE0B4"",
+          ""properties"": {
+            ""always_enabled"": true,
+            ""template"": ""\uE23A"",
+            ""prefix"": ""<parentBackground>\uE0B0</> ""
+          }
+        }
+      ]
+    }
+  ]
+}
+```
diff --git a/docs/docs/config-overview.md b/docs/docs/config-overview.md
index 1fdbcba..b554869 100644
--- a/docs/docs/config-overview.md
+++ b/docs/docs/config-overview.md
@@ -1,7 +1,7 @@
 ---
 id: config-overview
-title: Overview
-sidebar_label: Overview
+title: General
+sidebar_label: General
 ---
 
 Oh My Posh renders your prompt based on the definition of _blocks_ (like Lego) which contain one or more _segments_.
@@ -64,332 +64,7 @@ boxes with question marks, set up your terminal to use a [supported font][font] 
 - terminal_background: `string` [color][colors] - terminal background color, set to your terminal's background color when
 you notice black elements in Windows Terminal or the Visual Studio Code integrated terminal
 
-## Block
-
-Let's take a closer look at what defines a block.
-
-- type: `prompt` | `rprompt`
-- newline: `boolean`
-- alignment: `left` | `right`
-- vertical_offset: `int`
-- horizontal_offset: `int`
-- segments: `array` of one or more `segments`
-
-### Type
-
-Tells the engine what to do with the block. There are three options:
-
-- `prompt` renders one or more segments
-- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
-Supported on [ZSH][rprompt], Bash and Powershell.
-
-### Newline
-
-Start the block on a new line. Defaults to `false`.
-
-### Alignment
-
-Tell the engine if the block should be left or right-aligned.
-
-### Vertical offset
-
-Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
-moves it up one line.
-
-### Horizontal offset
-
-Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
-but on a horizontal level where a negative number moves the block left and a positive number right.
-
-### Segments
-
-Array of one or more segments.
-
-## Segment
-
-A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
-looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
-understand how to configure a segment.
-
-- type: `string` any of the included [segments][segments]
-- style: `powerline` | `plain` | `diamond`
-- powerline_symbol: `string`
-- invert_powerline: `boolean`
-- leading_diamond: `string`
-- trailing_diamond: `string`
-- foreground: `string` [color][colors]
-- foreground_templates: `array` of `string` values
-- background: `string` [color][colors]
-- background_templates: `array` of `string` values
-- properties: `array` of `Property`: `string`
-
-### Type
-
-Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
-
-### Style
-
-Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
-themes out there, we identified 3 types. All of these require a different configuration and depending on the look
-you want to achieve you might need to understand/use them all.
-
-#### Powerline
-
-What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
-background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
-if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
-
-#### Plain
-
-Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
-Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
-
-#### Diamond
-
-While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
-Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
-segment background as their foreground color.
-
-### Powerline symbol
-
-Text character to use when `""style"": ""powerline""`.
-
-### Invert Powerline
-
-If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
-in the perfectly mirrored variant for example.
-
-### Leading diamond
-
-Text character to use at the start of the segment. Will take the background color of the segment as
-its foreground color.
-
-### Trailing diamond
-
-Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
-
-### Foreground
-
-[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
-
-### Foreground Templates
-
-Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
-Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
-offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
-the documentation.
-
-The following sample is based on the [AWS Segment][aws].
-
-```json
-{
-  ""type"": ""aws"",
-  ""style"": ""powerline"",
-  ""powerline_symbol"": ""\uE0B0"",
-  ""foreground"": ""#ffffff"",
-  ""background"": ""#111111"",
-  ""foreground_templates"": [
-    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
-    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
-  ],
-  ""properties"": {
-    ""prefix"": "" \uE7AD ""
-  }
-}
-```
-
-The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
-one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
-returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
-templates returns a value, the foreground value `#ffffff` is used.
-
-### Background
-
-[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
-
-### Background Templates
-
-Same as [Foreground Templates][fg-templ] but for the background color.
-
-### Properties
-
-An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
-will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
-engine which allow you to customize the output even more.
-
-#### General-purpose properties
-
-You can use these on any segment, the engine is responsible for adding them correctly.
-
-- prefix: `string`
-- postfix: `string`
-- include_folders: `[]string`
-- exclude_folders: `[]string`
-
-##### Prefix
-
-The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
-specify this as `''`.
-
-##### Postfix
-
-The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
-specify this as `''`.
-
-##### Include / Exclude Folders
-
-Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
-the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
-will not be rendered when in one of the excluded locations.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-```json
-""exclude_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-The strings specified in these properties are evaluated as [regular expressions][regex]. You
-can use any valid regular expression construct, but the regular expression must match the entire directory
-name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-]
-```
-
-You can also combine these properties:
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-],
-""exclude_folders"": [
-  ""/Users/posh/Projects/secret-project.*""
-]
-```
-
-##### Notes
-
-- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
-is used by the current operating system.
-- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
-directory name, you need to specify it as `\\\\`.
-- The character `~` at the start of a specified folder will match the user's home directory.
-- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
-
-This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
-`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
-
-## Full Sample
-
-```json
-{
-  ""final_space"": true,
-  ""blocks"": [
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""right"",
-      ""vertical_offset"": -1,
-      ""segments"": [
-        {
-          ""type"": ""time"",
-          ""style"": ""plain"",
-          ""foreground"": ""#007ACC"",
-          ""properties"": {
-            ""time_format"": ""15:04:05""
-          }
-        }
-      ]
-    },
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""left"",
-      ""newline"": true,
-      ""segments"": [
-        {
-          ""type"": ""session"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#ffb300"",
-          ""leading_diamond"": ""\uE0B6"",
-          ""trailing_diamond"": ""\uE0B0"",
-          ""properties"": {
-            ""postfix"": "" ""
-          }
-        },
-        {
-          ""type"": ""path"",
-          ""style"": ""powerline"",
-          ""powerline_symbol"": ""\uE0B0"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#61AFEF"",
-          ""properties"": {
-            ""prefix"": "" \uE5FF "",
-            ""style"": ""folder"",
-            ""exclude_folders"": [
-              ""/super/secret/project""
-            ],
-            ""enable_hyperlink"": false
-          }
-        },
-        {
-          ""type"": ""git"",
-          ""style"": ""powerline"",
-          ""foreground"": ""#193549"",
-          ""foreground_templates"": [
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
-          ],
-          ""background"": ""#2e9599"",
-          ""background_templates"": [
-            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
-            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
-            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
-          ],
-          ""powerline_symbol"": ""\uE0B0"",
-          ""properties"": {
-            ""fetch_status"": true,
-            ""branch_max_length"": 25,
-            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
-          }
-        },
-        {
-          ""type"": ""exit"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#00897b"",
-          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
-          ""leading_diamond"": """",
-          ""trailing_diamond"": ""\uE0B4"",
-          ""properties"": {
-            ""always_enabled"": true,
-            ""template"": ""\uE23A"",
-            ""prefix"": ""<parentBackground>\uE0B0</> ""
-          }
-        }
-      ]
-    }
-  ]
-}
-```
-
 [releases]: https://github.com/JanDeDobbeleer/oh-my-posh/releases/latest
 [font]: /docs/config-fonts
 [schema]: https://github.com/JanDeDobbeleer/oh-my-posh/blob/main/themes/schema.json
 [themes]: https://github.com/JanDeDobbeleer/oh-my-posh/tree/main/themes
-[segments]: /docs/battery
-[colors]: /docs/config-colors
-[go-text-template]: https://golang.org/pkg/text/template/
-[sprig]: https://masterminds.github.io/sprig/
-[fg-templ]: /docs/config-overview#foreground-templates
-[regex]: https://www.regular-expressions.info/tutorial.html
-[aws]: /docs/aws
diff --git a/docs/docs/config-segment.md b/docs/docs/config-segment.md
new file mode 100644
index 0000000..08a66e4
--- /dev/null
+++ b/docs/docs/config-segment.md
@@ -0,0 +1,219 @@
+---
+id: config-segment
+title: Segment
+sidebar_label: Segment
+---
+
+A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
+looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
+understand how to configure a segment.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ...
+      ""segments"": [
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ...
+          }
+        }
+      ]
+    }
+  ]
+}
+```
+
+- type: `string` any of the included [segments][segments]
+- style: `powerline` | `plain` | `diamond`
+- powerline_symbol: `string`
+- invert_powerline: `boolean`
+- leading_diamond: `string`
+- trailing_diamond: `string`
+- foreground: `string` [color][colors]
+- foreground_templates: `array` of `string` values
+- background: `string` [color][colors]
+- background_templates: `array` of `string` values
+- properties: `array` of `Property`: `string`
+
+## Type
+
+Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
+
+## Style
+
+Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
+themes out there, we identified 3 types. All of these require a different configuration and depending on the look
+you want to achieve you might need to understand/use them all.
+
+### Powerline
+
+What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
+background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
+if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
+
+### Plain
+
+Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
+Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
+
+### Diamond
+
+While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
+Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
+segment background as their foreground color.
+
+## Powerline symbol
+
+Text character to use when `""style"": ""powerline""`.
+
+## Invert Powerline
+
+If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
+in the perfectly mirrored variant for example.
+
+## Leading diamond
+
+Text character to use at the start of the segment. Will take the background color of the segment as
+its foreground color.
+
+## Trailing diamond
+
+Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
+
+## Foreground
+
+[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
+
+## Foreground Templates
+
+Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
+Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
+offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
+the documentation.
+
+The following sample is based on the [AWS Segment][aws].
+
+```json
+{
+  ""type"": ""aws"",
+  ""style"": ""powerline"",
+  ""powerline_symbol"": ""\uE0B0"",
+  ""foreground"": ""#ffffff"",
+  ""background"": ""#111111"",
+  ""foreground_templates"": [
+    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
+    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
+  ],
+  ""properties"": {
+    ""prefix"": "" \uE7AD ""
+  }
+}
+```
+
+The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
+one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
+returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
+templates returns a value, the foreground value `#ffffff` is used.
+
+## Background
+
+[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
+
+## Background Templates
+
+Same as [Foreground Templates][fg-templ] but for the background color.
+
+## Properties
+
+An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
+will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
+engine which allow you to customize the output even more.
+
+### General-purpose properties
+
+You can use these on any segment, the engine is responsible for adding them correctly.
+
+- prefix: `string`
+- postfix: `string`
+- include_folders: `[]string`
+- exclude_folders: `[]string`
+
+#### Prefix
+
+The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
+specify this as `''`.
+
+#### Postfix
+
+The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
+specify this as `''`.
+
+#### Include / Exclude Folders
+
+Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
+the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
+will not be rendered when in one of the excluded locations.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+```json
+""exclude_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+The strings specified in these properties are evaluated as [regular expressions][regex]. You
+can use any valid regular expression construct, but the regular expression must match the entire directory
+name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+]
+```
+
+You can also combine these properties:
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+],
+""exclude_folders"": [
+  ""/Users/posh/Projects/secret-project.*""
+]
+```
+
+#### Notes
+
+- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
+is used by the current operating system.
+- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
+directory name, you need to specify it as `\\\\`.
+- The character `~` at the start of a specified folder will match the user's home directory.
+- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
+
+This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
+`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
+
+[segments]: /docs/battery
+[colors]: /docs/config-colors
+[go-text-template]: https://golang.org/pkg/text/template/
+[sprig]: https://masterminds.github.io/sprig/
+[fg-templ]: /docs/config-overview#foreground-templates
+[regex]: https://www.regular-expressions.info/tutorial.html
+[aws]: /docs/aws
diff --git a/docs/docs/segment-environment.md b/docs/docs/segment-environment.md
index f35bc87..982a0a5 100644
--- a/docs/docs/segment-environment.md
+++ b/docs/docs/segment-environment.md
@@ -34,7 +34,7 @@ New-Alias -Name 'Set-PoshContext' -Value 'Set-EnvVar' -Scope Global -Force
 
 The segment will show when the value of the environment variable isn't empty.
 
-## Sample Configuration
+## Sample *Configuration*
 
 ```json
 {
diff --git a/docs/sidebars.js b/docs/sidebars.js
index a75163e..8f151a2 100644
--- a/docs/sidebars.js
+++ b/docs/sidebars.js
@@ -20,6 +20,9 @@ module.exports = {
       label: ""⚙️ Configuration"",
       items: [
         ""config-overview"",
+        ""config-block"",
+        ""config-segment"",
+        ""config-sample"",
         ""config-title"",
         ""config-colors"",
         ""config-text-style"",
",1,"[""cb1f48b56ae0de93acb72e48726c7d610a1d538e""]","[""docs""]"
"initialize threejs objects in defaultRef, to fix undefined type errors","diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number
",1,"[""2561f4ade46fc9d59f289f328cc77733a6443697""]","[""fix""]"
use `regexp_instr != 0` instead of `REGEXP` keyword,"diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(
",1,"[""06e2be4e2019b6fa714e1fcb34485860ef1ede79""]","[""fix""]"
"cleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.","diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:
",1,"[""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7""]","[""refactor""]"
fix build ordering,"diff --git a/scripts/build.mjs b/scripts/build.mjs
index 204854f..b3cf067 100644
--- a/scripts/build.mjs
+++ b/scripts/build.mjs
@@ -3,8 +3,8 @@ import { write } from 'fsxx';
 import { info, success } from './helpers.mjs';
 
 await $`rm -rf dist/*`;
-await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 await $`unbuild`;
+await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 
 const packages = [
   'jsx-runtime',
",1,"[""c323d59c607cabc91f17a78528d998f376f30b10""]","[""build""]"
"remove deprecated settings

Removes deprecated ZEEBE_HOST environment variable, and removes
unnecessary log level environment variable, since it's already the
default in the log file","diff --git a/Dockerfile b/Dockerfile
index 6762a39..7f380cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -34,7 +34,6 @@ RUN wget -O - https://github.com/jvm-profiling-tools/async-profiler/releases/dow
 FROM ${APP_ENV} as app
 
 ENV ZB_HOME=/usr/local/zeebe \
-    ZEEBE_LOG_LEVEL=info \
     ZEEBE_BROKER_GATEWAY_NETWORK_HOST=0.0.0.0 \
     ZEEBE_STANDALONE_GATEWAY=false
 ENV PATH ""${ZB_HOME}/bin:${PATH}""
diff --git a/docker/utils/startup.sh b/docker/utils/startup.sh
index bc8d2fc..0fcde2b 100755
--- a/docker/utils/startup.sh
+++ b/docker/utils/startup.sh
@@ -1,17 +1,14 @@
 #!/bin/bash -xeu
 
-# legacy support
-# This environment variable was used to set the gatewway cluster host in standalone and embedded mode.
-# Now, there are two dedicated environment variables for the two different deployment scenarios.
-export ZEEBE_HOST=${ZEEBE_HOST:-$(hostname -i)}
-# Legacy support
+HOST=$(hostname -i)
 
 if [ ""$ZEEBE_STANDALONE_GATEWAY"" = ""true"" ]; then
-    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_GATEWAY_NETWORK_HOST=${ZEEBE_GATEWAY_NETWORK_HOST:-${HOST}}
+    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${HOST}}
 
     exec /usr/local/zeebe/bin/gateway
 else
-    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${HOST}}
     export ZEEBE_BROKER_GATEWAY_CLUSTER_HOST=${ZEEBE_BROKER_GATEWAY_CLUSTER_HOST:-${ZEEBE_BROKER_NETWORK_HOST}}
 
     exec /usr/local/zeebe/bin/broker
",1,"[""e4a11fd5c34942ba12737f1c8c084489428ee274""]","[""build""]"
add fallible peek_last_token(),"diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.
",1,"[""63eab619e6166eb6cab948028a7b89bf059dd878""]","[""refactor""]"
licensing,"diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;
",1,"[""a52a585d74894b3b4eeb8c784fa089ff95cddad0""]","[""docs""]"
detach ViewControllers when not active,"diff --git a/ionic/components/nav/nav-controller.ts b/ionic/components/nav/nav-controller.ts
index becdd99..1cc3c31 100644
--- a/ionic/components/nav/nav-controller.ts
+++ b/ionic/components/nav/nav-controller.ts
@@ -1410,6 +1410,9 @@ export class NavController extends Ion {
       // set the ComponentRef's instance to this ViewController
       view.setInstance(component);
 
+      // remember the ChangeDetectorRef for this ViewController
+      view.setChangeDetector(hostViewRef.changeDetectorRef);
+
       // remember the ElementRef to the ion-page elementRef that was just created
       view.setPageRef(pageElementRef);
 
diff --git a/ionic/components/nav/view-controller.ts b/ionic/components/nav/view-controller.ts
index 3207fa2..069c74d 100644
--- a/ionic/components/nav/view-controller.ts
+++ b/ionic/components/nav/view-controller.ts
@@ -1,4 +1,4 @@
-import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer} from 'angular2/core';
+import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer, ChangeDetectorRef} from 'angular2/core';
 
 import {Navbar} from '../navbar/navbar';
 import {NavController, NavOptions} from './nav-controller';
@@ -33,6 +33,7 @@ export class ViewController {
   private _nbVwRef: ViewContainerRef;
   private _onDismiss: Function = null;
   private _pgRef: ElementRef;
+  private _cd: ChangeDetectorRef;
   protected _nav: NavController;
 
   /**
@@ -166,6 +167,13 @@ export class ViewController {
   /**
    * @private
    */
+  setChangeDetector(cd: ChangeDetectorRef) {
+    this._cd = cd;
+  }
+
+  /**
+   * @private
+   */
   setInstance(instance: any) {
     this.instance = instance;
   }
@@ -467,6 +475,14 @@ export class ViewController {
    * The view is about to enter and become the active view.
    */
   willEnter() {
+    if (this._cd) {
+      // ensure this has been re-attached to the change detector
+      this._cd.reattach();
+
+      // detect changes before we run any user code
+      this._cd.detectChanges();
+    }
+
     ctrlFn(this, 'onPageWillEnter');
   }
 
@@ -496,6 +512,10 @@ export class ViewController {
    */
   didLeave() {
     ctrlFn(this, 'onPageDidLeave');
+
+    // when this is not the active page
+    // we no longer need to detect changes
+    this._cd && this._cd.detach();
   }
 
   /**
",1,"[""b282e90e2cbb74559aab79eee8443a4d7c85502a""]","[""feat""]"
"Add ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>","diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}
",1,"[""f823cf28652987d43c8324b4f5b203240032383a""]","[""feat""]"
allow disabling dynamic queue,"diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);
",1,"[""9ef5c0d14193a9abb09b39856f58477d1f4b0d77""]","[""fix""]"
"enable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 
",1,"[""fd8e563cc19ca4684885d4692acee6bebcca4ada""]","[""feat""]"
run pyspark tests in parallel,"diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index e23088e..9708157 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -202,11 +202,11 @@ jobs:
         run: poetry install --without dev --without docs --extras ${{ matrix.backend.name }} --extras geospatial
 
       - name: ""run parallel tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name != 'pyspark' && matrix.backend.name != 'impala'
+        if: matrix.backend.name != 'impala'
         run: just ci-check -m ${{ matrix.backend.name }} --numprocesses auto --dist=loadgroup
 
       - name: ""run serial tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name == 'pyspark' || matrix.backend.name == 'impala'
+        if: matrix.backend.name == 'impala'
         run: just ci-check -m ${{ matrix.backend.name }}
         env:
           IBIS_TEST_NN_HOST: localhost
",1,"[""4cbbd2552ba0de273e1dfe7d453c5b3efed751a3""]","[""cicd""]"
add riscv64gc-unknown-linux-gnu,"diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }
",1,"[""173553c0372e66e03bdab19e0e6c2dd44daa14a0""]","[""cicd""]"
split release docs build into separate workflow,"diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 753d57d..3e0aa15 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -88,14 +88,14 @@ jobs:
         run: poetry run pytest --benchmark-only --benchmark-json .benchmarks/output.json ibis/tests/benchmarks
 
       - uses: tibdex/github-app-token@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         id: generate-token
         with:
           app_id: ${{ secrets.SQUAWK_BOT_APP_ID }}
           private_key: ${{ secrets.SQUAWK_BOT_APP_PRIVATE_KEY }}
 
       - uses: benchmark-action/github-action-benchmark@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         with:
           tool: pytest
           github-token: ${{ steps.generate-token.outputs.token }}
@@ -107,6 +107,7 @@ jobs:
 
   docs:
     runs-on: ubuntu-latest
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
     needs:
       # wait on benchmarks to prevent a race condition when pushing to the
       # gh-pages branch
@@ -124,51 +125,25 @@ jobs:
           authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
           extraPullNames: nix-community,poetry2nix
 
-      - name: Generate a GitHub token
-        if: ${{ github.event_name == 'push' }}
-        uses: tibdex/github-app-token@v1
-        id: generate_token
-        with:
-          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
-          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
-
-      - name: checkout
-        if: ${{ github.event_name == 'push' }}
-        uses: actions/checkout@v3
-        with:
-          fetch-depth: 0
-          token: ${{ steps.generate_token.outputs.token }}
-
       - name: checkout
-        if: ${{ github.event_name != 'push' }}
         uses: actions/checkout@v3
 
-      - name: Configure git info
-        if: ${{ github.event_name == 'push' }}
-        run: |
-          set -euo pipefail
-
-          git config user.name 'ibis-docs-bot[bot]'
-          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
-
       - name: build docs
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c mkdocs build
 
       - name: verify internal links
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c just checklinks --offline --no-progress
 
-      - name: Pull gh-pages changes
+      - name: Configure git info
         if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
-          git fetch origin gh-pages
-          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
 
       - name: build and push dev docs
-        if: ${{ github.event_name == 'push' && !startsWith(github.ref, 'refs/tags/') }}
+        if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
@@ -180,19 +155,6 @@ jobs:
               --message 'docs(dev): ibis@${{ github.sha }}' \
                 dev
 
-      - name: build and push docs on tag
-        if: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/tags/') }}
-        run: |
-          set -euo pipefail
-
-          nix develop -f shell.nix --keep-going -c \
-            mic deploy \
-              --push \
-              --rebase \
-              --prefix docs \
-              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
-              ""${GITHUB_REF_NAME}"" latest
-
   simulate_release:
     runs-on: ubuntu-latest
     steps:
diff --git a/.github/workflows/ibis-docs-release.yml b/.github/workflows/ibis-docs-release.yml
new file mode 100644
index 0000000..da7ee49
--- /dev/null
+++ b/.github/workflows/ibis-docs-release.yml
@@ -0,0 +1,63 @@
+# vim: filetype=yaml
+name: Docs Release Build
+
+on:
+  release:
+    types:
+      - published
+jobs:
+  docs:
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
+    runs-on: ubuntu-latest
+    steps:
+      - name: install nix
+        uses: cachix/install-nix-action@v17
+        with:
+          nix_path: nixpkgs=channel:nixos-unstable-small
+
+      - name: setup cachix
+        uses: cachix/cachix-action@v10
+        with:
+          name: ibis
+          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
+          extraPullNames: nix-community,poetry2nix
+
+      - name: Generate a GitHub token
+        uses: tibdex/github-app-token@v1
+        id: generate_token
+        with:
+          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
+          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
+
+      - name: checkout
+        uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+          token: ${{ steps.generate_token.outputs.token }}
+
+      - name: Configure git info
+        run: |
+          set -euo pipefail
+
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
+
+      - name: Pull gh-pages changes
+        run: |
+          set -euo pipefail
+
+          git fetch origin gh-pages
+          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+
+      - name: build and push docs on tag
+        run: |
+          set -euo pipefail
+
+          nix develop -f shell.nix --keep-going -c \
+            mic deploy \
+              --push \
+              --rebase \
+              --update-aliases \
+              --prefix docs \
+              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
+              ""${GITHUB_REF_NAME}"" latest
",1,"[""32845e1bbd1efb5dbc16f671049509a409ba25ce""]","[""cicd""]"
setup jest and add m.ts tests,"diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });
",1,"[""229b53a632ea97d47c4be11f096bdd828fb415d8""]","[""test""]"
added suported tuple types,"diff --git a/src/List/Tuple.ts b/src/List/Tuple.ts
index 4c59caa..6e45503 100644
--- a/src/List/Tuple.ts
+++ b/src/List/Tuple.ts
@@ -1,15 +1,17 @@
-/** A [[Tuple]]
+import {NonNullable} from '../Object/NonNullable'
+
+/** A [[Tuple]] (supported)
  * @param A its type
- * @returns **`any[]`**
+ * @returns **`A[]`**
  * @example
  * ```ts
- * type list0 = [1, 2, 3]
- * type list1 = number[]
+ * type tuple0 = [1, 20, 42]
+ * type tuple1 = ['at', 420]
  * ```
  */
-export type Tuple = [
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-]
+export type Tuple<A = any> = NonNullable<[
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+]>
",1,"[""2954a0955ce9af6acb345ed1e8328e145ad30475""]","[""refactor""]"
"small error msg improvement

refs #1005","diff --git a/internal/pipe/git/errors.go b/internal/pipe/git/errors.go
index a8c15d5..13dfb56 100644
--- a/internal/pipe/git/errors.go
+++ b/internal/pipe/git/errors.go
@@ -11,7 +11,7 @@ type ErrDirty struct {
 }
 
 func (e ErrDirty) Error() string {
-	return fmt.Sprintf(""git is currently in a dirty state:\n%v"", e.status)
+	return fmt.Sprintf(""git is currently in a dirty state, please check in your pipeline what can be changing the following files:\n%v"", e.status)
 }
 
 // ErrWrongRef happens when the HEAD reference is different from the tag being built
",1,"[""a62314d9bb632be6af026686615d14b912250512""]","[""refactor""]"
"get tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.","diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }
",1,"[""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c""]","[""refactor""]"
xfail on to_parquet and to_csv that use pyarrow write options,"diff --git a/ibis/backends/tests/test_export.py b/ibis/backends/tests/test_export.py
index 4d536d7..5bb9775 100644
--- a/ibis/backends/tests/test_export.py
+++ b/ibis/backends/tests/test_export.py
@@ -222,18 +222,23 @@ def test_table_to_parquet(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs""), [({""version"": ""1.0""}), ({""version"": ""2.6""})])
-def test_table_to_parquet_writer_kwargs(kwargs, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.NotSupportedError,
+)
+@pytest.mark.parametrize(""version"", [""1.0"", ""2.6""])
+def test_table_to_parquet_writer_kwargs(version, tmp_path, backend, awards_players):
     outparquet = tmp_path / ""out.parquet""
-    awards_players.to_parquet(outparquet, **kwargs)
+    awards_players.to_parquet(outparquet, version=version)
 
     df = pd.read_parquet(outparquet)
 
     backend.assert_frame_equal(awards_players.to_pandas(), df)
 
-    file = pa.parquet.ParquetFile(outparquet)
+    md = pa.parquet.read_metadata(outparquet)
 
-    assert file.metadata.format_version == kwargs[""version""]
+    assert md.format_version == version
 
 
 @pytest.mark.notimpl(
@@ -316,14 +321,20 @@ def test_table_to_csv(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs"", ""delimiter""), [({""write_options"": pcsv.WriteOptions(delimiter="";"")}, "";""), ({""write_options"": pcsv.WriteOptions(delimiter=""\t"")}, ""\t"")])
-def test_table_to_csv_writer_kwargs(kwargs, delimiter, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.ProgrammingError,
+)
+@pytest.mark.parametrize(""delimiter"", ["";"", ""\t""], ids=[""semicolon"", ""tab""])
+def test_table_to_csv_writer_kwargs(delimiter, tmp_path, awards_players):
     outcsv = tmp_path / ""out.csv""
     # avoid pandas NaNonense
     awards_players = awards_players.select(""playerID"", ""awardID"", ""yearID"", ""lgID"")
 
-    awards_players.to_csv(outcsv, **kwargs)
-    pd.read_csv(outcsv, delimiter=delimiter)
+    awards_players.to_csv(outcsv, write_options=pcsv.WriteOptions(delimiter=delimiter))
+    df = pd.read_csv(outcsv, delimiter=delimiter, nrows=1)
+    assert len(df) == 1
 
 
 @pytest.mark.parametrize(
",1,"[""bedc7950b24c37809e36a585b7985d5aa5e3e458""]","[""test""]"
add props to get color and label from a route,"diff --git a/src/components/BottomNavigation.js b/src/components/BottomNavigation.js
index 1b72302..7d8ea75 100644
--- a/src/components/BottomNavigation.js
+++ b/src/components/BottomNavigation.js
@@ -24,8 +24,8 @@ const AnimatedPaper = Animated.createAnimatedComponent(Paper);
 
 type Route = {
   key: string,
-  title: string,
-  icon: IconSource,
+  title?: string,
+  icon?: IconSource,
   color?: string,
 };
 
@@ -51,7 +51,7 @@ type Props<T> = {
    * - `key`: a unique key to identify the route
    * - `title`: title of the route to use as the tab label
    * - `icon`: icon to use as the tab icon, can be a string, an image source or a react component
-   * - `color`: color to use as background color for shifting bottom navigation (optional)
+   * - `color`: color to use as background color for shifting bottom navigation
    *
    * Example:
    *
@@ -115,11 +115,27 @@ type Props<T> = {
   /**
    * Callback which returns a React Element to be used as tab icon.
    */
-  renderIcon?: (props: { route: T, focused: boolean }) => React.Node,
+  renderIcon?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
   /**
    * Callback which React Element to be used as tab label.
    */
-  renderLabel?: (props: { route: T, focused: boolean }) => React.Node,
+  renderLabel?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
+  /**
+   * Get label text for the tab, uses `route.title` by default. Use `renderLabel` to replace label component.
+   */
+  getLabelText?: (props: { route: T }) => string,
+  /**
+   * Get color for the tab, uses `route.color` by default.
+   */
+  getColor?: (props: { route: T }) => string,
   /**
    * Function to execute on tab press. It receives the route for the pressed tab, useful for things like scroll to top.
    */
@@ -159,6 +175,10 @@ type State = {
    */
   ripple: Animated.Value,
   /**
+   * Animation for the touch feedback, used to determine it's scale and opacity.
+   */
+  touch: Animated.Value,
+  /**
    * Layout of the tab bar. The width is used to determine the size and position of the ripple.
    */
   layout: { height: number, width: number, measured: boolean },
@@ -173,7 +193,7 @@ const MIN_SHIFT_AMOUNT = 10;
 const MIN_TAB_WIDTH = 96;
 const MAX_TAB_WIDTH = 168;
 const BAR_HEIGHT = 56;
-const SMALL_RIPPLE_SIZE = 72;
+const SMALL_RIPPLE_SIZE = 96;
 const ACTIVE_LABEL_SIZE = 14;
 const INACTIVE_LABEL_SIZE = 12;
 
@@ -251,6 +271,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ),
       index: new Animated.Value(index),
       ripple: new Animated.Value(MIN_RIPPLE_SCALE),
+      touch: new Animated.Value(MIN_RIPPLE_SCALE),
       layout: { height: 0, width: 0, measured: false },
       previous: 0,
     };
@@ -349,6 +370,15 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
   _handleTabPress = (index: number) => {
     const { navigationState } = this.props;
 
+    this.state.touch.setValue(MIN_RIPPLE_SCALE);
+
+    Animated.timing(this.state.touch, {
+      toValue: 1,
+      duration: 300,
+      easing: Easing.in(Easing.sin),
+      useNativeDriver: true,
+    }).start();
+
     if (index !== navigationState.index) {
       this.props.onIndexChange(index);
     }
@@ -376,6 +406,8 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       renderScene,
       renderIcon,
       renderLabel,
+      getLabelText = ({ route }) => route.title,
+      getColor = ({ route }) => route.color,
       barStyle,
       style,
       theme,
@@ -400,7 +432,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ? this.state.index.interpolate({
           inputRange: routes.map((_, i) => i),
           outputRange: routes.map(
-            route => route.color || approxBackgroundColor
+            route => getColor({ route }) || approxBackgroundColor
           ),
         })
       : approxBackgroundColor;
@@ -416,7 +448,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
           .rgb()
           .string();
 
-    const rippleColor = color(textColor)
+    const touchColor = color(textColor)
       .alpha(0.12)
       .rgb()
       .string();
@@ -430,22 +462,10 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
 
     // Since we have a single ripple, we have to reposition it so that it appears to expand from active tab.
     // We need to move it from the left to the active tab and also account for how much that tab has shifted.
-    const rippleShift =
-      navigationState.index * tabWidth +
-      tabWidth / 2 +
-      this._calculateShift(
-        this.state.previous,
-        navigationState.index,
-        routes.length
-      );
 
     return (
       <View
-        style={[
-          styles.container,
-          { backgroundColor: theme.dark ? white : black },
-          style,
-        ]}
+        style={[styles.container, style]}
         onLayout={this._handleLayout}
         pointerEvents={layout.measured ? 'auto' : 'none'}
       >
@@ -485,25 +505,30 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
             style={[styles.items, { maxWidth: maxTabWidth * routes.length }]}
           >
             {shifting ? (
-              // Large ripple with the backround color
               <Animated.View
                 pointerEvents=""none""
                 style={[
                   styles.ripple,
                   {
                     // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - layout.width / 2,
-                    left: rippleShift - layout.width / 2,
-                    height: layout.width,
-                    width: layout.width,
+                    top: BAR_HEIGHT / 2 - layout.width / 8,
+                    left:
+                      navigationState.index * tabWidth +
+                      tabWidth / 2 -
+                      layout.width / 8,
+                    height: layout.width / 4,
+                    width: layout.width / 4,
                     borderRadius: layout.width / 2,
-                    backgroundColor: routes[navigationState.index].color,
+                    backgroundColor: getColor({
+                      route: routes[navigationState.index],
+                    }),
                     transform: [
+                      { translateX: this.state.shifts[navigationState.index] },
                       {
                         // Scale to twice the size  to ensure it covers the whole tab bar
                         scale: this.state.ripple.interpolate({
                           inputRange: [0, 1],
-                          outputRange: [0, 2],
+                          outputRange: [0, 8],
                         }),
                       },
                     ],
@@ -515,36 +540,36 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                 ]}
               />
             ) : null}
-            {shifting ? (
-              // Small subtle ripple on touch
-              <Animated.View
-                pointerEvents=""none""
-                style={[
-                  styles.ripple,
-                  {
-                    // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
-                    left: rippleShift - SMALL_RIPPLE_SIZE / 2,
-                    height: SMALL_RIPPLE_SIZE,
-                    width: SMALL_RIPPLE_SIZE,
-                    borderRadius: SMALL_RIPPLE_SIZE / 2,
-                    backgroundColor: rippleColor,
-                    transform: [
-                      {
-                        scale: this.state.ripple.interpolate({
-                          inputRange: [0, 0.5, 1],
-                          outputRange: [0, 1, 1],
-                        }),
-                      },
-                    ],
-                    opacity: this.state.ripple.interpolate({
-                      inputRange: [0, MIN_RIPPLE_SCALE, 0.25, 0.5],
-                      outputRange: [0, 0, 1, 0],
-                    }),
-                  },
-                ]}
-              />
-            ) : null}
+            <Animated.View
+              pointerEvents=""none""
+              style={[
+                styles.ripple,
+                {
+                  // Set top and left values so that the ripple's center is same as the tab's center
+                  top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
+                  left:
+                    navigationState.index * tabWidth +
+                    tabWidth / 2 -
+                    SMALL_RIPPLE_SIZE / 2,
+                  height: SMALL_RIPPLE_SIZE,
+                  width: SMALL_RIPPLE_SIZE,
+                  borderRadius: SMALL_RIPPLE_SIZE / 2,
+                  backgroundColor: touchColor,
+                  transform: [
+                    {
+                      translateX: shifting
+                        ? this.state.shifts[navigationState.index]
+                        : 0,
+                    },
+                    { scale: this.state.touch },
+                  ],
+                  opacity: this.state.touch.interpolate({
+                    inputRange: [0, 0.5, 1],
+                    outputRange: [0, 1, 0],
+                  }),
+                },
+              ]}
+            />
             {routes.map((route, index) => {
               const shift = this.state.shifts[index];
               const focused = this.state.tabs[index];
@@ -607,7 +632,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderIcon ? (
-                          renderIcon({ route, focused: true })
+                          renderIcon({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <Icon
                             style={styles.icon}
@@ -625,7 +654,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderIcon ? (
-                            renderIcon({ route, focused: false })
+                            renderIcon({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <Icon
                               style={styles.icon}
@@ -652,7 +685,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderLabel ? (
-                          renderLabel({ route, focused: true })
+                          renderLabel({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <AnimatedText
                             style={[
@@ -662,7 +699,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                               },
                             ]}
                           >
-                            {route.title}
+                            {getLabelText({ route })}
                           </AnimatedText>
                         )}
                       </Animated.View>
@@ -674,7 +711,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderLabel ? (
-                            renderLabel({ route, focused: false })
+                            renderLabel({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <AnimatedText
                               style={[
@@ -684,7 +725,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                                 },
                               ]}
                             >
-                              {route.title}
+                              {getLabelText({ route })}
                             </AnimatedText>
                           )}
                         </Animated.View>
",1,"[""ded26d768ff432ad3bde3c0aa1e95ce50726100a""]","[""feat""]"
add benchmark for known-slow table expression,"diff --git a/.gitignore b/.gitignore
index 2e99ad3..eef9203 100644
--- a/.gitignore
+++ b/.gitignore
@@ -95,3 +95,4 @@ docs/backends/support_matrix.csv
 __pycache__
 tags
 .DS_Store
+prof/
diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index ac19aaf..36aed0e 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -602,3 +602,93 @@ def test_multiple_joins(benchmark, num_joins, num_columns):
         name=""t"",
     )
     benchmark(multiple_joins, table, num_joins)
+
+
+@pytest.fixture
+def customers():
+    return ibis.table(
+        dict(
+            customerid=""int32"",
+            name=""string"",
+            address=""string"",
+            citystatezip=""string"",
+            birthdate=""date"",
+            phone=""string"",
+            timezone=""string"",
+            lat=""float64"",
+            long=""float64"",
+        ),
+        name=""customers"",
+    )
+
+
+@pytest.fixture
+def orders():
+    return ibis.table(
+        dict(
+            orderid=""int32"",
+            customerid=""int32"",
+            ordered=""timestamp"",
+            shipped=""timestamp"",
+            items=""string"",
+            total=""float64"",
+        ),
+        name=""orders"",
+    )
+
+
+@pytest.fixture
+def orders_items():
+    return ibis.table(
+        dict(orderid=""int32"", sku=""string"", qty=""int32"", unit_price=""float64""),
+        name=""orders_items"",
+    )
+
+
+@pytest.fixture
+def products():
+    return ibis.table(
+        dict(
+            sku=""string"",
+            desc=""string"",
+            weight_kg=""float64"",
+            cost=""float64"",
+            dims_cm=""string"",
+        ),
+        name=""products"",
+    )
+
+
+@pytest.mark.benchmark(group=""compilation"")
+@pytest.mark.parametrize(
+    ""module"",
+    [
+        pytest.param(
+            mod,
+            marks=pytest.mark.xfail(
+                condition=mod in _XFAIL_COMPILE_BACKENDS,
+                reason=f""{mod} backend doesn't support compiling UnboundTable"",
+            ),
+        )
+        for mod in _backends
+    ],
+)
+def test_compile_with_drops(
+    benchmark, module, customers, orders, orders_items, products
+):
+    expr = (
+        customers.join(orders, ""customerid"")
+        .join(orders_items, ""orderid"")
+        .join(products, ""sku"")
+        .drop(""customerid"", ""qty"", ""total"", ""items"")
+        .drop(""dims_cm"", ""cost"")
+        .mutate(o_date=lambda t: t.shipped.date())
+        .filter(lambda t: t.ordered == t.shipped)
+    )
+
+    try:
+        mod = getattr(ibis, module)
+    except (AttributeError, ImportError) as e:
+        pytest.skip(str(e))
+    else:
+        benchmark(mod.compile, expr)
",1,"[""e9617f0854030e70365eb264bcb3b58078e79e9e""]","[""test""]"
"buffer assert and bpmn model api helper class

related to camunda-tngp/camunda-tngp#23","diff --git a/test-util/pom.xml b/test-util/pom.xml
index a097651..b6518ee 100644
--- a/test-util/pom.xml
+++ b/test-util/pom.xml
@@ -20,6 +20,7 @@
     <project.build.sourceEncoding>utf-8</project.build.sourceEncoding>
     <!-- TODO: Move to common parent -->
     <agrona.version>0.4.11</agrona.version>
+    <camunda.version>7.6.0-SNAPSHOT</camunda.version>
   </properties>
 
   <dependencies>
@@ -30,6 +31,13 @@
       <version>${agrona.version}</version>
       <scope>provided</scope>
     </dependency>
+    
+    <dependency>
+      <groupId>org.camunda.bpm.model</groupId>
+      <artifactId>camunda-bpmn-model</artifactId>
+      <version>${camunda.version}</version>
+      <scope>provided</scope>
+    </dependency>
 
     <dependency>
       <groupId>junit</groupId>
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
index 37e3a6f..b8d9b26 100644
--- a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
@@ -14,7 +14,7 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         super(actual, BufferAssert.class);
     }
 
-    public static BufferAssert assertThat(DirectBuffer buffer)
+    public static BufferAssert assertThatBuffer(DirectBuffer buffer)
     {
         return new BufferAssert(buffer);
     }
@@ -41,4 +41,16 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         return hasBytes(expected, 0);
     }
 
+    public BufferAssert hasCapacity(int expectedCapacity)
+    {
+        isNotNull();
+
+        if (expectedCapacity != actual.capacity())
+        {
+            failWithMessage(""Expected capacity "" + expectedCapacity + "" but was "" + actual.capacity());
+        }
+
+        return this;
+    }
+
 }
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
new file mode 100644
index 0000000..6f0d134
--- /dev/null
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
@@ -0,0 +1,121 @@
+package org.camunda.tngp.broker.test.util.bpmn;
+
+import java.util.Collection;
+
+import org.camunda.bpm.model.bpmn.BpmnModelInstance;
+import org.camunda.bpm.model.bpmn.impl.BpmnModelConstants;
+import org.camunda.bpm.model.bpmn.instance.Definitions;
+import org.camunda.bpm.model.xml.Model;
+import org.camunda.bpm.model.xml.instance.DomDocument;
+import org.camunda.bpm.model.xml.instance.ModelElementInstance;
+import org.camunda.bpm.model.xml.type.ModelElementType;
+import org.camunda.bpm.model.xml.validation.ModelElementValidator;
+import org.camunda.bpm.model.xml.validation.ValidationResults;
+
+public class TngpModelInstance implements BpmnModelInstance
+{
+    protected BpmnModelInstance wrappedInstance;
+
+    public TngpModelInstance(BpmnModelInstance wrappedInstance)
+    {
+        this.wrappedInstance = wrappedInstance;
+    }
+
+    @Override
+    public DomDocument getDocument()
+    {
+        return wrappedInstance.getDocument();
+    }
+
+    @Override
+    public ModelElementInstance getDocumentElement()
+    {
+        return wrappedInstance.getDocumentElement();
+    }
+
+    @Override
+    public void setDocumentElement(ModelElementInstance documentElement)
+    {
+        wrappedInstance.setDocumentElement(documentElement);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(Class<T> type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(ModelElementType type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public Model getModel()
+    {
+        return wrappedInstance.getModel();
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T getModelElementById(String id)
+    {
+        return wrappedInstance.getModelElementById(id);
+    }
+
+    @Override
+    public Collection<ModelElementInstance> getModelElementsByType(ModelElementType referencingType)
+    {
+        return wrappedInstance.getModelElementsByType(referencingType);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> Collection<T> getModelElementsByType(Class<T> referencingClass)
+    {
+        return wrappedInstance.getModelElementsByType(referencingClass);
+    }
+
+    @Override
+    public ValidationResults validate(Collection<ModelElementValidator<?>> validators)
+    {
+        return wrappedInstance.validate(validators);
+    }
+
+    @Override
+    public BpmnModelInstance clone()
+    {
+        return wrappedInstance.clone();
+    }
+
+    @Override
+    public Definitions getDefinitions()
+    {
+        return wrappedInstance.getDefinitions();
+    }
+
+    @Override
+    public void setDefinitions(Definitions arg0)
+    {
+        wrappedInstance.setDefinitions(arg0);
+    }
+
+    public TngpModelInstance taskAttributes(String taskId, String taskType, int taskQueueId)
+    {
+        final ModelElementInstance task = wrappedInstance.getModelElementById(taskId);
+
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskType"", taskType);
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskQueueId"", String.valueOf(taskQueueId));
+
+        return this;
+    }
+
+    public static TngpModelInstance wrap(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance);
+    }
+
+    public static TngpModelInstance wrapCopy(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance.clone());
+    }
+}
",1,"[""6ed56ce9ae743ba9a87e6c9643cc06b1de7b748d""]","[""feat""]"
"nginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection
",1,"[""e12d9e77a6fd531a22325337838a841b1c67f00d""]","[""docs""]"
"enable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>cleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.","diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 

diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:
",2,"[""fd8e563cc19ca4684885d4692acee6bebcca4ada"", ""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7""]","[""feat"", ""refactor""]"
do not use scripts and binaries from the libcc repo[gn win] link comctl32.lib to fix component build,"diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]
",2,"[""45837af24a33308a70a3454f0f650f9fe728e272"", ""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0""]","[""cicd"", ""build""]"
export a modal transition presetadd spacing in comment fix lint (#8555),"diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {

diff --git a/src/components/nav/test/basic/app-module.ts b/src/components/nav/test/basic/app-module.ts
index 467917a..375e662 100644
--- a/src/components/nav/test/basic/app-module.ts
+++ b/src/components/nav/test/basic/app-module.ts
@@ -633,7 +633,7 @@ export class Tab3 {
   }
 
   presentModal() {
-    //this.modalCtrl.create(MyModal).present();
+    // this.modalCtrl.create(MyModal).present();
   }
 
   selectPrevious() {
",2,"[""535708ae50aecb452560a23356fd396f99ef13a2"", ""af880ac5b4fecbc6c4f3d1eee0d95f326e8bd9d1""]","[""refactor"", ""docs""]"
"add hardware back button

Closes #5071add fallible peek_last_token()","diff --git a/ionic/components/app/app.ts b/ionic/components/app/app.ts
index 04d8c57..08aab92 100644
--- a/ionic/components/app/app.ts
+++ b/ionic/components/app/app.ts
@@ -3,8 +3,7 @@ import {Title} from 'angular2/platform/browser';
 
 import {Config} from '../../config/config';
 import {ClickBlock} from '../../util/click-block';
-import {Nav} from '../nav/nav';
-import {Tabs} from '../tabs/tabs';
+import {Platform} from '../../platform/platform';
 
 
 /**
@@ -23,8 +22,20 @@ export class IonicApp {
 
   constructor(
     private _config: Config,
-    private _clickBlock: ClickBlock
-  ) {}
+    private _clickBlock: ClickBlock,
+    platform: Platform
+  ) {
+    platform.backButton.subscribe(() => {
+      let activeNav = this.getActiveNav();
+      if (activeNav) {
+        if (activeNav.length() === 1) {
+          platform.exitApp();
+        } else {
+          activeNav.pop();
+        }
+      }
+    });
+  }
 
   /**
    * Sets the document title.
@@ -102,7 +113,7 @@ export class IonicApp {
   /**
    * @private
    */
-  getActiveNav(): Nav | Tabs {
+  getActiveNav(): any {
     var nav = this._rootNav || null;
     var activeChildNav;
 

diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.
",2,"[""68278b00450f2679761a2999500f6d87a579376b"", ""63eab619e6166eb6cab948028a7b89bf059dd878""]","[""feat"", ""refactor""]"
"only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>Adjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.","diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)
",2,"[""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3""]","[""cicd"", ""test""]"
skip flaky testadd a branch name to Slack notifications (#14793),"diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method

diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'
",2,"[""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d"", ""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da""]","[""test"", ""cicd""]"
"do not use scripts and binaries from the libcc repoassist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }
",2,"[""45837af24a33308a70a3454f0f650f9fe728e272"", ""1269431c8a3e7549f10fcbbb4b88ff625c8898b3""]","[""cicd"", ""build""]"
"terminated tasks linger for a bit

Signed-off-by: Eliza Weisman <eliza@buoyant.io>Adjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.","diff --git a/console/src/main.rs b/console/src/main.rs
index ebfa315..5328d96 100644
--- a/console/src/main.rs
+++ b/console/src/main.rs
@@ -69,6 +69,7 @@ async fn main() -> Result<(), Box<dyn std::error::Error>> {
                 .wrap(Wrap { trim: true });
             f.render_widget(header, chunks[0]);
             tasks.render(f, chunks[1]);
+            tasks.retain_active();
         })?;
     }
 
diff --git a/console/src/tasks.rs b/console/src/tasks.rs
index 7be39a4..eb41495 100644
--- a/console/src/tasks.rs
+++ b/console/src/tasks.rs
@@ -19,6 +19,7 @@ struct Task {
     fields: String,
     kind: &'static str,
     stats: Stats,
+    completed_for: usize,
 }
 
 #[derive(Default, Debug)]
@@ -28,10 +29,15 @@ struct Stats {
     idle: Duration,
     total: Duration,
 }
+
 impl State {
+    // How many updates to retain completed tasks for
+    const RETAIN_COMPLETED_FOR: usize = 6;
+
     pub(crate) fn len(&self) -> usize {
         self.tasks.len()
     }
+
     pub(crate) fn update(&mut self, update: proto::tasks::TaskUpdate) {
         let new_tasks = update.new_tasks.into_iter().filter_map(|task| {
             if task.id.is_none() {
@@ -48,6 +54,7 @@ impl State {
                 fields: task.string_fields,
                 kind,
                 stats: Default::default(),
+                completed_for: 0,
             };
             Some((id, task))
         });
@@ -60,7 +67,10 @@ impl State {
         }
 
         for proto::SpanId { id } in update.completed {
-            if self.tasks.remove(&id).is_none() {
+            if let Some(task) = self.tasks.get_mut(&id) {
+                task.kind = ""!"";
+                task.completed_for = 1;
+            } else {
                 tracing::warn!(?id, ""tried to complete a task that didn't exist"");
             }
         }
@@ -79,7 +89,7 @@ impl State {
         const DUR_PRECISION: usize = 4;
         const POLLS_LEN: usize = 5;
         let rows = self.tasks.values().map(|task| {
-            let row = Row::new(vec![
+            let mut row = Row::new(vec![
                 Cell::from(task.id_hex.as_str()),
                 // TODO(eliza): is there a way to write a `fmt::Debug` impl
                 // directly to tui without doing an allocation?
@@ -105,6 +115,9 @@ impl State {
                 Cell::from(format!(""{:>width$}"", task.stats.polls, width = POLLS_LEN)),
                 Cell::from(task.fields.as_str()),
             ]);
+            if task.completed_for > 0 {
+                row = row.style(Style::default().add_modifier(style::Modifier::DIM));
+            }
             row
         });
         let t = Table::new(rows)
@@ -126,6 +139,16 @@ impl State {
 
         frame.render_widget(t, area)
     }
+
+    pub(crate) fn retain_active(&mut self) {
+        self.tasks.retain(|_, task| {
+            if task.completed_for == 0 {
+                return true;
+            }
+            task.completed_for += 1;
+            task.completed_for <= Self::RETAIN_COMPLETED_FOR
+        })
+    }
 }
 
 impl From<proto::tasks::Stats> for Stats {

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)
",2,"[""1bcf88670b50155b50071e707f98f30cea0b7a24"", ""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3""]","[""feat"", ""test""]"
"fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.update `cargo-make` for `v0.35.3`","diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/CHANGELOG.md b/CHANGELOG.md
index 5e125e3..52d9b6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 * Fix: resizing/scrolling through heavily wrapped panes no longer hangs (https://github.com/zellij-org/zellij/pull/814)
 * Terminal compatibility: properly handle HOME/END keys in eg. vim/zsh (https://github.com/zellij-org/zellij/pull/815)
 * Fix: Typo (https://github.com/zellij-org/zellij/pull/821)
+* Fix: Update `cargo-make` instructions post `v0.35.3` (https://github.com/zellij-org/zellij/pull/819)
 
 ## [0.19.0] - 2021-10-20
 * Fix: Prevent text overwrite when scrolled up (https://github.com/zellij-org/zellij/pull/655)
",2,"[""9be725fa3906323d4bc9788f54eccf74109d632b"", ""0cfc5633d37ea06f645649138323f1820e18bdee""]","[""fix"", ""docs""]"
"fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.add remote [skip ci]","diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 06c9003..e19c703 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -47,7 +47,10 @@ jobs:
           git config --global user.email 'ibis-squawk-bot[bot]@users.noreply.github.com'
 
       - name: fetch and rebase on top of upstream
-        run: git pull --rebase -X ours https://github.com/ibis-project/ibis master
+        run: |
+          git remote add upstream https://github.com/ibis-project/ibis
+          git fetch upstream
+          git rebase -X ours upstream/master
 
       - uses: tibdex/github-app-token@v1
         id: generate_pr_token
",2,"[""9be725fa3906323d4bc9788f54eccf74109d632b"", ""e96487ad7ce90b141219d9032fa2bed68d5dae6a""]","[""fix"", ""cicd""]"
"assist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>update wrapping tests for v7","diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }

diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });
",2,"[""1269431c8a3e7549f10fcbbb4b88ff625c8898b3"", ""317f4eefecddfb1392ca71d551840f446feee302""]","[""build"", ""test""]"
"only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>update `cargo-make` for `v0.35.3`","diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/CHANGELOG.md b/CHANGELOG.md
index 5e125e3..52d9b6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 * Fix: resizing/scrolling through heavily wrapped panes no longer hangs (https://github.com/zellij-org/zellij/pull/814)
 * Terminal compatibility: properly handle HOME/END keys in eg. vim/zsh (https://github.com/zellij-org/zellij/pull/815)
 * Fix: Typo (https://github.com/zellij-org/zellij/pull/821)
+* Fix: Update `cargo-make` instructions post `v0.35.3` (https://github.com/zellij-org/zellij/pull/819)
 
 ## [0.19.0] - 2021-10-20
 * Fix: Prevent text overwrite when scrolled up (https://github.com/zellij-org/zellij/pull/655)
",2,"[""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""0cfc5633d37ea06f645649138323f1820e18bdee""]","[""cicd"", ""docs""]"
"restructure ClusterTopology to track completed changeupgrade to Flux v0.42.0

Skips a test that requires special dependencies to pass.","diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(

diff --git a/go.mod b/go.mod
index ea705da..8c352f7 100644
--- a/go.mod
+++ b/go.mod
@@ -38,7 +38,7 @@ require (
 	github.com/hashicorp/go-msgpack v0.0.0-20150518234257-fa3f63826f7c // indirect
 	github.com/hashicorp/raft v1.0.0 // indirect
 	github.com/hashicorp/vault/api v1.0.2
-	github.com/influxdata/flux v0.41.0
+	github.com/influxdata/flux v0.42.0
 	github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6
 	github.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368
 	github.com/jessevdk/go-flags v1.4.0
diff --git a/go.sum b/go.sum
index 4bfdf4c..634a0f1 100644
--- a/go.sum
+++ b/go.sum
@@ -206,8 +206,8 @@ github.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NH
 github.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=
 github.com/influxdata/changelog v1.0.0 h1:RstJD6H48zLQj0GdE6E6k/6RPwtUjkyzIe/T1E/xuWU=
 github.com/influxdata/changelog v1.0.0/go.mod h1:uzpGWE/qehT8L426YuXwpMQub+a63vIINhIeEI9mnSM=
-github.com/influxdata/flux v0.41.0 h1:ljbWJmE+aNx8Yoqhb04gWC4sXMV87eYUxz5vjYphLLs=
-github.com/influxdata/flux v0.41.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
+github.com/influxdata/flux v0.42.0 h1:2iEG6hLHdHEJ6LgD8OSnlHS9yoVrLO1/aM4P9ERb94U=
+github.com/influxdata/flux v0.42.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
 github.com/influxdata/goreleaser v0.97.0-influx h1:jT5OrcW7WfS0e2QxfwmTBjhLvpIC9CDLRhNgZJyhj8s=
 github.com/influxdata/goreleaser v0.97.0-influx/go.mod h1:MnjA0e0Uq6ISqjG1WxxMAl+3VS1QYjILSWVnMYDxasE=
 github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6 h1:CFx+pP90q/qg3spoiZjf8donE4WpAdjeJfPOcoNqkWo=
diff --git a/query/stdlib/testing/testing.go b/query/stdlib/testing/testing.go
index d41574a..85b0673 100644
--- a/query/stdlib/testing/testing.go
+++ b/query/stdlib/testing/testing.go
@@ -98,4 +98,6 @@ var FluxEndToEndSkipList = map[string]string{
 	""http_endpoint"": ""need ability to test side effects in e2e tests: (https://github.com/influxdata/flux/issues/1723)"",
 
 	""holt_winters_panic"": ""Expected output is an empty table which breaks the testing framework (https://github.com/influxdata/influxdb/issues/14749)"",
+
+	""secrets"": ""Cannot inject custom deps into the test framework so the secrets don't lookup correctly"",
 }
",2,"[""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2"", ""454003841aabeb74396d73541378bfa59c75b5db""]","[""refactor"", ""build""]"
"initialize threejs objects in defaultRef, to fix undefined type errorsget tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.","diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }
",2,"[""2561f4ade46fc9d59f289f328cc77733a6443697"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c""]","[""fix"", ""refactor""]"
"[gn] fix include_dirs ordering erroronly run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>","diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)

diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest
",2,"[""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945"", ""dbb537a26e388a8d7d17faf131abc30c2f7a84e6""]","[""build"", ""cicd""]"
updated react demo parcel commandadd fallible peek_last_token(),"diff --git a/demo/react/package.json b/demo/react/package.json
index be28bf9..32d0952 100644
--- a/demo/react/package.json
+++ b/demo/react/package.json
@@ -12,7 +12,7 @@
   },
   ""scripts"": {
     ""start"": ""parcel serve public/index.html --no-cache --open"",
-    ""build"": ""parcel build -t browser -d dist public/index.html --no-source-maps""
+    ""build"": ""parcel build --target browser --dist-dir dist public/index.html --no-source-maps""
   },
   ""bugs"": {
     ""url"": ""https://github.com/matteobruni/tsparticles/issues""

diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.
",2,"[""32b92cfa0b74a6c25990e32ac6aab12b8496794c"", ""63eab619e6166eb6cab948028a7b89bf059dd878""]","[""build"", ""refactor""]"
"add getter for protocol idnginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection
",2,"[""dc5238b2bda98a7c4f2fe9584fc3b0191a408109"", ""e12d9e77a6fd531a22325337838a841b1c67f00d""]","[""feat"", ""docs""]"
split release docs build into separate workflowFix typo,"diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 753d57d..3e0aa15 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -88,14 +88,14 @@ jobs:
         run: poetry run pytest --benchmark-only --benchmark-json .benchmarks/output.json ibis/tests/benchmarks
 
       - uses: tibdex/github-app-token@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         id: generate-token
         with:
           app_id: ${{ secrets.SQUAWK_BOT_APP_ID }}
           private_key: ${{ secrets.SQUAWK_BOT_APP_PRIVATE_KEY }}
 
       - uses: benchmark-action/github-action-benchmark@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         with:
           tool: pytest
           github-token: ${{ steps.generate-token.outputs.token }}
@@ -107,6 +107,7 @@ jobs:
 
   docs:
     runs-on: ubuntu-latest
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
     needs:
       # wait on benchmarks to prevent a race condition when pushing to the
       # gh-pages branch
@@ -124,51 +125,25 @@ jobs:
           authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
           extraPullNames: nix-community,poetry2nix
 
-      - name: Generate a GitHub token
-        if: ${{ github.event_name == 'push' }}
-        uses: tibdex/github-app-token@v1
-        id: generate_token
-        with:
-          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
-          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
-
-      - name: checkout
-        if: ${{ github.event_name == 'push' }}
-        uses: actions/checkout@v3
-        with:
-          fetch-depth: 0
-          token: ${{ steps.generate_token.outputs.token }}
-
       - name: checkout
-        if: ${{ github.event_name != 'push' }}
         uses: actions/checkout@v3
 
-      - name: Configure git info
-        if: ${{ github.event_name == 'push' }}
-        run: |
-          set -euo pipefail
-
-          git config user.name 'ibis-docs-bot[bot]'
-          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
-
       - name: build docs
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c mkdocs build
 
       - name: verify internal links
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c just checklinks --offline --no-progress
 
-      - name: Pull gh-pages changes
+      - name: Configure git info
         if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
-          git fetch origin gh-pages
-          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
 
       - name: build and push dev docs
-        if: ${{ github.event_name == 'push' && !startsWith(github.ref, 'refs/tags/') }}
+        if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
@@ -180,19 +155,6 @@ jobs:
               --message 'docs(dev): ibis@${{ github.sha }}' \
                 dev
 
-      - name: build and push docs on tag
-        if: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/tags/') }}
-        run: |
-          set -euo pipefail
-
-          nix develop -f shell.nix --keep-going -c \
-            mic deploy \
-              --push \
-              --rebase \
-              --prefix docs \
-              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
-              ""${GITHUB_REF_NAME}"" latest
-
   simulate_release:
     runs-on: ubuntu-latest
     steps:
diff --git a/.github/workflows/ibis-docs-release.yml b/.github/workflows/ibis-docs-release.yml
new file mode 100644
index 0000000..da7ee49
--- /dev/null
+++ b/.github/workflows/ibis-docs-release.yml
@@ -0,0 +1,63 @@
+# vim: filetype=yaml
+name: Docs Release Build
+
+on:
+  release:
+    types:
+      - published
+jobs:
+  docs:
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
+    runs-on: ubuntu-latest
+    steps:
+      - name: install nix
+        uses: cachix/install-nix-action@v17
+        with:
+          nix_path: nixpkgs=channel:nixos-unstable-small
+
+      - name: setup cachix
+        uses: cachix/cachix-action@v10
+        with:
+          name: ibis
+          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
+          extraPullNames: nix-community,poetry2nix
+
+      - name: Generate a GitHub token
+        uses: tibdex/github-app-token@v1
+        id: generate_token
+        with:
+          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
+          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
+
+      - name: checkout
+        uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+          token: ${{ steps.generate_token.outputs.token }}
+
+      - name: Configure git info
+        run: |
+          set -euo pipefail
+
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
+
+      - name: Pull gh-pages changes
+        run: |
+          set -euo pipefail
+
+          git fetch origin gh-pages
+          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+
+      - name: build and push docs on tag
+        run: |
+          set -euo pipefail
+
+          nix develop -f shell.nix --keep-going -c \
+            mic deploy \
+              --push \
+              --rebase \
+              --update-aliases \
+              --prefix docs \
+              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
+              ""${GITHUB_REF_NAME}"" latest

diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and
",2,"[""32845e1bbd1efb5dbc16f671049509a409ba25ce"", ""bf83c9155e9bee6925aa7102fab53fb803d52533""]","[""cicd"", ""docs""]"
"print errors without stacktracebuffer assert and bpmn model api helper class

related to camunda-tngp/camunda-tngp#23","diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {

diff --git a/test-util/pom.xml b/test-util/pom.xml
index a097651..b6518ee 100644
--- a/test-util/pom.xml
+++ b/test-util/pom.xml
@@ -20,6 +20,7 @@
     <project.build.sourceEncoding>utf-8</project.build.sourceEncoding>
     <!-- TODO: Move to common parent -->
     <agrona.version>0.4.11</agrona.version>
+    <camunda.version>7.6.0-SNAPSHOT</camunda.version>
   </properties>
 
   <dependencies>
@@ -30,6 +31,13 @@
       <version>${agrona.version}</version>
       <scope>provided</scope>
     </dependency>
+    
+    <dependency>
+      <groupId>org.camunda.bpm.model</groupId>
+      <artifactId>camunda-bpmn-model</artifactId>
+      <version>${camunda.version}</version>
+      <scope>provided</scope>
+    </dependency>
 
     <dependency>
       <groupId>junit</groupId>
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
index 37e3a6f..b8d9b26 100644
--- a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
@@ -14,7 +14,7 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         super(actual, BufferAssert.class);
     }
 
-    public static BufferAssert assertThat(DirectBuffer buffer)
+    public static BufferAssert assertThatBuffer(DirectBuffer buffer)
     {
         return new BufferAssert(buffer);
     }
@@ -41,4 +41,16 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         return hasBytes(expected, 0);
     }
 
+    public BufferAssert hasCapacity(int expectedCapacity)
+    {
+        isNotNull();
+
+        if (expectedCapacity != actual.capacity())
+        {
+            failWithMessage(""Expected capacity "" + expectedCapacity + "" but was "" + actual.capacity());
+        }
+
+        return this;
+    }
+
 }
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
new file mode 100644
index 0000000..6f0d134
--- /dev/null
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
@@ -0,0 +1,121 @@
+package org.camunda.tngp.broker.test.util.bpmn;
+
+import java.util.Collection;
+
+import org.camunda.bpm.model.bpmn.BpmnModelInstance;
+import org.camunda.bpm.model.bpmn.impl.BpmnModelConstants;
+import org.camunda.bpm.model.bpmn.instance.Definitions;
+import org.camunda.bpm.model.xml.Model;
+import org.camunda.bpm.model.xml.instance.DomDocument;
+import org.camunda.bpm.model.xml.instance.ModelElementInstance;
+import org.camunda.bpm.model.xml.type.ModelElementType;
+import org.camunda.bpm.model.xml.validation.ModelElementValidator;
+import org.camunda.bpm.model.xml.validation.ValidationResults;
+
+public class TngpModelInstance implements BpmnModelInstance
+{
+    protected BpmnModelInstance wrappedInstance;
+
+    public TngpModelInstance(BpmnModelInstance wrappedInstance)
+    {
+        this.wrappedInstance = wrappedInstance;
+    }
+
+    @Override
+    public DomDocument getDocument()
+    {
+        return wrappedInstance.getDocument();
+    }
+
+    @Override
+    public ModelElementInstance getDocumentElement()
+    {
+        return wrappedInstance.getDocumentElement();
+    }
+
+    @Override
+    public void setDocumentElement(ModelElementInstance documentElement)
+    {
+        wrappedInstance.setDocumentElement(documentElement);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(Class<T> type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(ModelElementType type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public Model getModel()
+    {
+        return wrappedInstance.getModel();
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T getModelElementById(String id)
+    {
+        return wrappedInstance.getModelElementById(id);
+    }
+
+    @Override
+    public Collection<ModelElementInstance> getModelElementsByType(ModelElementType referencingType)
+    {
+        return wrappedInstance.getModelElementsByType(referencingType);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> Collection<T> getModelElementsByType(Class<T> referencingClass)
+    {
+        return wrappedInstance.getModelElementsByType(referencingClass);
+    }
+
+    @Override
+    public ValidationResults validate(Collection<ModelElementValidator<?>> validators)
+    {
+        return wrappedInstance.validate(validators);
+    }
+
+    @Override
+    public BpmnModelInstance clone()
+    {
+        return wrappedInstance.clone();
+    }
+
+    @Override
+    public Definitions getDefinitions()
+    {
+        return wrappedInstance.getDefinitions();
+    }
+
+    @Override
+    public void setDefinitions(Definitions arg0)
+    {
+        wrappedInstance.setDefinitions(arg0);
+    }
+
+    public TngpModelInstance taskAttributes(String taskId, String taskType, int taskQueueId)
+    {
+        final ModelElementInstance task = wrappedInstance.getModelElementById(taskId);
+
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskType"", taskType);
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskQueueId"", String.valueOf(taskQueueId));
+
+        return this;
+    }
+
+    public static TngpModelInstance wrap(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance);
+    }
+
+    public static TngpModelInstance wrapCopy(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance.clone());
+    }
+}
",2,"[""d129eaf9125a967ac86c6c7276bbae6b4d50af36"", ""6ed56ce9ae743ba9a87e6c9643cc06b1de7b748d""]","[""fix"", ""feat""]"
"terminated tasks linger for a bit

Signed-off-by: Eliza Weisman <eliza@buoyant.io>remove ubuntu-latest from job title where that is the only os","diff --git a/console/src/main.rs b/console/src/main.rs
index ebfa315..5328d96 100644
--- a/console/src/main.rs
+++ b/console/src/main.rs
@@ -69,6 +69,7 @@ async fn main() -> Result<(), Box<dyn std::error::Error>> {
                 .wrap(Wrap { trim: true });
             f.render_widget(header, chunks[0]);
             tasks.render(f, chunks[1]);
+            tasks.retain_active();
         })?;
     }
 
diff --git a/console/src/tasks.rs b/console/src/tasks.rs
index 7be39a4..eb41495 100644
--- a/console/src/tasks.rs
+++ b/console/src/tasks.rs
@@ -19,6 +19,7 @@ struct Task {
     fields: String,
     kind: &'static str,
     stats: Stats,
+    completed_for: usize,
 }
 
 #[derive(Default, Debug)]
@@ -28,10 +29,15 @@ struct Stats {
     idle: Duration,
     total: Duration,
 }
+
 impl State {
+    // How many updates to retain completed tasks for
+    const RETAIN_COMPLETED_FOR: usize = 6;
+
     pub(crate) fn len(&self) -> usize {
         self.tasks.len()
     }
+
     pub(crate) fn update(&mut self, update: proto::tasks::TaskUpdate) {
         let new_tasks = update.new_tasks.into_iter().filter_map(|task| {
             if task.id.is_none() {
@@ -48,6 +54,7 @@ impl State {
                 fields: task.string_fields,
                 kind,
                 stats: Default::default(),
+                completed_for: 0,
             };
             Some((id, task))
         });
@@ -60,7 +67,10 @@ impl State {
         }
 
         for proto::SpanId { id } in update.completed {
-            if self.tasks.remove(&id).is_none() {
+            if let Some(task) = self.tasks.get_mut(&id) {
+                task.kind = ""!"";
+                task.completed_for = 1;
+            } else {
                 tracing::warn!(?id, ""tried to complete a task that didn't exist"");
             }
         }
@@ -79,7 +89,7 @@ impl State {
         const DUR_PRECISION: usize = 4;
         const POLLS_LEN: usize = 5;
         let rows = self.tasks.values().map(|task| {
-            let row = Row::new(vec![
+            let mut row = Row::new(vec![
                 Cell::from(task.id_hex.as_str()),
                 // TODO(eliza): is there a way to write a `fmt::Debug` impl
                 // directly to tui without doing an allocation?
@@ -105,6 +115,9 @@ impl State {
                 Cell::from(format!(""{:>width$}"", task.stats.polls, width = POLLS_LEN)),
                 Cell::from(task.fields.as_str()),
             ]);
+            if task.completed_for > 0 {
+                row = row.style(Style::default().add_modifier(style::Modifier::DIM));
+            }
             row
         });
         let t = Table::new(rows)
@@ -126,6 +139,16 @@ impl State {
 
         frame.render_widget(t, area)
     }
+
+    pub(crate) fn retain_active(&mut self) {
+        self.tasks.retain(|_, task| {
+            if task.completed_for == 0 {
+                return true;
+            }
+            task.completed_for += 1;
+            task.completed_for <= Self::RETAIN_COMPLETED_FOR
+        })
+    }
 }
 
 impl From<proto::tasks::Stats> for Stats {

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
",2,"[""1bcf88670b50155b50071e707f98f30cea0b7a24"", ""74e9de5ec97dc013a52aa063dff0f40ac74c407b""]","[""feat"", ""cicd""]"
add comments for the Handlerrun pyspark tests in parallel,"diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index e23088e..9708157 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -202,11 +202,11 @@ jobs:
         run: poetry install --without dev --without docs --extras ${{ matrix.backend.name }} --extras geospatial
 
       - name: ""run parallel tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name != 'pyspark' && matrix.backend.name != 'impala'
+        if: matrix.backend.name != 'impala'
         run: just ci-check -m ${{ matrix.backend.name }} --numprocesses auto --dist=loadgroup
 
       - name: ""run serial tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name == 'pyspark' || matrix.backend.name == 'impala'
+        if: matrix.backend.name == 'impala'
         run: just ci-check -m ${{ matrix.backend.name }}
         env:
           IBIS_TEST_NN_HOST: localhost
",2,"[""036a0ff49a7dade0e04c9c07071a1ff49133ee24"", ""4cbbd2552ba0de273e1dfe7d453c5b3efed751a3""]","[""docs"", ""cicd""]"
add benchmark for known-slow table expressionbetter layout for block and segment,"diff --git a/.gitignore b/.gitignore
index 2e99ad3..eef9203 100644
--- a/.gitignore
+++ b/.gitignore
@@ -95,3 +95,4 @@ docs/backends/support_matrix.csv
 __pycache__
 tags
 .DS_Store
+prof/
diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index ac19aaf..36aed0e 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -602,3 +602,93 @@ def test_multiple_joins(benchmark, num_joins, num_columns):
         name=""t"",
     )
     benchmark(multiple_joins, table, num_joins)
+
+
+@pytest.fixture
+def customers():
+    return ibis.table(
+        dict(
+            customerid=""int32"",
+            name=""string"",
+            address=""string"",
+            citystatezip=""string"",
+            birthdate=""date"",
+            phone=""string"",
+            timezone=""string"",
+            lat=""float64"",
+            long=""float64"",
+        ),
+        name=""customers"",
+    )
+
+
+@pytest.fixture
+def orders():
+    return ibis.table(
+        dict(
+            orderid=""int32"",
+            customerid=""int32"",
+            ordered=""timestamp"",
+            shipped=""timestamp"",
+            items=""string"",
+            total=""float64"",
+        ),
+        name=""orders"",
+    )
+
+
+@pytest.fixture
+def orders_items():
+    return ibis.table(
+        dict(orderid=""int32"", sku=""string"", qty=""int32"", unit_price=""float64""),
+        name=""orders_items"",
+    )
+
+
+@pytest.fixture
+def products():
+    return ibis.table(
+        dict(
+            sku=""string"",
+            desc=""string"",
+            weight_kg=""float64"",
+            cost=""float64"",
+            dims_cm=""string"",
+        ),
+        name=""products"",
+    )
+
+
+@pytest.mark.benchmark(group=""compilation"")
+@pytest.mark.parametrize(
+    ""module"",
+    [
+        pytest.param(
+            mod,
+            marks=pytest.mark.xfail(
+                condition=mod in _XFAIL_COMPILE_BACKENDS,
+                reason=f""{mod} backend doesn't support compiling UnboundTable"",
+            ),
+        )
+        for mod in _backends
+    ],
+)
+def test_compile_with_drops(
+    benchmark, module, customers, orders, orders_items, products
+):
+    expr = (
+        customers.join(orders, ""customerid"")
+        .join(orders_items, ""orderid"")
+        .join(products, ""sku"")
+        .drop(""customerid"", ""qty"", ""total"", ""items"")
+        .drop(""dims_cm"", ""cost"")
+        .mutate(o_date=lambda t: t.shipped.date())
+        .filter(lambda t: t.ordered == t.shipped)
+    )
+
+    try:
+        mod = getattr(ibis, module)
+    except (AttributeError, ImportError) as e:
+        pytest.skip(str(e))
+    else:
+        benchmark(mod.compile, expr)

diff --git a/docs/docs/config-block.md b/docs/docs/config-block.md
new file mode 100644
index 0000000..df1ee54
--- /dev/null
+++ b/docs/docs/config-block.md
@@ -0,0 +1,60 @@
+---
+id: config-block
+title: Block
+sidebar_label: Block
+---
+
+Let's take a closer look at what defines a block.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""segments"": [
+        ...
+      ]
+    }
+  ]
+}
+```
+
+- type: `prompt` | `rprompt`
+- newline: `boolean`
+- alignment: `left` | `right`
+- vertical_offset: `int`
+- horizontal_offset: `int`
+- segments: `array` of one or more `segments`
+
+### Type
+
+Tells the engine what to do with the block. There are three options:
+
+- `prompt` renders one or more segments
+- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
+Supported on [ZSH][rprompt], Bash and Powershell.
+
+### Newline
+
+Start the block on a new line. Defaults to `false`.
+
+### Alignment
+
+Tell the engine if the block should be left or right-aligned.
+
+### Vertical offset
+
+Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
+moves it up one line.
+
+### Horizontal offset
+
+Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
+but on a horizontal level where a negative number moves the block left and a positive number right.
+
+### Segments
+
+Array of one or more segments.
diff --git a/docs/docs/config-example.md b/docs/docs/config-example.md
new file mode 100644
index 0000000..c180c4f
--- /dev/null
+++ b/docs/docs/config-example.md
@@ -0,0 +1,96 @@
+---
+id: config-sample
+title: Sample
+sidebar_label: Sample
+---
+
+```json
+{
+  ""final_space"": true,
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""right"",
+      ""vertical_offset"": -1,
+      ""segments"": [
+        {
+          ""type"": ""time"",
+          ""style"": ""plain"",
+          ""foreground"": ""#007ACC"",
+          ""properties"": {
+            ""time_format"": ""15:04:05""
+          }
+        }
+      ]
+    },
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""newline"": true,
+      ""segments"": [
+        {
+          ""type"": ""session"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#ffb300"",
+          ""leading_diamond"": ""\uE0B6"",
+          ""trailing_diamond"": ""\uE0B0"",
+          ""properties"": {
+            ""postfix"": "" ""
+          }
+        },
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ""prefix"": "" \uE5FF "",
+            ""style"": ""folder"",
+            ""exclude_folders"": [
+              ""/super/secret/project""
+            ],
+            ""enable_hyperlink"": false
+          }
+        },
+        {
+          ""type"": ""git"",
+          ""style"": ""powerline"",
+          ""foreground"": ""#193549"",
+          ""foreground_templates"": [
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
+          ],
+          ""background"": ""#2e9599"",
+          ""background_templates"": [
+            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
+            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
+            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
+          ],
+          ""powerline_symbol"": ""\uE0B0"",
+          ""properties"": {
+            ""fetch_status"": true,
+            ""branch_max_length"": 25,
+            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
+          }
+        },
+        {
+          ""type"": ""exit"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#00897b"",
+          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
+          ""leading_diamond"": """",
+          ""trailing_diamond"": ""\uE0B4"",
+          ""properties"": {
+            ""always_enabled"": true,
+            ""template"": ""\uE23A"",
+            ""prefix"": ""<parentBackground>\uE0B0</> ""
+          }
+        }
+      ]
+    }
+  ]
+}
+```
diff --git a/docs/docs/config-overview.md b/docs/docs/config-overview.md
index 1fdbcba..b554869 100644
--- a/docs/docs/config-overview.md
+++ b/docs/docs/config-overview.md
@@ -1,7 +1,7 @@
 ---
 id: config-overview
-title: Overview
-sidebar_label: Overview
+title: General
+sidebar_label: General
 ---
 
 Oh My Posh renders your prompt based on the definition of _blocks_ (like Lego) which contain one or more _segments_.
@@ -64,332 +64,7 @@ boxes with question marks, set up your terminal to use a [supported font][font] 
 - terminal_background: `string` [color][colors] - terminal background color, set to your terminal's background color when
 you notice black elements in Windows Terminal or the Visual Studio Code integrated terminal
 
-## Block
-
-Let's take a closer look at what defines a block.
-
-- type: `prompt` | `rprompt`
-- newline: `boolean`
-- alignment: `left` | `right`
-- vertical_offset: `int`
-- horizontal_offset: `int`
-- segments: `array` of one or more `segments`
-
-### Type
-
-Tells the engine what to do with the block. There are three options:
-
-- `prompt` renders one or more segments
-- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
-Supported on [ZSH][rprompt], Bash and Powershell.
-
-### Newline
-
-Start the block on a new line. Defaults to `false`.
-
-### Alignment
-
-Tell the engine if the block should be left or right-aligned.
-
-### Vertical offset
-
-Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
-moves it up one line.
-
-### Horizontal offset
-
-Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
-but on a horizontal level where a negative number moves the block left and a positive number right.
-
-### Segments
-
-Array of one or more segments.
-
-## Segment
-
-A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
-looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
-understand how to configure a segment.
-
-- type: `string` any of the included [segments][segments]
-- style: `powerline` | `plain` | `diamond`
-- powerline_symbol: `string`
-- invert_powerline: `boolean`
-- leading_diamond: `string`
-- trailing_diamond: `string`
-- foreground: `string` [color][colors]
-- foreground_templates: `array` of `string` values
-- background: `string` [color][colors]
-- background_templates: `array` of `string` values
-- properties: `array` of `Property`: `string`
-
-### Type
-
-Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
-
-### Style
-
-Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
-themes out there, we identified 3 types. All of these require a different configuration and depending on the look
-you want to achieve you might need to understand/use them all.
-
-#### Powerline
-
-What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
-background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
-if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
-
-#### Plain
-
-Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
-Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
-
-#### Diamond
-
-While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
-Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
-segment background as their foreground color.
-
-### Powerline symbol
-
-Text character to use when `""style"": ""powerline""`.
-
-### Invert Powerline
-
-If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
-in the perfectly mirrored variant for example.
-
-### Leading diamond
-
-Text character to use at the start of the segment. Will take the background color of the segment as
-its foreground color.
-
-### Trailing diamond
-
-Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
-
-### Foreground
-
-[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
-
-### Foreground Templates
-
-Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
-Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
-offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
-the documentation.
-
-The following sample is based on the [AWS Segment][aws].
-
-```json
-{
-  ""type"": ""aws"",
-  ""style"": ""powerline"",
-  ""powerline_symbol"": ""\uE0B0"",
-  ""foreground"": ""#ffffff"",
-  ""background"": ""#111111"",
-  ""foreground_templates"": [
-    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
-    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
-  ],
-  ""properties"": {
-    ""prefix"": "" \uE7AD ""
-  }
-}
-```
-
-The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
-one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
-returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
-templates returns a value, the foreground value `#ffffff` is used.
-
-### Background
-
-[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
-
-### Background Templates
-
-Same as [Foreground Templates][fg-templ] but for the background color.
-
-### Properties
-
-An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
-will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
-engine which allow you to customize the output even more.
-
-#### General-purpose properties
-
-You can use these on any segment, the engine is responsible for adding them correctly.
-
-- prefix: `string`
-- postfix: `string`
-- include_folders: `[]string`
-- exclude_folders: `[]string`
-
-##### Prefix
-
-The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
-specify this as `''`.
-
-##### Postfix
-
-The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
-specify this as `''`.
-
-##### Include / Exclude Folders
-
-Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
-the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
-will not be rendered when in one of the excluded locations.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-```json
-""exclude_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-The strings specified in these properties are evaluated as [regular expressions][regex]. You
-can use any valid regular expression construct, but the regular expression must match the entire directory
-name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-]
-```
-
-You can also combine these properties:
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-],
-""exclude_folders"": [
-  ""/Users/posh/Projects/secret-project.*""
-]
-```
-
-##### Notes
-
-- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
-is used by the current operating system.
-- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
-directory name, you need to specify it as `\\\\`.
-- The character `~` at the start of a specified folder will match the user's home directory.
-- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
-
-This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
-`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
-
-## Full Sample
-
-```json
-{
-  ""final_space"": true,
-  ""blocks"": [
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""right"",
-      ""vertical_offset"": -1,
-      ""segments"": [
-        {
-          ""type"": ""time"",
-          ""style"": ""plain"",
-          ""foreground"": ""#007ACC"",
-          ""properties"": {
-            ""time_format"": ""15:04:05""
-          }
-        }
-      ]
-    },
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""left"",
-      ""newline"": true,
-      ""segments"": [
-        {
-          ""type"": ""session"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#ffb300"",
-          ""leading_diamond"": ""\uE0B6"",
-          ""trailing_diamond"": ""\uE0B0"",
-          ""properties"": {
-            ""postfix"": "" ""
-          }
-        },
-        {
-          ""type"": ""path"",
-          ""style"": ""powerline"",
-          ""powerline_symbol"": ""\uE0B0"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#61AFEF"",
-          ""properties"": {
-            ""prefix"": "" \uE5FF "",
-            ""style"": ""folder"",
-            ""exclude_folders"": [
-              ""/super/secret/project""
-            ],
-            ""enable_hyperlink"": false
-          }
-        },
-        {
-          ""type"": ""git"",
-          ""style"": ""powerline"",
-          ""foreground"": ""#193549"",
-          ""foreground_templates"": [
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
-          ],
-          ""background"": ""#2e9599"",
-          ""background_templates"": [
-            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
-            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
-            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
-          ],
-          ""powerline_symbol"": ""\uE0B0"",
-          ""properties"": {
-            ""fetch_status"": true,
-            ""branch_max_length"": 25,
-            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
-          }
-        },
-        {
-          ""type"": ""exit"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#00897b"",
-          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
-          ""leading_diamond"": """",
-          ""trailing_diamond"": ""\uE0B4"",
-          ""properties"": {
-            ""always_enabled"": true,
-            ""template"": ""\uE23A"",
-            ""prefix"": ""<parentBackground>\uE0B0</> ""
-          }
-        }
-      ]
-    }
-  ]
-}
-```
-
 [releases]: https://github.com/JanDeDobbeleer/oh-my-posh/releases/latest
 [font]: /docs/config-fonts
 [schema]: https://github.com/JanDeDobbeleer/oh-my-posh/blob/main/themes/schema.json
 [themes]: https://github.com/JanDeDobbeleer/oh-my-posh/tree/main/themes
-[segments]: /docs/battery
-[colors]: /docs/config-colors
-[go-text-template]: https://golang.org/pkg/text/template/
-[sprig]: https://masterminds.github.io/sprig/
-[fg-templ]: /docs/config-overview#foreground-templates
-[regex]: https://www.regular-expressions.info/tutorial.html
-[aws]: /docs/aws
diff --git a/docs/docs/config-segment.md b/docs/docs/config-segment.md
new file mode 100644
index 0000000..08a66e4
--- /dev/null
+++ b/docs/docs/config-segment.md
@@ -0,0 +1,219 @@
+---
+id: config-segment
+title: Segment
+sidebar_label: Segment
+---
+
+A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
+looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
+understand how to configure a segment.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ...
+      ""segments"": [
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ...
+          }
+        }
+      ]
+    }
+  ]
+}
+```
+
+- type: `string` any of the included [segments][segments]
+- style: `powerline` | `plain` | `diamond`
+- powerline_symbol: `string`
+- invert_powerline: `boolean`
+- leading_diamond: `string`
+- trailing_diamond: `string`
+- foreground: `string` [color][colors]
+- foreground_templates: `array` of `string` values
+- background: `string` [color][colors]
+- background_templates: `array` of `string` values
+- properties: `array` of `Property`: `string`
+
+## Type
+
+Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
+
+## Style
+
+Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
+themes out there, we identified 3 types. All of these require a different configuration and depending on the look
+you want to achieve you might need to understand/use them all.
+
+### Powerline
+
+What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
+background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
+if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
+
+### Plain
+
+Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
+Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
+
+### Diamond
+
+While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
+Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
+segment background as their foreground color.
+
+## Powerline symbol
+
+Text character to use when `""style"": ""powerline""`.
+
+## Invert Powerline
+
+If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
+in the perfectly mirrored variant for example.
+
+## Leading diamond
+
+Text character to use at the start of the segment. Will take the background color of the segment as
+its foreground color.
+
+## Trailing diamond
+
+Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
+
+## Foreground
+
+[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
+
+## Foreground Templates
+
+Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
+Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
+offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
+the documentation.
+
+The following sample is based on the [AWS Segment][aws].
+
+```json
+{
+  ""type"": ""aws"",
+  ""style"": ""powerline"",
+  ""powerline_symbol"": ""\uE0B0"",
+  ""foreground"": ""#ffffff"",
+  ""background"": ""#111111"",
+  ""foreground_templates"": [
+    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
+    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
+  ],
+  ""properties"": {
+    ""prefix"": "" \uE7AD ""
+  }
+}
+```
+
+The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
+one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
+returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
+templates returns a value, the foreground value `#ffffff` is used.
+
+## Background
+
+[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
+
+## Background Templates
+
+Same as [Foreground Templates][fg-templ] but for the background color.
+
+## Properties
+
+An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
+will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
+engine which allow you to customize the output even more.
+
+### General-purpose properties
+
+You can use these on any segment, the engine is responsible for adding them correctly.
+
+- prefix: `string`
+- postfix: `string`
+- include_folders: `[]string`
+- exclude_folders: `[]string`
+
+#### Prefix
+
+The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
+specify this as `''`.
+
+#### Postfix
+
+The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
+specify this as `''`.
+
+#### Include / Exclude Folders
+
+Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
+the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
+will not be rendered when in one of the excluded locations.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+```json
+""exclude_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+The strings specified in these properties are evaluated as [regular expressions][regex]. You
+can use any valid regular expression construct, but the regular expression must match the entire directory
+name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+]
+```
+
+You can also combine these properties:
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+],
+""exclude_folders"": [
+  ""/Users/posh/Projects/secret-project.*""
+]
+```
+
+#### Notes
+
+- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
+is used by the current operating system.
+- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
+directory name, you need to specify it as `\\\\`.
+- The character `~` at the start of a specified folder will match the user's home directory.
+- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
+
+This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
+`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
+
+[segments]: /docs/battery
+[colors]: /docs/config-colors
+[go-text-template]: https://golang.org/pkg/text/template/
+[sprig]: https://masterminds.github.io/sprig/
+[fg-templ]: /docs/config-overview#foreground-templates
+[regex]: https://www.regular-expressions.info/tutorial.html
+[aws]: /docs/aws
diff --git a/docs/docs/segment-environment.md b/docs/docs/segment-environment.md
index f35bc87..982a0a5 100644
--- a/docs/docs/segment-environment.md
+++ b/docs/docs/segment-environment.md
@@ -34,7 +34,7 @@ New-Alias -Name 'Set-PoshContext' -Value 'Set-EnvVar' -Scope Global -Force
 
 The segment will show when the value of the environment variable isn't empty.
 
-## Sample Configuration
+## Sample *Configuration*
 
 ```json
 {
diff --git a/docs/sidebars.js b/docs/sidebars.js
index a75163e..8f151a2 100644
--- a/docs/sidebars.js
+++ b/docs/sidebars.js
@@ -20,6 +20,9 @@ module.exports = {
       label: ""⚙️ Configuration"",
       items: [
         ""config-overview"",
+        ""config-block"",
+        ""config-segment"",
+        ""config-sample"",
         ""config-title"",
         ""config-colors"",
         ""config-text-style"",
",2,"[""e9617f0854030e70365eb264bcb3b58078e79e9e"", ""cb1f48b56ae0de93acb72e48726c7d610a1d538e""]","[""test"", ""docs""]"
"added changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284Add ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>","diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}
",2,"[""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""f823cf28652987d43c8324b4f5b203240032383a""]","[""docs"", ""feat""]"
remove appear css animationuse `regexp_instr != 0` instead of `REGEXP` keyword,"diff --git a/src/popup/Popup.tsx b/src/popup/Popup.tsx
index d485bb6..2abc22a 100644
--- a/src/popup/Popup.tsx
+++ b/src/popup/Popup.tsx
@@ -269,7 +269,6 @@ export class Popup extends React.Component<{ t: TranslationFunction }, PopupStat
         <CSSTransition
           classNames='fade'
           in={!!currentTabUrl}
-          appear
           timeout={500}
           exit={false}
           mountOnEnter

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(
",2,"[""47ef9104e4a89e80d7cc6c1950bc080841da4a7b"", ""06e2be4e2019b6fa714e1fcb34485860ef1ede79""]","[""refactor"", ""fix""]"
"[gn win] link comctl32.lib to fix component buildonly run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>","diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest
",2,"[""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""dbb537a26e388a8d7d17faf131abc30c2f7a84e6""]","[""build"", ""cicd""]"
"[gn win] link comctl32.lib to fix component buildcleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.","diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:
",2,"[""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7""]","[""build"", ""refactor""]"
allow disabling dynamic queueensure checksum persist flushes to disk,"diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);

diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);
",2,"[""9ef5c0d14193a9abb09b39856f58477d1f4b0d77"", ""b7ce2894fd1794064bd6db4ed730bb6cb7728739""]","[""fix"", ""test""]"
"fix build orderingupdate Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909","diff --git a/scripts/build.mjs b/scripts/build.mjs
index 204854f..b3cf067 100644
--- a/scripts/build.mjs
+++ b/scripts/build.mjs
@@ -3,8 +3,8 @@ import { write } from 'fsxx';
 import { info, success } from './helpers.mjs';
 
 await $`rm -rf dist/*`;
-await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 await $`unbuild`;
+await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 
 const packages = [
   'jsx-runtime',

diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })
",2,"[""c323d59c607cabc91f17a78528d998f376f30b10"", ""c2ee5cd5e709afd15c5565ee009a0d204403a119""]","[""build"", ""docs""]"
"fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>","diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest
",2,"[""9be725fa3906323d4bc9788f54eccf74109d632b"", ""dbb537a26e388a8d7d17faf131abc30c2f7a84e6""]","[""fix"", ""cicd""]"
"fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.increment failing test retries","diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
",2,"[""9be725fa3906323d4bc9788f54eccf74109d632b"", ""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57""]","[""fix"", ""cicd""]"
"update Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909get tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.","diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }
",2,"[""c2ee5cd5e709afd15c5565ee009a0d204403a119"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c""]","[""docs"", ""refactor""]"
update flushed index before truncatingsupport use meta key select multiple element,"diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index ab68624..aeee7b7 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -277,9 +277,11 @@ export default class LogicFlow {
   }
   /**
    * 将图形选中
+   * @param id 选择元素ID
+   * @param multiple 是否允许多选，如果为true，不会将上一个选中的元素重置
    */
-  select(id: string) {
-    this.graphModel.selectElementById(id);
+  select(id: string, multiple = false) {
+    this.graphModel.selectElementById(id, multiple);
   }
   /**
    * 将图形定位到画布中心
diff --git a/packages/core/src/model/EditConfigModel.ts b/packages/core/src/model/EditConfigModel.ts
index 67e334a..83e5f16 100644
--- a/packages/core/src/model/EditConfigModel.ts
+++ b/packages/core/src/model/EditConfigModel.ts
@@ -25,6 +25,7 @@ const SilentConfig = {
   edgeTextEdit: false,
   nodeTextDraggable: false,
   edgeTextDraggable: false,
+  metaKeyMultipleSelected: false,
 };
 
 /**
@@ -42,6 +43,7 @@ export default class EditConfigModel {
   @observable edgeTextEdit = true; // 允许连线文本可以编辑
   @observable nodeTextDraggable = false; // 允许节点文本可以拖拽
   @observable edgeTextDraggable = false; // 允许连线文本可以拖拽
+  @observable metaKeyMultipleSelected = false; // 允许meta多选元素
   constructor(data) {
     const keys = [
       'stopZoomGraph',
@@ -55,6 +57,7 @@ export default class EditConfigModel {
       'edgeTextEdit',
       'nodeTextDraggable',
       'edgeTextDraggable',
+      'metaKeyMultipleSelected',
     ];
     const { isSilentMode, textEdit } = data;
     if (isSilentMode) {
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 9667f4d..310daf4 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -34,6 +34,7 @@ class GraphModel {
   height: number;
   topElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
   selectElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
+  selectElements = new Map<string, IBaseModel>(); // 多选
   @observable edgeType: string;
   @observable nodes: BaseNodeModel[] = [];
   @observable activeElement: IBaseModel;
@@ -50,7 +51,6 @@ class GraphModel {
   @observable gridSize = 1;
   @observable partial = false; // 是否开启局部渲染
   @observable fakerNode: BaseNodeModel;
-  // @observable selectElements = new Map<string, IBaseModel>(); // 多选还没有做，先不加
   constructor(config) {
     const {
       container,
@@ -456,24 +456,44 @@ class GraphModel {
   }
 
   @action
-  selectNodeById(id) {
-    this.selectElement?.setSelected(false);
+  selectNodeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.nodesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectEdgeById(id) {
-    this.selectElement?.setSelected(false);
+  selectEdgeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.edgesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectElementById(id: string) {
-    this.selectElement?.setSelected(false);
+  selectElementById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
+  }
+
+  @action
+  clearSelectElements() {
+    this.selectElements.forEach(element => {
+      element.setSelected(false);
+    });
+    this.selectElements.clear();
   }
 
   /* 修改连线类型 */
diff --git a/packages/core/src/view/edge/BaseEdge.tsx b/packages/core/src/view/edge/BaseEdge.tsx
index d45ea9e..d7c8f38 100644
--- a/packages/core/src/view/edge/BaseEdge.tsx
+++ b/packages/core/src/view/edge/BaseEdge.tsx
@@ -178,7 +178,8 @@ export default class BaseEdge extends Component<IProps> {
   handleClick = (e) => {
     const { model, graphModel, eventCenter } = this.props;
     graphModel.toFront(model.id);
-    graphModel.selectEdgeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectEdgeById(model.id, e.metaKey && metaKeyMultipleSelected);
     // 边数据
     const edgeData = model?.getData();
     const position = graphModel.getPointByClient({
diff --git a/packages/core/src/view/node/BaseNode.tsx b/packages/core/src/view/node/BaseNode.tsx
index 140889c..5ee3975 100644
--- a/packages/core/src/view/node/BaseNode.tsx
+++ b/packages/core/src/view/node/BaseNode.tsx
@@ -275,7 +275,8 @@ export default abstract class BaseNode extends Component<IProps, Istate> {
       }, 400);
     }
     graphModel.toFront(model.id);
-    graphModel.selectNodeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectNodeById(model.id, e.metaKey && metaKeyMultipleSelected);
     this.preStartTime = this.startTime;
   };
   handleContextMenu = (ev: MouseEvent) => {
diff --git a/packages/core/src/view/overlay/CanvasOverlay.tsx b/packages/core/src/view/overlay/CanvasOverlay.tsx
index ef11822..8c79fd2 100644
--- a/packages/core/src/view/overlay/CanvasOverlay.tsx
+++ b/packages/core/src/view/overlay/CanvasOverlay.tsx
@@ -104,9 +104,9 @@ class CanvasOverlay extends Component<IProps, Istate> {
     const target = ev.target as HTMLElement;
     if (target.getAttribute('name') === 'canvas-overlay') {
       const { graphModel, eventCenter } = this.props;
-      const { selectElement, textEditElement } = graphModel;
-      if (selectElement) {
-        selectElement.setSelected(false);
+      const { textEditElement, selectElements } = graphModel;
+      if (selectElements.size > 0) {
+        graphModel.clearSelectElements();
       }
       if (textEditElement) {
         textEditElement.setElementState(ElementState.DEFAULT);
diff --git a/packages/extension/examples/bpmn/index.html b/packages/extension/examples/bpmn/index.html
index 7a68d6f..f7ea87d 100644
--- a/packages/extension/examples/bpmn/index.html
+++ b/packages/extension/examples/bpmn/index.html
@@ -6,6 +6,7 @@
   <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
   <title>LOGIN FLOW</title>
   <link rel=""stylesheet"" href=""/core/dist/style/index.css"">
+  <link rel=""stylesheet"" href=""/extension/lib/style/index.css"">
   <style>
     html,body {
       padding: 0;
@@ -129,11 +130,14 @@
     </div>
   </div>
   <script src=""/core/dist/logic-flow.js""></script>
+  <!-- <script src=""http://0.0.0.0:9090/logic-flow.js""></script> -->
   <script src=""/BpmnElement.js""></script>
   <script src=""/BpmnAdapter.js""></script>
+  <script src=""/Control.js""></script>
   <script src=""/Snapshot.js""></script>
   <script>
     LogicFlow.use(BpmnElement);
+    LogicFlow.use(Control);
     LogicFlow.use(BpmnAdapter);
     LogicFlow.use(Snapshot);
   </script>
diff --git a/packages/extension/examples/bpmn/index.js b/packages/extension/examples/bpmn/index.js
index 21d2da0..6f6aa39 100644
--- a/packages/extension/examples/bpmn/index.js
+++ b/packages/extension/examples/bpmn/index.js
@@ -3,6 +3,10 @@ window.onload = function () {
     container: document.querySelector('#app'),
     // fixme: grid成为了必传的了
     edgeTextDraggable: true,
+    metaKeyMultipleSelected: true,
+    // stopScrollGraph: true,
+    // stopMoveGraph: true,
+    // stopZoomGraph: true,
     grid: {
       type: 'dot',
       size: 20,
",2,"[""933ab6bb86372913c992567cf9660009900911a7"", ""e137f9fdbdb6bf3f85c3f7ac9323785e445844c8""]","[""fix"", ""feat""]"
"fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.[gn] fix include_dirs ordering error","diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)
",2,"[""9be725fa3906323d4bc9788f54eccf74109d632b"", ""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945""]","[""fix"", ""build""]"
"add riscv64gc-unknown-linux-gnunginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection
",2,"[""173553c0372e66e03bdab19e0e6c2dd44daa14a0"", ""e12d9e77a6fd531a22325337838a841b1c67f00d""]","[""cicd"", ""docs""]"
"publish sdks after docs/buildAdd ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>","diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}
",2,"[""6c9cb638cb4d1ecc42632fcf389c24898c5b3244"", ""f823cf28652987d43c8324b4f5b203240032383a""]","[""cicd"", ""feat""]"
"remove ubuntu-latest from job title where that is the only osupdate Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909","diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false

diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })
",2,"[""74e9de5ec97dc013a52aa063dff0f40ac74c407b"", ""c2ee5cd5e709afd15c5565ee009a0d204403a119""]","[""cicd"", ""docs""]"
update wrapping tests for v7[gn win] link comctl32.lib to fix component build,"diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });

diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]
",2,"[""317f4eefecddfb1392ca71d551840f446feee302"", ""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0""]","[""test"", ""build""]"
"licensingAdd ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>","diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}
",2,"[""a52a585d74894b3b4eeb8c784fa089ff95cddad0"", ""f823cf28652987d43c8324b4f5b203240032383a""]","[""docs"", ""feat""]"
remove appear css animation[gn win] link comctl32.lib to fix component build,"diff --git a/src/popup/Popup.tsx b/src/popup/Popup.tsx
index d485bb6..2abc22a 100644
--- a/src/popup/Popup.tsx
+++ b/src/popup/Popup.tsx
@@ -269,7 +269,6 @@ export class Popup extends React.Component<{ t: TranslationFunction }, PopupStat
         <CSSTransition
           classNames='fade'
           in={!!currentTabUrl}
-          appear
           timeout={500}
           exit={false}
           mountOnEnter

diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]
",2,"[""47ef9104e4a89e80d7cc6c1950bc080841da4a7b"", ""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0""]","[""refactor"", ""build""]"
support use meta key select multiple elementmake it mode less,"diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index ab68624..aeee7b7 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -277,9 +277,11 @@ export default class LogicFlow {
   }
   /**
    * 将图形选中
+   * @param id 选择元素ID
+   * @param multiple 是否允许多选，如果为true，不会将上一个选中的元素重置
    */
-  select(id: string) {
-    this.graphModel.selectElementById(id);
+  select(id: string, multiple = false) {
+    this.graphModel.selectElementById(id, multiple);
   }
   /**
    * 将图形定位到画布中心
diff --git a/packages/core/src/model/EditConfigModel.ts b/packages/core/src/model/EditConfigModel.ts
index 67e334a..83e5f16 100644
--- a/packages/core/src/model/EditConfigModel.ts
+++ b/packages/core/src/model/EditConfigModel.ts
@@ -25,6 +25,7 @@ const SilentConfig = {
   edgeTextEdit: false,
   nodeTextDraggable: false,
   edgeTextDraggable: false,
+  metaKeyMultipleSelected: false,
 };
 
 /**
@@ -42,6 +43,7 @@ export default class EditConfigModel {
   @observable edgeTextEdit = true; // 允许连线文本可以编辑
   @observable nodeTextDraggable = false; // 允许节点文本可以拖拽
   @observable edgeTextDraggable = false; // 允许连线文本可以拖拽
+  @observable metaKeyMultipleSelected = false; // 允许meta多选元素
   constructor(data) {
     const keys = [
       'stopZoomGraph',
@@ -55,6 +57,7 @@ export default class EditConfigModel {
       'edgeTextEdit',
       'nodeTextDraggable',
       'edgeTextDraggable',
+      'metaKeyMultipleSelected',
     ];
     const { isSilentMode, textEdit } = data;
     if (isSilentMode) {
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 9667f4d..310daf4 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -34,6 +34,7 @@ class GraphModel {
   height: number;
   topElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
   selectElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
+  selectElements = new Map<string, IBaseModel>(); // 多选
   @observable edgeType: string;
   @observable nodes: BaseNodeModel[] = [];
   @observable activeElement: IBaseModel;
@@ -50,7 +51,6 @@ class GraphModel {
   @observable gridSize = 1;
   @observable partial = false; // 是否开启局部渲染
   @observable fakerNode: BaseNodeModel;
-  // @observable selectElements = new Map<string, IBaseModel>(); // 多选还没有做，先不加
   constructor(config) {
     const {
       container,
@@ -456,24 +456,44 @@ class GraphModel {
   }
 
   @action
-  selectNodeById(id) {
-    this.selectElement?.setSelected(false);
+  selectNodeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.nodesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectEdgeById(id) {
-    this.selectElement?.setSelected(false);
+  selectEdgeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.edgesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectElementById(id: string) {
-    this.selectElement?.setSelected(false);
+  selectElementById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
+  }
+
+  @action
+  clearSelectElements() {
+    this.selectElements.forEach(element => {
+      element.setSelected(false);
+    });
+    this.selectElements.clear();
   }
 
   /* 修改连线类型 */
diff --git a/packages/core/src/view/edge/BaseEdge.tsx b/packages/core/src/view/edge/BaseEdge.tsx
index d45ea9e..d7c8f38 100644
--- a/packages/core/src/view/edge/BaseEdge.tsx
+++ b/packages/core/src/view/edge/BaseEdge.tsx
@@ -178,7 +178,8 @@ export default class BaseEdge extends Component<IProps> {
   handleClick = (e) => {
     const { model, graphModel, eventCenter } = this.props;
     graphModel.toFront(model.id);
-    graphModel.selectEdgeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectEdgeById(model.id, e.metaKey && metaKeyMultipleSelected);
     // 边数据
     const edgeData = model?.getData();
     const position = graphModel.getPointByClient({
diff --git a/packages/core/src/view/node/BaseNode.tsx b/packages/core/src/view/node/BaseNode.tsx
index 140889c..5ee3975 100644
--- a/packages/core/src/view/node/BaseNode.tsx
+++ b/packages/core/src/view/node/BaseNode.tsx
@@ -275,7 +275,8 @@ export default abstract class BaseNode extends Component<IProps, Istate> {
       }, 400);
     }
     graphModel.toFront(model.id);
-    graphModel.selectNodeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectNodeById(model.id, e.metaKey && metaKeyMultipleSelected);
     this.preStartTime = this.startTime;
   };
   handleContextMenu = (ev: MouseEvent) => {
diff --git a/packages/core/src/view/overlay/CanvasOverlay.tsx b/packages/core/src/view/overlay/CanvasOverlay.tsx
index ef11822..8c79fd2 100644
--- a/packages/core/src/view/overlay/CanvasOverlay.tsx
+++ b/packages/core/src/view/overlay/CanvasOverlay.tsx
@@ -104,9 +104,9 @@ class CanvasOverlay extends Component<IProps, Istate> {
     const target = ev.target as HTMLElement;
     if (target.getAttribute('name') === 'canvas-overlay') {
       const { graphModel, eventCenter } = this.props;
-      const { selectElement, textEditElement } = graphModel;
-      if (selectElement) {
-        selectElement.setSelected(false);
+      const { textEditElement, selectElements } = graphModel;
+      if (selectElements.size > 0) {
+        graphModel.clearSelectElements();
       }
       if (textEditElement) {
         textEditElement.setElementState(ElementState.DEFAULT);
diff --git a/packages/extension/examples/bpmn/index.html b/packages/extension/examples/bpmn/index.html
index 7a68d6f..f7ea87d 100644
--- a/packages/extension/examples/bpmn/index.html
+++ b/packages/extension/examples/bpmn/index.html
@@ -6,6 +6,7 @@
   <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
   <title>LOGIN FLOW</title>
   <link rel=""stylesheet"" href=""/core/dist/style/index.css"">
+  <link rel=""stylesheet"" href=""/extension/lib/style/index.css"">
   <style>
     html,body {
       padding: 0;
@@ -129,11 +130,14 @@
     </div>
   </div>
   <script src=""/core/dist/logic-flow.js""></script>
+  <!-- <script src=""http://0.0.0.0:9090/logic-flow.js""></script> -->
   <script src=""/BpmnElement.js""></script>
   <script src=""/BpmnAdapter.js""></script>
+  <script src=""/Control.js""></script>
   <script src=""/Snapshot.js""></script>
   <script>
     LogicFlow.use(BpmnElement);
+    LogicFlow.use(Control);
     LogicFlow.use(BpmnAdapter);
     LogicFlow.use(Snapshot);
   </script>
diff --git a/packages/extension/examples/bpmn/index.js b/packages/extension/examples/bpmn/index.js
index 21d2da0..6f6aa39 100644
--- a/packages/extension/examples/bpmn/index.js
+++ b/packages/extension/examples/bpmn/index.js
@@ -3,6 +3,10 @@ window.onload = function () {
     container: document.querySelector('#app'),
     // fixme: grid成为了必传的了
     edgeTextDraggable: true,
+    metaKeyMultipleSelected: true,
+    // stopScrollGraph: true,
+    // stopMoveGraph: true,
+    // stopZoomGraph: true,
     grid: {
       type: 'dot',
       size: 20,

diff --git a/core/src/components/slides/slides.tsx b/core/src/components/slides/slides.tsx
index 48fd53f..d5c2f75 100644
--- a/core/src/components/slides/slides.tsx
+++ b/core/src/components/slides/slides.tsx
@@ -1,7 +1,6 @@
 import { Component, Element, Event, EventEmitter, Method, Prop, Watch } from '@stencil/core';
 
 import { Mode } from '../../interface.js';
-import { createThemedClasses } from '../../utils/theme.js';
 
 import { Swiper } from './vendor/swiper.js';
 
@@ -15,6 +14,7 @@ import { Swiper } from './vendor/swiper.js';
   shadow: true
 })
 export class Slides {
+
   private container!: HTMLElement;
   private swiper: any;
 
@@ -391,12 +391,6 @@ export class Slides {
     return { ...swiperOptions, ...this.options, ...eventOptions };
   }
 
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'slides')
-    };
-  }
-
   render() {
     return (
       <div class=""swiper-container"" ref={el => this.container = el as HTMLElement }>
diff --git a/core/src/components/thumbnail/thumbnail.ios.scss b/core/src/components/thumbnail/thumbnail.ios.scss
deleted file mode 100644
index e3add45..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.ios.vars"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-ios-width};
-  --border-radius: #{$thumbnail-ios-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.ios.vars.scss b/core/src/components/thumbnail/thumbnail.ios.vars.scss
deleted file mode 100644
index 85d53e5..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.ios"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-ios-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-ios-height:                  $thumbnail-ios-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-ios-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.md.scss b/core/src/components/thumbnail/thumbnail.md.scss
deleted file mode 100644
index 0fbb2ca..0000000
--- a/core/src/components/thumbnail/thumbnail.md.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.md.vars"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-md-width};
-  --border-radius: #{$thumbnail-md-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.md.vars.scss b/core/src/components/thumbnail/thumbnail.md.vars.scss
deleted file mode 100644
index 94e48b2..0000000
--- a/core/src/components/thumbnail/thumbnail.md.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.md"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-md-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-md-height:                  $thumbnail-md-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-md-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.scss b/core/src/components/thumbnail/thumbnail.scss
index 8ac3a22..8af268d 100644
--- a/core/src/components/thumbnail/thumbnail.scss
+++ b/core/src/components/thumbnail/thumbnail.scss
@@ -9,6 +9,8 @@
    * @prop --border-radius: Border radius of the thumbnail
    * @prop --size: Size of the thumbnail
    */
+  --size: 48px;
+  --border-radius: 0;
 
   @include border-radius(var(--border-radius));
 
diff --git a/core/src/components/thumbnail/thumbnail.tsx b/core/src/components/thumbnail/thumbnail.tsx
index 50ff2c2..de76593 100644
--- a/core/src/components/thumbnail/thumbnail.tsx
+++ b/core/src/components/thumbnail/thumbnail.tsx
@@ -1,25 +1,11 @@
 import { Component } from '@stencil/core';
 
-import { Mode } from '../../interface';
-import { createThemedClasses } from '../../utils/theme';
-
 @Component({
   tag: 'ion-thumbnail',
-  styleUrls: {
-    ios: 'thumbnail.ios.scss',
-    md: 'thumbnail.md.scss'
-  },
+  styleUrl: 'thumbnail.scss',
   shadow: true
 })
 export class Thumbnail {
-  mode!: Mode;
-
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'thumbnail')
-    };
-  }
-
   render() {
     return <slot></slot>;
   }
",2,"[""e137f9fdbdb6bf3f85c3f7ac9323785e445844c8"", ""771857b1df9470ebc15357e8879118a72c649d5b""]","[""feat"", ""refactor""]"
"buffer assert and bpmn model api helper class

related to camunda-tngp/camunda-tngp#23wrong icon reference

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/test-util/pom.xml b/test-util/pom.xml
index a097651..b6518ee 100644
--- a/test-util/pom.xml
+++ b/test-util/pom.xml
@@ -20,6 +20,7 @@
     <project.build.sourceEncoding>utf-8</project.build.sourceEncoding>
     <!-- TODO: Move to common parent -->
     <agrona.version>0.4.11</agrona.version>
+    <camunda.version>7.6.0-SNAPSHOT</camunda.version>
   </properties>
 
   <dependencies>
@@ -30,6 +31,13 @@
       <version>${agrona.version}</version>
       <scope>provided</scope>
     </dependency>
+    
+    <dependency>
+      <groupId>org.camunda.bpm.model</groupId>
+      <artifactId>camunda-bpmn-model</artifactId>
+      <version>${camunda.version}</version>
+      <scope>provided</scope>
+    </dependency>
 
     <dependency>
       <groupId>junit</groupId>
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
index 37e3a6f..b8d9b26 100644
--- a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
@@ -14,7 +14,7 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         super(actual, BufferAssert.class);
     }
 
-    public static BufferAssert assertThat(DirectBuffer buffer)
+    public static BufferAssert assertThatBuffer(DirectBuffer buffer)
     {
         return new BufferAssert(buffer);
     }
@@ -41,4 +41,16 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         return hasBytes(expected, 0);
     }
 
+    public BufferAssert hasCapacity(int expectedCapacity)
+    {
+        isNotNull();
+
+        if (expectedCapacity != actual.capacity())
+        {
+            failWithMessage(""Expected capacity "" + expectedCapacity + "" but was "" + actual.capacity());
+        }
+
+        return this;
+    }
+
 }
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
new file mode 100644
index 0000000..6f0d134
--- /dev/null
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
@@ -0,0 +1,121 @@
+package org.camunda.tngp.broker.test.util.bpmn;
+
+import java.util.Collection;
+
+import org.camunda.bpm.model.bpmn.BpmnModelInstance;
+import org.camunda.bpm.model.bpmn.impl.BpmnModelConstants;
+import org.camunda.bpm.model.bpmn.instance.Definitions;
+import org.camunda.bpm.model.xml.Model;
+import org.camunda.bpm.model.xml.instance.DomDocument;
+import org.camunda.bpm.model.xml.instance.ModelElementInstance;
+import org.camunda.bpm.model.xml.type.ModelElementType;
+import org.camunda.bpm.model.xml.validation.ModelElementValidator;
+import org.camunda.bpm.model.xml.validation.ValidationResults;
+
+public class TngpModelInstance implements BpmnModelInstance
+{
+    protected BpmnModelInstance wrappedInstance;
+
+    public TngpModelInstance(BpmnModelInstance wrappedInstance)
+    {
+        this.wrappedInstance = wrappedInstance;
+    }
+
+    @Override
+    public DomDocument getDocument()
+    {
+        return wrappedInstance.getDocument();
+    }
+
+    @Override
+    public ModelElementInstance getDocumentElement()
+    {
+        return wrappedInstance.getDocumentElement();
+    }
+
+    @Override
+    public void setDocumentElement(ModelElementInstance documentElement)
+    {
+        wrappedInstance.setDocumentElement(documentElement);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(Class<T> type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(ModelElementType type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public Model getModel()
+    {
+        return wrappedInstance.getModel();
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T getModelElementById(String id)
+    {
+        return wrappedInstance.getModelElementById(id);
+    }
+
+    @Override
+    public Collection<ModelElementInstance> getModelElementsByType(ModelElementType referencingType)
+    {
+        return wrappedInstance.getModelElementsByType(referencingType);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> Collection<T> getModelElementsByType(Class<T> referencingClass)
+    {
+        return wrappedInstance.getModelElementsByType(referencingClass);
+    }
+
+    @Override
+    public ValidationResults validate(Collection<ModelElementValidator<?>> validators)
+    {
+        return wrappedInstance.validate(validators);
+    }
+
+    @Override
+    public BpmnModelInstance clone()
+    {
+        return wrappedInstance.clone();
+    }
+
+    @Override
+    public Definitions getDefinitions()
+    {
+        return wrappedInstance.getDefinitions();
+    }
+
+    @Override
+    public void setDefinitions(Definitions arg0)
+    {
+        wrappedInstance.setDefinitions(arg0);
+    }
+
+    public TngpModelInstance taskAttributes(String taskId, String taskType, int taskQueueId)
+    {
+        final ModelElementInstance task = wrappedInstance.getModelElementById(taskId);
+
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskType"", taskType);
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskQueueId"", String.valueOf(taskQueueId));
+
+        return this;
+    }
+
+    public static TngpModelInstance wrap(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance);
+    }
+
+    public static TngpModelInstance wrapCopy(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance.clone());
+    }
+}

diff --git a/packages/nc-gui/components.d.ts b/packages/nc-gui/components.d.ts
index b7e6585..bb86478 100644
--- a/packages/nc-gui/components.d.ts
+++ b/packages/nc-gui/components.d.ts
@@ -81,7 +81,6 @@ declare module '@vue/runtime-core' {
     ClaritySuccessLine: typeof import('~icons/clarity/success-line')['default']
     EvaEmailOutline: typeof import('~icons/eva/email-outline')['default']
     IcBaselineMoreVert: typeof import('~icons/ic/baseline-more-vert')['default']
-    Icon: typeof import('~icons/ic/on')['default']
     IcOutlineInsertDriveFile: typeof import('~icons/ic/outline-insert-drive-file')['default']
     IcRoundEdit: typeof import('~icons/ic/round-edit')['default']
     IcRoundKeyboardArrowDown: typeof import('~icons/ic/round-keyboard-arrow-down')['default']
",2,"[""6ed56ce9ae743ba9a87e6c9643cc06b1de7b748d"", ""d1d55e787b7d07f763852602b9939a5394607fd9""]","[""feat"", ""fix""]"
fix build orderingupdate `cargo-make` for `v0.35.3`,"diff --git a/scripts/build.mjs b/scripts/build.mjs
index 204854f..b3cf067 100644
--- a/scripts/build.mjs
+++ b/scripts/build.mjs
@@ -3,8 +3,8 @@ import { write } from 'fsxx';
 import { info, success } from './helpers.mjs';
 
 await $`rm -rf dist/*`;
-await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 await $`unbuild`;
+await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 
 const packages = [
   'jsx-runtime',

diff --git a/CHANGELOG.md b/CHANGELOG.md
index 5e125e3..52d9b6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 * Fix: resizing/scrolling through heavily wrapped panes no longer hangs (https://github.com/zellij-org/zellij/pull/814)
 * Terminal compatibility: properly handle HOME/END keys in eg. vim/zsh (https://github.com/zellij-org/zellij/pull/815)
 * Fix: Typo (https://github.com/zellij-org/zellij/pull/821)
+* Fix: Update `cargo-make` instructions post `v0.35.3` (https://github.com/zellij-org/zellij/pull/819)
 
 ## [0.19.0] - 2021-10-20
 * Fix: Prevent text overwrite when scrolled up (https://github.com/zellij-org/zellij/pull/655)
",2,"[""c323d59c607cabc91f17a78528d998f376f30b10"", ""0cfc5633d37ea06f645649138323f1820e18bdee""]","[""build"", ""docs""]"
add testsadded suported tuple types,"diff --git a/Cargo.lock b/Cargo.lock
index 84d5d07..6ad05da 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -293,6 +293,7 @@ version = ""0.1.0""
 dependencies = [
  ""git-cliff-core"",
  ""log"",
+ ""pretty_assertions"",
  ""pretty_env_logger"",
  ""structopt"",
 ]
diff --git a/git-cliff-core/src/lib.rs b/git-cliff-core/src/lib.rs
index 3b18ba0..a560c94 100644
--- a/git-cliff-core/src/lib.rs
+++ b/git-cliff-core/src/lib.rs
@@ -1,6 +1,8 @@
 //! Highly customizable Changelog Generator
 #![warn(missing_docs, clippy::unwrap_used)]
 
+/// Export regex crate.
+pub use regex;
 /// Git commit.
 pub mod commit;
 /// Config file parser.
diff --git a/git-cliff/Cargo.toml b/git-cliff/Cargo.toml
index 41eb2e9..cc64b37 100644
--- a/git-cliff/Cargo.toml
+++ b/git-cliff/Cargo.toml
@@ -20,3 +20,6 @@ log = ""0.4.14""
 version = ""0.3""
 default-features = false
 features = [""suggestions"", ""color"", ""wrap_help""]
+
+[dev-dependencies]
+pretty_assertions = ""0.7""
diff --git a/git-cliff/src/changelog.rs b/git-cliff/src/changelog.rs
index 3f9e994..23ea186 100644
--- a/git-cliff/src/changelog.rs
+++ b/git-cliff/src/changelog.rs
@@ -115,3 +115,171 @@ impl<'a> Changelog<'a> {
 		Ok(())
 	}
 }
+
+#[cfg(test)]
+mod test {
+	use super::*;
+	use git_cliff_core::config::{
+		ChangelogConfig,
+		CommitParser,
+		GitConfig,
+	};
+	use git_cliff_core::regex::Regex;
+	use pretty_assertions::assert_eq;
+	use std::str;
+	#[test]
+	fn changelog_generator() -> Result<()> {
+		let config = Config {
+			changelog: ChangelogConfig {
+				header: Some(String::from(""# Changelog"")),
+				body:   String::from(
+					r#""{% if version %}
+				## Release [{{ version }}] - {{ timestamp | date(format=""%Y-%m-%d"") }}
+				({{ commit_id }}){% else %}
+				## Unreleased{% endif %}
+				{% for group, commits in commits | group_by(attribute=""group"") %}
+				### {{ group }}{% for group, commits in commits | group_by(attribute=""scope"") %}
+				#### {{ group }}{% for commit in commits %}
+				- {{ commit.message }}{% endfor %}
+				{% endfor %}{% endfor %}""#,
+				)
+				.replace(""				"", """"),
+				footer: Some(String::from(""------------"")),
+			},
+			git:       GitConfig {
+				conventional_commits: true,
+				commit_parsers:       Some(vec![
+					CommitParser {
+						message: Regex::new(""feat*"").ok(),
+						body:    None,
+						group:   Some(String::from(""New features"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new(""fix*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Bug Fixes"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new("".*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Other"")),
+						skip:    None,
+					},
+				]),
+				filter_commits:       Some(false),
+				tag_pattern:          String::new(),
+				skip_tags:            Regex::new(""v3.*"").ok(),
+			},
+		};
+		let test_release = Release {
+			version:   Some(String::from(""v1.0.0"")),
+			commits:   vec![
+				Commit::new(
+					String::from(""0bc123""),
+					String::from(""feat(app): add cool features""),
+				),
+				Commit::new(
+					String::from(""0werty""),
+					String::from(""style(ui): make good stuff""),
+				),
+				Commit::new(
+					String::from(""0w3rty""),
+					String::from(""fix(ui): fix more stuff""),
+				),
+				Commit::new(
+					String::from(""0jkl12""),
+					String::from(""chore(app): do nothing""),
+				),
+			],
+			commit_id: Some(String::from(""0bc123"")),
+			timestamp: 50000000,
+			previous:  None,
+		};
+		let releases = vec![
+			test_release.clone(),
+			Release {
+				version: Some(String::from(""v3.0.0"")),
+				commits: vec![Commit::new(
+					String::from(""n0thin""),
+					String::from(""feat(xyz): skip commit""),
+				)],
+				..Release::default()
+			},
+			Release {
+				version:   None,
+				commits:   vec![
+					Commit::new(
+						String::from(""abc123""),
+						String::from(""feat(app): add xyz""),
+					),
+					Commit::new(
+						String::from(""abc124""),
+						String::from(""docs(app): document zyx""),
+					),
+					Commit::new(String::from(""def789""), String::from(""merge #4"")),
+					Commit::new(
+						String::from(""qwerty""),
+						String::from(""fix(app): fix abc""),
+					),
+					Commit::new(
+						String::from(""hjkl12""),
+						String::from(""chore(ui): do boring stuff""),
+					),
+				],
+				commit_id: None,
+				timestamp: 1000,
+				previous:  Some(Box::new(test_release)),
+			},
+		];
+		let changelog = Changelog::new(releases, &config)?;
+		let mut out = Vec::new();
+		changelog.generate(&mut out)?;
+		assert_eq!(
+			String::from(
+				r#""# Changelog
+
+			## Unreleased
+
+			### Bug Fixes
+			#### app
+			- fix abc
+
+			### New features
+			#### app
+			- add xyz
+
+			### Other
+			#### app
+			- document zyx
+
+			#### ui
+			- do boring stuff
+
+			## Release [v1.0.0] - 1971-08-02
+			(0bc123)
+
+			### Bug Fixes
+			#### ui
+			- fix more stuff
+
+			### New features
+			#### app
+			- add cool features
+
+			### Other
+			#### app
+			- do nothing
+
+			#### ui
+			- make good stuff
+			------------
+			""#
+			)
+			.replace(""			"", """"),
+			str::from_utf8(&out).unwrap()
+		);
+		Ok(())
+	}
+}

diff --git a/src/List/Tuple.ts b/src/List/Tuple.ts
index 4c59caa..6e45503 100644
--- a/src/List/Tuple.ts
+++ b/src/List/Tuple.ts
@@ -1,15 +1,17 @@
-/** A [[Tuple]]
+import {NonNullable} from '../Object/NonNullable'
+
+/** A [[Tuple]] (supported)
  * @param A its type
- * @returns **`any[]`**
+ * @returns **`A[]`**
  * @example
  * ```ts
- * type list0 = [1, 2, 3]
- * type list1 = number[]
+ * type tuple0 = [1, 20, 42]
+ * type tuple1 = ['at', 420]
  * ```
  */
-export type Tuple = [
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-]
+export type Tuple<A = any> = NonNullable<[
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+]>
",2,"[""8ee0611fbf0cd89abe7ae588f22e6ecb843598ea"", ""2954a0955ce9af6acb345ed1e8328e145ad30475""]","[""test"", ""refactor""]"
"cleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.never call ""onStart"" prop when idle","diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:

diff --git a/packages/core/src/SpringValue.ts b/packages/core/src/SpringValue.ts
index 18494a8..cbc4f27 100644
--- a/packages/core/src/SpringValue.ts
+++ b/packages/core/src/SpringValue.ts
@@ -596,11 +596,11 @@ export class SpringValue<T = any> extends AnimationValue<T> {
   /** Notify change observers */
   protected _onChange(value: T, idle = false) {
     const anim = this.animation
-    if (!anim.changed) {
+    if (!anim.changed && !idle) {
       anim.changed = true
       // The ""onStart"" prop is called on the first change after entering the
       // frameloop, but never for immediate animations.
-      if (anim.onStart && !anim.immediate) {
+      if (anim.onStart) {
         anim.onStart(this)
       }
     }
",2,"[""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7"", ""c8e0ae8612df3d6f2831acc004aaac332f6105e4""]","[""refactor"", ""fix""]"
"remove deprecated settings

Removes deprecated ZEEBE_HOST environment variable, and removes
unnecessary log level environment variable, since it's already the
default in the log fileadd riscv64gc-unknown-linux-gnu","diff --git a/Dockerfile b/Dockerfile
index 6762a39..7f380cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -34,7 +34,6 @@ RUN wget -O - https://github.com/jvm-profiling-tools/async-profiler/releases/dow
 FROM ${APP_ENV} as app
 
 ENV ZB_HOME=/usr/local/zeebe \
-    ZEEBE_LOG_LEVEL=info \
     ZEEBE_BROKER_GATEWAY_NETWORK_HOST=0.0.0.0 \
     ZEEBE_STANDALONE_GATEWAY=false
 ENV PATH ""${ZB_HOME}/bin:${PATH}""
diff --git a/docker/utils/startup.sh b/docker/utils/startup.sh
index bc8d2fc..0fcde2b 100755
--- a/docker/utils/startup.sh
+++ b/docker/utils/startup.sh
@@ -1,17 +1,14 @@
 #!/bin/bash -xeu
 
-# legacy support
-# This environment variable was used to set the gatewway cluster host in standalone and embedded mode.
-# Now, there are two dedicated environment variables for the two different deployment scenarios.
-export ZEEBE_HOST=${ZEEBE_HOST:-$(hostname -i)}
-# Legacy support
+HOST=$(hostname -i)
 
 if [ ""$ZEEBE_STANDALONE_GATEWAY"" = ""true"" ]; then
-    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_GATEWAY_NETWORK_HOST=${ZEEBE_GATEWAY_NETWORK_HOST:-${HOST}}
+    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${HOST}}
 
     exec /usr/local/zeebe/bin/gateway
 else
-    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${HOST}}
     export ZEEBE_BROKER_GATEWAY_CLUSTER_HOST=${ZEEBE_BROKER_GATEWAY_CLUSTER_HOST:-${ZEEBE_BROKER_NETWORK_HOST}}
 
     exec /usr/local/zeebe/bin/broker

diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }
",2,"[""e4a11fd5c34942ba12737f1c8c084489428ee274"", ""173553c0372e66e03bdab19e0e6c2dd44daa14a0""]","[""build"", ""cicd""]"
"never call ""onStart"" prop when idleadd numberOfLines prop to DataTableTitle (#863)

Closes #848","diff --git a/packages/core/src/SpringValue.ts b/packages/core/src/SpringValue.ts
index 18494a8..cbc4f27 100644
--- a/packages/core/src/SpringValue.ts
+++ b/packages/core/src/SpringValue.ts
@@ -596,11 +596,11 @@ export class SpringValue<T = any> extends AnimationValue<T> {
   /** Notify change observers */
   protected _onChange(value: T, idle = false) {
     const anim = this.animation
-    if (!anim.changed) {
+    if (!anim.changed && !idle) {
       anim.changed = true
       // The ""onStart"" prop is called on the first change after entering the
       // frameloop, but never for immediate animations.
-      if (anim.onStart && !anim.immediate) {
+      if (anim.onStart) {
         anim.onStart(this)
       }
     }

diff --git a/src/components/DataTable/DataTableTitle.js b/src/components/DataTable/DataTableTitle.js
index bfcf07e..d764fd5 100644
--- a/src/components/DataTable/DataTableTitle.js
+++ b/src/components/DataTable/DataTableTitle.js
@@ -27,6 +27,10 @@ type Props = React.ElementConfig<typeof TouchableWithoutFeedback> & {|
    */
   sortDirection?: 'ascending' | 'descending',
   /**
+   * The number of lines to show.
+   */
+  numberOfLines?: number,
+  /**
    * Function to execute on press.
    */
   onPress?: () => mixed,
@@ -44,6 +48,10 @@ type State = {
 class DataTableTitle extends React.Component<Props, State> {
   static displayName = 'DataTable.Title';
 
+  static defaultProps = {
+    numberOfLines: 1,
+  };
+
   state = {
     spinAnim: new Animated.Value(
       this.props.sortDirection === 'ascending' ? 0 : 1
@@ -70,6 +78,7 @@ class DataTableTitle extends React.Component<Props, State> {
       sortDirection,
       theme,
       style,
+      numberOfLines,
       ...rest
     } = this.props;
 
@@ -99,7 +108,7 @@ class DataTableTitle extends React.Component<Props, State> {
               styles.cell,
               sortDirection ? styles.sorted : { color: textColor },
             ]}
-            numberOfLines={1}
+            numberOfLines={numberOfLines}
           >
             {children}
           </Text>
",2,"[""c8e0ae8612df3d6f2831acc004aaac332f6105e4"", ""f9a094918b62534614c47aa8a13f33aec751a1e0""]","[""fix"", ""feat""]"
make it mode lessupdate `cargo-make` for `v0.35.3`,"diff --git a/core/src/components/slides/slides.tsx b/core/src/components/slides/slides.tsx
index 48fd53f..d5c2f75 100644
--- a/core/src/components/slides/slides.tsx
+++ b/core/src/components/slides/slides.tsx
@@ -1,7 +1,6 @@
 import { Component, Element, Event, EventEmitter, Method, Prop, Watch } from '@stencil/core';
 
 import { Mode } from '../../interface.js';
-import { createThemedClasses } from '../../utils/theme.js';
 
 import { Swiper } from './vendor/swiper.js';
 
@@ -15,6 +14,7 @@ import { Swiper } from './vendor/swiper.js';
   shadow: true
 })
 export class Slides {
+
   private container!: HTMLElement;
   private swiper: any;
 
@@ -391,12 +391,6 @@ export class Slides {
     return { ...swiperOptions, ...this.options, ...eventOptions };
   }
 
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'slides')
-    };
-  }
-
   render() {
     return (
       <div class=""swiper-container"" ref={el => this.container = el as HTMLElement }>
diff --git a/core/src/components/thumbnail/thumbnail.ios.scss b/core/src/components/thumbnail/thumbnail.ios.scss
deleted file mode 100644
index e3add45..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.ios.vars"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-ios-width};
-  --border-radius: #{$thumbnail-ios-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.ios.vars.scss b/core/src/components/thumbnail/thumbnail.ios.vars.scss
deleted file mode 100644
index 85d53e5..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.ios"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-ios-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-ios-height:                  $thumbnail-ios-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-ios-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.md.scss b/core/src/components/thumbnail/thumbnail.md.scss
deleted file mode 100644
index 0fbb2ca..0000000
--- a/core/src/components/thumbnail/thumbnail.md.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.md.vars"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-md-width};
-  --border-radius: #{$thumbnail-md-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.md.vars.scss b/core/src/components/thumbnail/thumbnail.md.vars.scss
deleted file mode 100644
index 94e48b2..0000000
--- a/core/src/components/thumbnail/thumbnail.md.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.md"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-md-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-md-height:                  $thumbnail-md-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-md-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.scss b/core/src/components/thumbnail/thumbnail.scss
index 8ac3a22..8af268d 100644
--- a/core/src/components/thumbnail/thumbnail.scss
+++ b/core/src/components/thumbnail/thumbnail.scss
@@ -9,6 +9,8 @@
    * @prop --border-radius: Border radius of the thumbnail
    * @prop --size: Size of the thumbnail
    */
+  --size: 48px;
+  --border-radius: 0;
 
   @include border-radius(var(--border-radius));
 
diff --git a/core/src/components/thumbnail/thumbnail.tsx b/core/src/components/thumbnail/thumbnail.tsx
index 50ff2c2..de76593 100644
--- a/core/src/components/thumbnail/thumbnail.tsx
+++ b/core/src/components/thumbnail/thumbnail.tsx
@@ -1,25 +1,11 @@
 import { Component } from '@stencil/core';
 
-import { Mode } from '../../interface';
-import { createThemedClasses } from '../../utils/theme';
-
 @Component({
   tag: 'ion-thumbnail',
-  styleUrls: {
-    ios: 'thumbnail.ios.scss',
-    md: 'thumbnail.md.scss'
-  },
+  styleUrl: 'thumbnail.scss',
   shadow: true
 })
 export class Thumbnail {
-  mode!: Mode;
-
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'thumbnail')
-    };
-  }
-
   render() {
     return <slot></slot>;
   }

diff --git a/CHANGELOG.md b/CHANGELOG.md
index 5e125e3..52d9b6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 * Fix: resizing/scrolling through heavily wrapped panes no longer hangs (https://github.com/zellij-org/zellij/pull/814)
 * Terminal compatibility: properly handle HOME/END keys in eg. vim/zsh (https://github.com/zellij-org/zellij/pull/815)
 * Fix: Typo (https://github.com/zellij-org/zellij/pull/821)
+* Fix: Update `cargo-make` instructions post `v0.35.3` (https://github.com/zellij-org/zellij/pull/819)
 
 ## [0.19.0] - 2021-10-20
 * Fix: Prevent text overwrite when scrolled up (https://github.com/zellij-org/zellij/pull/655)
",2,"[""771857b1df9470ebc15357e8879118a72c649d5b"", ""0cfc5633d37ea06f645649138323f1820e18bdee""]","[""refactor"", ""docs""]"
"buffer assert and bpmn model api helper class

related to camunda-tngp/camunda-tngp#23repository creation","diff --git a/test-util/pom.xml b/test-util/pom.xml
index a097651..b6518ee 100644
--- a/test-util/pom.xml
+++ b/test-util/pom.xml
@@ -20,6 +20,7 @@
     <project.build.sourceEncoding>utf-8</project.build.sourceEncoding>
     <!-- TODO: Move to common parent -->
     <agrona.version>0.4.11</agrona.version>
+    <camunda.version>7.6.0-SNAPSHOT</camunda.version>
   </properties>
 
   <dependencies>
@@ -30,6 +31,13 @@
       <version>${agrona.version}</version>
       <scope>provided</scope>
     </dependency>
+    
+    <dependency>
+      <groupId>org.camunda.bpm.model</groupId>
+      <artifactId>camunda-bpmn-model</artifactId>
+      <version>${camunda.version}</version>
+      <scope>provided</scope>
+    </dependency>
 
     <dependency>
       <groupId>junit</groupId>
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
index 37e3a6f..b8d9b26 100644
--- a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
@@ -14,7 +14,7 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         super(actual, BufferAssert.class);
     }
 
-    public static BufferAssert assertThat(DirectBuffer buffer)
+    public static BufferAssert assertThatBuffer(DirectBuffer buffer)
     {
         return new BufferAssert(buffer);
     }
@@ -41,4 +41,16 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         return hasBytes(expected, 0);
     }
 
+    public BufferAssert hasCapacity(int expectedCapacity)
+    {
+        isNotNull();
+
+        if (expectedCapacity != actual.capacity())
+        {
+            failWithMessage(""Expected capacity "" + expectedCapacity + "" but was "" + actual.capacity());
+        }
+
+        return this;
+    }
+
 }
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
new file mode 100644
index 0000000..6f0d134
--- /dev/null
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
@@ -0,0 +1,121 @@
+package org.camunda.tngp.broker.test.util.bpmn;
+
+import java.util.Collection;
+
+import org.camunda.bpm.model.bpmn.BpmnModelInstance;
+import org.camunda.bpm.model.bpmn.impl.BpmnModelConstants;
+import org.camunda.bpm.model.bpmn.instance.Definitions;
+import org.camunda.bpm.model.xml.Model;
+import org.camunda.bpm.model.xml.instance.DomDocument;
+import org.camunda.bpm.model.xml.instance.ModelElementInstance;
+import org.camunda.bpm.model.xml.type.ModelElementType;
+import org.camunda.bpm.model.xml.validation.ModelElementValidator;
+import org.camunda.bpm.model.xml.validation.ValidationResults;
+
+public class TngpModelInstance implements BpmnModelInstance
+{
+    protected BpmnModelInstance wrappedInstance;
+
+    public TngpModelInstance(BpmnModelInstance wrappedInstance)
+    {
+        this.wrappedInstance = wrappedInstance;
+    }
+
+    @Override
+    public DomDocument getDocument()
+    {
+        return wrappedInstance.getDocument();
+    }
+
+    @Override
+    public ModelElementInstance getDocumentElement()
+    {
+        return wrappedInstance.getDocumentElement();
+    }
+
+    @Override
+    public void setDocumentElement(ModelElementInstance documentElement)
+    {
+        wrappedInstance.setDocumentElement(documentElement);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(Class<T> type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(ModelElementType type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public Model getModel()
+    {
+        return wrappedInstance.getModel();
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T getModelElementById(String id)
+    {
+        return wrappedInstance.getModelElementById(id);
+    }
+
+    @Override
+    public Collection<ModelElementInstance> getModelElementsByType(ModelElementType referencingType)
+    {
+        return wrappedInstance.getModelElementsByType(referencingType);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> Collection<T> getModelElementsByType(Class<T> referencingClass)
+    {
+        return wrappedInstance.getModelElementsByType(referencingClass);
+    }
+
+    @Override
+    public ValidationResults validate(Collection<ModelElementValidator<?>> validators)
+    {
+        return wrappedInstance.validate(validators);
+    }
+
+    @Override
+    public BpmnModelInstance clone()
+    {
+        return wrappedInstance.clone();
+    }
+
+    @Override
+    public Definitions getDefinitions()
+    {
+        return wrappedInstance.getDefinitions();
+    }
+
+    @Override
+    public void setDefinitions(Definitions arg0)
+    {
+        wrappedInstance.setDefinitions(arg0);
+    }
+
+    public TngpModelInstance taskAttributes(String taskId, String taskType, int taskQueueId)
+    {
+        final ModelElementInstance task = wrappedInstance.getModelElementById(taskId);
+
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskType"", taskType);
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskQueueId"", String.valueOf(taskQueueId));
+
+        return this;
+    }
+
+    public static TngpModelInstance wrap(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance);
+    }
+
+    public static TngpModelInstance wrapCopy(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance.clone());
+    }
+}

diff --git a/server/src/services/repository.service.ts b/server/src/services/repository.service.ts
index 3869c98..d675b30 100644
--- a/server/src/services/repository.service.ts
+++ b/server/src/services/repository.service.ts
@@ -19,6 +19,8 @@ export class RepositoryService {
       return;
     }
 
+    await this.createTeam(this.github, this.getTeamName(course), course.id);
+
     const studentRepo = getCustomRepository(StudentRepository);
     const students = await studentRepo.findActiveByCourseId(this.courseId);
 
@@ -31,8 +33,8 @@ export class RepositoryService {
         if (mentorGithubId) {
           await this.inviteMentor(mentorGithubId, course);
         }
-        await this.addTeamToRepository(this.github, course, student.githubId);
       }
+      await this.addTeamToRepository(this.github, course, student.githubId);
       if (record?.repository) {
         result.push({ repository: record.repository });
       }
",2,"[""6ed56ce9ae743ba9a87e6c9643cc06b1de7b748d"", ""87d5d4e55ab7149b593d29410f1fe426ba2447d4""]","[""feat"", ""fix""]"
convert `run_tag_values_test_case` to a functionsetup jest and add m.ts tests,"diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });
",2,"[""1db13ec43727aca872a0f3836e4023ed85db665e"", ""229b53a632ea97d47c4be11f096bdd828fb415d8""]","[""refactor"", ""test""]"
update wrapping tests for v7add fallible peek_last_token(),"diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });

diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.
",2,"[""317f4eefecddfb1392ca71d551840f446feee302"", ""63eab619e6166eb6cab948028a7b89bf059dd878""]","[""test"", ""refactor""]"
"nginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>[gn] fix include_dirs ordering error","diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection

diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)
",2,"[""e12d9e77a6fd531a22325337838a841b1c67f00d"", ""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945""]","[""docs"", ""build""]"
convert `run_tag_values_test_case` to a functionupdated react demo parcel command,"diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]

diff --git a/demo/react/package.json b/demo/react/package.json
index be28bf9..32d0952 100644
--- a/demo/react/package.json
+++ b/demo/react/package.json
@@ -12,7 +12,7 @@
   },
   ""scripts"": {
     ""start"": ""parcel serve public/index.html --no-cache --open"",
-    ""build"": ""parcel build -t browser -d dist public/index.html --no-source-maps""
+    ""build"": ""parcel build --target browser --dist-dir dist public/index.html --no-source-maps""
   },
   ""bugs"": {
     ""url"": ""https://github.com/matteobruni/tsparticles/issues""
",2,"[""1db13ec43727aca872a0f3836e4023ed85db665e"", ""32b92cfa0b74a6c25990e32ac6aab12b8496794c""]","[""refactor"", ""build""]"
"update Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909autostart feature fixed","diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();
",2,"[""c2ee5cd5e709afd15c5565ee009a0d204403a119"", ""bed78248c941d57ad4cc20a455147e186e97c7a1""]","[""docs"", ""fix""]"
Fix typoadd riscv64gc-unknown-linux-gnu,"diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }
",2,"[""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""173553c0372e66e03bdab19e0e6c2dd44daa14a0""]","[""docs"", ""cicd""]"
"cleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.remove ubuntu-latest from job title where that is the only os","diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
",2,"[""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7"", ""74e9de5ec97dc013a52aa063dff0f40ac74c407b""]","[""refactor"", ""cicd""]"
add benchmark for known-slow table expressionrepository creation,"diff --git a/.gitignore b/.gitignore
index 2e99ad3..eef9203 100644
--- a/.gitignore
+++ b/.gitignore
@@ -95,3 +95,4 @@ docs/backends/support_matrix.csv
 __pycache__
 tags
 .DS_Store
+prof/
diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index ac19aaf..36aed0e 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -602,3 +602,93 @@ def test_multiple_joins(benchmark, num_joins, num_columns):
         name=""t"",
     )
     benchmark(multiple_joins, table, num_joins)
+
+
+@pytest.fixture
+def customers():
+    return ibis.table(
+        dict(
+            customerid=""int32"",
+            name=""string"",
+            address=""string"",
+            citystatezip=""string"",
+            birthdate=""date"",
+            phone=""string"",
+            timezone=""string"",
+            lat=""float64"",
+            long=""float64"",
+        ),
+        name=""customers"",
+    )
+
+
+@pytest.fixture
+def orders():
+    return ibis.table(
+        dict(
+            orderid=""int32"",
+            customerid=""int32"",
+            ordered=""timestamp"",
+            shipped=""timestamp"",
+            items=""string"",
+            total=""float64"",
+        ),
+        name=""orders"",
+    )
+
+
+@pytest.fixture
+def orders_items():
+    return ibis.table(
+        dict(orderid=""int32"", sku=""string"", qty=""int32"", unit_price=""float64""),
+        name=""orders_items"",
+    )
+
+
+@pytest.fixture
+def products():
+    return ibis.table(
+        dict(
+            sku=""string"",
+            desc=""string"",
+            weight_kg=""float64"",
+            cost=""float64"",
+            dims_cm=""string"",
+        ),
+        name=""products"",
+    )
+
+
+@pytest.mark.benchmark(group=""compilation"")
+@pytest.mark.parametrize(
+    ""module"",
+    [
+        pytest.param(
+            mod,
+            marks=pytest.mark.xfail(
+                condition=mod in _XFAIL_COMPILE_BACKENDS,
+                reason=f""{mod} backend doesn't support compiling UnboundTable"",
+            ),
+        )
+        for mod in _backends
+    ],
+)
+def test_compile_with_drops(
+    benchmark, module, customers, orders, orders_items, products
+):
+    expr = (
+        customers.join(orders, ""customerid"")
+        .join(orders_items, ""orderid"")
+        .join(products, ""sku"")
+        .drop(""customerid"", ""qty"", ""total"", ""items"")
+        .drop(""dims_cm"", ""cost"")
+        .mutate(o_date=lambda t: t.shipped.date())
+        .filter(lambda t: t.ordered == t.shipped)
+    )
+
+    try:
+        mod = getattr(ibis, module)
+    except (AttributeError, ImportError) as e:
+        pytest.skip(str(e))
+    else:
+        benchmark(mod.compile, expr)

diff --git a/server/src/services/repository.service.ts b/server/src/services/repository.service.ts
index 3869c98..d675b30 100644
--- a/server/src/services/repository.service.ts
+++ b/server/src/services/repository.service.ts
@@ -19,6 +19,8 @@ export class RepositoryService {
       return;
     }
 
+    await this.createTeam(this.github, this.getTeamName(course), course.id);
+
     const studentRepo = getCustomRepository(StudentRepository);
     const students = await studentRepo.findActiveByCourseId(this.courseId);
 
@@ -31,8 +33,8 @@ export class RepositoryService {
         if (mentorGithubId) {
           await this.inviteMentor(mentorGithubId, course);
         }
-        await this.addTeamToRepository(this.github, course, student.githubId);
       }
+      await this.addTeamToRepository(this.github, course, student.githubId);
       if (record?.repository) {
         result.push({ repository: record.repository });
       }
",2,"[""e9617f0854030e70365eb264bcb3b58078e79e9e"", ""87d5d4e55ab7149b593d29410f1fe426ba2447d4""]","[""test"", ""fix""]"
support use meta key select multiple elementremove appear css animation,"diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index ab68624..aeee7b7 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -277,9 +277,11 @@ export default class LogicFlow {
   }
   /**
    * 将图形选中
+   * @param id 选择元素ID
+   * @param multiple 是否允许多选，如果为true，不会将上一个选中的元素重置
    */
-  select(id: string) {
-    this.graphModel.selectElementById(id);
+  select(id: string, multiple = false) {
+    this.graphModel.selectElementById(id, multiple);
   }
   /**
    * 将图形定位到画布中心
diff --git a/packages/core/src/model/EditConfigModel.ts b/packages/core/src/model/EditConfigModel.ts
index 67e334a..83e5f16 100644
--- a/packages/core/src/model/EditConfigModel.ts
+++ b/packages/core/src/model/EditConfigModel.ts
@@ -25,6 +25,7 @@ const SilentConfig = {
   edgeTextEdit: false,
   nodeTextDraggable: false,
   edgeTextDraggable: false,
+  metaKeyMultipleSelected: false,
 };
 
 /**
@@ -42,6 +43,7 @@ export default class EditConfigModel {
   @observable edgeTextEdit = true; // 允许连线文本可以编辑
   @observable nodeTextDraggable = false; // 允许节点文本可以拖拽
   @observable edgeTextDraggable = false; // 允许连线文本可以拖拽
+  @observable metaKeyMultipleSelected = false; // 允许meta多选元素
   constructor(data) {
     const keys = [
       'stopZoomGraph',
@@ -55,6 +57,7 @@ export default class EditConfigModel {
       'edgeTextEdit',
       'nodeTextDraggable',
       'edgeTextDraggable',
+      'metaKeyMultipleSelected',
     ];
     const { isSilentMode, textEdit } = data;
     if (isSilentMode) {
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 9667f4d..310daf4 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -34,6 +34,7 @@ class GraphModel {
   height: number;
   topElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
   selectElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
+  selectElements = new Map<string, IBaseModel>(); // 多选
   @observable edgeType: string;
   @observable nodes: BaseNodeModel[] = [];
   @observable activeElement: IBaseModel;
@@ -50,7 +51,6 @@ class GraphModel {
   @observable gridSize = 1;
   @observable partial = false; // 是否开启局部渲染
   @observable fakerNode: BaseNodeModel;
-  // @observable selectElements = new Map<string, IBaseModel>(); // 多选还没有做，先不加
   constructor(config) {
     const {
       container,
@@ -456,24 +456,44 @@ class GraphModel {
   }
 
   @action
-  selectNodeById(id) {
-    this.selectElement?.setSelected(false);
+  selectNodeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.nodesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectEdgeById(id) {
-    this.selectElement?.setSelected(false);
+  selectEdgeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.edgesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectElementById(id: string) {
-    this.selectElement?.setSelected(false);
+  selectElementById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
+  }
+
+  @action
+  clearSelectElements() {
+    this.selectElements.forEach(element => {
+      element.setSelected(false);
+    });
+    this.selectElements.clear();
   }
 
   /* 修改连线类型 */
diff --git a/packages/core/src/view/edge/BaseEdge.tsx b/packages/core/src/view/edge/BaseEdge.tsx
index d45ea9e..d7c8f38 100644
--- a/packages/core/src/view/edge/BaseEdge.tsx
+++ b/packages/core/src/view/edge/BaseEdge.tsx
@@ -178,7 +178,8 @@ export default class BaseEdge extends Component<IProps> {
   handleClick = (e) => {
     const { model, graphModel, eventCenter } = this.props;
     graphModel.toFront(model.id);
-    graphModel.selectEdgeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectEdgeById(model.id, e.metaKey && metaKeyMultipleSelected);
     // 边数据
     const edgeData = model?.getData();
     const position = graphModel.getPointByClient({
diff --git a/packages/core/src/view/node/BaseNode.tsx b/packages/core/src/view/node/BaseNode.tsx
index 140889c..5ee3975 100644
--- a/packages/core/src/view/node/BaseNode.tsx
+++ b/packages/core/src/view/node/BaseNode.tsx
@@ -275,7 +275,8 @@ export default abstract class BaseNode extends Component<IProps, Istate> {
       }, 400);
     }
     graphModel.toFront(model.id);
-    graphModel.selectNodeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectNodeById(model.id, e.metaKey && metaKeyMultipleSelected);
     this.preStartTime = this.startTime;
   };
   handleContextMenu = (ev: MouseEvent) => {
diff --git a/packages/core/src/view/overlay/CanvasOverlay.tsx b/packages/core/src/view/overlay/CanvasOverlay.tsx
index ef11822..8c79fd2 100644
--- a/packages/core/src/view/overlay/CanvasOverlay.tsx
+++ b/packages/core/src/view/overlay/CanvasOverlay.tsx
@@ -104,9 +104,9 @@ class CanvasOverlay extends Component<IProps, Istate> {
     const target = ev.target as HTMLElement;
     if (target.getAttribute('name') === 'canvas-overlay') {
       const { graphModel, eventCenter } = this.props;
-      const { selectElement, textEditElement } = graphModel;
-      if (selectElement) {
-        selectElement.setSelected(false);
+      const { textEditElement, selectElements } = graphModel;
+      if (selectElements.size > 0) {
+        graphModel.clearSelectElements();
       }
       if (textEditElement) {
         textEditElement.setElementState(ElementState.DEFAULT);
diff --git a/packages/extension/examples/bpmn/index.html b/packages/extension/examples/bpmn/index.html
index 7a68d6f..f7ea87d 100644
--- a/packages/extension/examples/bpmn/index.html
+++ b/packages/extension/examples/bpmn/index.html
@@ -6,6 +6,7 @@
   <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
   <title>LOGIN FLOW</title>
   <link rel=""stylesheet"" href=""/core/dist/style/index.css"">
+  <link rel=""stylesheet"" href=""/extension/lib/style/index.css"">
   <style>
     html,body {
       padding: 0;
@@ -129,11 +130,14 @@
     </div>
   </div>
   <script src=""/core/dist/logic-flow.js""></script>
+  <!-- <script src=""http://0.0.0.0:9090/logic-flow.js""></script> -->
   <script src=""/BpmnElement.js""></script>
   <script src=""/BpmnAdapter.js""></script>
+  <script src=""/Control.js""></script>
   <script src=""/Snapshot.js""></script>
   <script>
     LogicFlow.use(BpmnElement);
+    LogicFlow.use(Control);
     LogicFlow.use(BpmnAdapter);
     LogicFlow.use(Snapshot);
   </script>
diff --git a/packages/extension/examples/bpmn/index.js b/packages/extension/examples/bpmn/index.js
index 21d2da0..6f6aa39 100644
--- a/packages/extension/examples/bpmn/index.js
+++ b/packages/extension/examples/bpmn/index.js
@@ -3,6 +3,10 @@ window.onload = function () {
     container: document.querySelector('#app'),
     // fixme: grid成为了必传的了
     edgeTextDraggable: true,
+    metaKeyMultipleSelected: true,
+    // stopScrollGraph: true,
+    // stopMoveGraph: true,
+    // stopZoomGraph: true,
     grid: {
       type: 'dot',
       size: 20,

diff --git a/src/popup/Popup.tsx b/src/popup/Popup.tsx
index d485bb6..2abc22a 100644
--- a/src/popup/Popup.tsx
+++ b/src/popup/Popup.tsx
@@ -269,7 +269,6 @@ export class Popup extends React.Component<{ t: TranslationFunction }, PopupStat
         <CSSTransition
           classNames='fade'
           in={!!currentTabUrl}
-          appear
           timeout={500}
           exit={false}
           mountOnEnter
",2,"[""e137f9fdbdb6bf3f85c3f7ac9323785e445844c8"", ""47ef9104e4a89e80d7cc6c1950bc080841da4a7b""]","[""feat"", ""refactor""]"
"initialize threejs objects in defaultRef, to fix undefined type errorsremove ubuntu-latest from job title where that is the only os","diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
",2,"[""2561f4ade46fc9d59f289f328cc77733a6443697"", ""74e9de5ec97dc013a52aa063dff0f40ac74c407b""]","[""fix"", ""cicd""]"
[gn win] link comctl32.lib to fix component buildadd remote [skip ci],"diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 06c9003..e19c703 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -47,7 +47,10 @@ jobs:
           git config --global user.email 'ibis-squawk-bot[bot]@users.noreply.github.com'
 
       - name: fetch and rebase on top of upstream
-        run: git pull --rebase -X ours https://github.com/ibis-project/ibis master
+        run: |
+          git remote add upstream https://github.com/ibis-project/ibis
+          git fetch upstream
+          git rebase -X ours upstream/master
 
       - uses: tibdex/github-app-token@v1
         id: generate_pr_token
",2,"[""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""e96487ad7ce90b141219d9032fa2bed68d5dae6a""]","[""build"", ""cicd""]"
updated react demo parcel commandadd tests,"diff --git a/demo/react/package.json b/demo/react/package.json
index be28bf9..32d0952 100644
--- a/demo/react/package.json
+++ b/demo/react/package.json
@@ -12,7 +12,7 @@
   },
   ""scripts"": {
     ""start"": ""parcel serve public/index.html --no-cache --open"",
-    ""build"": ""parcel build -t browser -d dist public/index.html --no-source-maps""
+    ""build"": ""parcel build --target browser --dist-dir dist public/index.html --no-source-maps""
   },
   ""bugs"": {
     ""url"": ""https://github.com/matteobruni/tsparticles/issues""

diff --git a/Cargo.lock b/Cargo.lock
index 84d5d07..6ad05da 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -293,6 +293,7 @@ version = ""0.1.0""
 dependencies = [
  ""git-cliff-core"",
  ""log"",
+ ""pretty_assertions"",
  ""pretty_env_logger"",
  ""structopt"",
 ]
diff --git a/git-cliff-core/src/lib.rs b/git-cliff-core/src/lib.rs
index 3b18ba0..a560c94 100644
--- a/git-cliff-core/src/lib.rs
+++ b/git-cliff-core/src/lib.rs
@@ -1,6 +1,8 @@
 //! Highly customizable Changelog Generator
 #![warn(missing_docs, clippy::unwrap_used)]
 
+/// Export regex crate.
+pub use regex;
 /// Git commit.
 pub mod commit;
 /// Config file parser.
diff --git a/git-cliff/Cargo.toml b/git-cliff/Cargo.toml
index 41eb2e9..cc64b37 100644
--- a/git-cliff/Cargo.toml
+++ b/git-cliff/Cargo.toml
@@ -20,3 +20,6 @@ log = ""0.4.14""
 version = ""0.3""
 default-features = false
 features = [""suggestions"", ""color"", ""wrap_help""]
+
+[dev-dependencies]
+pretty_assertions = ""0.7""
diff --git a/git-cliff/src/changelog.rs b/git-cliff/src/changelog.rs
index 3f9e994..23ea186 100644
--- a/git-cliff/src/changelog.rs
+++ b/git-cliff/src/changelog.rs
@@ -115,3 +115,171 @@ impl<'a> Changelog<'a> {
 		Ok(())
 	}
 }
+
+#[cfg(test)]
+mod test {
+	use super::*;
+	use git_cliff_core::config::{
+		ChangelogConfig,
+		CommitParser,
+		GitConfig,
+	};
+	use git_cliff_core::regex::Regex;
+	use pretty_assertions::assert_eq;
+	use std::str;
+	#[test]
+	fn changelog_generator() -> Result<()> {
+		let config = Config {
+			changelog: ChangelogConfig {
+				header: Some(String::from(""# Changelog"")),
+				body:   String::from(
+					r#""{% if version %}
+				## Release [{{ version }}] - {{ timestamp | date(format=""%Y-%m-%d"") }}
+				({{ commit_id }}){% else %}
+				## Unreleased{% endif %}
+				{% for group, commits in commits | group_by(attribute=""group"") %}
+				### {{ group }}{% for group, commits in commits | group_by(attribute=""scope"") %}
+				#### {{ group }}{% for commit in commits %}
+				- {{ commit.message }}{% endfor %}
+				{% endfor %}{% endfor %}""#,
+				)
+				.replace(""				"", """"),
+				footer: Some(String::from(""------------"")),
+			},
+			git:       GitConfig {
+				conventional_commits: true,
+				commit_parsers:       Some(vec![
+					CommitParser {
+						message: Regex::new(""feat*"").ok(),
+						body:    None,
+						group:   Some(String::from(""New features"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new(""fix*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Bug Fixes"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new("".*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Other"")),
+						skip:    None,
+					},
+				]),
+				filter_commits:       Some(false),
+				tag_pattern:          String::new(),
+				skip_tags:            Regex::new(""v3.*"").ok(),
+			},
+		};
+		let test_release = Release {
+			version:   Some(String::from(""v1.0.0"")),
+			commits:   vec![
+				Commit::new(
+					String::from(""0bc123""),
+					String::from(""feat(app): add cool features""),
+				),
+				Commit::new(
+					String::from(""0werty""),
+					String::from(""style(ui): make good stuff""),
+				),
+				Commit::new(
+					String::from(""0w3rty""),
+					String::from(""fix(ui): fix more stuff""),
+				),
+				Commit::new(
+					String::from(""0jkl12""),
+					String::from(""chore(app): do nothing""),
+				),
+			],
+			commit_id: Some(String::from(""0bc123"")),
+			timestamp: 50000000,
+			previous:  None,
+		};
+		let releases = vec![
+			test_release.clone(),
+			Release {
+				version: Some(String::from(""v3.0.0"")),
+				commits: vec![Commit::new(
+					String::from(""n0thin""),
+					String::from(""feat(xyz): skip commit""),
+				)],
+				..Release::default()
+			},
+			Release {
+				version:   None,
+				commits:   vec![
+					Commit::new(
+						String::from(""abc123""),
+						String::from(""feat(app): add xyz""),
+					),
+					Commit::new(
+						String::from(""abc124""),
+						String::from(""docs(app): document zyx""),
+					),
+					Commit::new(String::from(""def789""), String::from(""merge #4"")),
+					Commit::new(
+						String::from(""qwerty""),
+						String::from(""fix(app): fix abc""),
+					),
+					Commit::new(
+						String::from(""hjkl12""),
+						String::from(""chore(ui): do boring stuff""),
+					),
+				],
+				commit_id: None,
+				timestamp: 1000,
+				previous:  Some(Box::new(test_release)),
+			},
+		];
+		let changelog = Changelog::new(releases, &config)?;
+		let mut out = Vec::new();
+		changelog.generate(&mut out)?;
+		assert_eq!(
+			String::from(
+				r#""# Changelog
+
+			## Unreleased
+
+			### Bug Fixes
+			#### app
+			- fix abc
+
+			### New features
+			#### app
+			- add xyz
+
+			### Other
+			#### app
+			- document zyx
+
+			#### ui
+			- do boring stuff
+
+			## Release [v1.0.0] - 1971-08-02
+			(0bc123)
+
+			### Bug Fixes
+			#### ui
+			- fix more stuff
+
+			### New features
+			#### app
+			- add cool features
+
+			### Other
+			#### app
+			- do nothing
+
+			#### ui
+			- make good stuff
+			------------
+			""#
+			)
+			.replace(""			"", """"),
+			str::from_utf8(&out).unwrap()
+		);
+		Ok(())
+	}
+}
",2,"[""32b92cfa0b74a6c25990e32ac6aab12b8496794c"", ""8ee0611fbf0cd89abe7ae588f22e6ecb843598ea""]","[""build"", ""test""]"
convert `run_tag_values_test_case` to a functionremove ubuntu-latest from job title where that is the only os,"diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
",2,"[""1db13ec43727aca872a0f3836e4023ed85db665e"", ""74e9de5ec97dc013a52aa063dff0f40ac74c407b""]","[""refactor"", ""cicd""]"
"initialize threejs objects in defaultRef, to fix undefined type errorsspring version, core version","diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number

diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 
",2,"[""2561f4ade46fc9d59f289f328cc77733a6443697"", ""c55591ba157298a9c5816693c102a89dfd058830""]","[""fix"", ""build""]"
[gn win] link comctl32.lib to fix component buildconvert `run_tag_values_test_case` to a function,"diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
",2,"[""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""1db13ec43727aca872a0f3836e4023ed85db665e""]","[""build"", ""refactor""]"
add testsadd remote [skip ci],"diff --git a/Cargo.lock b/Cargo.lock
index 84d5d07..6ad05da 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -293,6 +293,7 @@ version = ""0.1.0""
 dependencies = [
  ""git-cliff-core"",
  ""log"",
+ ""pretty_assertions"",
  ""pretty_env_logger"",
  ""structopt"",
 ]
diff --git a/git-cliff-core/src/lib.rs b/git-cliff-core/src/lib.rs
index 3b18ba0..a560c94 100644
--- a/git-cliff-core/src/lib.rs
+++ b/git-cliff-core/src/lib.rs
@@ -1,6 +1,8 @@
 //! Highly customizable Changelog Generator
 #![warn(missing_docs, clippy::unwrap_used)]
 
+/// Export regex crate.
+pub use regex;
 /// Git commit.
 pub mod commit;
 /// Config file parser.
diff --git a/git-cliff/Cargo.toml b/git-cliff/Cargo.toml
index 41eb2e9..cc64b37 100644
--- a/git-cliff/Cargo.toml
+++ b/git-cliff/Cargo.toml
@@ -20,3 +20,6 @@ log = ""0.4.14""
 version = ""0.3""
 default-features = false
 features = [""suggestions"", ""color"", ""wrap_help""]
+
+[dev-dependencies]
+pretty_assertions = ""0.7""
diff --git a/git-cliff/src/changelog.rs b/git-cliff/src/changelog.rs
index 3f9e994..23ea186 100644
--- a/git-cliff/src/changelog.rs
+++ b/git-cliff/src/changelog.rs
@@ -115,3 +115,171 @@ impl<'a> Changelog<'a> {
 		Ok(())
 	}
 }
+
+#[cfg(test)]
+mod test {
+	use super::*;
+	use git_cliff_core::config::{
+		ChangelogConfig,
+		CommitParser,
+		GitConfig,
+	};
+	use git_cliff_core::regex::Regex;
+	use pretty_assertions::assert_eq;
+	use std::str;
+	#[test]
+	fn changelog_generator() -> Result<()> {
+		let config = Config {
+			changelog: ChangelogConfig {
+				header: Some(String::from(""# Changelog"")),
+				body:   String::from(
+					r#""{% if version %}
+				## Release [{{ version }}] - {{ timestamp | date(format=""%Y-%m-%d"") }}
+				({{ commit_id }}){% else %}
+				## Unreleased{% endif %}
+				{% for group, commits in commits | group_by(attribute=""group"") %}
+				### {{ group }}{% for group, commits in commits | group_by(attribute=""scope"") %}
+				#### {{ group }}{% for commit in commits %}
+				- {{ commit.message }}{% endfor %}
+				{% endfor %}{% endfor %}""#,
+				)
+				.replace(""				"", """"),
+				footer: Some(String::from(""------------"")),
+			},
+			git:       GitConfig {
+				conventional_commits: true,
+				commit_parsers:       Some(vec![
+					CommitParser {
+						message: Regex::new(""feat*"").ok(),
+						body:    None,
+						group:   Some(String::from(""New features"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new(""fix*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Bug Fixes"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new("".*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Other"")),
+						skip:    None,
+					},
+				]),
+				filter_commits:       Some(false),
+				tag_pattern:          String::new(),
+				skip_tags:            Regex::new(""v3.*"").ok(),
+			},
+		};
+		let test_release = Release {
+			version:   Some(String::from(""v1.0.0"")),
+			commits:   vec![
+				Commit::new(
+					String::from(""0bc123""),
+					String::from(""feat(app): add cool features""),
+				),
+				Commit::new(
+					String::from(""0werty""),
+					String::from(""style(ui): make good stuff""),
+				),
+				Commit::new(
+					String::from(""0w3rty""),
+					String::from(""fix(ui): fix more stuff""),
+				),
+				Commit::new(
+					String::from(""0jkl12""),
+					String::from(""chore(app): do nothing""),
+				),
+			],
+			commit_id: Some(String::from(""0bc123"")),
+			timestamp: 50000000,
+			previous:  None,
+		};
+		let releases = vec![
+			test_release.clone(),
+			Release {
+				version: Some(String::from(""v3.0.0"")),
+				commits: vec![Commit::new(
+					String::from(""n0thin""),
+					String::from(""feat(xyz): skip commit""),
+				)],
+				..Release::default()
+			},
+			Release {
+				version:   None,
+				commits:   vec![
+					Commit::new(
+						String::from(""abc123""),
+						String::from(""feat(app): add xyz""),
+					),
+					Commit::new(
+						String::from(""abc124""),
+						String::from(""docs(app): document zyx""),
+					),
+					Commit::new(String::from(""def789""), String::from(""merge #4"")),
+					Commit::new(
+						String::from(""qwerty""),
+						String::from(""fix(app): fix abc""),
+					),
+					Commit::new(
+						String::from(""hjkl12""),
+						String::from(""chore(ui): do boring stuff""),
+					),
+				],
+				commit_id: None,
+				timestamp: 1000,
+				previous:  Some(Box::new(test_release)),
+			},
+		];
+		let changelog = Changelog::new(releases, &config)?;
+		let mut out = Vec::new();
+		changelog.generate(&mut out)?;
+		assert_eq!(
+			String::from(
+				r#""# Changelog
+
+			## Unreleased
+
+			### Bug Fixes
+			#### app
+			- fix abc
+
+			### New features
+			#### app
+			- add xyz
+
+			### Other
+			#### app
+			- document zyx
+
+			#### ui
+			- do boring stuff
+
+			## Release [v1.0.0] - 1971-08-02
+			(0bc123)
+
+			### Bug Fixes
+			#### ui
+			- fix more stuff
+
+			### New features
+			#### app
+			- add cool features
+
+			### Other
+			#### app
+			- do nothing
+
+			#### ui
+			- make good stuff
+			------------
+			""#
+			)
+			.replace(""			"", """"),
+			str::from_utf8(&out).unwrap()
+		);
+		Ok(())
+	}
+}

diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 06c9003..e19c703 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -47,7 +47,10 @@ jobs:
           git config --global user.email 'ibis-squawk-bot[bot]@users.noreply.github.com'
 
       - name: fetch and rebase on top of upstream
-        run: git pull --rebase -X ours https://github.com/ibis-project/ibis master
+        run: |
+          git remote add upstream https://github.com/ibis-project/ibis
+          git fetch upstream
+          git rebase -X ours upstream/master
 
       - uses: tibdex/github-app-token@v1
         id: generate_pr_token
",2,"[""8ee0611fbf0cd89abe7ae588f22e6ecb843598ea"", ""e96487ad7ce90b141219d9032fa2bed68d5dae6a""]","[""test"", ""cicd""]"
"xfail on to_parquet and to_csv that use pyarrow write optionsget tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.","diff --git a/ibis/backends/tests/test_export.py b/ibis/backends/tests/test_export.py
index 4d536d7..5bb9775 100644
--- a/ibis/backends/tests/test_export.py
+++ b/ibis/backends/tests/test_export.py
@@ -222,18 +222,23 @@ def test_table_to_parquet(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs""), [({""version"": ""1.0""}), ({""version"": ""2.6""})])
-def test_table_to_parquet_writer_kwargs(kwargs, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.NotSupportedError,
+)
+@pytest.mark.parametrize(""version"", [""1.0"", ""2.6""])
+def test_table_to_parquet_writer_kwargs(version, tmp_path, backend, awards_players):
     outparquet = tmp_path / ""out.parquet""
-    awards_players.to_parquet(outparquet, **kwargs)
+    awards_players.to_parquet(outparquet, version=version)
 
     df = pd.read_parquet(outparquet)
 
     backend.assert_frame_equal(awards_players.to_pandas(), df)
 
-    file = pa.parquet.ParquetFile(outparquet)
+    md = pa.parquet.read_metadata(outparquet)
 
-    assert file.metadata.format_version == kwargs[""version""]
+    assert md.format_version == version
 
 
 @pytest.mark.notimpl(
@@ -316,14 +321,20 @@ def test_table_to_csv(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs"", ""delimiter""), [({""write_options"": pcsv.WriteOptions(delimiter="";"")}, "";""), ({""write_options"": pcsv.WriteOptions(delimiter=""\t"")}, ""\t"")])
-def test_table_to_csv_writer_kwargs(kwargs, delimiter, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.ProgrammingError,
+)
+@pytest.mark.parametrize(""delimiter"", ["";"", ""\t""], ids=[""semicolon"", ""tab""])
+def test_table_to_csv_writer_kwargs(delimiter, tmp_path, awards_players):
     outcsv = tmp_path / ""out.csv""
     # avoid pandas NaNonense
     awards_players = awards_players.select(""playerID"", ""awardID"", ""yearID"", ""lgID"")
 
-    awards_players.to_csv(outcsv, **kwargs)
-    pd.read_csv(outcsv, delimiter=delimiter)
+    awards_players.to_csv(outcsv, write_options=pcsv.WriteOptions(delimiter=delimiter))
+    df = pd.read_csv(outcsv, delimiter=delimiter, nrows=1)
+    assert len(df) == 1
 
 
 @pytest.mark.parametrize(

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }
",2,"[""bedc7950b24c37809e36a585b7985d5aa5e3e458"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c""]","[""test"", ""refactor""]"
remove ubuntu-latest from job title where that is the only osadd fallible peek_last_token(),"diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false

diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.
",2,"[""74e9de5ec97dc013a52aa063dff0f40ac74c407b"", ""63eab619e6166eb6cab948028a7b89bf059dd878""]","[""cicd"", ""refactor""]"
update wrapping tests for v7add spacing in comment fix lint (#8555),"diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });

diff --git a/src/components/nav/test/basic/app-module.ts b/src/components/nav/test/basic/app-module.ts
index 467917a..375e662 100644
--- a/src/components/nav/test/basic/app-module.ts
+++ b/src/components/nav/test/basic/app-module.ts
@@ -633,7 +633,7 @@ export class Tab3 {
   }
 
   presentModal() {
-    //this.modalCtrl.create(MyModal).present();
+    // this.modalCtrl.create(MyModal).present();
   }
 
   selectPrevious() {
",2,"[""317f4eefecddfb1392ca71d551840f446feee302"", ""af880ac5b4fecbc6c4f3d1eee0d95f326e8bd9d1""]","[""test"", ""docs""]"
add getter for protocol idallow disabling dynamic queue,"diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }

diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);
",2,"[""dc5238b2bda98a7c4f2fe9584fc3b0191a408109"", ""9ef5c0d14193a9abb09b39856f58477d1f4b0d77""]","[""feat"", ""fix""]"
"remove deprecated settings

Removes deprecated ZEEBE_HOST environment variable, and removes
unnecessary log level environment variable, since it's already the
default in the log filenginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/Dockerfile b/Dockerfile
index 6762a39..7f380cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -34,7 +34,6 @@ RUN wget -O - https://github.com/jvm-profiling-tools/async-profiler/releases/dow
 FROM ${APP_ENV} as app
 
 ENV ZB_HOME=/usr/local/zeebe \
-    ZEEBE_LOG_LEVEL=info \
     ZEEBE_BROKER_GATEWAY_NETWORK_HOST=0.0.0.0 \
     ZEEBE_STANDALONE_GATEWAY=false
 ENV PATH ""${ZB_HOME}/bin:${PATH}""
diff --git a/docker/utils/startup.sh b/docker/utils/startup.sh
index bc8d2fc..0fcde2b 100755
--- a/docker/utils/startup.sh
+++ b/docker/utils/startup.sh
@@ -1,17 +1,14 @@
 #!/bin/bash -xeu
 
-# legacy support
-# This environment variable was used to set the gatewway cluster host in standalone and embedded mode.
-# Now, there are two dedicated environment variables for the two different deployment scenarios.
-export ZEEBE_HOST=${ZEEBE_HOST:-$(hostname -i)}
-# Legacy support
+HOST=$(hostname -i)
 
 if [ ""$ZEEBE_STANDALONE_GATEWAY"" = ""true"" ]; then
-    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_GATEWAY_NETWORK_HOST=${ZEEBE_GATEWAY_NETWORK_HOST:-${HOST}}
+    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${HOST}}
 
     exec /usr/local/zeebe/bin/gateway
 else
-    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${HOST}}
     export ZEEBE_BROKER_GATEWAY_CLUSTER_HOST=${ZEEBE_BROKER_GATEWAY_CLUSTER_HOST:-${ZEEBE_BROKER_NETWORK_HOST}}
 
     exec /usr/local/zeebe/bin/broker

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection
",2,"[""e4a11fd5c34942ba12737f1c8c084489428ee274"", ""e12d9e77a6fd531a22325337838a841b1c67f00d""]","[""build"", ""docs""]"
"buffer assert and bpmn model api helper class

related to camunda-tngp/camunda-tngp#23add fallible peek_last_token()","diff --git a/test-util/pom.xml b/test-util/pom.xml
index a097651..b6518ee 100644
--- a/test-util/pom.xml
+++ b/test-util/pom.xml
@@ -20,6 +20,7 @@
     <project.build.sourceEncoding>utf-8</project.build.sourceEncoding>
     <!-- TODO: Move to common parent -->
     <agrona.version>0.4.11</agrona.version>
+    <camunda.version>7.6.0-SNAPSHOT</camunda.version>
   </properties>
 
   <dependencies>
@@ -30,6 +31,13 @@
       <version>${agrona.version}</version>
       <scope>provided</scope>
     </dependency>
+    
+    <dependency>
+      <groupId>org.camunda.bpm.model</groupId>
+      <artifactId>camunda-bpmn-model</artifactId>
+      <version>${camunda.version}</version>
+      <scope>provided</scope>
+    </dependency>
 
     <dependency>
       <groupId>junit</groupId>
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
index 37e3a6f..b8d9b26 100644
--- a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
@@ -14,7 +14,7 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         super(actual, BufferAssert.class);
     }
 
-    public static BufferAssert assertThat(DirectBuffer buffer)
+    public static BufferAssert assertThatBuffer(DirectBuffer buffer)
     {
         return new BufferAssert(buffer);
     }
@@ -41,4 +41,16 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         return hasBytes(expected, 0);
     }
 
+    public BufferAssert hasCapacity(int expectedCapacity)
+    {
+        isNotNull();
+
+        if (expectedCapacity != actual.capacity())
+        {
+            failWithMessage(""Expected capacity "" + expectedCapacity + "" but was "" + actual.capacity());
+        }
+
+        return this;
+    }
+
 }
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
new file mode 100644
index 0000000..6f0d134
--- /dev/null
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
@@ -0,0 +1,121 @@
+package org.camunda.tngp.broker.test.util.bpmn;
+
+import java.util.Collection;
+
+import org.camunda.bpm.model.bpmn.BpmnModelInstance;
+import org.camunda.bpm.model.bpmn.impl.BpmnModelConstants;
+import org.camunda.bpm.model.bpmn.instance.Definitions;
+import org.camunda.bpm.model.xml.Model;
+import org.camunda.bpm.model.xml.instance.DomDocument;
+import org.camunda.bpm.model.xml.instance.ModelElementInstance;
+import org.camunda.bpm.model.xml.type.ModelElementType;
+import org.camunda.bpm.model.xml.validation.ModelElementValidator;
+import org.camunda.bpm.model.xml.validation.ValidationResults;
+
+public class TngpModelInstance implements BpmnModelInstance
+{
+    protected BpmnModelInstance wrappedInstance;
+
+    public TngpModelInstance(BpmnModelInstance wrappedInstance)
+    {
+        this.wrappedInstance = wrappedInstance;
+    }
+
+    @Override
+    public DomDocument getDocument()
+    {
+        return wrappedInstance.getDocument();
+    }
+
+    @Override
+    public ModelElementInstance getDocumentElement()
+    {
+        return wrappedInstance.getDocumentElement();
+    }
+
+    @Override
+    public void setDocumentElement(ModelElementInstance documentElement)
+    {
+        wrappedInstance.setDocumentElement(documentElement);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(Class<T> type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(ModelElementType type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public Model getModel()
+    {
+        return wrappedInstance.getModel();
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T getModelElementById(String id)
+    {
+        return wrappedInstance.getModelElementById(id);
+    }
+
+    @Override
+    public Collection<ModelElementInstance> getModelElementsByType(ModelElementType referencingType)
+    {
+        return wrappedInstance.getModelElementsByType(referencingType);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> Collection<T> getModelElementsByType(Class<T> referencingClass)
+    {
+        return wrappedInstance.getModelElementsByType(referencingClass);
+    }
+
+    @Override
+    public ValidationResults validate(Collection<ModelElementValidator<?>> validators)
+    {
+        return wrappedInstance.validate(validators);
+    }
+
+    @Override
+    public BpmnModelInstance clone()
+    {
+        return wrappedInstance.clone();
+    }
+
+    @Override
+    public Definitions getDefinitions()
+    {
+        return wrappedInstance.getDefinitions();
+    }
+
+    @Override
+    public void setDefinitions(Definitions arg0)
+    {
+        wrappedInstance.setDefinitions(arg0);
+    }
+
+    public TngpModelInstance taskAttributes(String taskId, String taskType, int taskQueueId)
+    {
+        final ModelElementInstance task = wrappedInstance.getModelElementById(taskId);
+
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskType"", taskType);
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskQueueId"", String.valueOf(taskQueueId));
+
+        return this;
+    }
+
+    public static TngpModelInstance wrap(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance);
+    }
+
+    public static TngpModelInstance wrapCopy(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance.clone());
+    }
+}

diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.
",2,"[""6ed56ce9ae743ba9a87e6c9643cc06b1de7b748d"", ""63eab619e6166eb6cab948028a7b89bf059dd878""]","[""feat"", ""refactor""]"
"only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>print errors without stacktracebetter layout for block and segment","diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {

diff --git a/docs/docs/config-block.md b/docs/docs/config-block.md
new file mode 100644
index 0000000..df1ee54
--- /dev/null
+++ b/docs/docs/config-block.md
@@ -0,0 +1,60 @@
+---
+id: config-block
+title: Block
+sidebar_label: Block
+---
+
+Let's take a closer look at what defines a block.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""segments"": [
+        ...
+      ]
+    }
+  ]
+}
+```
+
+- type: `prompt` | `rprompt`
+- newline: `boolean`
+- alignment: `left` | `right`
+- vertical_offset: `int`
+- horizontal_offset: `int`
+- segments: `array` of one or more `segments`
+
+### Type
+
+Tells the engine what to do with the block. There are three options:
+
+- `prompt` renders one or more segments
+- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
+Supported on [ZSH][rprompt], Bash and Powershell.
+
+### Newline
+
+Start the block on a new line. Defaults to `false`.
+
+### Alignment
+
+Tell the engine if the block should be left or right-aligned.
+
+### Vertical offset
+
+Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
+moves it up one line.
+
+### Horizontal offset
+
+Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
+but on a horizontal level where a negative number moves the block left and a positive number right.
+
+### Segments
+
+Array of one or more segments.
diff --git a/docs/docs/config-example.md b/docs/docs/config-example.md
new file mode 100644
index 0000000..c180c4f
--- /dev/null
+++ b/docs/docs/config-example.md
@@ -0,0 +1,96 @@
+---
+id: config-sample
+title: Sample
+sidebar_label: Sample
+---
+
+```json
+{
+  ""final_space"": true,
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""right"",
+      ""vertical_offset"": -1,
+      ""segments"": [
+        {
+          ""type"": ""time"",
+          ""style"": ""plain"",
+          ""foreground"": ""#007ACC"",
+          ""properties"": {
+            ""time_format"": ""15:04:05""
+          }
+        }
+      ]
+    },
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""newline"": true,
+      ""segments"": [
+        {
+          ""type"": ""session"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#ffb300"",
+          ""leading_diamond"": ""\uE0B6"",
+          ""trailing_diamond"": ""\uE0B0"",
+          ""properties"": {
+            ""postfix"": "" ""
+          }
+        },
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ""prefix"": "" \uE5FF "",
+            ""style"": ""folder"",
+            ""exclude_folders"": [
+              ""/super/secret/project""
+            ],
+            ""enable_hyperlink"": false
+          }
+        },
+        {
+          ""type"": ""git"",
+          ""style"": ""powerline"",
+          ""foreground"": ""#193549"",
+          ""foreground_templates"": [
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
+          ],
+          ""background"": ""#2e9599"",
+          ""background_templates"": [
+            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
+            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
+            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
+          ],
+          ""powerline_symbol"": ""\uE0B0"",
+          ""properties"": {
+            ""fetch_status"": true,
+            ""branch_max_length"": 25,
+            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
+          }
+        },
+        {
+          ""type"": ""exit"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#00897b"",
+          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
+          ""leading_diamond"": """",
+          ""trailing_diamond"": ""\uE0B4"",
+          ""properties"": {
+            ""always_enabled"": true,
+            ""template"": ""\uE23A"",
+            ""prefix"": ""<parentBackground>\uE0B0</> ""
+          }
+        }
+      ]
+    }
+  ]
+}
+```
diff --git a/docs/docs/config-overview.md b/docs/docs/config-overview.md
index 1fdbcba..b554869 100644
--- a/docs/docs/config-overview.md
+++ b/docs/docs/config-overview.md
@@ -1,7 +1,7 @@
 ---
 id: config-overview
-title: Overview
-sidebar_label: Overview
+title: General
+sidebar_label: General
 ---
 
 Oh My Posh renders your prompt based on the definition of _blocks_ (like Lego) which contain one or more _segments_.
@@ -64,332 +64,7 @@ boxes with question marks, set up your terminal to use a [supported font][font] 
 - terminal_background: `string` [color][colors] - terminal background color, set to your terminal's background color when
 you notice black elements in Windows Terminal or the Visual Studio Code integrated terminal
 
-## Block
-
-Let's take a closer look at what defines a block.
-
-- type: `prompt` | `rprompt`
-- newline: `boolean`
-- alignment: `left` | `right`
-- vertical_offset: `int`
-- horizontal_offset: `int`
-- segments: `array` of one or more `segments`
-
-### Type
-
-Tells the engine what to do with the block. There are three options:
-
-- `prompt` renders one or more segments
-- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
-Supported on [ZSH][rprompt], Bash and Powershell.
-
-### Newline
-
-Start the block on a new line. Defaults to `false`.
-
-### Alignment
-
-Tell the engine if the block should be left or right-aligned.
-
-### Vertical offset
-
-Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
-moves it up one line.
-
-### Horizontal offset
-
-Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
-but on a horizontal level where a negative number moves the block left and a positive number right.
-
-### Segments
-
-Array of one or more segments.
-
-## Segment
-
-A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
-looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
-understand how to configure a segment.
-
-- type: `string` any of the included [segments][segments]
-- style: `powerline` | `plain` | `diamond`
-- powerline_symbol: `string`
-- invert_powerline: `boolean`
-- leading_diamond: `string`
-- trailing_diamond: `string`
-- foreground: `string` [color][colors]
-- foreground_templates: `array` of `string` values
-- background: `string` [color][colors]
-- background_templates: `array` of `string` values
-- properties: `array` of `Property`: `string`
-
-### Type
-
-Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
-
-### Style
-
-Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
-themes out there, we identified 3 types. All of these require a different configuration and depending on the look
-you want to achieve you might need to understand/use them all.
-
-#### Powerline
-
-What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
-background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
-if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
-
-#### Plain
-
-Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
-Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
-
-#### Diamond
-
-While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
-Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
-segment background as their foreground color.
-
-### Powerline symbol
-
-Text character to use when `""style"": ""powerline""`.
-
-### Invert Powerline
-
-If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
-in the perfectly mirrored variant for example.
-
-### Leading diamond
-
-Text character to use at the start of the segment. Will take the background color of the segment as
-its foreground color.
-
-### Trailing diamond
-
-Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
-
-### Foreground
-
-[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
-
-### Foreground Templates
-
-Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
-Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
-offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
-the documentation.
-
-The following sample is based on the [AWS Segment][aws].
-
-```json
-{
-  ""type"": ""aws"",
-  ""style"": ""powerline"",
-  ""powerline_symbol"": ""\uE0B0"",
-  ""foreground"": ""#ffffff"",
-  ""background"": ""#111111"",
-  ""foreground_templates"": [
-    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
-    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
-  ],
-  ""properties"": {
-    ""prefix"": "" \uE7AD ""
-  }
-}
-```
-
-The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
-one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
-returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
-templates returns a value, the foreground value `#ffffff` is used.
-
-### Background
-
-[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
-
-### Background Templates
-
-Same as [Foreground Templates][fg-templ] but for the background color.
-
-### Properties
-
-An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
-will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
-engine which allow you to customize the output even more.
-
-#### General-purpose properties
-
-You can use these on any segment, the engine is responsible for adding them correctly.
-
-- prefix: `string`
-- postfix: `string`
-- include_folders: `[]string`
-- exclude_folders: `[]string`
-
-##### Prefix
-
-The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
-specify this as `''`.
-
-##### Postfix
-
-The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
-specify this as `''`.
-
-##### Include / Exclude Folders
-
-Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
-the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
-will not be rendered when in one of the excluded locations.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-```json
-""exclude_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-The strings specified in these properties are evaluated as [regular expressions][regex]. You
-can use any valid regular expression construct, but the regular expression must match the entire directory
-name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-]
-```
-
-You can also combine these properties:
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-],
-""exclude_folders"": [
-  ""/Users/posh/Projects/secret-project.*""
-]
-```
-
-##### Notes
-
-- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
-is used by the current operating system.
-- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
-directory name, you need to specify it as `\\\\`.
-- The character `~` at the start of a specified folder will match the user's home directory.
-- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
-
-This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
-`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
-
-## Full Sample
-
-```json
-{
-  ""final_space"": true,
-  ""blocks"": [
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""right"",
-      ""vertical_offset"": -1,
-      ""segments"": [
-        {
-          ""type"": ""time"",
-          ""style"": ""plain"",
-          ""foreground"": ""#007ACC"",
-          ""properties"": {
-            ""time_format"": ""15:04:05""
-          }
-        }
-      ]
-    },
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""left"",
-      ""newline"": true,
-      ""segments"": [
-        {
-          ""type"": ""session"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#ffb300"",
-          ""leading_diamond"": ""\uE0B6"",
-          ""trailing_diamond"": ""\uE0B0"",
-          ""properties"": {
-            ""postfix"": "" ""
-          }
-        },
-        {
-          ""type"": ""path"",
-          ""style"": ""powerline"",
-          ""powerline_symbol"": ""\uE0B0"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#61AFEF"",
-          ""properties"": {
-            ""prefix"": "" \uE5FF "",
-            ""style"": ""folder"",
-            ""exclude_folders"": [
-              ""/super/secret/project""
-            ],
-            ""enable_hyperlink"": false
-          }
-        },
-        {
-          ""type"": ""git"",
-          ""style"": ""powerline"",
-          ""foreground"": ""#193549"",
-          ""foreground_templates"": [
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
-          ],
-          ""background"": ""#2e9599"",
-          ""background_templates"": [
-            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
-            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
-            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
-          ],
-          ""powerline_symbol"": ""\uE0B0"",
-          ""properties"": {
-            ""fetch_status"": true,
-            ""branch_max_length"": 25,
-            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
-          }
-        },
-        {
-          ""type"": ""exit"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#00897b"",
-          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
-          ""leading_diamond"": """",
-          ""trailing_diamond"": ""\uE0B4"",
-          ""properties"": {
-            ""always_enabled"": true,
-            ""template"": ""\uE23A"",
-            ""prefix"": ""<parentBackground>\uE0B0</> ""
-          }
-        }
-      ]
-    }
-  ]
-}
-```
-
 [releases]: https://github.com/JanDeDobbeleer/oh-my-posh/releases/latest
 [font]: /docs/config-fonts
 [schema]: https://github.com/JanDeDobbeleer/oh-my-posh/blob/main/themes/schema.json
 [themes]: https://github.com/JanDeDobbeleer/oh-my-posh/tree/main/themes
-[segments]: /docs/battery
-[colors]: /docs/config-colors
-[go-text-template]: https://golang.org/pkg/text/template/
-[sprig]: https://masterminds.github.io/sprig/
-[fg-templ]: /docs/config-overview#foreground-templates
-[regex]: https://www.regular-expressions.info/tutorial.html
-[aws]: /docs/aws
diff --git a/docs/docs/config-segment.md b/docs/docs/config-segment.md
new file mode 100644
index 0000000..08a66e4
--- /dev/null
+++ b/docs/docs/config-segment.md
@@ -0,0 +1,219 @@
+---
+id: config-segment
+title: Segment
+sidebar_label: Segment
+---
+
+A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
+looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
+understand how to configure a segment.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ...
+      ""segments"": [
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ...
+          }
+        }
+      ]
+    }
+  ]
+}
+```
+
+- type: `string` any of the included [segments][segments]
+- style: `powerline` | `plain` | `diamond`
+- powerline_symbol: `string`
+- invert_powerline: `boolean`
+- leading_diamond: `string`
+- trailing_diamond: `string`
+- foreground: `string` [color][colors]
+- foreground_templates: `array` of `string` values
+- background: `string` [color][colors]
+- background_templates: `array` of `string` values
+- properties: `array` of `Property`: `string`
+
+## Type
+
+Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
+
+## Style
+
+Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
+themes out there, we identified 3 types. All of these require a different configuration and depending on the look
+you want to achieve you might need to understand/use them all.
+
+### Powerline
+
+What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
+background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
+if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
+
+### Plain
+
+Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
+Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
+
+### Diamond
+
+While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
+Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
+segment background as their foreground color.
+
+## Powerline symbol
+
+Text character to use when `""style"": ""powerline""`.
+
+## Invert Powerline
+
+If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
+in the perfectly mirrored variant for example.
+
+## Leading diamond
+
+Text character to use at the start of the segment. Will take the background color of the segment as
+its foreground color.
+
+## Trailing diamond
+
+Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
+
+## Foreground
+
+[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
+
+## Foreground Templates
+
+Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
+Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
+offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
+the documentation.
+
+The following sample is based on the [AWS Segment][aws].
+
+```json
+{
+  ""type"": ""aws"",
+  ""style"": ""powerline"",
+  ""powerline_symbol"": ""\uE0B0"",
+  ""foreground"": ""#ffffff"",
+  ""background"": ""#111111"",
+  ""foreground_templates"": [
+    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
+    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
+  ],
+  ""properties"": {
+    ""prefix"": "" \uE7AD ""
+  }
+}
+```
+
+The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
+one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
+returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
+templates returns a value, the foreground value `#ffffff` is used.
+
+## Background
+
+[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
+
+## Background Templates
+
+Same as [Foreground Templates][fg-templ] but for the background color.
+
+## Properties
+
+An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
+will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
+engine which allow you to customize the output even more.
+
+### General-purpose properties
+
+You can use these on any segment, the engine is responsible for adding them correctly.
+
+- prefix: `string`
+- postfix: `string`
+- include_folders: `[]string`
+- exclude_folders: `[]string`
+
+#### Prefix
+
+The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
+specify this as `''`.
+
+#### Postfix
+
+The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
+specify this as `''`.
+
+#### Include / Exclude Folders
+
+Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
+the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
+will not be rendered when in one of the excluded locations.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+```json
+""exclude_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+The strings specified in these properties are evaluated as [regular expressions][regex]. You
+can use any valid regular expression construct, but the regular expression must match the entire directory
+name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+]
+```
+
+You can also combine these properties:
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+],
+""exclude_folders"": [
+  ""/Users/posh/Projects/secret-project.*""
+]
+```
+
+#### Notes
+
+- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
+is used by the current operating system.
+- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
+directory name, you need to specify it as `\\\\`.
+- The character `~` at the start of a specified folder will match the user's home directory.
+- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
+
+This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
+`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
+
+[segments]: /docs/battery
+[colors]: /docs/config-colors
+[go-text-template]: https://golang.org/pkg/text/template/
+[sprig]: https://masterminds.github.io/sprig/
+[fg-templ]: /docs/config-overview#foreground-templates
+[regex]: https://www.regular-expressions.info/tutorial.html
+[aws]: /docs/aws
diff --git a/docs/docs/segment-environment.md b/docs/docs/segment-environment.md
index f35bc87..982a0a5 100644
--- a/docs/docs/segment-environment.md
+++ b/docs/docs/segment-environment.md
@@ -34,7 +34,7 @@ New-Alias -Name 'Set-PoshContext' -Value 'Set-EnvVar' -Scope Global -Force
 
 The segment will show when the value of the environment variable isn't empty.
 
-## Sample Configuration
+## Sample *Configuration*
 
 ```json
 {
diff --git a/docs/sidebars.js b/docs/sidebars.js
index a75163e..8f151a2 100644
--- a/docs/sidebars.js
+++ b/docs/sidebars.js
@@ -20,6 +20,9 @@ module.exports = {
       label: ""⚙️ Configuration"",
       items: [
         ""config-overview"",
+        ""config-block"",
+        ""config-segment"",
+        ""config-sample"",
         ""config-title"",
         ""config-colors"",
         ""config-text-style"",
",3,"[""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""d129eaf9125a967ac86c6c7276bbae6b4d50af36"", ""cb1f48b56ae0de93acb72e48726c7d610a1d538e""]","[""cicd"", ""fix"", ""docs""]"
"update flushed index before truncatingrestructure ClusterTopology to track completed changebuffer assert and bpmn model api helper class

related to camunda-tngp/camunda-tngp#23","diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(

diff --git a/test-util/pom.xml b/test-util/pom.xml
index a097651..b6518ee 100644
--- a/test-util/pom.xml
+++ b/test-util/pom.xml
@@ -20,6 +20,7 @@
     <project.build.sourceEncoding>utf-8</project.build.sourceEncoding>
     <!-- TODO: Move to common parent -->
     <agrona.version>0.4.11</agrona.version>
+    <camunda.version>7.6.0-SNAPSHOT</camunda.version>
   </properties>
 
   <dependencies>
@@ -30,6 +31,13 @@
       <version>${agrona.version}</version>
       <scope>provided</scope>
     </dependency>
+    
+    <dependency>
+      <groupId>org.camunda.bpm.model</groupId>
+      <artifactId>camunda-bpmn-model</artifactId>
+      <version>${camunda.version}</version>
+      <scope>provided</scope>
+    </dependency>
 
     <dependency>
       <groupId>junit</groupId>
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
index 37e3a6f..b8d9b26 100644
--- a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
@@ -14,7 +14,7 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         super(actual, BufferAssert.class);
     }
 
-    public static BufferAssert assertThat(DirectBuffer buffer)
+    public static BufferAssert assertThatBuffer(DirectBuffer buffer)
     {
         return new BufferAssert(buffer);
     }
@@ -41,4 +41,16 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         return hasBytes(expected, 0);
     }
 
+    public BufferAssert hasCapacity(int expectedCapacity)
+    {
+        isNotNull();
+
+        if (expectedCapacity != actual.capacity())
+        {
+            failWithMessage(""Expected capacity "" + expectedCapacity + "" but was "" + actual.capacity());
+        }
+
+        return this;
+    }
+
 }
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
new file mode 100644
index 0000000..6f0d134
--- /dev/null
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
@@ -0,0 +1,121 @@
+package org.camunda.tngp.broker.test.util.bpmn;
+
+import java.util.Collection;
+
+import org.camunda.bpm.model.bpmn.BpmnModelInstance;
+import org.camunda.bpm.model.bpmn.impl.BpmnModelConstants;
+import org.camunda.bpm.model.bpmn.instance.Definitions;
+import org.camunda.bpm.model.xml.Model;
+import org.camunda.bpm.model.xml.instance.DomDocument;
+import org.camunda.bpm.model.xml.instance.ModelElementInstance;
+import org.camunda.bpm.model.xml.type.ModelElementType;
+import org.camunda.bpm.model.xml.validation.ModelElementValidator;
+import org.camunda.bpm.model.xml.validation.ValidationResults;
+
+public class TngpModelInstance implements BpmnModelInstance
+{
+    protected BpmnModelInstance wrappedInstance;
+
+    public TngpModelInstance(BpmnModelInstance wrappedInstance)
+    {
+        this.wrappedInstance = wrappedInstance;
+    }
+
+    @Override
+    public DomDocument getDocument()
+    {
+        return wrappedInstance.getDocument();
+    }
+
+    @Override
+    public ModelElementInstance getDocumentElement()
+    {
+        return wrappedInstance.getDocumentElement();
+    }
+
+    @Override
+    public void setDocumentElement(ModelElementInstance documentElement)
+    {
+        wrappedInstance.setDocumentElement(documentElement);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(Class<T> type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(ModelElementType type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public Model getModel()
+    {
+        return wrappedInstance.getModel();
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T getModelElementById(String id)
+    {
+        return wrappedInstance.getModelElementById(id);
+    }
+
+    @Override
+    public Collection<ModelElementInstance> getModelElementsByType(ModelElementType referencingType)
+    {
+        return wrappedInstance.getModelElementsByType(referencingType);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> Collection<T> getModelElementsByType(Class<T> referencingClass)
+    {
+        return wrappedInstance.getModelElementsByType(referencingClass);
+    }
+
+    @Override
+    public ValidationResults validate(Collection<ModelElementValidator<?>> validators)
+    {
+        return wrappedInstance.validate(validators);
+    }
+
+    @Override
+    public BpmnModelInstance clone()
+    {
+        return wrappedInstance.clone();
+    }
+
+    @Override
+    public Definitions getDefinitions()
+    {
+        return wrappedInstance.getDefinitions();
+    }
+
+    @Override
+    public void setDefinitions(Definitions arg0)
+    {
+        wrappedInstance.setDefinitions(arg0);
+    }
+
+    public TngpModelInstance taskAttributes(String taskId, String taskType, int taskQueueId)
+    {
+        final ModelElementInstance task = wrappedInstance.getModelElementById(taskId);
+
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskType"", taskType);
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskQueueId"", String.valueOf(taskQueueId));
+
+        return this;
+    }
+
+    public static TngpModelInstance wrap(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance);
+    }
+
+    public static TngpModelInstance wrapCopy(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance.clone());
+    }
+}
",3,"[""933ab6bb86372913c992567cf9660009900911a7"", ""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2"", ""6ed56ce9ae743ba9a87e6c9643cc06b1de7b748d""]","[""fix"", ""refactor"", ""feat""]"
[gn win] link comctl32.lib to fix component buildsupport use meta key select multiple elementsplit release docs build into separate workflow,"diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index ab68624..aeee7b7 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -277,9 +277,11 @@ export default class LogicFlow {
   }
   /**
    * 将图形选中
+   * @param id 选择元素ID
+   * @param multiple 是否允许多选，如果为true，不会将上一个选中的元素重置
    */
-  select(id: string) {
-    this.graphModel.selectElementById(id);
+  select(id: string, multiple = false) {
+    this.graphModel.selectElementById(id, multiple);
   }
   /**
    * 将图形定位到画布中心
diff --git a/packages/core/src/model/EditConfigModel.ts b/packages/core/src/model/EditConfigModel.ts
index 67e334a..83e5f16 100644
--- a/packages/core/src/model/EditConfigModel.ts
+++ b/packages/core/src/model/EditConfigModel.ts
@@ -25,6 +25,7 @@ const SilentConfig = {
   edgeTextEdit: false,
   nodeTextDraggable: false,
   edgeTextDraggable: false,
+  metaKeyMultipleSelected: false,
 };
 
 /**
@@ -42,6 +43,7 @@ export default class EditConfigModel {
   @observable edgeTextEdit = true; // 允许连线文本可以编辑
   @observable nodeTextDraggable = false; // 允许节点文本可以拖拽
   @observable edgeTextDraggable = false; // 允许连线文本可以拖拽
+  @observable metaKeyMultipleSelected = false; // 允许meta多选元素
   constructor(data) {
     const keys = [
       'stopZoomGraph',
@@ -55,6 +57,7 @@ export default class EditConfigModel {
       'edgeTextEdit',
       'nodeTextDraggable',
       'edgeTextDraggable',
+      'metaKeyMultipleSelected',
     ];
     const { isSilentMode, textEdit } = data;
     if (isSilentMode) {
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 9667f4d..310daf4 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -34,6 +34,7 @@ class GraphModel {
   height: number;
   topElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
   selectElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
+  selectElements = new Map<string, IBaseModel>(); // 多选
   @observable edgeType: string;
   @observable nodes: BaseNodeModel[] = [];
   @observable activeElement: IBaseModel;
@@ -50,7 +51,6 @@ class GraphModel {
   @observable gridSize = 1;
   @observable partial = false; // 是否开启局部渲染
   @observable fakerNode: BaseNodeModel;
-  // @observable selectElements = new Map<string, IBaseModel>(); // 多选还没有做，先不加
   constructor(config) {
     const {
       container,
@@ -456,24 +456,44 @@ class GraphModel {
   }
 
   @action
-  selectNodeById(id) {
-    this.selectElement?.setSelected(false);
+  selectNodeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.nodesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectEdgeById(id) {
-    this.selectElement?.setSelected(false);
+  selectEdgeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.edgesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectElementById(id: string) {
-    this.selectElement?.setSelected(false);
+  selectElementById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
+  }
+
+  @action
+  clearSelectElements() {
+    this.selectElements.forEach(element => {
+      element.setSelected(false);
+    });
+    this.selectElements.clear();
   }
 
   /* 修改连线类型 */
diff --git a/packages/core/src/view/edge/BaseEdge.tsx b/packages/core/src/view/edge/BaseEdge.tsx
index d45ea9e..d7c8f38 100644
--- a/packages/core/src/view/edge/BaseEdge.tsx
+++ b/packages/core/src/view/edge/BaseEdge.tsx
@@ -178,7 +178,8 @@ export default class BaseEdge extends Component<IProps> {
   handleClick = (e) => {
     const { model, graphModel, eventCenter } = this.props;
     graphModel.toFront(model.id);
-    graphModel.selectEdgeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectEdgeById(model.id, e.metaKey && metaKeyMultipleSelected);
     // 边数据
     const edgeData = model?.getData();
     const position = graphModel.getPointByClient({
diff --git a/packages/core/src/view/node/BaseNode.tsx b/packages/core/src/view/node/BaseNode.tsx
index 140889c..5ee3975 100644
--- a/packages/core/src/view/node/BaseNode.tsx
+++ b/packages/core/src/view/node/BaseNode.tsx
@@ -275,7 +275,8 @@ export default abstract class BaseNode extends Component<IProps, Istate> {
       }, 400);
     }
     graphModel.toFront(model.id);
-    graphModel.selectNodeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectNodeById(model.id, e.metaKey && metaKeyMultipleSelected);
     this.preStartTime = this.startTime;
   };
   handleContextMenu = (ev: MouseEvent) => {
diff --git a/packages/core/src/view/overlay/CanvasOverlay.tsx b/packages/core/src/view/overlay/CanvasOverlay.tsx
index ef11822..8c79fd2 100644
--- a/packages/core/src/view/overlay/CanvasOverlay.tsx
+++ b/packages/core/src/view/overlay/CanvasOverlay.tsx
@@ -104,9 +104,9 @@ class CanvasOverlay extends Component<IProps, Istate> {
     const target = ev.target as HTMLElement;
     if (target.getAttribute('name') === 'canvas-overlay') {
       const { graphModel, eventCenter } = this.props;
-      const { selectElement, textEditElement } = graphModel;
-      if (selectElement) {
-        selectElement.setSelected(false);
+      const { textEditElement, selectElements } = graphModel;
+      if (selectElements.size > 0) {
+        graphModel.clearSelectElements();
       }
       if (textEditElement) {
         textEditElement.setElementState(ElementState.DEFAULT);
diff --git a/packages/extension/examples/bpmn/index.html b/packages/extension/examples/bpmn/index.html
index 7a68d6f..f7ea87d 100644
--- a/packages/extension/examples/bpmn/index.html
+++ b/packages/extension/examples/bpmn/index.html
@@ -6,6 +6,7 @@
   <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
   <title>LOGIN FLOW</title>
   <link rel=""stylesheet"" href=""/core/dist/style/index.css"">
+  <link rel=""stylesheet"" href=""/extension/lib/style/index.css"">
   <style>
     html,body {
       padding: 0;
@@ -129,11 +130,14 @@
     </div>
   </div>
   <script src=""/core/dist/logic-flow.js""></script>
+  <!-- <script src=""http://0.0.0.0:9090/logic-flow.js""></script> -->
   <script src=""/BpmnElement.js""></script>
   <script src=""/BpmnAdapter.js""></script>
+  <script src=""/Control.js""></script>
   <script src=""/Snapshot.js""></script>
   <script>
     LogicFlow.use(BpmnElement);
+    LogicFlow.use(Control);
     LogicFlow.use(BpmnAdapter);
     LogicFlow.use(Snapshot);
   </script>
diff --git a/packages/extension/examples/bpmn/index.js b/packages/extension/examples/bpmn/index.js
index 21d2da0..6f6aa39 100644
--- a/packages/extension/examples/bpmn/index.js
+++ b/packages/extension/examples/bpmn/index.js
@@ -3,6 +3,10 @@ window.onload = function () {
     container: document.querySelector('#app'),
     // fixme: grid成为了必传的了
     edgeTextDraggable: true,
+    metaKeyMultipleSelected: true,
+    // stopScrollGraph: true,
+    // stopMoveGraph: true,
+    // stopZoomGraph: true,
     grid: {
       type: 'dot',
       size: 20,

diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 753d57d..3e0aa15 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -88,14 +88,14 @@ jobs:
         run: poetry run pytest --benchmark-only --benchmark-json .benchmarks/output.json ibis/tests/benchmarks
 
       - uses: tibdex/github-app-token@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         id: generate-token
         with:
           app_id: ${{ secrets.SQUAWK_BOT_APP_ID }}
           private_key: ${{ secrets.SQUAWK_BOT_APP_PRIVATE_KEY }}
 
       - uses: benchmark-action/github-action-benchmark@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         with:
           tool: pytest
           github-token: ${{ steps.generate-token.outputs.token }}
@@ -107,6 +107,7 @@ jobs:
 
   docs:
     runs-on: ubuntu-latest
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
     needs:
       # wait on benchmarks to prevent a race condition when pushing to the
       # gh-pages branch
@@ -124,51 +125,25 @@ jobs:
           authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
           extraPullNames: nix-community,poetry2nix
 
-      - name: Generate a GitHub token
-        if: ${{ github.event_name == 'push' }}
-        uses: tibdex/github-app-token@v1
-        id: generate_token
-        with:
-          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
-          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
-
-      - name: checkout
-        if: ${{ github.event_name == 'push' }}
-        uses: actions/checkout@v3
-        with:
-          fetch-depth: 0
-          token: ${{ steps.generate_token.outputs.token }}
-
       - name: checkout
-        if: ${{ github.event_name != 'push' }}
         uses: actions/checkout@v3
 
-      - name: Configure git info
-        if: ${{ github.event_name == 'push' }}
-        run: |
-          set -euo pipefail
-
-          git config user.name 'ibis-docs-bot[bot]'
-          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
-
       - name: build docs
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c mkdocs build
 
       - name: verify internal links
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c just checklinks --offline --no-progress
 
-      - name: Pull gh-pages changes
+      - name: Configure git info
         if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
-          git fetch origin gh-pages
-          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
 
       - name: build and push dev docs
-        if: ${{ github.event_name == 'push' && !startsWith(github.ref, 'refs/tags/') }}
+        if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
@@ -180,19 +155,6 @@ jobs:
               --message 'docs(dev): ibis@${{ github.sha }}' \
                 dev
 
-      - name: build and push docs on tag
-        if: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/tags/') }}
-        run: |
-          set -euo pipefail
-
-          nix develop -f shell.nix --keep-going -c \
-            mic deploy \
-              --push \
-              --rebase \
-              --prefix docs \
-              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
-              ""${GITHUB_REF_NAME}"" latest
-
   simulate_release:
     runs-on: ubuntu-latest
     steps:
diff --git a/.github/workflows/ibis-docs-release.yml b/.github/workflows/ibis-docs-release.yml
new file mode 100644
index 0000000..da7ee49
--- /dev/null
+++ b/.github/workflows/ibis-docs-release.yml
@@ -0,0 +1,63 @@
+# vim: filetype=yaml
+name: Docs Release Build
+
+on:
+  release:
+    types:
+      - published
+jobs:
+  docs:
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
+    runs-on: ubuntu-latest
+    steps:
+      - name: install nix
+        uses: cachix/install-nix-action@v17
+        with:
+          nix_path: nixpkgs=channel:nixos-unstable-small
+
+      - name: setup cachix
+        uses: cachix/cachix-action@v10
+        with:
+          name: ibis
+          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
+          extraPullNames: nix-community,poetry2nix
+
+      - name: Generate a GitHub token
+        uses: tibdex/github-app-token@v1
+        id: generate_token
+        with:
+          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
+          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
+
+      - name: checkout
+        uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+          token: ${{ steps.generate_token.outputs.token }}
+
+      - name: Configure git info
+        run: |
+          set -euo pipefail
+
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
+
+      - name: Pull gh-pages changes
+        run: |
+          set -euo pipefail
+
+          git fetch origin gh-pages
+          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+
+      - name: build and push docs on tag
+        run: |
+          set -euo pipefail
+
+          nix develop -f shell.nix --keep-going -c \
+            mic deploy \
+              --push \
+              --rebase \
+              --update-aliases \
+              --prefix docs \
+              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
+              ""${GITHUB_REF_NAME}"" latest
",3,"[""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""e137f9fdbdb6bf3f85c3f7ac9323785e445844c8"", ""32845e1bbd1efb5dbc16f671049509a409ba25ce""]","[""build"", ""feat"", ""cicd""]"
"do not use scripts and binaries from the libcc repoadd .nullif() exampleAdd ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>","diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}
",3,"[""45837af24a33308a70a3454f0f650f9fe728e272"", ""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21"", ""f823cf28652987d43c8324b4f5b203240032383a""]","[""cicd"", ""docs"", ""feat""]"
publish sdks after docs/buildFix typofix build ordering,"diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/

diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/scripts/build.mjs b/scripts/build.mjs
index 204854f..b3cf067 100644
--- a/scripts/build.mjs
+++ b/scripts/build.mjs
@@ -3,8 +3,8 @@ import { write } from 'fsxx';
 import { info, success } from './helpers.mjs';
 
 await $`rm -rf dist/*`;
-await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 await $`unbuild`;
+await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 
 const packages = [
   'jsx-runtime',
",3,"[""6c9cb638cb4d1ecc42632fcf389c24898c5b3244"", ""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""c323d59c607cabc91f17a78528d998f376f30b10""]","[""cicd"", ""docs"", ""build""]"
"setup jest and add m.ts testsnginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>print errors without stacktrace","diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection

diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {
",3,"[""229b53a632ea97d47c4be11f096bdd828fb415d8"", ""e12d9e77a6fd531a22325337838a841b1c67f00d"", ""d129eaf9125a967ac86c6c7276bbae6b4d50af36""]","[""test"", ""docs"", ""fix""]"
"add hardware back button

Closes #5071update Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909export a modal transition preset","diff --git a/ionic/components/app/app.ts b/ionic/components/app/app.ts
index 04d8c57..08aab92 100644
--- a/ionic/components/app/app.ts
+++ b/ionic/components/app/app.ts
@@ -3,8 +3,7 @@ import {Title} from 'angular2/platform/browser';
 
 import {Config} from '../../config/config';
 import {ClickBlock} from '../../util/click-block';
-import {Nav} from '../nav/nav';
-import {Tabs} from '../tabs/tabs';
+import {Platform} from '../../platform/platform';
 
 
 /**
@@ -23,8 +22,20 @@ export class IonicApp {
 
   constructor(
     private _config: Config,
-    private _clickBlock: ClickBlock
-  ) {}
+    private _clickBlock: ClickBlock,
+    platform: Platform
+  ) {
+    platform.backButton.subscribe(() => {
+      let activeNav = this.getActiveNav();
+      if (activeNav) {
+        if (activeNav.length() === 1) {
+          platform.exitApp();
+        } else {
+          activeNav.pop();
+        }
+      }
+    });
+  }
 
   /**
    * Sets the document title.
@@ -102,7 +113,7 @@ export class IonicApp {
   /**
    * @private
    */
-  getActiveNav(): Nav | Tabs {
+  getActiveNav(): any {
     var nav = this._rootNav || null;
     var activeChildNav;
 

diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })

diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {
",3,"[""68278b00450f2679761a2999500f6d87a579376b"", ""c2ee5cd5e709afd15c5565ee009a0d204403a119"", ""535708ae50aecb452560a23356fd396f99ef13a2""]","[""feat"", ""docs"", ""refactor""]"
"update `cargo-make` for `v0.35.3`publish sdks after docs/buildAdjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 5e125e3..52d9b6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 * Fix: resizing/scrolling through heavily wrapped panes no longer hangs (https://github.com/zellij-org/zellij/pull/814)
 * Terminal compatibility: properly handle HOME/END keys in eg. vim/zsh (https://github.com/zellij-org/zellij/pull/815)
 * Fix: Typo (https://github.com/zellij-org/zellij/pull/821)
+* Fix: Update `cargo-make` instructions post `v0.35.3` (https://github.com/zellij-org/zellij/pull/819)
 
 ## [0.19.0] - 2021-10-20
 * Fix: Prevent text overwrite when scrolled up (https://github.com/zellij-org/zellij/pull/655)

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)
",3,"[""0cfc5633d37ea06f645649138323f1820e18bdee"", ""6c9cb638cb4d1ecc42632fcf389c24898c5b3244"", ""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3""]","[""docs"", ""cicd"", ""test""]"
"assist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>update flushed index before truncatingcleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.","diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }

diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:
",3,"[""1269431c8a3e7549f10fcbbb4b88ff625c8898b3"", ""933ab6bb86372913c992567cf9660009900911a7"", ""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7""]","[""build"", ""fix"", ""refactor""]"
"fixed docker link testsupdate flushed index before truncatingupdate Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909","diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()

diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })
",3,"[""c7b25726df94a2530c9b1c0d2b6a0acaa103822f"", ""933ab6bb86372913c992567cf9660009900911a7"", ""c2ee5cd5e709afd15c5565ee009a0d204403a119""]","[""test"", ""fix"", ""docs""]"
updated react demo parcel commandmake it mode lessuse `regexp_instr != 0` instead of `REGEXP` keyword,"diff --git a/demo/react/package.json b/demo/react/package.json
index be28bf9..32d0952 100644
--- a/demo/react/package.json
+++ b/demo/react/package.json
@@ -12,7 +12,7 @@
   },
   ""scripts"": {
     ""start"": ""parcel serve public/index.html --no-cache --open"",
-    ""build"": ""parcel build -t browser -d dist public/index.html --no-source-maps""
+    ""build"": ""parcel build --target browser --dist-dir dist public/index.html --no-source-maps""
   },
   ""bugs"": {
     ""url"": ""https://github.com/matteobruni/tsparticles/issues""

diff --git a/core/src/components/slides/slides.tsx b/core/src/components/slides/slides.tsx
index 48fd53f..d5c2f75 100644
--- a/core/src/components/slides/slides.tsx
+++ b/core/src/components/slides/slides.tsx
@@ -1,7 +1,6 @@
 import { Component, Element, Event, EventEmitter, Method, Prop, Watch } from '@stencil/core';
 
 import { Mode } from '../../interface.js';
-import { createThemedClasses } from '../../utils/theme.js';
 
 import { Swiper } from './vendor/swiper.js';
 
@@ -15,6 +14,7 @@ import { Swiper } from './vendor/swiper.js';
   shadow: true
 })
 export class Slides {
+
   private container!: HTMLElement;
   private swiper: any;
 
@@ -391,12 +391,6 @@ export class Slides {
     return { ...swiperOptions, ...this.options, ...eventOptions };
   }
 
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'slides')
-    };
-  }
-
   render() {
     return (
       <div class=""swiper-container"" ref={el => this.container = el as HTMLElement }>
diff --git a/core/src/components/thumbnail/thumbnail.ios.scss b/core/src/components/thumbnail/thumbnail.ios.scss
deleted file mode 100644
index e3add45..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.ios.vars"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-ios-width};
-  --border-radius: #{$thumbnail-ios-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.ios.vars.scss b/core/src/components/thumbnail/thumbnail.ios.vars.scss
deleted file mode 100644
index 85d53e5..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.ios"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-ios-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-ios-height:                  $thumbnail-ios-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-ios-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.md.scss b/core/src/components/thumbnail/thumbnail.md.scss
deleted file mode 100644
index 0fbb2ca..0000000
--- a/core/src/components/thumbnail/thumbnail.md.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.md.vars"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-md-width};
-  --border-radius: #{$thumbnail-md-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.md.vars.scss b/core/src/components/thumbnail/thumbnail.md.vars.scss
deleted file mode 100644
index 94e48b2..0000000
--- a/core/src/components/thumbnail/thumbnail.md.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.md"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-md-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-md-height:                  $thumbnail-md-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-md-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.scss b/core/src/components/thumbnail/thumbnail.scss
index 8ac3a22..8af268d 100644
--- a/core/src/components/thumbnail/thumbnail.scss
+++ b/core/src/components/thumbnail/thumbnail.scss
@@ -9,6 +9,8 @@
    * @prop --border-radius: Border radius of the thumbnail
    * @prop --size: Size of the thumbnail
    */
+  --size: 48px;
+  --border-radius: 0;
 
   @include border-radius(var(--border-radius));
 
diff --git a/core/src/components/thumbnail/thumbnail.tsx b/core/src/components/thumbnail/thumbnail.tsx
index 50ff2c2..de76593 100644
--- a/core/src/components/thumbnail/thumbnail.tsx
+++ b/core/src/components/thumbnail/thumbnail.tsx
@@ -1,25 +1,11 @@
 import { Component } from '@stencil/core';
 
-import { Mode } from '../../interface';
-import { createThemedClasses } from '../../utils/theme';
-
 @Component({
   tag: 'ion-thumbnail',
-  styleUrls: {
-    ios: 'thumbnail.ios.scss',
-    md: 'thumbnail.md.scss'
-  },
+  styleUrl: 'thumbnail.scss',
   shadow: true
 })
 export class Thumbnail {
-  mode!: Mode;
-
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'thumbnail')
-    };
-  }
-
   render() {
     return <slot></slot>;
   }

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(
",3,"[""32b92cfa0b74a6c25990e32ac6aab12b8496794c"", ""771857b1df9470ebc15357e8879118a72c649d5b"", ""06e2be4e2019b6fa714e1fcb34485860ef1ede79""]","[""build"", ""refactor"", ""fix""]"
"Adjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.add comments for the Handler[gn] fix include_dirs ordering error","diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)

diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }

diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)
",3,"[""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3"", ""036a0ff49a7dade0e04c9c07071a1ff49133ee24"", ""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945""]","[""test"", ""docs"", ""build""]"
"buffer assert and bpmn model api helper class

related to camunda-tngp/camunda-tngp#23fixed docker link testsexport a modal transition preset","diff --git a/test-util/pom.xml b/test-util/pom.xml
index a097651..b6518ee 100644
--- a/test-util/pom.xml
+++ b/test-util/pom.xml
@@ -20,6 +20,7 @@
     <project.build.sourceEncoding>utf-8</project.build.sourceEncoding>
     <!-- TODO: Move to common parent -->
     <agrona.version>0.4.11</agrona.version>
+    <camunda.version>7.6.0-SNAPSHOT</camunda.version>
   </properties>
 
   <dependencies>
@@ -30,6 +31,13 @@
       <version>${agrona.version}</version>
       <scope>provided</scope>
     </dependency>
+    
+    <dependency>
+      <groupId>org.camunda.bpm.model</groupId>
+      <artifactId>camunda-bpmn-model</artifactId>
+      <version>${camunda.version}</version>
+      <scope>provided</scope>
+    </dependency>
 
     <dependency>
       <groupId>junit</groupId>
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
index 37e3a6f..b8d9b26 100644
--- a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
@@ -14,7 +14,7 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         super(actual, BufferAssert.class);
     }
 
-    public static BufferAssert assertThat(DirectBuffer buffer)
+    public static BufferAssert assertThatBuffer(DirectBuffer buffer)
     {
         return new BufferAssert(buffer);
     }
@@ -41,4 +41,16 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         return hasBytes(expected, 0);
     }
 
+    public BufferAssert hasCapacity(int expectedCapacity)
+    {
+        isNotNull();
+
+        if (expectedCapacity != actual.capacity())
+        {
+            failWithMessage(""Expected capacity "" + expectedCapacity + "" but was "" + actual.capacity());
+        }
+
+        return this;
+    }
+
 }
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
new file mode 100644
index 0000000..6f0d134
--- /dev/null
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
@@ -0,0 +1,121 @@
+package org.camunda.tngp.broker.test.util.bpmn;
+
+import java.util.Collection;
+
+import org.camunda.bpm.model.bpmn.BpmnModelInstance;
+import org.camunda.bpm.model.bpmn.impl.BpmnModelConstants;
+import org.camunda.bpm.model.bpmn.instance.Definitions;
+import org.camunda.bpm.model.xml.Model;
+import org.camunda.bpm.model.xml.instance.DomDocument;
+import org.camunda.bpm.model.xml.instance.ModelElementInstance;
+import org.camunda.bpm.model.xml.type.ModelElementType;
+import org.camunda.bpm.model.xml.validation.ModelElementValidator;
+import org.camunda.bpm.model.xml.validation.ValidationResults;
+
+public class TngpModelInstance implements BpmnModelInstance
+{
+    protected BpmnModelInstance wrappedInstance;
+
+    public TngpModelInstance(BpmnModelInstance wrappedInstance)
+    {
+        this.wrappedInstance = wrappedInstance;
+    }
+
+    @Override
+    public DomDocument getDocument()
+    {
+        return wrappedInstance.getDocument();
+    }
+
+    @Override
+    public ModelElementInstance getDocumentElement()
+    {
+        return wrappedInstance.getDocumentElement();
+    }
+
+    @Override
+    public void setDocumentElement(ModelElementInstance documentElement)
+    {
+        wrappedInstance.setDocumentElement(documentElement);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(Class<T> type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(ModelElementType type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public Model getModel()
+    {
+        return wrappedInstance.getModel();
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T getModelElementById(String id)
+    {
+        return wrappedInstance.getModelElementById(id);
+    }
+
+    @Override
+    public Collection<ModelElementInstance> getModelElementsByType(ModelElementType referencingType)
+    {
+        return wrappedInstance.getModelElementsByType(referencingType);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> Collection<T> getModelElementsByType(Class<T> referencingClass)
+    {
+        return wrappedInstance.getModelElementsByType(referencingClass);
+    }
+
+    @Override
+    public ValidationResults validate(Collection<ModelElementValidator<?>> validators)
+    {
+        return wrappedInstance.validate(validators);
+    }
+
+    @Override
+    public BpmnModelInstance clone()
+    {
+        return wrappedInstance.clone();
+    }
+
+    @Override
+    public Definitions getDefinitions()
+    {
+        return wrappedInstance.getDefinitions();
+    }
+
+    @Override
+    public void setDefinitions(Definitions arg0)
+    {
+        wrappedInstance.setDefinitions(arg0);
+    }
+
+    public TngpModelInstance taskAttributes(String taskId, String taskType, int taskQueueId)
+    {
+        final ModelElementInstance task = wrappedInstance.getModelElementById(taskId);
+
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskType"", taskType);
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskQueueId"", String.valueOf(taskQueueId));
+
+        return this;
+    }
+
+    public static TngpModelInstance wrap(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance);
+    }
+
+    public static TngpModelInstance wrapCopy(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance.clone());
+    }
+}

diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()

diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {
",3,"[""6ed56ce9ae743ba9a87e6c9643cc06b1de7b748d"", ""c7b25726df94a2530c9b1c0d2b6a0acaa103822f"", ""535708ae50aecb452560a23356fd396f99ef13a2""]","[""feat"", ""test"", ""refactor""]"
add .nullif() exampleadd props to get color and label from a routeprint errors without stacktrace,"diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 

diff --git a/src/components/BottomNavigation.js b/src/components/BottomNavigation.js
index 1b72302..7d8ea75 100644
--- a/src/components/BottomNavigation.js
+++ b/src/components/BottomNavigation.js
@@ -24,8 +24,8 @@ const AnimatedPaper = Animated.createAnimatedComponent(Paper);
 
 type Route = {
   key: string,
-  title: string,
-  icon: IconSource,
+  title?: string,
+  icon?: IconSource,
   color?: string,
 };
 
@@ -51,7 +51,7 @@ type Props<T> = {
    * - `key`: a unique key to identify the route
    * - `title`: title of the route to use as the tab label
    * - `icon`: icon to use as the tab icon, can be a string, an image source or a react component
-   * - `color`: color to use as background color for shifting bottom navigation (optional)
+   * - `color`: color to use as background color for shifting bottom navigation
    *
    * Example:
    *
@@ -115,11 +115,27 @@ type Props<T> = {
   /**
    * Callback which returns a React Element to be used as tab icon.
    */
-  renderIcon?: (props: { route: T, focused: boolean }) => React.Node,
+  renderIcon?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
   /**
    * Callback which React Element to be used as tab label.
    */
-  renderLabel?: (props: { route: T, focused: boolean }) => React.Node,
+  renderLabel?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
+  /**
+   * Get label text for the tab, uses `route.title` by default. Use `renderLabel` to replace label component.
+   */
+  getLabelText?: (props: { route: T }) => string,
+  /**
+   * Get color for the tab, uses `route.color` by default.
+   */
+  getColor?: (props: { route: T }) => string,
   /**
    * Function to execute on tab press. It receives the route for the pressed tab, useful for things like scroll to top.
    */
@@ -159,6 +175,10 @@ type State = {
    */
   ripple: Animated.Value,
   /**
+   * Animation for the touch feedback, used to determine it's scale and opacity.
+   */
+  touch: Animated.Value,
+  /**
    * Layout of the tab bar. The width is used to determine the size and position of the ripple.
    */
   layout: { height: number, width: number, measured: boolean },
@@ -173,7 +193,7 @@ const MIN_SHIFT_AMOUNT = 10;
 const MIN_TAB_WIDTH = 96;
 const MAX_TAB_WIDTH = 168;
 const BAR_HEIGHT = 56;
-const SMALL_RIPPLE_SIZE = 72;
+const SMALL_RIPPLE_SIZE = 96;
 const ACTIVE_LABEL_SIZE = 14;
 const INACTIVE_LABEL_SIZE = 12;
 
@@ -251,6 +271,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ),
       index: new Animated.Value(index),
       ripple: new Animated.Value(MIN_RIPPLE_SCALE),
+      touch: new Animated.Value(MIN_RIPPLE_SCALE),
       layout: { height: 0, width: 0, measured: false },
       previous: 0,
     };
@@ -349,6 +370,15 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
   _handleTabPress = (index: number) => {
     const { navigationState } = this.props;
 
+    this.state.touch.setValue(MIN_RIPPLE_SCALE);
+
+    Animated.timing(this.state.touch, {
+      toValue: 1,
+      duration: 300,
+      easing: Easing.in(Easing.sin),
+      useNativeDriver: true,
+    }).start();
+
     if (index !== navigationState.index) {
       this.props.onIndexChange(index);
     }
@@ -376,6 +406,8 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       renderScene,
       renderIcon,
       renderLabel,
+      getLabelText = ({ route }) => route.title,
+      getColor = ({ route }) => route.color,
       barStyle,
       style,
       theme,
@@ -400,7 +432,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ? this.state.index.interpolate({
           inputRange: routes.map((_, i) => i),
           outputRange: routes.map(
-            route => route.color || approxBackgroundColor
+            route => getColor({ route }) || approxBackgroundColor
           ),
         })
       : approxBackgroundColor;
@@ -416,7 +448,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
           .rgb()
           .string();
 
-    const rippleColor = color(textColor)
+    const touchColor = color(textColor)
       .alpha(0.12)
       .rgb()
       .string();
@@ -430,22 +462,10 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
 
     // Since we have a single ripple, we have to reposition it so that it appears to expand from active tab.
     // We need to move it from the left to the active tab and also account for how much that tab has shifted.
-    const rippleShift =
-      navigationState.index * tabWidth +
-      tabWidth / 2 +
-      this._calculateShift(
-        this.state.previous,
-        navigationState.index,
-        routes.length
-      );
 
     return (
       <View
-        style={[
-          styles.container,
-          { backgroundColor: theme.dark ? white : black },
-          style,
-        ]}
+        style={[styles.container, style]}
         onLayout={this._handleLayout}
         pointerEvents={layout.measured ? 'auto' : 'none'}
       >
@@ -485,25 +505,30 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
             style={[styles.items, { maxWidth: maxTabWidth * routes.length }]}
           >
             {shifting ? (
-              // Large ripple with the backround color
               <Animated.View
                 pointerEvents=""none""
                 style={[
                   styles.ripple,
                   {
                     // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - layout.width / 2,
-                    left: rippleShift - layout.width / 2,
-                    height: layout.width,
-                    width: layout.width,
+                    top: BAR_HEIGHT / 2 - layout.width / 8,
+                    left:
+                      navigationState.index * tabWidth +
+                      tabWidth / 2 -
+                      layout.width / 8,
+                    height: layout.width / 4,
+                    width: layout.width / 4,
                     borderRadius: layout.width / 2,
-                    backgroundColor: routes[navigationState.index].color,
+                    backgroundColor: getColor({
+                      route: routes[navigationState.index],
+                    }),
                     transform: [
+                      { translateX: this.state.shifts[navigationState.index] },
                       {
                         // Scale to twice the size  to ensure it covers the whole tab bar
                         scale: this.state.ripple.interpolate({
                           inputRange: [0, 1],
-                          outputRange: [0, 2],
+                          outputRange: [0, 8],
                         }),
                       },
                     ],
@@ -515,36 +540,36 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                 ]}
               />
             ) : null}
-            {shifting ? (
-              // Small subtle ripple on touch
-              <Animated.View
-                pointerEvents=""none""
-                style={[
-                  styles.ripple,
-                  {
-                    // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
-                    left: rippleShift - SMALL_RIPPLE_SIZE / 2,
-                    height: SMALL_RIPPLE_SIZE,
-                    width: SMALL_RIPPLE_SIZE,
-                    borderRadius: SMALL_RIPPLE_SIZE / 2,
-                    backgroundColor: rippleColor,
-                    transform: [
-                      {
-                        scale: this.state.ripple.interpolate({
-                          inputRange: [0, 0.5, 1],
-                          outputRange: [0, 1, 1],
-                        }),
-                      },
-                    ],
-                    opacity: this.state.ripple.interpolate({
-                      inputRange: [0, MIN_RIPPLE_SCALE, 0.25, 0.5],
-                      outputRange: [0, 0, 1, 0],
-                    }),
-                  },
-                ]}
-              />
-            ) : null}
+            <Animated.View
+              pointerEvents=""none""
+              style={[
+                styles.ripple,
+                {
+                  // Set top and left values so that the ripple's center is same as the tab's center
+                  top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
+                  left:
+                    navigationState.index * tabWidth +
+                    tabWidth / 2 -
+                    SMALL_RIPPLE_SIZE / 2,
+                  height: SMALL_RIPPLE_SIZE,
+                  width: SMALL_RIPPLE_SIZE,
+                  borderRadius: SMALL_RIPPLE_SIZE / 2,
+                  backgroundColor: touchColor,
+                  transform: [
+                    {
+                      translateX: shifting
+                        ? this.state.shifts[navigationState.index]
+                        : 0,
+                    },
+                    { scale: this.state.touch },
+                  ],
+                  opacity: this.state.touch.interpolate({
+                    inputRange: [0, 0.5, 1],
+                    outputRange: [0, 1, 0],
+                  }),
+                },
+              ]}
+            />
             {routes.map((route, index) => {
               const shift = this.state.shifts[index];
               const focused = this.state.tabs[index];
@@ -607,7 +632,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderIcon ? (
-                          renderIcon({ route, focused: true })
+                          renderIcon({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <Icon
                             style={styles.icon}
@@ -625,7 +654,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderIcon ? (
-                            renderIcon({ route, focused: false })
+                            renderIcon({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <Icon
                               style={styles.icon}
@@ -652,7 +685,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderLabel ? (
-                          renderLabel({ route, focused: true })
+                          renderLabel({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <AnimatedText
                             style={[
@@ -662,7 +699,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                               },
                             ]}
                           >
-                            {route.title}
+                            {getLabelText({ route })}
                           </AnimatedText>
                         )}
                       </Animated.View>
@@ -674,7 +711,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderLabel ? (
-                            renderLabel({ route, focused: false })
+                            renderLabel({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <AnimatedText
                               style={[
@@ -684,7 +725,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                                 },
                               ]}
                             >
-                              {route.title}
+                              {getLabelText({ route })}
                             </AnimatedText>
                           )}
                         </Animated.View>

diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {
",3,"[""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21"", ""ded26d768ff432ad3bde3c0aa1e95ce50726100a"", ""d129eaf9125a967ac86c6c7276bbae6b4d50af36""]","[""docs"", ""feat"", ""fix""]"
"increment failing test retriesupdate Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909autostart feature fixed","diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 

diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();
",3,"[""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57"", ""c2ee5cd5e709afd15c5565ee009a0d204403a119"", ""bed78248c941d57ad4cc20a455147e186e97c7a1""]","[""cicd"", ""docs"", ""fix""]"
"remove ubuntu-latest from job title where that is the only osadded changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284print errors without stacktrace","diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false

diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {
",3,"[""74e9de5ec97dc013a52aa063dff0f40ac74c407b"", ""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""d129eaf9125a967ac86c6c7276bbae6b4d50af36""]","[""cicd"", ""docs"", ""fix""]"
"fixed docker link testsautostart feature fixedspring version, core version","diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();

diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 
",3,"[""c7b25726df94a2530c9b1c0d2b6a0acaa103822f"", ""bed78248c941d57ad4cc20a455147e186e97c7a1"", ""c55591ba157298a9c5816693c102a89dfd058830""]","[""test"", ""fix"", ""build""]"
licensingincrement failing test retriesautostart feature fixed,"diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;

diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();
",3,"[""a52a585d74894b3b4eeb8c784fa089ff95cddad0"", ""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57"", ""bed78248c941d57ad4cc20a455147e186e97c7a1""]","[""docs"", ""cicd"", ""fix""]"
"fix netty dependency

netty-bom 4.1.70 contains the changes from pull request
https://github.com/netty/netty/pull/11798, which moved the classes out
of the native modules to make sure the same classes don't end up on the
classpath multiple times. For us it means that we need to depend on both
the native and classes modules. However, since we don't use the native
module directly (only classes that were moved to this classes module),
we need to force the dependency plugin to consider the native module as
used.publish sdks after docs/buildfixed docker link tests","diff --git a/atomix/cluster/pom.xml b/atomix/cluster/pom.xml
index a477873..b6db695 100644
--- a/atomix/cluster/pom.xml
+++ b/atomix/cluster/pom.xml
@@ -69,6 +69,10 @@
     </dependency>
     <dependency>
       <groupId>io.netty</groupId>
+      <artifactId>netty-transport-classes-epoll</artifactId>
+    </dependency>
+    <dependency>
+      <groupId>io.netty</groupId>
       <artifactId>netty-transport-native-epoll</artifactId>
       <classifier>linux-x86_64</classifier>
     </dependency>
@@ -278,6 +282,7 @@
             <dependency>uk.co.real-logic:sbe-tool</dependency>
             <dependency>net.jqwik:jqwik</dependency>
             <dependency>io.netty:netty-tcnative-boringssl-static</dependency>
+            <dependency>io.netty:netty-transport-native-epoll</dependency>
           </usedDependencies>
         </configuration>
       </plugin>

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/

diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
",3,"[""f00a4d3e307b89842250358ee432e6800bb24362"", ""6c9cb638cb4d1ecc42632fcf389c24898c5b3244"", ""c7b25726df94a2530c9b1c0d2b6a0acaa103822f""]","[""build"", ""cicd"", ""test""]"
added suported tuple typesadd getter for protocol idallow disabling dynamic queue,"diff --git a/src/List/Tuple.ts b/src/List/Tuple.ts
index 4c59caa..6e45503 100644
--- a/src/List/Tuple.ts
+++ b/src/List/Tuple.ts
@@ -1,15 +1,17 @@
-/** A [[Tuple]]
+import {NonNullable} from '../Object/NonNullable'
+
+/** A [[Tuple]] (supported)
  * @param A its type
- * @returns **`any[]`**
+ * @returns **`A[]`**
  * @example
  * ```ts
- * type list0 = [1, 2, 3]
- * type list1 = number[]
+ * type tuple0 = [1, 20, 42]
+ * type tuple1 = ['at', 420]
  * ```
  */
-export type Tuple = [
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-]
+export type Tuple<A = any> = NonNullable<[
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+]>

diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }

diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);
",3,"[""2954a0955ce9af6acb345ed1e8328e145ad30475"", ""dc5238b2bda98a7c4f2fe9584fc3b0191a408109"", ""9ef5c0d14193a9abb09b39856f58477d1f4b0d77""]","[""refactor"", ""feat"", ""fix""]"
"run pyspark tests in parallelAdjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.use `regexp_instr != 0` instead of `REGEXP` keyword","diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index e23088e..9708157 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -202,11 +202,11 @@ jobs:
         run: poetry install --without dev --without docs --extras ${{ matrix.backend.name }} --extras geospatial
 
       - name: ""run parallel tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name != 'pyspark' && matrix.backend.name != 'impala'
+        if: matrix.backend.name != 'impala'
         run: just ci-check -m ${{ matrix.backend.name }} --numprocesses auto --dist=loadgroup
 
       - name: ""run serial tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name == 'pyspark' || matrix.backend.name == 'impala'
+        if: matrix.backend.name == 'impala'
         run: just ci-check -m ${{ matrix.backend.name }}
         env:
           IBIS_TEST_NN_HOST: localhost

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(
",3,"[""4cbbd2552ba0de273e1dfe7d453c5b3efed751a3"", ""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3"", ""06e2be4e2019b6fa714e1fcb34485860ef1ede79""]","[""cicd"", ""test"", ""fix""]"
"detach ViewControllers when not activeconvert `run_tag_values_test_case` to a functiondocker PG version upgrade

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>","diff --git a/ionic/components/nav/nav-controller.ts b/ionic/components/nav/nav-controller.ts
index becdd99..1cc3c31 100644
--- a/ionic/components/nav/nav-controller.ts
+++ b/ionic/components/nav/nav-controller.ts
@@ -1410,6 +1410,9 @@ export class NavController extends Ion {
       // set the ComponentRef's instance to this ViewController
       view.setInstance(component);
 
+      // remember the ChangeDetectorRef for this ViewController
+      view.setChangeDetector(hostViewRef.changeDetectorRef);
+
       // remember the ElementRef to the ion-page elementRef that was just created
       view.setPageRef(pageElementRef);
 
diff --git a/ionic/components/nav/view-controller.ts b/ionic/components/nav/view-controller.ts
index 3207fa2..069c74d 100644
--- a/ionic/components/nav/view-controller.ts
+++ b/ionic/components/nav/view-controller.ts
@@ -1,4 +1,4 @@
-import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer} from 'angular2/core';
+import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer, ChangeDetectorRef} from 'angular2/core';
 
 import {Navbar} from '../navbar/navbar';
 import {NavController, NavOptions} from './nav-controller';
@@ -33,6 +33,7 @@ export class ViewController {
   private _nbVwRef: ViewContainerRef;
   private _onDismiss: Function = null;
   private _pgRef: ElementRef;
+  private _cd: ChangeDetectorRef;
   protected _nav: NavController;
 
   /**
@@ -166,6 +167,13 @@ export class ViewController {
   /**
    * @private
    */
+  setChangeDetector(cd: ChangeDetectorRef) {
+    this._cd = cd;
+  }
+
+  /**
+   * @private
+   */
   setInstance(instance: any) {
     this.instance = instance;
   }
@@ -467,6 +475,14 @@ export class ViewController {
    * The view is about to enter and become the active view.
    */
   willEnter() {
+    if (this._cd) {
+      // ensure this has been re-attached to the change detector
+      this._cd.reattach();
+
+      // detect changes before we run any user code
+      this._cd.detectChanges();
+    }
+
     ctrlFn(this, 'onPageWillEnter');
   }
 
@@ -496,6 +512,10 @@ export class ViewController {
    */
   didLeave() {
     ctrlFn(this, 'onPageDidLeave');
+
+    // when this is not the active page
+    // we no longer need to detect changes
+    this._cd && this._cd.detach();
   }
 
   /**

diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]

diff --git a/packages/nocodb/docker-compose.yml b/packages/nocodb/docker-compose.yml
index 7fabf79..ba2ab7b 100644
--- a/packages/nocodb/docker-compose.yml
+++ b/packages/nocodb/docker-compose.yml
@@ -1,4 +1,4 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
     # db55:
@@ -96,8 +96,8 @@ services:
     #     - 5495:5432
     #   volumes:
     #     - ./pg-sakila-db:/docker-entrypoint-initdb.d
-    pg96:
-     image: postgres:9.6
+    pg147:
+     image: postgres:14.7
      restart: always
      environment:
        POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
index 19dfab2..97d346b 100644
--- a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
+++ b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg.yml b/tests/playwright/scripts/docker-compose-pg.yml
index 0396579..9fab10e 100644
--- a/tests/playwright/scripts/docker-compose-pg.yml
+++ b/tests/playwright/scripts/docker-compose-pg.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
",3,"[""b282e90e2cbb74559aab79eee8443a4d7c85502a"", ""1db13ec43727aca872a0f3836e4023ed85db665e"", ""37b1cbfd3d2c462ef4f2a131e4172c38dc8d9ddf""]","[""feat"", ""refactor"", ""build""]"
"print errors without stacktraceenable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>add riscv64gc-unknown-linux-gnu","diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {

diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 

diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }
",3,"[""d129eaf9125a967ac86c6c7276bbae6b4d50af36"", ""fd8e563cc19ca4684885d4692acee6bebcca4ada"", ""173553c0372e66e03bdab19e0e6c2dd44daa14a0""]","[""fix"", ""feat"", ""cicd""]"
add comments for the Handleradd fallible peek_last_token()setup jest and add m.ts tests,"diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }

diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });
",3,"[""036a0ff49a7dade0e04c9c07071a1ff49133ee24"", ""63eab619e6166eb6cab948028a7b89bf059dd878"", ""229b53a632ea97d47c4be11f096bdd828fb415d8""]","[""docs"", ""refactor"", ""test""]"
fixed docker link testssplit release docs build into separate workflowdetach ViewControllers when not active,"diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()

diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 753d57d..3e0aa15 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -88,14 +88,14 @@ jobs:
         run: poetry run pytest --benchmark-only --benchmark-json .benchmarks/output.json ibis/tests/benchmarks
 
       - uses: tibdex/github-app-token@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         id: generate-token
         with:
           app_id: ${{ secrets.SQUAWK_BOT_APP_ID }}
           private_key: ${{ secrets.SQUAWK_BOT_APP_PRIVATE_KEY }}
 
       - uses: benchmark-action/github-action-benchmark@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         with:
           tool: pytest
           github-token: ${{ steps.generate-token.outputs.token }}
@@ -107,6 +107,7 @@ jobs:
 
   docs:
     runs-on: ubuntu-latest
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
     needs:
       # wait on benchmarks to prevent a race condition when pushing to the
       # gh-pages branch
@@ -124,51 +125,25 @@ jobs:
           authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
           extraPullNames: nix-community,poetry2nix
 
-      - name: Generate a GitHub token
-        if: ${{ github.event_name == 'push' }}
-        uses: tibdex/github-app-token@v1
-        id: generate_token
-        with:
-          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
-          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
-
-      - name: checkout
-        if: ${{ github.event_name == 'push' }}
-        uses: actions/checkout@v3
-        with:
-          fetch-depth: 0
-          token: ${{ steps.generate_token.outputs.token }}
-
       - name: checkout
-        if: ${{ github.event_name != 'push' }}
         uses: actions/checkout@v3
 
-      - name: Configure git info
-        if: ${{ github.event_name == 'push' }}
-        run: |
-          set -euo pipefail
-
-          git config user.name 'ibis-docs-bot[bot]'
-          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
-
       - name: build docs
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c mkdocs build
 
       - name: verify internal links
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c just checklinks --offline --no-progress
 
-      - name: Pull gh-pages changes
+      - name: Configure git info
         if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
-          git fetch origin gh-pages
-          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
 
       - name: build and push dev docs
-        if: ${{ github.event_name == 'push' && !startsWith(github.ref, 'refs/tags/') }}
+        if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
@@ -180,19 +155,6 @@ jobs:
               --message 'docs(dev): ibis@${{ github.sha }}' \
                 dev
 
-      - name: build and push docs on tag
-        if: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/tags/') }}
-        run: |
-          set -euo pipefail
-
-          nix develop -f shell.nix --keep-going -c \
-            mic deploy \
-              --push \
-              --rebase \
-              --prefix docs \
-              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
-              ""${GITHUB_REF_NAME}"" latest
-
   simulate_release:
     runs-on: ubuntu-latest
     steps:
diff --git a/.github/workflows/ibis-docs-release.yml b/.github/workflows/ibis-docs-release.yml
new file mode 100644
index 0000000..da7ee49
--- /dev/null
+++ b/.github/workflows/ibis-docs-release.yml
@@ -0,0 +1,63 @@
+# vim: filetype=yaml
+name: Docs Release Build
+
+on:
+  release:
+    types:
+      - published
+jobs:
+  docs:
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
+    runs-on: ubuntu-latest
+    steps:
+      - name: install nix
+        uses: cachix/install-nix-action@v17
+        with:
+          nix_path: nixpkgs=channel:nixos-unstable-small
+
+      - name: setup cachix
+        uses: cachix/cachix-action@v10
+        with:
+          name: ibis
+          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
+          extraPullNames: nix-community,poetry2nix
+
+      - name: Generate a GitHub token
+        uses: tibdex/github-app-token@v1
+        id: generate_token
+        with:
+          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
+          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
+
+      - name: checkout
+        uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+          token: ${{ steps.generate_token.outputs.token }}
+
+      - name: Configure git info
+        run: |
+          set -euo pipefail
+
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
+
+      - name: Pull gh-pages changes
+        run: |
+          set -euo pipefail
+
+          git fetch origin gh-pages
+          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+
+      - name: build and push docs on tag
+        run: |
+          set -euo pipefail
+
+          nix develop -f shell.nix --keep-going -c \
+            mic deploy \
+              --push \
+              --rebase \
+              --update-aliases \
+              --prefix docs \
+              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
+              ""${GITHUB_REF_NAME}"" latest

diff --git a/ionic/components/nav/nav-controller.ts b/ionic/components/nav/nav-controller.ts
index becdd99..1cc3c31 100644
--- a/ionic/components/nav/nav-controller.ts
+++ b/ionic/components/nav/nav-controller.ts
@@ -1410,6 +1410,9 @@ export class NavController extends Ion {
       // set the ComponentRef's instance to this ViewController
       view.setInstance(component);
 
+      // remember the ChangeDetectorRef for this ViewController
+      view.setChangeDetector(hostViewRef.changeDetectorRef);
+
       // remember the ElementRef to the ion-page elementRef that was just created
       view.setPageRef(pageElementRef);
 
diff --git a/ionic/components/nav/view-controller.ts b/ionic/components/nav/view-controller.ts
index 3207fa2..069c74d 100644
--- a/ionic/components/nav/view-controller.ts
+++ b/ionic/components/nav/view-controller.ts
@@ -1,4 +1,4 @@
-import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer} from 'angular2/core';
+import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer, ChangeDetectorRef} from 'angular2/core';
 
 import {Navbar} from '../navbar/navbar';
 import {NavController, NavOptions} from './nav-controller';
@@ -33,6 +33,7 @@ export class ViewController {
   private _nbVwRef: ViewContainerRef;
   private _onDismiss: Function = null;
   private _pgRef: ElementRef;
+  private _cd: ChangeDetectorRef;
   protected _nav: NavController;
 
   /**
@@ -166,6 +167,13 @@ export class ViewController {
   /**
    * @private
    */
+  setChangeDetector(cd: ChangeDetectorRef) {
+    this._cd = cd;
+  }
+
+  /**
+   * @private
+   */
   setInstance(instance: any) {
     this.instance = instance;
   }
@@ -467,6 +475,14 @@ export class ViewController {
    * The view is about to enter and become the active view.
    */
   willEnter() {
+    if (this._cd) {
+      // ensure this has been re-attached to the change detector
+      this._cd.reattach();
+
+      // detect changes before we run any user code
+      this._cd.detectChanges();
+    }
+
     ctrlFn(this, 'onPageWillEnter');
   }
 
@@ -496,6 +512,10 @@ export class ViewController {
    */
   didLeave() {
     ctrlFn(this, 'onPageDidLeave');
+
+    // when this is not the active page
+    // we no longer need to detect changes
+    this._cd && this._cd.detach();
   }
 
   /**
",3,"[""c7b25726df94a2530c9b1c0d2b6a0acaa103822f"", ""32845e1bbd1efb5dbc16f671049509a409ba25ce"", ""b282e90e2cbb74559aab79eee8443a4d7c85502a""]","[""test"", ""cicd"", ""feat""]"
"add numberOfLines prop to DataTableTitle (#863)

Closes #848[gn win] link comctl32.lib to fix component buildcleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.","diff --git a/src/components/DataTable/DataTableTitle.js b/src/components/DataTable/DataTableTitle.js
index bfcf07e..d764fd5 100644
--- a/src/components/DataTable/DataTableTitle.js
+++ b/src/components/DataTable/DataTableTitle.js
@@ -27,6 +27,10 @@ type Props = React.ElementConfig<typeof TouchableWithoutFeedback> & {|
    */
   sortDirection?: 'ascending' | 'descending',
   /**
+   * The number of lines to show.
+   */
+  numberOfLines?: number,
+  /**
    * Function to execute on press.
    */
   onPress?: () => mixed,
@@ -44,6 +48,10 @@ type State = {
 class DataTableTitle extends React.Component<Props, State> {
   static displayName = 'DataTable.Title';
 
+  static defaultProps = {
+    numberOfLines: 1,
+  };
+
   state = {
     spinAnim: new Animated.Value(
       this.props.sortDirection === 'ascending' ? 0 : 1
@@ -70,6 +78,7 @@ class DataTableTitle extends React.Component<Props, State> {
       sortDirection,
       theme,
       style,
+      numberOfLines,
       ...rest
     } = this.props;
 
@@ -99,7 +108,7 @@ class DataTableTitle extends React.Component<Props, State> {
               styles.cell,
               sortDirection ? styles.sorted : { color: textColor },
             ]}
-            numberOfLines={1}
+            numberOfLines={numberOfLines}
           >
             {children}
           </Text>

diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:
",3,"[""f9a094918b62534614c47aa8a13f33aec751a1e0"", ""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7""]","[""feat"", ""build"", ""refactor""]"
"support use meta key select multiple elementdocker PG version upgrade

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>nginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index ab68624..aeee7b7 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -277,9 +277,11 @@ export default class LogicFlow {
   }
   /**
    * 将图形选中
+   * @param id 选择元素ID
+   * @param multiple 是否允许多选，如果为true，不会将上一个选中的元素重置
    */
-  select(id: string) {
-    this.graphModel.selectElementById(id);
+  select(id: string, multiple = false) {
+    this.graphModel.selectElementById(id, multiple);
   }
   /**
    * 将图形定位到画布中心
diff --git a/packages/core/src/model/EditConfigModel.ts b/packages/core/src/model/EditConfigModel.ts
index 67e334a..83e5f16 100644
--- a/packages/core/src/model/EditConfigModel.ts
+++ b/packages/core/src/model/EditConfigModel.ts
@@ -25,6 +25,7 @@ const SilentConfig = {
   edgeTextEdit: false,
   nodeTextDraggable: false,
   edgeTextDraggable: false,
+  metaKeyMultipleSelected: false,
 };
 
 /**
@@ -42,6 +43,7 @@ export default class EditConfigModel {
   @observable edgeTextEdit = true; // 允许连线文本可以编辑
   @observable nodeTextDraggable = false; // 允许节点文本可以拖拽
   @observable edgeTextDraggable = false; // 允许连线文本可以拖拽
+  @observable metaKeyMultipleSelected = false; // 允许meta多选元素
   constructor(data) {
     const keys = [
       'stopZoomGraph',
@@ -55,6 +57,7 @@ export default class EditConfigModel {
       'edgeTextEdit',
       'nodeTextDraggable',
       'edgeTextDraggable',
+      'metaKeyMultipleSelected',
     ];
     const { isSilentMode, textEdit } = data;
     if (isSilentMode) {
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 9667f4d..310daf4 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -34,6 +34,7 @@ class GraphModel {
   height: number;
   topElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
   selectElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
+  selectElements = new Map<string, IBaseModel>(); // 多选
   @observable edgeType: string;
   @observable nodes: BaseNodeModel[] = [];
   @observable activeElement: IBaseModel;
@@ -50,7 +51,6 @@ class GraphModel {
   @observable gridSize = 1;
   @observable partial = false; // 是否开启局部渲染
   @observable fakerNode: BaseNodeModel;
-  // @observable selectElements = new Map<string, IBaseModel>(); // 多选还没有做，先不加
   constructor(config) {
     const {
       container,
@@ -456,24 +456,44 @@ class GraphModel {
   }
 
   @action
-  selectNodeById(id) {
-    this.selectElement?.setSelected(false);
+  selectNodeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.nodesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectEdgeById(id) {
-    this.selectElement?.setSelected(false);
+  selectEdgeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.edgesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectElementById(id: string) {
-    this.selectElement?.setSelected(false);
+  selectElementById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
+  }
+
+  @action
+  clearSelectElements() {
+    this.selectElements.forEach(element => {
+      element.setSelected(false);
+    });
+    this.selectElements.clear();
   }
 
   /* 修改连线类型 */
diff --git a/packages/core/src/view/edge/BaseEdge.tsx b/packages/core/src/view/edge/BaseEdge.tsx
index d45ea9e..d7c8f38 100644
--- a/packages/core/src/view/edge/BaseEdge.tsx
+++ b/packages/core/src/view/edge/BaseEdge.tsx
@@ -178,7 +178,8 @@ export default class BaseEdge extends Component<IProps> {
   handleClick = (e) => {
     const { model, graphModel, eventCenter } = this.props;
     graphModel.toFront(model.id);
-    graphModel.selectEdgeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectEdgeById(model.id, e.metaKey && metaKeyMultipleSelected);
     // 边数据
     const edgeData = model?.getData();
     const position = graphModel.getPointByClient({
diff --git a/packages/core/src/view/node/BaseNode.tsx b/packages/core/src/view/node/BaseNode.tsx
index 140889c..5ee3975 100644
--- a/packages/core/src/view/node/BaseNode.tsx
+++ b/packages/core/src/view/node/BaseNode.tsx
@@ -275,7 +275,8 @@ export default abstract class BaseNode extends Component<IProps, Istate> {
       }, 400);
     }
     graphModel.toFront(model.id);
-    graphModel.selectNodeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectNodeById(model.id, e.metaKey && metaKeyMultipleSelected);
     this.preStartTime = this.startTime;
   };
   handleContextMenu = (ev: MouseEvent) => {
diff --git a/packages/core/src/view/overlay/CanvasOverlay.tsx b/packages/core/src/view/overlay/CanvasOverlay.tsx
index ef11822..8c79fd2 100644
--- a/packages/core/src/view/overlay/CanvasOverlay.tsx
+++ b/packages/core/src/view/overlay/CanvasOverlay.tsx
@@ -104,9 +104,9 @@ class CanvasOverlay extends Component<IProps, Istate> {
     const target = ev.target as HTMLElement;
     if (target.getAttribute('name') === 'canvas-overlay') {
       const { graphModel, eventCenter } = this.props;
-      const { selectElement, textEditElement } = graphModel;
-      if (selectElement) {
-        selectElement.setSelected(false);
+      const { textEditElement, selectElements } = graphModel;
+      if (selectElements.size > 0) {
+        graphModel.clearSelectElements();
       }
       if (textEditElement) {
         textEditElement.setElementState(ElementState.DEFAULT);
diff --git a/packages/extension/examples/bpmn/index.html b/packages/extension/examples/bpmn/index.html
index 7a68d6f..f7ea87d 100644
--- a/packages/extension/examples/bpmn/index.html
+++ b/packages/extension/examples/bpmn/index.html
@@ -6,6 +6,7 @@
   <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
   <title>LOGIN FLOW</title>
   <link rel=""stylesheet"" href=""/core/dist/style/index.css"">
+  <link rel=""stylesheet"" href=""/extension/lib/style/index.css"">
   <style>
     html,body {
       padding: 0;
@@ -129,11 +130,14 @@
     </div>
   </div>
   <script src=""/core/dist/logic-flow.js""></script>
+  <!-- <script src=""http://0.0.0.0:9090/logic-flow.js""></script> -->
   <script src=""/BpmnElement.js""></script>
   <script src=""/BpmnAdapter.js""></script>
+  <script src=""/Control.js""></script>
   <script src=""/Snapshot.js""></script>
   <script>
     LogicFlow.use(BpmnElement);
+    LogicFlow.use(Control);
     LogicFlow.use(BpmnAdapter);
     LogicFlow.use(Snapshot);
   </script>
diff --git a/packages/extension/examples/bpmn/index.js b/packages/extension/examples/bpmn/index.js
index 21d2da0..6f6aa39 100644
--- a/packages/extension/examples/bpmn/index.js
+++ b/packages/extension/examples/bpmn/index.js
@@ -3,6 +3,10 @@ window.onload = function () {
     container: document.querySelector('#app'),
     // fixme: grid成为了必传的了
     edgeTextDraggable: true,
+    metaKeyMultipleSelected: true,
+    // stopScrollGraph: true,
+    // stopMoveGraph: true,
+    // stopZoomGraph: true,
     grid: {
       type: 'dot',
       size: 20,

diff --git a/packages/nocodb/docker-compose.yml b/packages/nocodb/docker-compose.yml
index 7fabf79..ba2ab7b 100644
--- a/packages/nocodb/docker-compose.yml
+++ b/packages/nocodb/docker-compose.yml
@@ -1,4 +1,4 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
     # db55:
@@ -96,8 +96,8 @@ services:
     #     - 5495:5432
     #   volumes:
     #     - ./pg-sakila-db:/docker-entrypoint-initdb.d
-    pg96:
-     image: postgres:9.6
+    pg147:
+     image: postgres:14.7
      restart: always
      environment:
        POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
index 19dfab2..97d346b 100644
--- a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
+++ b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg.yml b/tests/playwright/scripts/docker-compose-pg.yml
index 0396579..9fab10e 100644
--- a/tests/playwright/scripts/docker-compose-pg.yml
+++ b/tests/playwright/scripts/docker-compose-pg.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection
",3,"[""e137f9fdbdb6bf3f85c3f7ac9323785e445844c8"", ""37b1cbfd3d2c462ef4f2a131e4172c38dc8d9ddf"", ""e12d9e77a6fd531a22325337838a841b1c67f00d""]","[""feat"", ""build"", ""docs""]"
"fix netty dependency

netty-bom 4.1.70 contains the changes from pull request
https://github.com/netty/netty/pull/11798, which moved the classes out
of the native modules to make sure the same classes don't end up on the
classpath multiple times. For us it means that we need to depend on both
the native and classes modules. However, since we don't use the native
module directly (only classes that were moved to this classes module),
we need to force the dependency plugin to consider the native module as
used.cleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.run pyspark tests in parallel","diff --git a/atomix/cluster/pom.xml b/atomix/cluster/pom.xml
index a477873..b6db695 100644
--- a/atomix/cluster/pom.xml
+++ b/atomix/cluster/pom.xml
@@ -69,6 +69,10 @@
     </dependency>
     <dependency>
       <groupId>io.netty</groupId>
+      <artifactId>netty-transport-classes-epoll</artifactId>
+    </dependency>
+    <dependency>
+      <groupId>io.netty</groupId>
       <artifactId>netty-transport-native-epoll</artifactId>
       <classifier>linux-x86_64</classifier>
     </dependency>
@@ -278,6 +282,7 @@
             <dependency>uk.co.real-logic:sbe-tool</dependency>
             <dependency>net.jqwik:jqwik</dependency>
             <dependency>io.netty:netty-tcnative-boringssl-static</dependency>
+            <dependency>io.netty:netty-transport-native-epoll</dependency>
           </usedDependencies>
         </configuration>
       </plugin>

diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index e23088e..9708157 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -202,11 +202,11 @@ jobs:
         run: poetry install --without dev --without docs --extras ${{ matrix.backend.name }} --extras geospatial
 
       - name: ""run parallel tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name != 'pyspark' && matrix.backend.name != 'impala'
+        if: matrix.backend.name != 'impala'
         run: just ci-check -m ${{ matrix.backend.name }} --numprocesses auto --dist=loadgroup
 
       - name: ""run serial tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name == 'pyspark' || matrix.backend.name == 'impala'
+        if: matrix.backend.name == 'impala'
         run: just ci-check -m ${{ matrix.backend.name }}
         env:
           IBIS_TEST_NN_HOST: localhost
",3,"[""f00a4d3e307b89842250358ee432e6800bb24362"", ""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7"", ""4cbbd2552ba0de273e1dfe7d453c5b3efed751a3""]","[""build"", ""refactor"", ""cicd""]"
"better layout for block and segmentadd remote [skip ci]upgrade to Flux v0.42.0

Skips a test that requires special dependencies to pass.","diff --git a/docs/docs/config-block.md b/docs/docs/config-block.md
new file mode 100644
index 0000000..df1ee54
--- /dev/null
+++ b/docs/docs/config-block.md
@@ -0,0 +1,60 @@
+---
+id: config-block
+title: Block
+sidebar_label: Block
+---
+
+Let's take a closer look at what defines a block.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""segments"": [
+        ...
+      ]
+    }
+  ]
+}
+```
+
+- type: `prompt` | `rprompt`
+- newline: `boolean`
+- alignment: `left` | `right`
+- vertical_offset: `int`
+- horizontal_offset: `int`
+- segments: `array` of one or more `segments`
+
+### Type
+
+Tells the engine what to do with the block. There are three options:
+
+- `prompt` renders one or more segments
+- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
+Supported on [ZSH][rprompt], Bash and Powershell.
+
+### Newline
+
+Start the block on a new line. Defaults to `false`.
+
+### Alignment
+
+Tell the engine if the block should be left or right-aligned.
+
+### Vertical offset
+
+Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
+moves it up one line.
+
+### Horizontal offset
+
+Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
+but on a horizontal level where a negative number moves the block left and a positive number right.
+
+### Segments
+
+Array of one or more segments.
diff --git a/docs/docs/config-example.md b/docs/docs/config-example.md
new file mode 100644
index 0000000..c180c4f
--- /dev/null
+++ b/docs/docs/config-example.md
@@ -0,0 +1,96 @@
+---
+id: config-sample
+title: Sample
+sidebar_label: Sample
+---
+
+```json
+{
+  ""final_space"": true,
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""right"",
+      ""vertical_offset"": -1,
+      ""segments"": [
+        {
+          ""type"": ""time"",
+          ""style"": ""plain"",
+          ""foreground"": ""#007ACC"",
+          ""properties"": {
+            ""time_format"": ""15:04:05""
+          }
+        }
+      ]
+    },
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""newline"": true,
+      ""segments"": [
+        {
+          ""type"": ""session"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#ffb300"",
+          ""leading_diamond"": ""\uE0B6"",
+          ""trailing_diamond"": ""\uE0B0"",
+          ""properties"": {
+            ""postfix"": "" ""
+          }
+        },
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ""prefix"": "" \uE5FF "",
+            ""style"": ""folder"",
+            ""exclude_folders"": [
+              ""/super/secret/project""
+            ],
+            ""enable_hyperlink"": false
+          }
+        },
+        {
+          ""type"": ""git"",
+          ""style"": ""powerline"",
+          ""foreground"": ""#193549"",
+          ""foreground_templates"": [
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
+          ],
+          ""background"": ""#2e9599"",
+          ""background_templates"": [
+            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
+            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
+            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
+          ],
+          ""powerline_symbol"": ""\uE0B0"",
+          ""properties"": {
+            ""fetch_status"": true,
+            ""branch_max_length"": 25,
+            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
+          }
+        },
+        {
+          ""type"": ""exit"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#00897b"",
+          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
+          ""leading_diamond"": """",
+          ""trailing_diamond"": ""\uE0B4"",
+          ""properties"": {
+            ""always_enabled"": true,
+            ""template"": ""\uE23A"",
+            ""prefix"": ""<parentBackground>\uE0B0</> ""
+          }
+        }
+      ]
+    }
+  ]
+}
+```
diff --git a/docs/docs/config-overview.md b/docs/docs/config-overview.md
index 1fdbcba..b554869 100644
--- a/docs/docs/config-overview.md
+++ b/docs/docs/config-overview.md
@@ -1,7 +1,7 @@
 ---
 id: config-overview
-title: Overview
-sidebar_label: Overview
+title: General
+sidebar_label: General
 ---
 
 Oh My Posh renders your prompt based on the definition of _blocks_ (like Lego) which contain one or more _segments_.
@@ -64,332 +64,7 @@ boxes with question marks, set up your terminal to use a [supported font][font] 
 - terminal_background: `string` [color][colors] - terminal background color, set to your terminal's background color when
 you notice black elements in Windows Terminal or the Visual Studio Code integrated terminal
 
-## Block
-
-Let's take a closer look at what defines a block.
-
-- type: `prompt` | `rprompt`
-- newline: `boolean`
-- alignment: `left` | `right`
-- vertical_offset: `int`
-- horizontal_offset: `int`
-- segments: `array` of one or more `segments`
-
-### Type
-
-Tells the engine what to do with the block. There are three options:
-
-- `prompt` renders one or more segments
-- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
-Supported on [ZSH][rprompt], Bash and Powershell.
-
-### Newline
-
-Start the block on a new line. Defaults to `false`.
-
-### Alignment
-
-Tell the engine if the block should be left or right-aligned.
-
-### Vertical offset
-
-Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
-moves it up one line.
-
-### Horizontal offset
-
-Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
-but on a horizontal level where a negative number moves the block left and a positive number right.
-
-### Segments
-
-Array of one or more segments.
-
-## Segment
-
-A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
-looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
-understand how to configure a segment.
-
-- type: `string` any of the included [segments][segments]
-- style: `powerline` | `plain` | `diamond`
-- powerline_symbol: `string`
-- invert_powerline: `boolean`
-- leading_diamond: `string`
-- trailing_diamond: `string`
-- foreground: `string` [color][colors]
-- foreground_templates: `array` of `string` values
-- background: `string` [color][colors]
-- background_templates: `array` of `string` values
-- properties: `array` of `Property`: `string`
-
-### Type
-
-Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
-
-### Style
-
-Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
-themes out there, we identified 3 types. All of these require a different configuration and depending on the look
-you want to achieve you might need to understand/use them all.
-
-#### Powerline
-
-What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
-background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
-if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
-
-#### Plain
-
-Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
-Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
-
-#### Diamond
-
-While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
-Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
-segment background as their foreground color.
-
-### Powerline symbol
-
-Text character to use when `""style"": ""powerline""`.
-
-### Invert Powerline
-
-If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
-in the perfectly mirrored variant for example.
-
-### Leading diamond
-
-Text character to use at the start of the segment. Will take the background color of the segment as
-its foreground color.
-
-### Trailing diamond
-
-Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
-
-### Foreground
-
-[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
-
-### Foreground Templates
-
-Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
-Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
-offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
-the documentation.
-
-The following sample is based on the [AWS Segment][aws].
-
-```json
-{
-  ""type"": ""aws"",
-  ""style"": ""powerline"",
-  ""powerline_symbol"": ""\uE0B0"",
-  ""foreground"": ""#ffffff"",
-  ""background"": ""#111111"",
-  ""foreground_templates"": [
-    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
-    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
-  ],
-  ""properties"": {
-    ""prefix"": "" \uE7AD ""
-  }
-}
-```
-
-The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
-one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
-returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
-templates returns a value, the foreground value `#ffffff` is used.
-
-### Background
-
-[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
-
-### Background Templates
-
-Same as [Foreground Templates][fg-templ] but for the background color.
-
-### Properties
-
-An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
-will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
-engine which allow you to customize the output even more.
-
-#### General-purpose properties
-
-You can use these on any segment, the engine is responsible for adding them correctly.
-
-- prefix: `string`
-- postfix: `string`
-- include_folders: `[]string`
-- exclude_folders: `[]string`
-
-##### Prefix
-
-The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
-specify this as `''`.
-
-##### Postfix
-
-The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
-specify this as `''`.
-
-##### Include / Exclude Folders
-
-Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
-the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
-will not be rendered when in one of the excluded locations.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-```json
-""exclude_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-The strings specified in these properties are evaluated as [regular expressions][regex]. You
-can use any valid regular expression construct, but the regular expression must match the entire directory
-name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-]
-```
-
-You can also combine these properties:
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-],
-""exclude_folders"": [
-  ""/Users/posh/Projects/secret-project.*""
-]
-```
-
-##### Notes
-
-- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
-is used by the current operating system.
-- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
-directory name, you need to specify it as `\\\\`.
-- The character `~` at the start of a specified folder will match the user's home directory.
-- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
-
-This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
-`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
-
-## Full Sample
-
-```json
-{
-  ""final_space"": true,
-  ""blocks"": [
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""right"",
-      ""vertical_offset"": -1,
-      ""segments"": [
-        {
-          ""type"": ""time"",
-          ""style"": ""plain"",
-          ""foreground"": ""#007ACC"",
-          ""properties"": {
-            ""time_format"": ""15:04:05""
-          }
-        }
-      ]
-    },
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""left"",
-      ""newline"": true,
-      ""segments"": [
-        {
-          ""type"": ""session"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#ffb300"",
-          ""leading_diamond"": ""\uE0B6"",
-          ""trailing_diamond"": ""\uE0B0"",
-          ""properties"": {
-            ""postfix"": "" ""
-          }
-        },
-        {
-          ""type"": ""path"",
-          ""style"": ""powerline"",
-          ""powerline_symbol"": ""\uE0B0"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#61AFEF"",
-          ""properties"": {
-            ""prefix"": "" \uE5FF "",
-            ""style"": ""folder"",
-            ""exclude_folders"": [
-              ""/super/secret/project""
-            ],
-            ""enable_hyperlink"": false
-          }
-        },
-        {
-          ""type"": ""git"",
-          ""style"": ""powerline"",
-          ""foreground"": ""#193549"",
-          ""foreground_templates"": [
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
-          ],
-          ""background"": ""#2e9599"",
-          ""background_templates"": [
-            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
-            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
-            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
-          ],
-          ""powerline_symbol"": ""\uE0B0"",
-          ""properties"": {
-            ""fetch_status"": true,
-            ""branch_max_length"": 25,
-            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
-          }
-        },
-        {
-          ""type"": ""exit"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#00897b"",
-          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
-          ""leading_diamond"": """",
-          ""trailing_diamond"": ""\uE0B4"",
-          ""properties"": {
-            ""always_enabled"": true,
-            ""template"": ""\uE23A"",
-            ""prefix"": ""<parentBackground>\uE0B0</> ""
-          }
-        }
-      ]
-    }
-  ]
-}
-```
-
 [releases]: https://github.com/JanDeDobbeleer/oh-my-posh/releases/latest
 [font]: /docs/config-fonts
 [schema]: https://github.com/JanDeDobbeleer/oh-my-posh/blob/main/themes/schema.json
 [themes]: https://github.com/JanDeDobbeleer/oh-my-posh/tree/main/themes
-[segments]: /docs/battery
-[colors]: /docs/config-colors
-[go-text-template]: https://golang.org/pkg/text/template/
-[sprig]: https://masterminds.github.io/sprig/
-[fg-templ]: /docs/config-overview#foreground-templates
-[regex]: https://www.regular-expressions.info/tutorial.html
-[aws]: /docs/aws
diff --git a/docs/docs/config-segment.md b/docs/docs/config-segment.md
new file mode 100644
index 0000000..08a66e4
--- /dev/null
+++ b/docs/docs/config-segment.md
@@ -0,0 +1,219 @@
+---
+id: config-segment
+title: Segment
+sidebar_label: Segment
+---
+
+A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
+looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
+understand how to configure a segment.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ...
+      ""segments"": [
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ...
+          }
+        }
+      ]
+    }
+  ]
+}
+```
+
+- type: `string` any of the included [segments][segments]
+- style: `powerline` | `plain` | `diamond`
+- powerline_symbol: `string`
+- invert_powerline: `boolean`
+- leading_diamond: `string`
+- trailing_diamond: `string`
+- foreground: `string` [color][colors]
+- foreground_templates: `array` of `string` values
+- background: `string` [color][colors]
+- background_templates: `array` of `string` values
+- properties: `array` of `Property`: `string`
+
+## Type
+
+Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
+
+## Style
+
+Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
+themes out there, we identified 3 types. All of these require a different configuration and depending on the look
+you want to achieve you might need to understand/use them all.
+
+### Powerline
+
+What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
+background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
+if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
+
+### Plain
+
+Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
+Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
+
+### Diamond
+
+While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
+Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
+segment background as their foreground color.
+
+## Powerline symbol
+
+Text character to use when `""style"": ""powerline""`.
+
+## Invert Powerline
+
+If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
+in the perfectly mirrored variant for example.
+
+## Leading diamond
+
+Text character to use at the start of the segment. Will take the background color of the segment as
+its foreground color.
+
+## Trailing diamond
+
+Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
+
+## Foreground
+
+[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
+
+## Foreground Templates
+
+Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
+Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
+offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
+the documentation.
+
+The following sample is based on the [AWS Segment][aws].
+
+```json
+{
+  ""type"": ""aws"",
+  ""style"": ""powerline"",
+  ""powerline_symbol"": ""\uE0B0"",
+  ""foreground"": ""#ffffff"",
+  ""background"": ""#111111"",
+  ""foreground_templates"": [
+    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
+    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
+  ],
+  ""properties"": {
+    ""prefix"": "" \uE7AD ""
+  }
+}
+```
+
+The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
+one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
+returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
+templates returns a value, the foreground value `#ffffff` is used.
+
+## Background
+
+[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
+
+## Background Templates
+
+Same as [Foreground Templates][fg-templ] but for the background color.
+
+## Properties
+
+An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
+will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
+engine which allow you to customize the output even more.
+
+### General-purpose properties
+
+You can use these on any segment, the engine is responsible for adding them correctly.
+
+- prefix: `string`
+- postfix: `string`
+- include_folders: `[]string`
+- exclude_folders: `[]string`
+
+#### Prefix
+
+The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
+specify this as `''`.
+
+#### Postfix
+
+The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
+specify this as `''`.
+
+#### Include / Exclude Folders
+
+Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
+the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
+will not be rendered when in one of the excluded locations.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+```json
+""exclude_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+The strings specified in these properties are evaluated as [regular expressions][regex]. You
+can use any valid regular expression construct, but the regular expression must match the entire directory
+name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+]
+```
+
+You can also combine these properties:
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+],
+""exclude_folders"": [
+  ""/Users/posh/Projects/secret-project.*""
+]
+```
+
+#### Notes
+
+- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
+is used by the current operating system.
+- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
+directory name, you need to specify it as `\\\\`.
+- The character `~` at the start of a specified folder will match the user's home directory.
+- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
+
+This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
+`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
+
+[segments]: /docs/battery
+[colors]: /docs/config-colors
+[go-text-template]: https://golang.org/pkg/text/template/
+[sprig]: https://masterminds.github.io/sprig/
+[fg-templ]: /docs/config-overview#foreground-templates
+[regex]: https://www.regular-expressions.info/tutorial.html
+[aws]: /docs/aws
diff --git a/docs/docs/segment-environment.md b/docs/docs/segment-environment.md
index f35bc87..982a0a5 100644
--- a/docs/docs/segment-environment.md
+++ b/docs/docs/segment-environment.md
@@ -34,7 +34,7 @@ New-Alias -Name 'Set-PoshContext' -Value 'Set-EnvVar' -Scope Global -Force
 
 The segment will show when the value of the environment variable isn't empty.
 
-## Sample Configuration
+## Sample *Configuration*
 
 ```json
 {
diff --git a/docs/sidebars.js b/docs/sidebars.js
index a75163e..8f151a2 100644
--- a/docs/sidebars.js
+++ b/docs/sidebars.js
@@ -20,6 +20,9 @@ module.exports = {
       label: ""⚙️ Configuration"",
       items: [
         ""config-overview"",
+        ""config-block"",
+        ""config-segment"",
+        ""config-sample"",
         ""config-title"",
         ""config-colors"",
         ""config-text-style"",

diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 06c9003..e19c703 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -47,7 +47,10 @@ jobs:
           git config --global user.email 'ibis-squawk-bot[bot]@users.noreply.github.com'
 
       - name: fetch and rebase on top of upstream
-        run: git pull --rebase -X ours https://github.com/ibis-project/ibis master
+        run: |
+          git remote add upstream https://github.com/ibis-project/ibis
+          git fetch upstream
+          git rebase -X ours upstream/master
 
       - uses: tibdex/github-app-token@v1
         id: generate_pr_token

diff --git a/go.mod b/go.mod
index ea705da..8c352f7 100644
--- a/go.mod
+++ b/go.mod
@@ -38,7 +38,7 @@ require (
 	github.com/hashicorp/go-msgpack v0.0.0-20150518234257-fa3f63826f7c // indirect
 	github.com/hashicorp/raft v1.0.0 // indirect
 	github.com/hashicorp/vault/api v1.0.2
-	github.com/influxdata/flux v0.41.0
+	github.com/influxdata/flux v0.42.0
 	github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6
 	github.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368
 	github.com/jessevdk/go-flags v1.4.0
diff --git a/go.sum b/go.sum
index 4bfdf4c..634a0f1 100644
--- a/go.sum
+++ b/go.sum
@@ -206,8 +206,8 @@ github.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NH
 github.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=
 github.com/influxdata/changelog v1.0.0 h1:RstJD6H48zLQj0GdE6E6k/6RPwtUjkyzIe/T1E/xuWU=
 github.com/influxdata/changelog v1.0.0/go.mod h1:uzpGWE/qehT8L426YuXwpMQub+a63vIINhIeEI9mnSM=
-github.com/influxdata/flux v0.41.0 h1:ljbWJmE+aNx8Yoqhb04gWC4sXMV87eYUxz5vjYphLLs=
-github.com/influxdata/flux v0.41.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
+github.com/influxdata/flux v0.42.0 h1:2iEG6hLHdHEJ6LgD8OSnlHS9yoVrLO1/aM4P9ERb94U=
+github.com/influxdata/flux v0.42.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
 github.com/influxdata/goreleaser v0.97.0-influx h1:jT5OrcW7WfS0e2QxfwmTBjhLvpIC9CDLRhNgZJyhj8s=
 github.com/influxdata/goreleaser v0.97.0-influx/go.mod h1:MnjA0e0Uq6ISqjG1WxxMAl+3VS1QYjILSWVnMYDxasE=
 github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6 h1:CFx+pP90q/qg3spoiZjf8donE4WpAdjeJfPOcoNqkWo=
diff --git a/query/stdlib/testing/testing.go b/query/stdlib/testing/testing.go
index d41574a..85b0673 100644
--- a/query/stdlib/testing/testing.go
+++ b/query/stdlib/testing/testing.go
@@ -98,4 +98,6 @@ var FluxEndToEndSkipList = map[string]string{
 	""http_endpoint"": ""need ability to test side effects in e2e tests: (https://github.com/influxdata/flux/issues/1723)"",
 
 	""holt_winters_panic"": ""Expected output is an empty table which breaks the testing framework (https://github.com/influxdata/influxdb/issues/14749)"",
+
+	""secrets"": ""Cannot inject custom deps into the test framework so the secrets don't lookup correctly"",
 }
",3,"[""cb1f48b56ae0de93acb72e48726c7d610a1d538e"", ""e96487ad7ce90b141219d9032fa2bed68d5dae6a"", ""454003841aabeb74396d73541378bfa59c75b5db""]","[""docs"", ""cicd"", ""build""]"
"print errors without stacktraceskip flaky testassist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method

diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }
",3,"[""d129eaf9125a967ac86c6c7276bbae6b4d50af36"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d"", ""1269431c8a3e7549f10fcbbb4b88ff625c8898b3""]","[""fix"", ""test"", ""build""]"
added suported tuple typeslicensingdetach ViewControllers when not active,"diff --git a/src/List/Tuple.ts b/src/List/Tuple.ts
index 4c59caa..6e45503 100644
--- a/src/List/Tuple.ts
+++ b/src/List/Tuple.ts
@@ -1,15 +1,17 @@
-/** A [[Tuple]]
+import {NonNullable} from '../Object/NonNullable'
+
+/** A [[Tuple]] (supported)
  * @param A its type
- * @returns **`any[]`**
+ * @returns **`A[]`**
  * @example
  * ```ts
- * type list0 = [1, 2, 3]
- * type list1 = number[]
+ * type tuple0 = [1, 20, 42]
+ * type tuple1 = ['at', 420]
  * ```
  */
-export type Tuple = [
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-]
+export type Tuple<A = any> = NonNullable<[
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+]>

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;

diff --git a/ionic/components/nav/nav-controller.ts b/ionic/components/nav/nav-controller.ts
index becdd99..1cc3c31 100644
--- a/ionic/components/nav/nav-controller.ts
+++ b/ionic/components/nav/nav-controller.ts
@@ -1410,6 +1410,9 @@ export class NavController extends Ion {
       // set the ComponentRef's instance to this ViewController
       view.setInstance(component);
 
+      // remember the ChangeDetectorRef for this ViewController
+      view.setChangeDetector(hostViewRef.changeDetectorRef);
+
       // remember the ElementRef to the ion-page elementRef that was just created
       view.setPageRef(pageElementRef);
 
diff --git a/ionic/components/nav/view-controller.ts b/ionic/components/nav/view-controller.ts
index 3207fa2..069c74d 100644
--- a/ionic/components/nav/view-controller.ts
+++ b/ionic/components/nav/view-controller.ts
@@ -1,4 +1,4 @@
-import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer} from 'angular2/core';
+import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer, ChangeDetectorRef} from 'angular2/core';
 
 import {Navbar} from '../navbar/navbar';
 import {NavController, NavOptions} from './nav-controller';
@@ -33,6 +33,7 @@ export class ViewController {
   private _nbVwRef: ViewContainerRef;
   private _onDismiss: Function = null;
   private _pgRef: ElementRef;
+  private _cd: ChangeDetectorRef;
   protected _nav: NavController;
 
   /**
@@ -166,6 +167,13 @@ export class ViewController {
   /**
    * @private
    */
+  setChangeDetector(cd: ChangeDetectorRef) {
+    this._cd = cd;
+  }
+
+  /**
+   * @private
+   */
   setInstance(instance: any) {
     this.instance = instance;
   }
@@ -467,6 +475,14 @@ export class ViewController {
    * The view is about to enter and become the active view.
    */
   willEnter() {
+    if (this._cd) {
+      // ensure this has been re-attached to the change detector
+      this._cd.reattach();
+
+      // detect changes before we run any user code
+      this._cd.detectChanges();
+    }
+
     ctrlFn(this, 'onPageWillEnter');
   }
 
@@ -496,6 +512,10 @@ export class ViewController {
    */
   didLeave() {
     ctrlFn(this, 'onPageDidLeave');
+
+    // when this is not the active page
+    // we no longer need to detect changes
+    this._cd && this._cd.detach();
   }
 
   /**
",3,"[""2954a0955ce9af6acb345ed1e8328e145ad30475"", ""a52a585d74894b3b4eeb8c784fa089ff95cddad0"", ""b282e90e2cbb74559aab79eee8443a4d7c85502a""]","[""refactor"", ""docs"", ""feat""]"
update `cargo-make` for `v0.35.3`convert `run_tag_values_test_case` to a functionxfail on to_parquet and to_csv that use pyarrow write options,"diff --git a/CHANGELOG.md b/CHANGELOG.md
index 5e125e3..52d9b6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 * Fix: resizing/scrolling through heavily wrapped panes no longer hangs (https://github.com/zellij-org/zellij/pull/814)
 * Terminal compatibility: properly handle HOME/END keys in eg. vim/zsh (https://github.com/zellij-org/zellij/pull/815)
 * Fix: Typo (https://github.com/zellij-org/zellij/pull/821)
+* Fix: Update `cargo-make` instructions post `v0.35.3` (https://github.com/zellij-org/zellij/pull/819)
 
 ## [0.19.0] - 2021-10-20
 * Fix: Prevent text overwrite when scrolled up (https://github.com/zellij-org/zellij/pull/655)

diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]

diff --git a/ibis/backends/tests/test_export.py b/ibis/backends/tests/test_export.py
index 4d536d7..5bb9775 100644
--- a/ibis/backends/tests/test_export.py
+++ b/ibis/backends/tests/test_export.py
@@ -222,18 +222,23 @@ def test_table_to_parquet(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs""), [({""version"": ""1.0""}), ({""version"": ""2.6""})])
-def test_table_to_parquet_writer_kwargs(kwargs, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.NotSupportedError,
+)
+@pytest.mark.parametrize(""version"", [""1.0"", ""2.6""])
+def test_table_to_parquet_writer_kwargs(version, tmp_path, backend, awards_players):
     outparquet = tmp_path / ""out.parquet""
-    awards_players.to_parquet(outparquet, **kwargs)
+    awards_players.to_parquet(outparquet, version=version)
 
     df = pd.read_parquet(outparquet)
 
     backend.assert_frame_equal(awards_players.to_pandas(), df)
 
-    file = pa.parquet.ParquetFile(outparquet)
+    md = pa.parquet.read_metadata(outparquet)
 
-    assert file.metadata.format_version == kwargs[""version""]
+    assert md.format_version == version
 
 
 @pytest.mark.notimpl(
@@ -316,14 +321,20 @@ def test_table_to_csv(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs"", ""delimiter""), [({""write_options"": pcsv.WriteOptions(delimiter="";"")}, "";""), ({""write_options"": pcsv.WriteOptions(delimiter=""\t"")}, ""\t"")])
-def test_table_to_csv_writer_kwargs(kwargs, delimiter, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.ProgrammingError,
+)
+@pytest.mark.parametrize(""delimiter"", ["";"", ""\t""], ids=[""semicolon"", ""tab""])
+def test_table_to_csv_writer_kwargs(delimiter, tmp_path, awards_players):
     outcsv = tmp_path / ""out.csv""
     # avoid pandas NaNonense
     awards_players = awards_players.select(""playerID"", ""awardID"", ""yearID"", ""lgID"")
 
-    awards_players.to_csv(outcsv, **kwargs)
-    pd.read_csv(outcsv, delimiter=delimiter)
+    awards_players.to_csv(outcsv, write_options=pcsv.WriteOptions(delimiter=delimiter))
+    df = pd.read_csv(outcsv, delimiter=delimiter, nrows=1)
+    assert len(df) == 1
 
 
 @pytest.mark.parametrize(
",3,"[""0cfc5633d37ea06f645649138323f1820e18bdee"", ""1db13ec43727aca872a0f3836e4023ed85db665e"", ""bedc7950b24c37809e36a585b7985d5aa5e3e458""]","[""docs"", ""refactor"", ""test""]"
update flushed index before truncatingupdate `cargo-make` for `v0.35.3`fixed docker link tests,"diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/CHANGELOG.md b/CHANGELOG.md
index 5e125e3..52d9b6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 * Fix: resizing/scrolling through heavily wrapped panes no longer hangs (https://github.com/zellij-org/zellij/pull/814)
 * Terminal compatibility: properly handle HOME/END keys in eg. vim/zsh (https://github.com/zellij-org/zellij/pull/815)
 * Fix: Typo (https://github.com/zellij-org/zellij/pull/821)
+* Fix: Update `cargo-make` instructions post `v0.35.3` (https://github.com/zellij-org/zellij/pull/819)
 
 ## [0.19.0] - 2021-10-20
 * Fix: Prevent text overwrite when scrolled up (https://github.com/zellij-org/zellij/pull/655)

diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
",3,"[""933ab6bb86372913c992567cf9660009900911a7"", ""0cfc5633d37ea06f645649138323f1820e18bdee"", ""c7b25726df94a2530c9b1c0d2b6a0acaa103822f""]","[""fix"", ""docs"", ""test""]"
"cleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.publish sdks after docs/buildsetup jest and add m.ts tests","diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });
",3,"[""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7"", ""6c9cb638cb4d1ecc42632fcf389c24898c5b3244"", ""229b53a632ea97d47c4be11f096bdd828fb415d8""]","[""refactor"", ""cicd"", ""test""]"
"add a branch name to Slack notifications (#14793)setup jest and add m.ts testsadded changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284","diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });

diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')
",3,"[""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da"", ""229b53a632ea97d47c4be11f096bdd828fb415d8"", ""aca23027da1295c78fdf42ba9687d8ccc88784d7""]","[""cicd"", ""test"", ""docs""]"
"Add ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>update `cargo-make` for `v0.35.3`allow disabling dynamic queue","diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}

diff --git a/CHANGELOG.md b/CHANGELOG.md
index 5e125e3..52d9b6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 * Fix: resizing/scrolling through heavily wrapped panes no longer hangs (https://github.com/zellij-org/zellij/pull/814)
 * Terminal compatibility: properly handle HOME/END keys in eg. vim/zsh (https://github.com/zellij-org/zellij/pull/815)
 * Fix: Typo (https://github.com/zellij-org/zellij/pull/821)
+* Fix: Update `cargo-make` instructions post `v0.35.3` (https://github.com/zellij-org/zellij/pull/819)
 
 ## [0.19.0] - 2021-10-20
 * Fix: Prevent text overwrite when scrolled up (https://github.com/zellij-org/zellij/pull/655)

diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);
",3,"[""f823cf28652987d43c8324b4f5b203240032383a"", ""0cfc5633d37ea06f645649138323f1820e18bdee"", ""9ef5c0d14193a9abb09b39856f58477d1f4b0d77""]","[""feat"", ""docs"", ""fix""]"
"update wrapping tests for v7use `regexp_instr != 0` instead of `REGEXP` keywordspring version, core version","diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(

diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 
",3,"[""317f4eefecddfb1392ca71d551840f446feee302"", ""06e2be4e2019b6fa714e1fcb34485860ef1ede79"", ""c55591ba157298a9c5816693c102a89dfd058830""]","[""test"", ""fix"", ""build""]"
"support use meta key select multiple elementFix typocleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.","diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index ab68624..aeee7b7 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -277,9 +277,11 @@ export default class LogicFlow {
   }
   /**
    * 将图形选中
+   * @param id 选择元素ID
+   * @param multiple 是否允许多选，如果为true，不会将上一个选中的元素重置
    */
-  select(id: string) {
-    this.graphModel.selectElementById(id);
+  select(id: string, multiple = false) {
+    this.graphModel.selectElementById(id, multiple);
   }
   /**
    * 将图形定位到画布中心
diff --git a/packages/core/src/model/EditConfigModel.ts b/packages/core/src/model/EditConfigModel.ts
index 67e334a..83e5f16 100644
--- a/packages/core/src/model/EditConfigModel.ts
+++ b/packages/core/src/model/EditConfigModel.ts
@@ -25,6 +25,7 @@ const SilentConfig = {
   edgeTextEdit: false,
   nodeTextDraggable: false,
   edgeTextDraggable: false,
+  metaKeyMultipleSelected: false,
 };
 
 /**
@@ -42,6 +43,7 @@ export default class EditConfigModel {
   @observable edgeTextEdit = true; // 允许连线文本可以编辑
   @observable nodeTextDraggable = false; // 允许节点文本可以拖拽
   @observable edgeTextDraggable = false; // 允许连线文本可以拖拽
+  @observable metaKeyMultipleSelected = false; // 允许meta多选元素
   constructor(data) {
     const keys = [
       'stopZoomGraph',
@@ -55,6 +57,7 @@ export default class EditConfigModel {
       'edgeTextEdit',
       'nodeTextDraggable',
       'edgeTextDraggable',
+      'metaKeyMultipleSelected',
     ];
     const { isSilentMode, textEdit } = data;
     if (isSilentMode) {
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 9667f4d..310daf4 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -34,6 +34,7 @@ class GraphModel {
   height: number;
   topElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
   selectElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
+  selectElements = new Map<string, IBaseModel>(); // 多选
   @observable edgeType: string;
   @observable nodes: BaseNodeModel[] = [];
   @observable activeElement: IBaseModel;
@@ -50,7 +51,6 @@ class GraphModel {
   @observable gridSize = 1;
   @observable partial = false; // 是否开启局部渲染
   @observable fakerNode: BaseNodeModel;
-  // @observable selectElements = new Map<string, IBaseModel>(); // 多选还没有做，先不加
   constructor(config) {
     const {
       container,
@@ -456,24 +456,44 @@ class GraphModel {
   }
 
   @action
-  selectNodeById(id) {
-    this.selectElement?.setSelected(false);
+  selectNodeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.nodesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectEdgeById(id) {
-    this.selectElement?.setSelected(false);
+  selectEdgeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.edgesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectElementById(id: string) {
-    this.selectElement?.setSelected(false);
+  selectElementById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
+  }
+
+  @action
+  clearSelectElements() {
+    this.selectElements.forEach(element => {
+      element.setSelected(false);
+    });
+    this.selectElements.clear();
   }
 
   /* 修改连线类型 */
diff --git a/packages/core/src/view/edge/BaseEdge.tsx b/packages/core/src/view/edge/BaseEdge.tsx
index d45ea9e..d7c8f38 100644
--- a/packages/core/src/view/edge/BaseEdge.tsx
+++ b/packages/core/src/view/edge/BaseEdge.tsx
@@ -178,7 +178,8 @@ export default class BaseEdge extends Component<IProps> {
   handleClick = (e) => {
     const { model, graphModel, eventCenter } = this.props;
     graphModel.toFront(model.id);
-    graphModel.selectEdgeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectEdgeById(model.id, e.metaKey && metaKeyMultipleSelected);
     // 边数据
     const edgeData = model?.getData();
     const position = graphModel.getPointByClient({
diff --git a/packages/core/src/view/node/BaseNode.tsx b/packages/core/src/view/node/BaseNode.tsx
index 140889c..5ee3975 100644
--- a/packages/core/src/view/node/BaseNode.tsx
+++ b/packages/core/src/view/node/BaseNode.tsx
@@ -275,7 +275,8 @@ export default abstract class BaseNode extends Component<IProps, Istate> {
       }, 400);
     }
     graphModel.toFront(model.id);
-    graphModel.selectNodeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectNodeById(model.id, e.metaKey && metaKeyMultipleSelected);
     this.preStartTime = this.startTime;
   };
   handleContextMenu = (ev: MouseEvent) => {
diff --git a/packages/core/src/view/overlay/CanvasOverlay.tsx b/packages/core/src/view/overlay/CanvasOverlay.tsx
index ef11822..8c79fd2 100644
--- a/packages/core/src/view/overlay/CanvasOverlay.tsx
+++ b/packages/core/src/view/overlay/CanvasOverlay.tsx
@@ -104,9 +104,9 @@ class CanvasOverlay extends Component<IProps, Istate> {
     const target = ev.target as HTMLElement;
     if (target.getAttribute('name') === 'canvas-overlay') {
       const { graphModel, eventCenter } = this.props;
-      const { selectElement, textEditElement } = graphModel;
-      if (selectElement) {
-        selectElement.setSelected(false);
+      const { textEditElement, selectElements } = graphModel;
+      if (selectElements.size > 0) {
+        graphModel.clearSelectElements();
       }
       if (textEditElement) {
         textEditElement.setElementState(ElementState.DEFAULT);
diff --git a/packages/extension/examples/bpmn/index.html b/packages/extension/examples/bpmn/index.html
index 7a68d6f..f7ea87d 100644
--- a/packages/extension/examples/bpmn/index.html
+++ b/packages/extension/examples/bpmn/index.html
@@ -6,6 +6,7 @@
   <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
   <title>LOGIN FLOW</title>
   <link rel=""stylesheet"" href=""/core/dist/style/index.css"">
+  <link rel=""stylesheet"" href=""/extension/lib/style/index.css"">
   <style>
     html,body {
       padding: 0;
@@ -129,11 +130,14 @@
     </div>
   </div>
   <script src=""/core/dist/logic-flow.js""></script>
+  <!-- <script src=""http://0.0.0.0:9090/logic-flow.js""></script> -->
   <script src=""/BpmnElement.js""></script>
   <script src=""/BpmnAdapter.js""></script>
+  <script src=""/Control.js""></script>
   <script src=""/Snapshot.js""></script>
   <script>
     LogicFlow.use(BpmnElement);
+    LogicFlow.use(Control);
     LogicFlow.use(BpmnAdapter);
     LogicFlow.use(Snapshot);
   </script>
diff --git a/packages/extension/examples/bpmn/index.js b/packages/extension/examples/bpmn/index.js
index 21d2da0..6f6aa39 100644
--- a/packages/extension/examples/bpmn/index.js
+++ b/packages/extension/examples/bpmn/index.js
@@ -3,6 +3,10 @@ window.onload = function () {
     container: document.querySelector('#app'),
     // fixme: grid成为了必传的了
     edgeTextDraggable: true,
+    metaKeyMultipleSelected: true,
+    // stopScrollGraph: true,
+    // stopMoveGraph: true,
+    // stopZoomGraph: true,
     grid: {
       type: 'dot',
       size: 20,

diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:
",3,"[""e137f9fdbdb6bf3f85c3f7ac9323785e445844c8"", ""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7""]","[""feat"", ""docs"", ""refactor""]"
print errors without stacktracepublish sdks after docs/build[gn] fix include_dirs ordering error,"diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/

diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)
",3,"[""d129eaf9125a967ac86c6c7276bbae6b4d50af36"", ""6c9cb638cb4d1ecc42632fcf389c24898c5b3244"", ""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945""]","[""fix"", ""cicd"", ""build""]"
"initialize threejs objects in defaultRef, to fix undefined type errorsadded suported tuple typeslicensing","diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number

diff --git a/src/List/Tuple.ts b/src/List/Tuple.ts
index 4c59caa..6e45503 100644
--- a/src/List/Tuple.ts
+++ b/src/List/Tuple.ts
@@ -1,15 +1,17 @@
-/** A [[Tuple]]
+import {NonNullable} from '../Object/NonNullable'
+
+/** A [[Tuple]] (supported)
  * @param A its type
- * @returns **`any[]`**
+ * @returns **`A[]`**
  * @example
  * ```ts
- * type list0 = [1, 2, 3]
- * type list1 = number[]
+ * type tuple0 = [1, 20, 42]
+ * type tuple1 = ['at', 420]
  * ```
  */
-export type Tuple = [
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-]
+export type Tuple<A = any> = NonNullable<[
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+]>

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;
",3,"[""2561f4ade46fc9d59f289f328cc77733a6443697"", ""2954a0955ce9af6acb345ed1e8328e145ad30475"", ""a52a585d74894b3b4eeb8c784fa089ff95cddad0""]","[""fix"", ""refactor"", ""docs""]"
"spring version, core versionadd getter for protocol idfix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.","diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 

diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }

diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 
",3,"[""c55591ba157298a9c5816693c102a89dfd058830"", ""dc5238b2bda98a7c4f2fe9584fc3b0191a408109"", ""9be725fa3906323d4bc9788f54eccf74109d632b""]","[""build"", ""feat"", ""fix""]"
"setup jest and add m.ts testscleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.add props to get color and label from a route","diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });

diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:

diff --git a/src/components/BottomNavigation.js b/src/components/BottomNavigation.js
index 1b72302..7d8ea75 100644
--- a/src/components/BottomNavigation.js
+++ b/src/components/BottomNavigation.js
@@ -24,8 +24,8 @@ const AnimatedPaper = Animated.createAnimatedComponent(Paper);
 
 type Route = {
   key: string,
-  title: string,
-  icon: IconSource,
+  title?: string,
+  icon?: IconSource,
   color?: string,
 };
 
@@ -51,7 +51,7 @@ type Props<T> = {
    * - `key`: a unique key to identify the route
    * - `title`: title of the route to use as the tab label
    * - `icon`: icon to use as the tab icon, can be a string, an image source or a react component
-   * - `color`: color to use as background color for shifting bottom navigation (optional)
+   * - `color`: color to use as background color for shifting bottom navigation
    *
    * Example:
    *
@@ -115,11 +115,27 @@ type Props<T> = {
   /**
    * Callback which returns a React Element to be used as tab icon.
    */
-  renderIcon?: (props: { route: T, focused: boolean }) => React.Node,
+  renderIcon?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
   /**
    * Callback which React Element to be used as tab label.
    */
-  renderLabel?: (props: { route: T, focused: boolean }) => React.Node,
+  renderLabel?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
+  /**
+   * Get label text for the tab, uses `route.title` by default. Use `renderLabel` to replace label component.
+   */
+  getLabelText?: (props: { route: T }) => string,
+  /**
+   * Get color for the tab, uses `route.color` by default.
+   */
+  getColor?: (props: { route: T }) => string,
   /**
    * Function to execute on tab press. It receives the route for the pressed tab, useful for things like scroll to top.
    */
@@ -159,6 +175,10 @@ type State = {
    */
   ripple: Animated.Value,
   /**
+   * Animation for the touch feedback, used to determine it's scale and opacity.
+   */
+  touch: Animated.Value,
+  /**
    * Layout of the tab bar. The width is used to determine the size and position of the ripple.
    */
   layout: { height: number, width: number, measured: boolean },
@@ -173,7 +193,7 @@ const MIN_SHIFT_AMOUNT = 10;
 const MIN_TAB_WIDTH = 96;
 const MAX_TAB_WIDTH = 168;
 const BAR_HEIGHT = 56;
-const SMALL_RIPPLE_SIZE = 72;
+const SMALL_RIPPLE_SIZE = 96;
 const ACTIVE_LABEL_SIZE = 14;
 const INACTIVE_LABEL_SIZE = 12;
 
@@ -251,6 +271,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ),
       index: new Animated.Value(index),
       ripple: new Animated.Value(MIN_RIPPLE_SCALE),
+      touch: new Animated.Value(MIN_RIPPLE_SCALE),
       layout: { height: 0, width: 0, measured: false },
       previous: 0,
     };
@@ -349,6 +370,15 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
   _handleTabPress = (index: number) => {
     const { navigationState } = this.props;
 
+    this.state.touch.setValue(MIN_RIPPLE_SCALE);
+
+    Animated.timing(this.state.touch, {
+      toValue: 1,
+      duration: 300,
+      easing: Easing.in(Easing.sin),
+      useNativeDriver: true,
+    }).start();
+
     if (index !== navigationState.index) {
       this.props.onIndexChange(index);
     }
@@ -376,6 +406,8 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       renderScene,
       renderIcon,
       renderLabel,
+      getLabelText = ({ route }) => route.title,
+      getColor = ({ route }) => route.color,
       barStyle,
       style,
       theme,
@@ -400,7 +432,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ? this.state.index.interpolate({
           inputRange: routes.map((_, i) => i),
           outputRange: routes.map(
-            route => route.color || approxBackgroundColor
+            route => getColor({ route }) || approxBackgroundColor
           ),
         })
       : approxBackgroundColor;
@@ -416,7 +448,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
           .rgb()
           .string();
 
-    const rippleColor = color(textColor)
+    const touchColor = color(textColor)
       .alpha(0.12)
       .rgb()
       .string();
@@ -430,22 +462,10 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
 
     // Since we have a single ripple, we have to reposition it so that it appears to expand from active tab.
     // We need to move it from the left to the active tab and also account for how much that tab has shifted.
-    const rippleShift =
-      navigationState.index * tabWidth +
-      tabWidth / 2 +
-      this._calculateShift(
-        this.state.previous,
-        navigationState.index,
-        routes.length
-      );
 
     return (
       <View
-        style={[
-          styles.container,
-          { backgroundColor: theme.dark ? white : black },
-          style,
-        ]}
+        style={[styles.container, style]}
         onLayout={this._handleLayout}
         pointerEvents={layout.measured ? 'auto' : 'none'}
       >
@@ -485,25 +505,30 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
             style={[styles.items, { maxWidth: maxTabWidth * routes.length }]}
           >
             {shifting ? (
-              // Large ripple with the backround color
               <Animated.View
                 pointerEvents=""none""
                 style={[
                   styles.ripple,
                   {
                     // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - layout.width / 2,
-                    left: rippleShift - layout.width / 2,
-                    height: layout.width,
-                    width: layout.width,
+                    top: BAR_HEIGHT / 2 - layout.width / 8,
+                    left:
+                      navigationState.index * tabWidth +
+                      tabWidth / 2 -
+                      layout.width / 8,
+                    height: layout.width / 4,
+                    width: layout.width / 4,
                     borderRadius: layout.width / 2,
-                    backgroundColor: routes[navigationState.index].color,
+                    backgroundColor: getColor({
+                      route: routes[navigationState.index],
+                    }),
                     transform: [
+                      { translateX: this.state.shifts[navigationState.index] },
                       {
                         // Scale to twice the size  to ensure it covers the whole tab bar
                         scale: this.state.ripple.interpolate({
                           inputRange: [0, 1],
-                          outputRange: [0, 2],
+                          outputRange: [0, 8],
                         }),
                       },
                     ],
@@ -515,36 +540,36 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                 ]}
               />
             ) : null}
-            {shifting ? (
-              // Small subtle ripple on touch
-              <Animated.View
-                pointerEvents=""none""
-                style={[
-                  styles.ripple,
-                  {
-                    // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
-                    left: rippleShift - SMALL_RIPPLE_SIZE / 2,
-                    height: SMALL_RIPPLE_SIZE,
-                    width: SMALL_RIPPLE_SIZE,
-                    borderRadius: SMALL_RIPPLE_SIZE / 2,
-                    backgroundColor: rippleColor,
-                    transform: [
-                      {
-                        scale: this.state.ripple.interpolate({
-                          inputRange: [0, 0.5, 1],
-                          outputRange: [0, 1, 1],
-                        }),
-                      },
-                    ],
-                    opacity: this.state.ripple.interpolate({
-                      inputRange: [0, MIN_RIPPLE_SCALE, 0.25, 0.5],
-                      outputRange: [0, 0, 1, 0],
-                    }),
-                  },
-                ]}
-              />
-            ) : null}
+            <Animated.View
+              pointerEvents=""none""
+              style={[
+                styles.ripple,
+                {
+                  // Set top and left values so that the ripple's center is same as the tab's center
+                  top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
+                  left:
+                    navigationState.index * tabWidth +
+                    tabWidth / 2 -
+                    SMALL_RIPPLE_SIZE / 2,
+                  height: SMALL_RIPPLE_SIZE,
+                  width: SMALL_RIPPLE_SIZE,
+                  borderRadius: SMALL_RIPPLE_SIZE / 2,
+                  backgroundColor: touchColor,
+                  transform: [
+                    {
+                      translateX: shifting
+                        ? this.state.shifts[navigationState.index]
+                        : 0,
+                    },
+                    { scale: this.state.touch },
+                  ],
+                  opacity: this.state.touch.interpolate({
+                    inputRange: [0, 0.5, 1],
+                    outputRange: [0, 1, 0],
+                  }),
+                },
+              ]}
+            />
             {routes.map((route, index) => {
               const shift = this.state.shifts[index];
               const focused = this.state.tabs[index];
@@ -607,7 +632,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderIcon ? (
-                          renderIcon({ route, focused: true })
+                          renderIcon({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <Icon
                             style={styles.icon}
@@ -625,7 +654,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderIcon ? (
-                            renderIcon({ route, focused: false })
+                            renderIcon({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <Icon
                               style={styles.icon}
@@ -652,7 +685,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderLabel ? (
-                          renderLabel({ route, focused: true })
+                          renderLabel({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <AnimatedText
                             style={[
@@ -662,7 +699,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                               },
                             ]}
                           >
-                            {route.title}
+                            {getLabelText({ route })}
                           </AnimatedText>
                         )}
                       </Animated.View>
@@ -674,7 +711,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderLabel ? (
-                            renderLabel({ route, focused: false })
+                            renderLabel({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <AnimatedText
                               style={[
@@ -684,7 +725,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                                 },
                               ]}
                             >
-                              {route.title}
+                              {getLabelText({ route })}
                             </AnimatedText>
                           )}
                         </Animated.View>
",3,"[""229b53a632ea97d47c4be11f096bdd828fb415d8"", ""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7"", ""ded26d768ff432ad3bde3c0aa1e95ce50726100a""]","[""test"", ""refactor"", ""feat""]"
"verify checkpoint listeners are notifiedspring version, core versionincrement failing test retries","diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }

diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 

diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
",3,"[""e0198f74b81da3663144cfe1d971939319f82a0f"", ""c55591ba157298a9c5816693c102a89dfd058830"", ""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57""]","[""test"", ""build"", ""cicd""]"
xfail on to_parquet and to_csv that use pyarrow write optionsupdate flushed index before truncatingadd .nullif() example,"diff --git a/ibis/backends/tests/test_export.py b/ibis/backends/tests/test_export.py
index 4d536d7..5bb9775 100644
--- a/ibis/backends/tests/test_export.py
+++ b/ibis/backends/tests/test_export.py
@@ -222,18 +222,23 @@ def test_table_to_parquet(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs""), [({""version"": ""1.0""}), ({""version"": ""2.6""})])
-def test_table_to_parquet_writer_kwargs(kwargs, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.NotSupportedError,
+)
+@pytest.mark.parametrize(""version"", [""1.0"", ""2.6""])
+def test_table_to_parquet_writer_kwargs(version, tmp_path, backend, awards_players):
     outparquet = tmp_path / ""out.parquet""
-    awards_players.to_parquet(outparquet, **kwargs)
+    awards_players.to_parquet(outparquet, version=version)
 
     df = pd.read_parquet(outparquet)
 
     backend.assert_frame_equal(awards_players.to_pandas(), df)
 
-    file = pa.parquet.ParquetFile(outparquet)
+    md = pa.parquet.read_metadata(outparquet)
 
-    assert file.metadata.format_version == kwargs[""version""]
+    assert md.format_version == version
 
 
 @pytest.mark.notimpl(
@@ -316,14 +321,20 @@ def test_table_to_csv(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs"", ""delimiter""), [({""write_options"": pcsv.WriteOptions(delimiter="";"")}, "";""), ({""write_options"": pcsv.WriteOptions(delimiter=""\t"")}, ""\t"")])
-def test_table_to_csv_writer_kwargs(kwargs, delimiter, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.ProgrammingError,
+)
+@pytest.mark.parametrize(""delimiter"", ["";"", ""\t""], ids=[""semicolon"", ""tab""])
+def test_table_to_csv_writer_kwargs(delimiter, tmp_path, awards_players):
     outcsv = tmp_path / ""out.csv""
     # avoid pandas NaNonense
     awards_players = awards_players.select(""playerID"", ""awardID"", ""yearID"", ""lgID"")
 
-    awards_players.to_csv(outcsv, **kwargs)
-    pd.read_csv(outcsv, delimiter=delimiter)
+    awards_players.to_csv(outcsv, write_options=pcsv.WriteOptions(delimiter=delimiter))
+    df = pd.read_csv(outcsv, delimiter=delimiter, nrows=1)
+    assert len(df) == 1
 
 
 @pytest.mark.parametrize(

diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 
",3,"[""bedc7950b24c37809e36a585b7985d5aa5e3e458"", ""933ab6bb86372913c992567cf9660009900911a7"", ""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21""]","[""test"", ""fix"", ""docs""]"
print errors without stacktraceupdated react demo parcel commandupdate wrapping tests for v7,"diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {

diff --git a/demo/react/package.json b/demo/react/package.json
index be28bf9..32d0952 100644
--- a/demo/react/package.json
+++ b/demo/react/package.json
@@ -12,7 +12,7 @@
   },
   ""scripts"": {
     ""start"": ""parcel serve public/index.html --no-cache --open"",
-    ""build"": ""parcel build -t browser -d dist public/index.html --no-source-maps""
+    ""build"": ""parcel build --target browser --dist-dir dist public/index.html --no-source-maps""
   },
   ""bugs"": {
     ""url"": ""https://github.com/matteobruni/tsparticles/issues""

diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });
",3,"[""d129eaf9125a967ac86c6c7276bbae6b4d50af36"", ""32b92cfa0b74a6c25990e32ac6aab12b8496794c"", ""317f4eefecddfb1392ca71d551840f446feee302""]","[""fix"", ""build"", ""test""]"
"Add ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.split release docs build into separate workflow","diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}

diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 753d57d..3e0aa15 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -88,14 +88,14 @@ jobs:
         run: poetry run pytest --benchmark-only --benchmark-json .benchmarks/output.json ibis/tests/benchmarks
 
       - uses: tibdex/github-app-token@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         id: generate-token
         with:
           app_id: ${{ secrets.SQUAWK_BOT_APP_ID }}
           private_key: ${{ secrets.SQUAWK_BOT_APP_PRIVATE_KEY }}
 
       - uses: benchmark-action/github-action-benchmark@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         with:
           tool: pytest
           github-token: ${{ steps.generate-token.outputs.token }}
@@ -107,6 +107,7 @@ jobs:
 
   docs:
     runs-on: ubuntu-latest
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
     needs:
       # wait on benchmarks to prevent a race condition when pushing to the
       # gh-pages branch
@@ -124,51 +125,25 @@ jobs:
           authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
           extraPullNames: nix-community,poetry2nix
 
-      - name: Generate a GitHub token
-        if: ${{ github.event_name == 'push' }}
-        uses: tibdex/github-app-token@v1
-        id: generate_token
-        with:
-          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
-          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
-
-      - name: checkout
-        if: ${{ github.event_name == 'push' }}
-        uses: actions/checkout@v3
-        with:
-          fetch-depth: 0
-          token: ${{ steps.generate_token.outputs.token }}
-
       - name: checkout
-        if: ${{ github.event_name != 'push' }}
         uses: actions/checkout@v3
 
-      - name: Configure git info
-        if: ${{ github.event_name == 'push' }}
-        run: |
-          set -euo pipefail
-
-          git config user.name 'ibis-docs-bot[bot]'
-          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
-
       - name: build docs
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c mkdocs build
 
       - name: verify internal links
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c just checklinks --offline --no-progress
 
-      - name: Pull gh-pages changes
+      - name: Configure git info
         if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
-          git fetch origin gh-pages
-          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
 
       - name: build and push dev docs
-        if: ${{ github.event_name == 'push' && !startsWith(github.ref, 'refs/tags/') }}
+        if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
@@ -180,19 +155,6 @@ jobs:
               --message 'docs(dev): ibis@${{ github.sha }}' \
                 dev
 
-      - name: build and push docs on tag
-        if: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/tags/') }}
-        run: |
-          set -euo pipefail
-
-          nix develop -f shell.nix --keep-going -c \
-            mic deploy \
-              --push \
-              --rebase \
-              --prefix docs \
-              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
-              ""${GITHUB_REF_NAME}"" latest
-
   simulate_release:
     runs-on: ubuntu-latest
     steps:
diff --git a/.github/workflows/ibis-docs-release.yml b/.github/workflows/ibis-docs-release.yml
new file mode 100644
index 0000000..da7ee49
--- /dev/null
+++ b/.github/workflows/ibis-docs-release.yml
@@ -0,0 +1,63 @@
+# vim: filetype=yaml
+name: Docs Release Build
+
+on:
+  release:
+    types:
+      - published
+jobs:
+  docs:
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
+    runs-on: ubuntu-latest
+    steps:
+      - name: install nix
+        uses: cachix/install-nix-action@v17
+        with:
+          nix_path: nixpkgs=channel:nixos-unstable-small
+
+      - name: setup cachix
+        uses: cachix/cachix-action@v10
+        with:
+          name: ibis
+          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
+          extraPullNames: nix-community,poetry2nix
+
+      - name: Generate a GitHub token
+        uses: tibdex/github-app-token@v1
+        id: generate_token
+        with:
+          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
+          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
+
+      - name: checkout
+        uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+          token: ${{ steps.generate_token.outputs.token }}
+
+      - name: Configure git info
+        run: |
+          set -euo pipefail
+
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
+
+      - name: Pull gh-pages changes
+        run: |
+          set -euo pipefail
+
+          git fetch origin gh-pages
+          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+
+      - name: build and push docs on tag
+        run: |
+          set -euo pipefail
+
+          nix develop -f shell.nix --keep-going -c \
+            mic deploy \
+              --push \
+              --rebase \
+              --update-aliases \
+              --prefix docs \
+              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
+              ""${GITHUB_REF_NAME}"" latest
",3,"[""f823cf28652987d43c8324b4f5b203240032383a"", ""9be725fa3906323d4bc9788f54eccf74109d632b"", ""32845e1bbd1efb5dbc16f671049509a409ba25ce""]","[""feat"", ""fix"", ""cicd""]"
"allow disabling dynamic queuelicensingdocker PG version upgrade

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>","diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;

diff --git a/packages/nocodb/docker-compose.yml b/packages/nocodb/docker-compose.yml
index 7fabf79..ba2ab7b 100644
--- a/packages/nocodb/docker-compose.yml
+++ b/packages/nocodb/docker-compose.yml
@@ -1,4 +1,4 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
     # db55:
@@ -96,8 +96,8 @@ services:
     #     - 5495:5432
     #   volumes:
     #     - ./pg-sakila-db:/docker-entrypoint-initdb.d
-    pg96:
-     image: postgres:9.6
+    pg147:
+     image: postgres:14.7
      restart: always
      environment:
        POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
index 19dfab2..97d346b 100644
--- a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
+++ b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg.yml b/tests/playwright/scripts/docker-compose-pg.yml
index 0396579..9fab10e 100644
--- a/tests/playwright/scripts/docker-compose-pg.yml
+++ b/tests/playwright/scripts/docker-compose-pg.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
",3,"[""9ef5c0d14193a9abb09b39856f58477d1f4b0d77"", ""a52a585d74894b3b4eeb8c784fa089ff95cddad0"", ""37b1cbfd3d2c462ef4f2a131e4172c38dc8d9ddf""]","[""fix"", ""docs"", ""build""]"
repository creationrun pyspark tests in paralleladd .nullif() example,"diff --git a/server/src/services/repository.service.ts b/server/src/services/repository.service.ts
index 3869c98..d675b30 100644
--- a/server/src/services/repository.service.ts
+++ b/server/src/services/repository.service.ts
@@ -19,6 +19,8 @@ export class RepositoryService {
       return;
     }
 
+    await this.createTeam(this.github, this.getTeamName(course), course.id);
+
     const studentRepo = getCustomRepository(StudentRepository);
     const students = await studentRepo.findActiveByCourseId(this.courseId);
 
@@ -31,8 +33,8 @@ export class RepositoryService {
         if (mentorGithubId) {
           await this.inviteMentor(mentorGithubId, course);
         }
-        await this.addTeamToRepository(this.github, course, student.githubId);
       }
+      await this.addTeamToRepository(this.github, course, student.githubId);
       if (record?.repository) {
         result.push({ repository: record.repository });
       }

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index e23088e..9708157 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -202,11 +202,11 @@ jobs:
         run: poetry install --without dev --without docs --extras ${{ matrix.backend.name }} --extras geospatial
 
       - name: ""run parallel tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name != 'pyspark' && matrix.backend.name != 'impala'
+        if: matrix.backend.name != 'impala'
         run: just ci-check -m ${{ matrix.backend.name }} --numprocesses auto --dist=loadgroup
 
       - name: ""run serial tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name == 'pyspark' || matrix.backend.name == 'impala'
+        if: matrix.backend.name == 'impala'
         run: just ci-check -m ${{ matrix.backend.name }}
         env:
           IBIS_TEST_NN_HOST: localhost

diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 
",3,"[""87d5d4e55ab7149b593d29410f1fe426ba2447d4"", ""4cbbd2552ba0de273e1dfe7d453c5b3efed751a3"", ""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21""]","[""fix"", ""cicd"", ""docs""]"
"enable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>better layout for block and segmentautostart feature fixed","diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 

diff --git a/docs/docs/config-block.md b/docs/docs/config-block.md
new file mode 100644
index 0000000..df1ee54
--- /dev/null
+++ b/docs/docs/config-block.md
@@ -0,0 +1,60 @@
+---
+id: config-block
+title: Block
+sidebar_label: Block
+---
+
+Let's take a closer look at what defines a block.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""segments"": [
+        ...
+      ]
+    }
+  ]
+}
+```
+
+- type: `prompt` | `rprompt`
+- newline: `boolean`
+- alignment: `left` | `right`
+- vertical_offset: `int`
+- horizontal_offset: `int`
+- segments: `array` of one or more `segments`
+
+### Type
+
+Tells the engine what to do with the block. There are three options:
+
+- `prompt` renders one or more segments
+- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
+Supported on [ZSH][rprompt], Bash and Powershell.
+
+### Newline
+
+Start the block on a new line. Defaults to `false`.
+
+### Alignment
+
+Tell the engine if the block should be left or right-aligned.
+
+### Vertical offset
+
+Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
+moves it up one line.
+
+### Horizontal offset
+
+Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
+but on a horizontal level where a negative number moves the block left and a positive number right.
+
+### Segments
+
+Array of one or more segments.
diff --git a/docs/docs/config-example.md b/docs/docs/config-example.md
new file mode 100644
index 0000000..c180c4f
--- /dev/null
+++ b/docs/docs/config-example.md
@@ -0,0 +1,96 @@
+---
+id: config-sample
+title: Sample
+sidebar_label: Sample
+---
+
+```json
+{
+  ""final_space"": true,
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""right"",
+      ""vertical_offset"": -1,
+      ""segments"": [
+        {
+          ""type"": ""time"",
+          ""style"": ""plain"",
+          ""foreground"": ""#007ACC"",
+          ""properties"": {
+            ""time_format"": ""15:04:05""
+          }
+        }
+      ]
+    },
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""newline"": true,
+      ""segments"": [
+        {
+          ""type"": ""session"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#ffb300"",
+          ""leading_diamond"": ""\uE0B6"",
+          ""trailing_diamond"": ""\uE0B0"",
+          ""properties"": {
+            ""postfix"": "" ""
+          }
+        },
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ""prefix"": "" \uE5FF "",
+            ""style"": ""folder"",
+            ""exclude_folders"": [
+              ""/super/secret/project""
+            ],
+            ""enable_hyperlink"": false
+          }
+        },
+        {
+          ""type"": ""git"",
+          ""style"": ""powerline"",
+          ""foreground"": ""#193549"",
+          ""foreground_templates"": [
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
+          ],
+          ""background"": ""#2e9599"",
+          ""background_templates"": [
+            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
+            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
+            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
+          ],
+          ""powerline_symbol"": ""\uE0B0"",
+          ""properties"": {
+            ""fetch_status"": true,
+            ""branch_max_length"": 25,
+            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
+          }
+        },
+        {
+          ""type"": ""exit"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#00897b"",
+          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
+          ""leading_diamond"": """",
+          ""trailing_diamond"": ""\uE0B4"",
+          ""properties"": {
+            ""always_enabled"": true,
+            ""template"": ""\uE23A"",
+            ""prefix"": ""<parentBackground>\uE0B0</> ""
+          }
+        }
+      ]
+    }
+  ]
+}
+```
diff --git a/docs/docs/config-overview.md b/docs/docs/config-overview.md
index 1fdbcba..b554869 100644
--- a/docs/docs/config-overview.md
+++ b/docs/docs/config-overview.md
@@ -1,7 +1,7 @@
 ---
 id: config-overview
-title: Overview
-sidebar_label: Overview
+title: General
+sidebar_label: General
 ---
 
 Oh My Posh renders your prompt based on the definition of _blocks_ (like Lego) which contain one or more _segments_.
@@ -64,332 +64,7 @@ boxes with question marks, set up your terminal to use a [supported font][font] 
 - terminal_background: `string` [color][colors] - terminal background color, set to your terminal's background color when
 you notice black elements in Windows Terminal or the Visual Studio Code integrated terminal
 
-## Block
-
-Let's take a closer look at what defines a block.
-
-- type: `prompt` | `rprompt`
-- newline: `boolean`
-- alignment: `left` | `right`
-- vertical_offset: `int`
-- horizontal_offset: `int`
-- segments: `array` of one or more `segments`
-
-### Type
-
-Tells the engine what to do with the block. There are three options:
-
-- `prompt` renders one or more segments
-- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
-Supported on [ZSH][rprompt], Bash and Powershell.
-
-### Newline
-
-Start the block on a new line. Defaults to `false`.
-
-### Alignment
-
-Tell the engine if the block should be left or right-aligned.
-
-### Vertical offset
-
-Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
-moves it up one line.
-
-### Horizontal offset
-
-Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
-but on a horizontal level where a negative number moves the block left and a positive number right.
-
-### Segments
-
-Array of one or more segments.
-
-## Segment
-
-A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
-looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
-understand how to configure a segment.
-
-- type: `string` any of the included [segments][segments]
-- style: `powerline` | `plain` | `diamond`
-- powerline_symbol: `string`
-- invert_powerline: `boolean`
-- leading_diamond: `string`
-- trailing_diamond: `string`
-- foreground: `string` [color][colors]
-- foreground_templates: `array` of `string` values
-- background: `string` [color][colors]
-- background_templates: `array` of `string` values
-- properties: `array` of `Property`: `string`
-
-### Type
-
-Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
-
-### Style
-
-Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
-themes out there, we identified 3 types. All of these require a different configuration and depending on the look
-you want to achieve you might need to understand/use them all.
-
-#### Powerline
-
-What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
-background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
-if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
-
-#### Plain
-
-Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
-Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
-
-#### Diamond
-
-While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
-Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
-segment background as their foreground color.
-
-### Powerline symbol
-
-Text character to use when `""style"": ""powerline""`.
-
-### Invert Powerline
-
-If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
-in the perfectly mirrored variant for example.
-
-### Leading diamond
-
-Text character to use at the start of the segment. Will take the background color of the segment as
-its foreground color.
-
-### Trailing diamond
-
-Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
-
-### Foreground
-
-[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
-
-### Foreground Templates
-
-Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
-Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
-offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
-the documentation.
-
-The following sample is based on the [AWS Segment][aws].
-
-```json
-{
-  ""type"": ""aws"",
-  ""style"": ""powerline"",
-  ""powerline_symbol"": ""\uE0B0"",
-  ""foreground"": ""#ffffff"",
-  ""background"": ""#111111"",
-  ""foreground_templates"": [
-    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
-    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
-  ],
-  ""properties"": {
-    ""prefix"": "" \uE7AD ""
-  }
-}
-```
-
-The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
-one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
-returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
-templates returns a value, the foreground value `#ffffff` is used.
-
-### Background
-
-[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
-
-### Background Templates
-
-Same as [Foreground Templates][fg-templ] but for the background color.
-
-### Properties
-
-An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
-will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
-engine which allow you to customize the output even more.
-
-#### General-purpose properties
-
-You can use these on any segment, the engine is responsible for adding them correctly.
-
-- prefix: `string`
-- postfix: `string`
-- include_folders: `[]string`
-- exclude_folders: `[]string`
-
-##### Prefix
-
-The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
-specify this as `''`.
-
-##### Postfix
-
-The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
-specify this as `''`.
-
-##### Include / Exclude Folders
-
-Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
-the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
-will not be rendered when in one of the excluded locations.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-```json
-""exclude_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-The strings specified in these properties are evaluated as [regular expressions][regex]. You
-can use any valid regular expression construct, but the regular expression must match the entire directory
-name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-]
-```
-
-You can also combine these properties:
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-],
-""exclude_folders"": [
-  ""/Users/posh/Projects/secret-project.*""
-]
-```
-
-##### Notes
-
-- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
-is used by the current operating system.
-- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
-directory name, you need to specify it as `\\\\`.
-- The character `~` at the start of a specified folder will match the user's home directory.
-- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
-
-This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
-`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
-
-## Full Sample
-
-```json
-{
-  ""final_space"": true,
-  ""blocks"": [
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""right"",
-      ""vertical_offset"": -1,
-      ""segments"": [
-        {
-          ""type"": ""time"",
-          ""style"": ""plain"",
-          ""foreground"": ""#007ACC"",
-          ""properties"": {
-            ""time_format"": ""15:04:05""
-          }
-        }
-      ]
-    },
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""left"",
-      ""newline"": true,
-      ""segments"": [
-        {
-          ""type"": ""session"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#ffb300"",
-          ""leading_diamond"": ""\uE0B6"",
-          ""trailing_diamond"": ""\uE0B0"",
-          ""properties"": {
-            ""postfix"": "" ""
-          }
-        },
-        {
-          ""type"": ""path"",
-          ""style"": ""powerline"",
-          ""powerline_symbol"": ""\uE0B0"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#61AFEF"",
-          ""properties"": {
-            ""prefix"": "" \uE5FF "",
-            ""style"": ""folder"",
-            ""exclude_folders"": [
-              ""/super/secret/project""
-            ],
-            ""enable_hyperlink"": false
-          }
-        },
-        {
-          ""type"": ""git"",
-          ""style"": ""powerline"",
-          ""foreground"": ""#193549"",
-          ""foreground_templates"": [
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
-          ],
-          ""background"": ""#2e9599"",
-          ""background_templates"": [
-            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
-            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
-            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
-          ],
-          ""powerline_symbol"": ""\uE0B0"",
-          ""properties"": {
-            ""fetch_status"": true,
-            ""branch_max_length"": 25,
-            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
-          }
-        },
-        {
-          ""type"": ""exit"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#00897b"",
-          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
-          ""leading_diamond"": """",
-          ""trailing_diamond"": ""\uE0B4"",
-          ""properties"": {
-            ""always_enabled"": true,
-            ""template"": ""\uE23A"",
-            ""prefix"": ""<parentBackground>\uE0B0</> ""
-          }
-        }
-      ]
-    }
-  ]
-}
-```
-
 [releases]: https://github.com/JanDeDobbeleer/oh-my-posh/releases/latest
 [font]: /docs/config-fonts
 [schema]: https://github.com/JanDeDobbeleer/oh-my-posh/blob/main/themes/schema.json
 [themes]: https://github.com/JanDeDobbeleer/oh-my-posh/tree/main/themes
-[segments]: /docs/battery
-[colors]: /docs/config-colors
-[go-text-template]: https://golang.org/pkg/text/template/
-[sprig]: https://masterminds.github.io/sprig/
-[fg-templ]: /docs/config-overview#foreground-templates
-[regex]: https://www.regular-expressions.info/tutorial.html
-[aws]: /docs/aws
diff --git a/docs/docs/config-segment.md b/docs/docs/config-segment.md
new file mode 100644
index 0000000..08a66e4
--- /dev/null
+++ b/docs/docs/config-segment.md
@@ -0,0 +1,219 @@
+---
+id: config-segment
+title: Segment
+sidebar_label: Segment
+---
+
+A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
+looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
+understand how to configure a segment.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ...
+      ""segments"": [
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ...
+          }
+        }
+      ]
+    }
+  ]
+}
+```
+
+- type: `string` any of the included [segments][segments]
+- style: `powerline` | `plain` | `diamond`
+- powerline_symbol: `string`
+- invert_powerline: `boolean`
+- leading_diamond: `string`
+- trailing_diamond: `string`
+- foreground: `string` [color][colors]
+- foreground_templates: `array` of `string` values
+- background: `string` [color][colors]
+- background_templates: `array` of `string` values
+- properties: `array` of `Property`: `string`
+
+## Type
+
+Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
+
+## Style
+
+Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
+themes out there, we identified 3 types. All of these require a different configuration and depending on the look
+you want to achieve you might need to understand/use them all.
+
+### Powerline
+
+What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
+background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
+if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
+
+### Plain
+
+Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
+Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
+
+### Diamond
+
+While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
+Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
+segment background as their foreground color.
+
+## Powerline symbol
+
+Text character to use when `""style"": ""powerline""`.
+
+## Invert Powerline
+
+If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
+in the perfectly mirrored variant for example.
+
+## Leading diamond
+
+Text character to use at the start of the segment. Will take the background color of the segment as
+its foreground color.
+
+## Trailing diamond
+
+Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
+
+## Foreground
+
+[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
+
+## Foreground Templates
+
+Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
+Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
+offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
+the documentation.
+
+The following sample is based on the [AWS Segment][aws].
+
+```json
+{
+  ""type"": ""aws"",
+  ""style"": ""powerline"",
+  ""powerline_symbol"": ""\uE0B0"",
+  ""foreground"": ""#ffffff"",
+  ""background"": ""#111111"",
+  ""foreground_templates"": [
+    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
+    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
+  ],
+  ""properties"": {
+    ""prefix"": "" \uE7AD ""
+  }
+}
+```
+
+The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
+one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
+returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
+templates returns a value, the foreground value `#ffffff` is used.
+
+## Background
+
+[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
+
+## Background Templates
+
+Same as [Foreground Templates][fg-templ] but for the background color.
+
+## Properties
+
+An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
+will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
+engine which allow you to customize the output even more.
+
+### General-purpose properties
+
+You can use these on any segment, the engine is responsible for adding them correctly.
+
+- prefix: `string`
+- postfix: `string`
+- include_folders: `[]string`
+- exclude_folders: `[]string`
+
+#### Prefix
+
+The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
+specify this as `''`.
+
+#### Postfix
+
+The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
+specify this as `''`.
+
+#### Include / Exclude Folders
+
+Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
+the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
+will not be rendered when in one of the excluded locations.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+```json
+""exclude_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+The strings specified in these properties are evaluated as [regular expressions][regex]. You
+can use any valid regular expression construct, but the regular expression must match the entire directory
+name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+]
+```
+
+You can also combine these properties:
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+],
+""exclude_folders"": [
+  ""/Users/posh/Projects/secret-project.*""
+]
+```
+
+#### Notes
+
+- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
+is used by the current operating system.
+- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
+directory name, you need to specify it as `\\\\`.
+- The character `~` at the start of a specified folder will match the user's home directory.
+- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
+
+This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
+`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
+
+[segments]: /docs/battery
+[colors]: /docs/config-colors
+[go-text-template]: https://golang.org/pkg/text/template/
+[sprig]: https://masterminds.github.io/sprig/
+[fg-templ]: /docs/config-overview#foreground-templates
+[regex]: https://www.regular-expressions.info/tutorial.html
+[aws]: /docs/aws
diff --git a/docs/docs/segment-environment.md b/docs/docs/segment-environment.md
index f35bc87..982a0a5 100644
--- a/docs/docs/segment-environment.md
+++ b/docs/docs/segment-environment.md
@@ -34,7 +34,7 @@ New-Alias -Name 'Set-PoshContext' -Value 'Set-EnvVar' -Scope Global -Force
 
 The segment will show when the value of the environment variable isn't empty.
 
-## Sample Configuration
+## Sample *Configuration*
 
 ```json
 {
diff --git a/docs/sidebars.js b/docs/sidebars.js
index a75163e..8f151a2 100644
--- a/docs/sidebars.js
+++ b/docs/sidebars.js
@@ -20,6 +20,9 @@ module.exports = {
       label: ""⚙️ Configuration"",
       items: [
         ""config-overview"",
+        ""config-block"",
+        ""config-segment"",
+        ""config-sample"",
         ""config-title"",
         ""config-colors"",
         ""config-text-style"",

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();
",3,"[""fd8e563cc19ca4684885d4692acee6bebcca4ada"", ""cb1f48b56ae0de93acb72e48726c7d610a1d538e"", ""bed78248c941d57ad4cc20a455147e186e97c7a1""]","[""feat"", ""docs"", ""fix""]"
"terminated tasks linger for a bit

Signed-off-by: Eliza Weisman <eliza@buoyant.io>allow disabling dynamic queueget tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.","diff --git a/console/src/main.rs b/console/src/main.rs
index ebfa315..5328d96 100644
--- a/console/src/main.rs
+++ b/console/src/main.rs
@@ -69,6 +69,7 @@ async fn main() -> Result<(), Box<dyn std::error::Error>> {
                 .wrap(Wrap { trim: true });
             f.render_widget(header, chunks[0]);
             tasks.render(f, chunks[1]);
+            tasks.retain_active();
         })?;
     }
 
diff --git a/console/src/tasks.rs b/console/src/tasks.rs
index 7be39a4..eb41495 100644
--- a/console/src/tasks.rs
+++ b/console/src/tasks.rs
@@ -19,6 +19,7 @@ struct Task {
     fields: String,
     kind: &'static str,
     stats: Stats,
+    completed_for: usize,
 }
 
 #[derive(Default, Debug)]
@@ -28,10 +29,15 @@ struct Stats {
     idle: Duration,
     total: Duration,
 }
+
 impl State {
+    // How many updates to retain completed tasks for
+    const RETAIN_COMPLETED_FOR: usize = 6;
+
     pub(crate) fn len(&self) -> usize {
         self.tasks.len()
     }
+
     pub(crate) fn update(&mut self, update: proto::tasks::TaskUpdate) {
         let new_tasks = update.new_tasks.into_iter().filter_map(|task| {
             if task.id.is_none() {
@@ -48,6 +54,7 @@ impl State {
                 fields: task.string_fields,
                 kind,
                 stats: Default::default(),
+                completed_for: 0,
             };
             Some((id, task))
         });
@@ -60,7 +67,10 @@ impl State {
         }
 
         for proto::SpanId { id } in update.completed {
-            if self.tasks.remove(&id).is_none() {
+            if let Some(task) = self.tasks.get_mut(&id) {
+                task.kind = ""!"";
+                task.completed_for = 1;
+            } else {
                 tracing::warn!(?id, ""tried to complete a task that didn't exist"");
             }
         }
@@ -79,7 +89,7 @@ impl State {
         const DUR_PRECISION: usize = 4;
         const POLLS_LEN: usize = 5;
         let rows = self.tasks.values().map(|task| {
-            let row = Row::new(vec![
+            let mut row = Row::new(vec![
                 Cell::from(task.id_hex.as_str()),
                 // TODO(eliza): is there a way to write a `fmt::Debug` impl
                 // directly to tui without doing an allocation?
@@ -105,6 +115,9 @@ impl State {
                 Cell::from(format!(""{:>width$}"", task.stats.polls, width = POLLS_LEN)),
                 Cell::from(task.fields.as_str()),
             ]);
+            if task.completed_for > 0 {
+                row = row.style(Style::default().add_modifier(style::Modifier::DIM));
+            }
             row
         });
         let t = Table::new(rows)
@@ -126,6 +139,16 @@ impl State {
 
         frame.render_widget(t, area)
     }
+
+    pub(crate) fn retain_active(&mut self) {
+        self.tasks.retain(|_, task| {
+            if task.completed_for == 0 {
+                return true;
+            }
+            task.completed_for += 1;
+            task.completed_for <= Self::RETAIN_COMPLETED_FOR
+        })
+    }
 }
 
 impl From<proto::tasks::Stats> for Stats {

diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }
",3,"[""1bcf88670b50155b50071e707f98f30cea0b7a24"", ""9ef5c0d14193a9abb09b39856f58477d1f4b0d77"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c""]","[""feat"", ""fix"", ""refactor""]"
autostart feature fixedlicensingadd benchmark for known-slow table expression,"diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;

diff --git a/.gitignore b/.gitignore
index 2e99ad3..eef9203 100644
--- a/.gitignore
+++ b/.gitignore
@@ -95,3 +95,4 @@ docs/backends/support_matrix.csv
 __pycache__
 tags
 .DS_Store
+prof/
diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index ac19aaf..36aed0e 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -602,3 +602,93 @@ def test_multiple_joins(benchmark, num_joins, num_columns):
         name=""t"",
     )
     benchmark(multiple_joins, table, num_joins)
+
+
+@pytest.fixture
+def customers():
+    return ibis.table(
+        dict(
+            customerid=""int32"",
+            name=""string"",
+            address=""string"",
+            citystatezip=""string"",
+            birthdate=""date"",
+            phone=""string"",
+            timezone=""string"",
+            lat=""float64"",
+            long=""float64"",
+        ),
+        name=""customers"",
+    )
+
+
+@pytest.fixture
+def orders():
+    return ibis.table(
+        dict(
+            orderid=""int32"",
+            customerid=""int32"",
+            ordered=""timestamp"",
+            shipped=""timestamp"",
+            items=""string"",
+            total=""float64"",
+        ),
+        name=""orders"",
+    )
+
+
+@pytest.fixture
+def orders_items():
+    return ibis.table(
+        dict(orderid=""int32"", sku=""string"", qty=""int32"", unit_price=""float64""),
+        name=""orders_items"",
+    )
+
+
+@pytest.fixture
+def products():
+    return ibis.table(
+        dict(
+            sku=""string"",
+            desc=""string"",
+            weight_kg=""float64"",
+            cost=""float64"",
+            dims_cm=""string"",
+        ),
+        name=""products"",
+    )
+
+
+@pytest.mark.benchmark(group=""compilation"")
+@pytest.mark.parametrize(
+    ""module"",
+    [
+        pytest.param(
+            mod,
+            marks=pytest.mark.xfail(
+                condition=mod in _XFAIL_COMPILE_BACKENDS,
+                reason=f""{mod} backend doesn't support compiling UnboundTable"",
+            ),
+        )
+        for mod in _backends
+    ],
+)
+def test_compile_with_drops(
+    benchmark, module, customers, orders, orders_items, products
+):
+    expr = (
+        customers.join(orders, ""customerid"")
+        .join(orders_items, ""orderid"")
+        .join(products, ""sku"")
+        .drop(""customerid"", ""qty"", ""total"", ""items"")
+        .drop(""dims_cm"", ""cost"")
+        .mutate(o_date=lambda t: t.shipped.date())
+        .filter(lambda t: t.ordered == t.shipped)
+    )
+
+    try:
+        mod = getattr(ibis, module)
+    except (AttributeError, ImportError) as e:
+        pytest.skip(str(e))
+    else:
+        benchmark(mod.compile, expr)
",3,"[""bed78248c941d57ad4cc20a455147e186e97c7a1"", ""a52a585d74894b3b4eeb8c784fa089ff95cddad0"", ""e9617f0854030e70365eb264bcb3b58078e79e9e""]","[""fix"", ""docs"", ""test""]"
"update Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>add props to get color and label from a route","diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })

diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/src/components/BottomNavigation.js b/src/components/BottomNavigation.js
index 1b72302..7d8ea75 100644
--- a/src/components/BottomNavigation.js
+++ b/src/components/BottomNavigation.js
@@ -24,8 +24,8 @@ const AnimatedPaper = Animated.createAnimatedComponent(Paper);
 
 type Route = {
   key: string,
-  title: string,
-  icon: IconSource,
+  title?: string,
+  icon?: IconSource,
   color?: string,
 };
 
@@ -51,7 +51,7 @@ type Props<T> = {
    * - `key`: a unique key to identify the route
    * - `title`: title of the route to use as the tab label
    * - `icon`: icon to use as the tab icon, can be a string, an image source or a react component
-   * - `color`: color to use as background color for shifting bottom navigation (optional)
+   * - `color`: color to use as background color for shifting bottom navigation
    *
    * Example:
    *
@@ -115,11 +115,27 @@ type Props<T> = {
   /**
    * Callback which returns a React Element to be used as tab icon.
    */
-  renderIcon?: (props: { route: T, focused: boolean }) => React.Node,
+  renderIcon?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
   /**
    * Callback which React Element to be used as tab label.
    */
-  renderLabel?: (props: { route: T, focused: boolean }) => React.Node,
+  renderLabel?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
+  /**
+   * Get label text for the tab, uses `route.title` by default. Use `renderLabel` to replace label component.
+   */
+  getLabelText?: (props: { route: T }) => string,
+  /**
+   * Get color for the tab, uses `route.color` by default.
+   */
+  getColor?: (props: { route: T }) => string,
   /**
    * Function to execute on tab press. It receives the route for the pressed tab, useful for things like scroll to top.
    */
@@ -159,6 +175,10 @@ type State = {
    */
   ripple: Animated.Value,
   /**
+   * Animation for the touch feedback, used to determine it's scale and opacity.
+   */
+  touch: Animated.Value,
+  /**
    * Layout of the tab bar. The width is used to determine the size and position of the ripple.
    */
   layout: { height: number, width: number, measured: boolean },
@@ -173,7 +193,7 @@ const MIN_SHIFT_AMOUNT = 10;
 const MIN_TAB_WIDTH = 96;
 const MAX_TAB_WIDTH = 168;
 const BAR_HEIGHT = 56;
-const SMALL_RIPPLE_SIZE = 72;
+const SMALL_RIPPLE_SIZE = 96;
 const ACTIVE_LABEL_SIZE = 14;
 const INACTIVE_LABEL_SIZE = 12;
 
@@ -251,6 +271,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ),
       index: new Animated.Value(index),
       ripple: new Animated.Value(MIN_RIPPLE_SCALE),
+      touch: new Animated.Value(MIN_RIPPLE_SCALE),
       layout: { height: 0, width: 0, measured: false },
       previous: 0,
     };
@@ -349,6 +370,15 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
   _handleTabPress = (index: number) => {
     const { navigationState } = this.props;
 
+    this.state.touch.setValue(MIN_RIPPLE_SCALE);
+
+    Animated.timing(this.state.touch, {
+      toValue: 1,
+      duration: 300,
+      easing: Easing.in(Easing.sin),
+      useNativeDriver: true,
+    }).start();
+
     if (index !== navigationState.index) {
       this.props.onIndexChange(index);
     }
@@ -376,6 +406,8 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       renderScene,
       renderIcon,
       renderLabel,
+      getLabelText = ({ route }) => route.title,
+      getColor = ({ route }) => route.color,
       barStyle,
       style,
       theme,
@@ -400,7 +432,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ? this.state.index.interpolate({
           inputRange: routes.map((_, i) => i),
           outputRange: routes.map(
-            route => route.color || approxBackgroundColor
+            route => getColor({ route }) || approxBackgroundColor
           ),
         })
       : approxBackgroundColor;
@@ -416,7 +448,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
           .rgb()
           .string();
 
-    const rippleColor = color(textColor)
+    const touchColor = color(textColor)
       .alpha(0.12)
       .rgb()
       .string();
@@ -430,22 +462,10 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
 
     // Since we have a single ripple, we have to reposition it so that it appears to expand from active tab.
     // We need to move it from the left to the active tab and also account for how much that tab has shifted.
-    const rippleShift =
-      navigationState.index * tabWidth +
-      tabWidth / 2 +
-      this._calculateShift(
-        this.state.previous,
-        navigationState.index,
-        routes.length
-      );
 
     return (
       <View
-        style={[
-          styles.container,
-          { backgroundColor: theme.dark ? white : black },
-          style,
-        ]}
+        style={[styles.container, style]}
         onLayout={this._handleLayout}
         pointerEvents={layout.measured ? 'auto' : 'none'}
       >
@@ -485,25 +505,30 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
             style={[styles.items, { maxWidth: maxTabWidth * routes.length }]}
           >
             {shifting ? (
-              // Large ripple with the backround color
               <Animated.View
                 pointerEvents=""none""
                 style={[
                   styles.ripple,
                   {
                     // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - layout.width / 2,
-                    left: rippleShift - layout.width / 2,
-                    height: layout.width,
-                    width: layout.width,
+                    top: BAR_HEIGHT / 2 - layout.width / 8,
+                    left:
+                      navigationState.index * tabWidth +
+                      tabWidth / 2 -
+                      layout.width / 8,
+                    height: layout.width / 4,
+                    width: layout.width / 4,
                     borderRadius: layout.width / 2,
-                    backgroundColor: routes[navigationState.index].color,
+                    backgroundColor: getColor({
+                      route: routes[navigationState.index],
+                    }),
                     transform: [
+                      { translateX: this.state.shifts[navigationState.index] },
                       {
                         // Scale to twice the size  to ensure it covers the whole tab bar
                         scale: this.state.ripple.interpolate({
                           inputRange: [0, 1],
-                          outputRange: [0, 2],
+                          outputRange: [0, 8],
                         }),
                       },
                     ],
@@ -515,36 +540,36 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                 ]}
               />
             ) : null}
-            {shifting ? (
-              // Small subtle ripple on touch
-              <Animated.View
-                pointerEvents=""none""
-                style={[
-                  styles.ripple,
-                  {
-                    // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
-                    left: rippleShift - SMALL_RIPPLE_SIZE / 2,
-                    height: SMALL_RIPPLE_SIZE,
-                    width: SMALL_RIPPLE_SIZE,
-                    borderRadius: SMALL_RIPPLE_SIZE / 2,
-                    backgroundColor: rippleColor,
-                    transform: [
-                      {
-                        scale: this.state.ripple.interpolate({
-                          inputRange: [0, 0.5, 1],
-                          outputRange: [0, 1, 1],
-                        }),
-                      },
-                    ],
-                    opacity: this.state.ripple.interpolate({
-                      inputRange: [0, MIN_RIPPLE_SCALE, 0.25, 0.5],
-                      outputRange: [0, 0, 1, 0],
-                    }),
-                  },
-                ]}
-              />
-            ) : null}
+            <Animated.View
+              pointerEvents=""none""
+              style={[
+                styles.ripple,
+                {
+                  // Set top and left values so that the ripple's center is same as the tab's center
+                  top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
+                  left:
+                    navigationState.index * tabWidth +
+                    tabWidth / 2 -
+                    SMALL_RIPPLE_SIZE / 2,
+                  height: SMALL_RIPPLE_SIZE,
+                  width: SMALL_RIPPLE_SIZE,
+                  borderRadius: SMALL_RIPPLE_SIZE / 2,
+                  backgroundColor: touchColor,
+                  transform: [
+                    {
+                      translateX: shifting
+                        ? this.state.shifts[navigationState.index]
+                        : 0,
+                    },
+                    { scale: this.state.touch },
+                  ],
+                  opacity: this.state.touch.interpolate({
+                    inputRange: [0, 0.5, 1],
+                    outputRange: [0, 1, 0],
+                  }),
+                },
+              ]}
+            />
             {routes.map((route, index) => {
               const shift = this.state.shifts[index];
               const focused = this.state.tabs[index];
@@ -607,7 +632,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderIcon ? (
-                          renderIcon({ route, focused: true })
+                          renderIcon({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <Icon
                             style={styles.icon}
@@ -625,7 +654,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderIcon ? (
-                            renderIcon({ route, focused: false })
+                            renderIcon({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <Icon
                               style={styles.icon}
@@ -652,7 +685,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderLabel ? (
-                          renderLabel({ route, focused: true })
+                          renderLabel({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <AnimatedText
                             style={[
@@ -662,7 +699,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                               },
                             ]}
                           >
-                            {route.title}
+                            {getLabelText({ route })}
                           </AnimatedText>
                         )}
                       </Animated.View>
@@ -674,7 +711,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderLabel ? (
-                            renderLabel({ route, focused: false })
+                            renderLabel({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <AnimatedText
                               style={[
@@ -684,7 +725,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                                 },
                               ]}
                             >
-                              {route.title}
+                              {getLabelText({ route })}
                             </AnimatedText>
                           )}
                         </Animated.View>
",3,"[""c2ee5cd5e709afd15c5565ee009a0d204403a119"", ""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""ded26d768ff432ad3bde3c0aa1e95ce50726100a""]","[""docs"", ""cicd"", ""feat""]"
"upgrade to Flux v0.42.0

Skips a test that requires special dependencies to pass.only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>get tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.","diff --git a/go.mod b/go.mod
index ea705da..8c352f7 100644
--- a/go.mod
+++ b/go.mod
@@ -38,7 +38,7 @@ require (
 	github.com/hashicorp/go-msgpack v0.0.0-20150518234257-fa3f63826f7c // indirect
 	github.com/hashicorp/raft v1.0.0 // indirect
 	github.com/hashicorp/vault/api v1.0.2
-	github.com/influxdata/flux v0.41.0
+	github.com/influxdata/flux v0.42.0
 	github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6
 	github.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368
 	github.com/jessevdk/go-flags v1.4.0
diff --git a/go.sum b/go.sum
index 4bfdf4c..634a0f1 100644
--- a/go.sum
+++ b/go.sum
@@ -206,8 +206,8 @@ github.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NH
 github.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=
 github.com/influxdata/changelog v1.0.0 h1:RstJD6H48zLQj0GdE6E6k/6RPwtUjkyzIe/T1E/xuWU=
 github.com/influxdata/changelog v1.0.0/go.mod h1:uzpGWE/qehT8L426YuXwpMQub+a63vIINhIeEI9mnSM=
-github.com/influxdata/flux v0.41.0 h1:ljbWJmE+aNx8Yoqhb04gWC4sXMV87eYUxz5vjYphLLs=
-github.com/influxdata/flux v0.41.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
+github.com/influxdata/flux v0.42.0 h1:2iEG6hLHdHEJ6LgD8OSnlHS9yoVrLO1/aM4P9ERb94U=
+github.com/influxdata/flux v0.42.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
 github.com/influxdata/goreleaser v0.97.0-influx h1:jT5OrcW7WfS0e2QxfwmTBjhLvpIC9CDLRhNgZJyhj8s=
 github.com/influxdata/goreleaser v0.97.0-influx/go.mod h1:MnjA0e0Uq6ISqjG1WxxMAl+3VS1QYjILSWVnMYDxasE=
 github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6 h1:CFx+pP90q/qg3spoiZjf8donE4WpAdjeJfPOcoNqkWo=
diff --git a/query/stdlib/testing/testing.go b/query/stdlib/testing/testing.go
index d41574a..85b0673 100644
--- a/query/stdlib/testing/testing.go
+++ b/query/stdlib/testing/testing.go
@@ -98,4 +98,6 @@ var FluxEndToEndSkipList = map[string]string{
 	""http_endpoint"": ""need ability to test side effects in e2e tests: (https://github.com/influxdata/flux/issues/1723)"",
 
 	""holt_winters_panic"": ""Expected output is an empty table which breaks the testing framework (https://github.com/influxdata/influxdb/issues/14749)"",
+
+	""secrets"": ""Cannot inject custom deps into the test framework so the secrets don't lookup correctly"",
 }

diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }
",3,"[""454003841aabeb74396d73541378bfa59c75b5db"", ""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c""]","[""build"", ""cicd"", ""refactor""]"
"enable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>wrong icon reference

Signed-off-by: Pranav C <pranavxc@gmail.com>ensure checksum persist flushes to disk","diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 

diff --git a/packages/nc-gui/components.d.ts b/packages/nc-gui/components.d.ts
index b7e6585..bb86478 100644
--- a/packages/nc-gui/components.d.ts
+++ b/packages/nc-gui/components.d.ts
@@ -81,7 +81,6 @@ declare module '@vue/runtime-core' {
     ClaritySuccessLine: typeof import('~icons/clarity/success-line')['default']
     EvaEmailOutline: typeof import('~icons/eva/email-outline')['default']
     IcBaselineMoreVert: typeof import('~icons/ic/baseline-more-vert')['default']
-    Icon: typeof import('~icons/ic/on')['default']
     IcOutlineInsertDriveFile: typeof import('~icons/ic/outline-insert-drive-file')['default']
     IcRoundEdit: typeof import('~icons/ic/round-edit')['default']
     IcRoundKeyboardArrowDown: typeof import('~icons/ic/round-keyboard-arrow-down')['default']

diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);
",3,"[""fd8e563cc19ca4684885d4692acee6bebcca4ada"", ""d1d55e787b7d07f763852602b9939a5394607fd9"", ""b7ce2894fd1794064bd6db4ed730bb6cb7728739""]","[""feat"", ""fix"", ""test""]"
"Fix typoensure checksum persist flushes to diskdocker PG version upgrade

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>","diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);

diff --git a/packages/nocodb/docker-compose.yml b/packages/nocodb/docker-compose.yml
index 7fabf79..ba2ab7b 100644
--- a/packages/nocodb/docker-compose.yml
+++ b/packages/nocodb/docker-compose.yml
@@ -1,4 +1,4 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
     # db55:
@@ -96,8 +96,8 @@ services:
     #     - 5495:5432
     #   volumes:
     #     - ./pg-sakila-db:/docker-entrypoint-initdb.d
-    pg96:
-     image: postgres:9.6
+    pg147:
+     image: postgres:14.7
      restart: always
      environment:
        POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
index 19dfab2..97d346b 100644
--- a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
+++ b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg.yml b/tests/playwright/scripts/docker-compose-pg.yml
index 0396579..9fab10e 100644
--- a/tests/playwright/scripts/docker-compose-pg.yml
+++ b/tests/playwright/scripts/docker-compose-pg.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
",3,"[""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""b7ce2894fd1794064bd6db4ed730bb6cb7728739"", ""37b1cbfd3d2c462ef4f2a131e4172c38dc8d9ddf""]","[""docs"", ""test"", ""build""]"
print errors without stacktraceincrement failing test retriesupdate wrapping tests for v7,"diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {

diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 

diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });
",3,"[""d129eaf9125a967ac86c6c7276bbae6b4d50af36"", ""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57"", ""317f4eefecddfb1392ca71d551840f446feee302""]","[""fix"", ""cicd"", ""test""]"
"update Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909wrong icon reference

Signed-off-by: Pranav C <pranavxc@gmail.com>publish sdks after docs/build","diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })

diff --git a/packages/nc-gui/components.d.ts b/packages/nc-gui/components.d.ts
index b7e6585..bb86478 100644
--- a/packages/nc-gui/components.d.ts
+++ b/packages/nc-gui/components.d.ts
@@ -81,7 +81,6 @@ declare module '@vue/runtime-core' {
     ClaritySuccessLine: typeof import('~icons/clarity/success-line')['default']
     EvaEmailOutline: typeof import('~icons/eva/email-outline')['default']
     IcBaselineMoreVert: typeof import('~icons/ic/baseline-more-vert')['default']
-    Icon: typeof import('~icons/ic/on')['default']
     IcOutlineInsertDriveFile: typeof import('~icons/ic/outline-insert-drive-file')['default']
     IcRoundEdit: typeof import('~icons/ic/round-edit')['default']
     IcRoundKeyboardArrowDown: typeof import('~icons/ic/round-keyboard-arrow-down')['default']

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/
",3,"[""c2ee5cd5e709afd15c5565ee009a0d204403a119"", ""d1d55e787b7d07f763852602b9939a5394607fd9"", ""6c9cb638cb4d1ecc42632fcf389c24898c5b3244""]","[""docs"", ""fix"", ""cicd""]"
"only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>never call ""onStart"" prop when idlenginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/packages/core/src/SpringValue.ts b/packages/core/src/SpringValue.ts
index 18494a8..cbc4f27 100644
--- a/packages/core/src/SpringValue.ts
+++ b/packages/core/src/SpringValue.ts
@@ -596,11 +596,11 @@ export class SpringValue<T = any> extends AnimationValue<T> {
   /** Notify change observers */
   protected _onChange(value: T, idle = false) {
     const anim = this.animation
-    if (!anim.changed) {
+    if (!anim.changed && !idle) {
       anim.changed = true
       // The ""onStart"" prop is called on the first change after entering the
       // frameloop, but never for immediate animations.
-      if (anim.onStart && !anim.immediate) {
+      if (anim.onStart) {
         anim.onStart(this)
       }
     }

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection
",3,"[""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""c8e0ae8612df3d6f2831acc004aaac332f6105e4"", ""e12d9e77a6fd531a22325337838a841b1c67f00d""]","[""cicd"", ""fix"", ""docs""]"
"spring version, core versionupdate Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909small error msg improvement

refs #1005","diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 

diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })

diff --git a/internal/pipe/git/errors.go b/internal/pipe/git/errors.go
index a8c15d5..13dfb56 100644
--- a/internal/pipe/git/errors.go
+++ b/internal/pipe/git/errors.go
@@ -11,7 +11,7 @@ type ErrDirty struct {
 }
 
 func (e ErrDirty) Error() string {
-	return fmt.Sprintf(""git is currently in a dirty state:\n%v"", e.status)
+	return fmt.Sprintf(""git is currently in a dirty state, please check in your pipeline what can be changing the following files:\n%v"", e.status)
 }
 
 // ErrWrongRef happens when the HEAD reference is different from the tag being built
",3,"[""c55591ba157298a9c5816693c102a89dfd058830"", ""c2ee5cd5e709afd15c5565ee009a0d204403a119"", ""a62314d9bb632be6af026686615d14b912250512""]","[""build"", ""docs"", ""refactor""]"
"wrong icon reference

Signed-off-by: Pranav C <pranavxc@gmail.com>updated react demo parcel commandget tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.","diff --git a/packages/nc-gui/components.d.ts b/packages/nc-gui/components.d.ts
index b7e6585..bb86478 100644
--- a/packages/nc-gui/components.d.ts
+++ b/packages/nc-gui/components.d.ts
@@ -81,7 +81,6 @@ declare module '@vue/runtime-core' {
     ClaritySuccessLine: typeof import('~icons/clarity/success-line')['default']
     EvaEmailOutline: typeof import('~icons/eva/email-outline')['default']
     IcBaselineMoreVert: typeof import('~icons/ic/baseline-more-vert')['default']
-    Icon: typeof import('~icons/ic/on')['default']
     IcOutlineInsertDriveFile: typeof import('~icons/ic/outline-insert-drive-file')['default']
     IcRoundEdit: typeof import('~icons/ic/round-edit')['default']
     IcRoundKeyboardArrowDown: typeof import('~icons/ic/round-keyboard-arrow-down')['default']

diff --git a/demo/react/package.json b/demo/react/package.json
index be28bf9..32d0952 100644
--- a/demo/react/package.json
+++ b/demo/react/package.json
@@ -12,7 +12,7 @@
   },
   ""scripts"": {
     ""start"": ""parcel serve public/index.html --no-cache --open"",
-    ""build"": ""parcel build -t browser -d dist public/index.html --no-source-maps""
+    ""build"": ""parcel build --target browser --dist-dir dist public/index.html --no-source-maps""
   },
   ""bugs"": {
     ""url"": ""https://github.com/matteobruni/tsparticles/issues""

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }
",3,"[""d1d55e787b7d07f763852602b9939a5394607fd9"", ""32b92cfa0b74a6c25990e32ac6aab12b8496794c"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c""]","[""fix"", ""build"", ""refactor""]"
"Adjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.add spacing in comment fix lint (#8555)assist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)

diff --git a/src/components/nav/test/basic/app-module.ts b/src/components/nav/test/basic/app-module.ts
index 467917a..375e662 100644
--- a/src/components/nav/test/basic/app-module.ts
+++ b/src/components/nav/test/basic/app-module.ts
@@ -633,7 +633,7 @@ export class Tab3 {
   }
 
   presentModal() {
-    //this.modalCtrl.create(MyModal).present();
+    // this.modalCtrl.create(MyModal).present();
   }
 
   selectPrevious() {

diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }
",3,"[""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3"", ""af880ac5b4fecbc6c4f3d1eee0d95f326e8bd9d1"", ""1269431c8a3e7549f10fcbbb4b88ff625c8898b3""]","[""test"", ""docs"", ""build""]"
"add numberOfLines prop to DataTableTitle (#863)

Closes #848repository creationupdate wrapping tests for v7","diff --git a/src/components/DataTable/DataTableTitle.js b/src/components/DataTable/DataTableTitle.js
index bfcf07e..d764fd5 100644
--- a/src/components/DataTable/DataTableTitle.js
+++ b/src/components/DataTable/DataTableTitle.js
@@ -27,6 +27,10 @@ type Props = React.ElementConfig<typeof TouchableWithoutFeedback> & {|
    */
   sortDirection?: 'ascending' | 'descending',
   /**
+   * The number of lines to show.
+   */
+  numberOfLines?: number,
+  /**
    * Function to execute on press.
    */
   onPress?: () => mixed,
@@ -44,6 +48,10 @@ type State = {
 class DataTableTitle extends React.Component<Props, State> {
   static displayName = 'DataTable.Title';
 
+  static defaultProps = {
+    numberOfLines: 1,
+  };
+
   state = {
     spinAnim: new Animated.Value(
       this.props.sortDirection === 'ascending' ? 0 : 1
@@ -70,6 +78,7 @@ class DataTableTitle extends React.Component<Props, State> {
       sortDirection,
       theme,
       style,
+      numberOfLines,
       ...rest
     } = this.props;
 
@@ -99,7 +108,7 @@ class DataTableTitle extends React.Component<Props, State> {
               styles.cell,
               sortDirection ? styles.sorted : { color: textColor },
             ]}
-            numberOfLines={1}
+            numberOfLines={numberOfLines}
           >
             {children}
           </Text>

diff --git a/server/src/services/repository.service.ts b/server/src/services/repository.service.ts
index 3869c98..d675b30 100644
--- a/server/src/services/repository.service.ts
+++ b/server/src/services/repository.service.ts
@@ -19,6 +19,8 @@ export class RepositoryService {
       return;
     }
 
+    await this.createTeam(this.github, this.getTeamName(course), course.id);
+
     const studentRepo = getCustomRepository(StudentRepository);
     const students = await studentRepo.findActiveByCourseId(this.courseId);
 
@@ -31,8 +33,8 @@ export class RepositoryService {
         if (mentorGithubId) {
           await this.inviteMentor(mentorGithubId, course);
         }
-        await this.addTeamToRepository(this.github, course, student.githubId);
       }
+      await this.addTeamToRepository(this.github, course, student.githubId);
       if (record?.repository) {
         result.push({ repository: record.repository });
       }

diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });
",3,"[""f9a094918b62534614c47aa8a13f33aec751a1e0"", ""87d5d4e55ab7149b593d29410f1fe426ba2447d4"", ""317f4eefecddfb1392ca71d551840f446feee302""]","[""feat"", ""fix"", ""test""]"
"setup jest and add m.ts testsnever call ""onStart"" prop when idleAdd ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>","diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });

diff --git a/packages/core/src/SpringValue.ts b/packages/core/src/SpringValue.ts
index 18494a8..cbc4f27 100644
--- a/packages/core/src/SpringValue.ts
+++ b/packages/core/src/SpringValue.ts
@@ -596,11 +596,11 @@ export class SpringValue<T = any> extends AnimationValue<T> {
   /** Notify change observers */
   protected _onChange(value: T, idle = false) {
     const anim = this.animation
-    if (!anim.changed) {
+    if (!anim.changed && !idle) {
       anim.changed = true
       // The ""onStart"" prop is called on the first change after entering the
       // frameloop, but never for immediate animations.
-      if (anim.onStart && !anim.immediate) {
+      if (anim.onStart) {
         anim.onStart(this)
       }
     }

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}
",3,"[""229b53a632ea97d47c4be11f096bdd828fb415d8"", ""c8e0ae8612df3d6f2831acc004aaac332f6105e4"", ""f823cf28652987d43c8324b4f5b203240032383a""]","[""test"", ""fix"", ""feat""]"
add getter for protocol iduse `regexp_instr != 0` instead of `REGEXP` keywordadd spacing in comment fix lint (#8555),"diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(

diff --git a/src/components/nav/test/basic/app-module.ts b/src/components/nav/test/basic/app-module.ts
index 467917a..375e662 100644
--- a/src/components/nav/test/basic/app-module.ts
+++ b/src/components/nav/test/basic/app-module.ts
@@ -633,7 +633,7 @@ export class Tab3 {
   }
 
   presentModal() {
-    //this.modalCtrl.create(MyModal).present();
+    // this.modalCtrl.create(MyModal).present();
   }
 
   selectPrevious() {
",3,"[""dc5238b2bda98a7c4f2fe9584fc3b0191a408109"", ""06e2be4e2019b6fa714e1fcb34485860ef1ede79"", ""af880ac5b4fecbc6c4f3d1eee0d95f326e8bd9d1""]","[""feat"", ""fix"", ""docs""]"
"add riscv64gc-unknown-linux-gnunginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>fixed docker link tests","diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection

diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
",3,"[""173553c0372e66e03bdab19e0e6c2dd44daa14a0"", ""e12d9e77a6fd531a22325337838a841b1c67f00d"", ""c7b25726df94a2530c9b1c0d2b6a0acaa103822f""]","[""cicd"", ""docs"", ""test""]"
"only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>initialize threejs objects in defaultRef, to fix undefined type errorsnginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection
",3,"[""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""2561f4ade46fc9d59f289f328cc77733a6443697"", ""e12d9e77a6fd531a22325337838a841b1c67f00d""]","[""cicd"", ""fix"", ""docs""]"
"Add ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>allow disabling dynamic queuesetup jest and add m.ts tests","diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}

diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });
",3,"[""f823cf28652987d43c8324b4f5b203240032383a"", ""9ef5c0d14193a9abb09b39856f58477d1f4b0d77"", ""229b53a632ea97d47c4be11f096bdd828fb415d8""]","[""feat"", ""fix"", ""test""]"
add .nullif() exampleadd riscv64gc-unknown-linux-gnudetach ViewControllers when not active,"diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 

diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }

diff --git a/ionic/components/nav/nav-controller.ts b/ionic/components/nav/nav-controller.ts
index becdd99..1cc3c31 100644
--- a/ionic/components/nav/nav-controller.ts
+++ b/ionic/components/nav/nav-controller.ts
@@ -1410,6 +1410,9 @@ export class NavController extends Ion {
       // set the ComponentRef's instance to this ViewController
       view.setInstance(component);
 
+      // remember the ChangeDetectorRef for this ViewController
+      view.setChangeDetector(hostViewRef.changeDetectorRef);
+
       // remember the ElementRef to the ion-page elementRef that was just created
       view.setPageRef(pageElementRef);
 
diff --git a/ionic/components/nav/view-controller.ts b/ionic/components/nav/view-controller.ts
index 3207fa2..069c74d 100644
--- a/ionic/components/nav/view-controller.ts
+++ b/ionic/components/nav/view-controller.ts
@@ -1,4 +1,4 @@
-import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer} from 'angular2/core';
+import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer, ChangeDetectorRef} from 'angular2/core';
 
 import {Navbar} from '../navbar/navbar';
 import {NavController, NavOptions} from './nav-controller';
@@ -33,6 +33,7 @@ export class ViewController {
   private _nbVwRef: ViewContainerRef;
   private _onDismiss: Function = null;
   private _pgRef: ElementRef;
+  private _cd: ChangeDetectorRef;
   protected _nav: NavController;
 
   /**
@@ -166,6 +167,13 @@ export class ViewController {
   /**
    * @private
    */
+  setChangeDetector(cd: ChangeDetectorRef) {
+    this._cd = cd;
+  }
+
+  /**
+   * @private
+   */
   setInstance(instance: any) {
     this.instance = instance;
   }
@@ -467,6 +475,14 @@ export class ViewController {
    * The view is about to enter and become the active view.
    */
   willEnter() {
+    if (this._cd) {
+      // ensure this has been re-attached to the change detector
+      this._cd.reattach();
+
+      // detect changes before we run any user code
+      this._cd.detectChanges();
+    }
+
     ctrlFn(this, 'onPageWillEnter');
   }
 
@@ -496,6 +512,10 @@ export class ViewController {
    */
   didLeave() {
     ctrlFn(this, 'onPageDidLeave');
+
+    // when this is not the active page
+    // we no longer need to detect changes
+    this._cd && this._cd.detach();
   }
 
   /**
",3,"[""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21"", ""173553c0372e66e03bdab19e0e6c2dd44daa14a0"", ""b282e90e2cbb74559aab79eee8443a4d7c85502a""]","[""docs"", ""cicd"", ""feat""]"
add a branch name to Slack notifications (#14793)add comments for the Handler[gn] fix include_dirs ordering error,"diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'

diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }

diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)
",3,"[""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da"", ""036a0ff49a7dade0e04c9c07071a1ff49133ee24"", ""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945""]","[""cicd"", ""docs"", ""build""]"
"split release docs build into separate workflowdetach ViewControllers when not activedocker PG version upgrade

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>","diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 753d57d..3e0aa15 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -88,14 +88,14 @@ jobs:
         run: poetry run pytest --benchmark-only --benchmark-json .benchmarks/output.json ibis/tests/benchmarks
 
       - uses: tibdex/github-app-token@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         id: generate-token
         with:
           app_id: ${{ secrets.SQUAWK_BOT_APP_ID }}
           private_key: ${{ secrets.SQUAWK_BOT_APP_PRIVATE_KEY }}
 
       - uses: benchmark-action/github-action-benchmark@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         with:
           tool: pytest
           github-token: ${{ steps.generate-token.outputs.token }}
@@ -107,6 +107,7 @@ jobs:
 
   docs:
     runs-on: ubuntu-latest
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
     needs:
       # wait on benchmarks to prevent a race condition when pushing to the
       # gh-pages branch
@@ -124,51 +125,25 @@ jobs:
           authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
           extraPullNames: nix-community,poetry2nix
 
-      - name: Generate a GitHub token
-        if: ${{ github.event_name == 'push' }}
-        uses: tibdex/github-app-token@v1
-        id: generate_token
-        with:
-          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
-          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
-
-      - name: checkout
-        if: ${{ github.event_name == 'push' }}
-        uses: actions/checkout@v3
-        with:
-          fetch-depth: 0
-          token: ${{ steps.generate_token.outputs.token }}
-
       - name: checkout
-        if: ${{ github.event_name != 'push' }}
         uses: actions/checkout@v3
 
-      - name: Configure git info
-        if: ${{ github.event_name == 'push' }}
-        run: |
-          set -euo pipefail
-
-          git config user.name 'ibis-docs-bot[bot]'
-          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
-
       - name: build docs
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c mkdocs build
 
       - name: verify internal links
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c just checklinks --offline --no-progress
 
-      - name: Pull gh-pages changes
+      - name: Configure git info
         if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
-          git fetch origin gh-pages
-          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
 
       - name: build and push dev docs
-        if: ${{ github.event_name == 'push' && !startsWith(github.ref, 'refs/tags/') }}
+        if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
@@ -180,19 +155,6 @@ jobs:
               --message 'docs(dev): ibis@${{ github.sha }}' \
                 dev
 
-      - name: build and push docs on tag
-        if: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/tags/') }}
-        run: |
-          set -euo pipefail
-
-          nix develop -f shell.nix --keep-going -c \
-            mic deploy \
-              --push \
-              --rebase \
-              --prefix docs \
-              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
-              ""${GITHUB_REF_NAME}"" latest
-
   simulate_release:
     runs-on: ubuntu-latest
     steps:
diff --git a/.github/workflows/ibis-docs-release.yml b/.github/workflows/ibis-docs-release.yml
new file mode 100644
index 0000000..da7ee49
--- /dev/null
+++ b/.github/workflows/ibis-docs-release.yml
@@ -0,0 +1,63 @@
+# vim: filetype=yaml
+name: Docs Release Build
+
+on:
+  release:
+    types:
+      - published
+jobs:
+  docs:
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
+    runs-on: ubuntu-latest
+    steps:
+      - name: install nix
+        uses: cachix/install-nix-action@v17
+        with:
+          nix_path: nixpkgs=channel:nixos-unstable-small
+
+      - name: setup cachix
+        uses: cachix/cachix-action@v10
+        with:
+          name: ibis
+          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
+          extraPullNames: nix-community,poetry2nix
+
+      - name: Generate a GitHub token
+        uses: tibdex/github-app-token@v1
+        id: generate_token
+        with:
+          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
+          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
+
+      - name: checkout
+        uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+          token: ${{ steps.generate_token.outputs.token }}
+
+      - name: Configure git info
+        run: |
+          set -euo pipefail
+
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
+
+      - name: Pull gh-pages changes
+        run: |
+          set -euo pipefail
+
+          git fetch origin gh-pages
+          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+
+      - name: build and push docs on tag
+        run: |
+          set -euo pipefail
+
+          nix develop -f shell.nix --keep-going -c \
+            mic deploy \
+              --push \
+              --rebase \
+              --update-aliases \
+              --prefix docs \
+              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
+              ""${GITHUB_REF_NAME}"" latest

diff --git a/ionic/components/nav/nav-controller.ts b/ionic/components/nav/nav-controller.ts
index becdd99..1cc3c31 100644
--- a/ionic/components/nav/nav-controller.ts
+++ b/ionic/components/nav/nav-controller.ts
@@ -1410,6 +1410,9 @@ export class NavController extends Ion {
       // set the ComponentRef's instance to this ViewController
       view.setInstance(component);
 
+      // remember the ChangeDetectorRef for this ViewController
+      view.setChangeDetector(hostViewRef.changeDetectorRef);
+
       // remember the ElementRef to the ion-page elementRef that was just created
       view.setPageRef(pageElementRef);
 
diff --git a/ionic/components/nav/view-controller.ts b/ionic/components/nav/view-controller.ts
index 3207fa2..069c74d 100644
--- a/ionic/components/nav/view-controller.ts
+++ b/ionic/components/nav/view-controller.ts
@@ -1,4 +1,4 @@
-import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer} from 'angular2/core';
+import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer, ChangeDetectorRef} from 'angular2/core';
 
 import {Navbar} from '../navbar/navbar';
 import {NavController, NavOptions} from './nav-controller';
@@ -33,6 +33,7 @@ export class ViewController {
   private _nbVwRef: ViewContainerRef;
   private _onDismiss: Function = null;
   private _pgRef: ElementRef;
+  private _cd: ChangeDetectorRef;
   protected _nav: NavController;
 
   /**
@@ -166,6 +167,13 @@ export class ViewController {
   /**
    * @private
    */
+  setChangeDetector(cd: ChangeDetectorRef) {
+    this._cd = cd;
+  }
+
+  /**
+   * @private
+   */
   setInstance(instance: any) {
     this.instance = instance;
   }
@@ -467,6 +475,14 @@ export class ViewController {
    * The view is about to enter and become the active view.
    */
   willEnter() {
+    if (this._cd) {
+      // ensure this has been re-attached to the change detector
+      this._cd.reattach();
+
+      // detect changes before we run any user code
+      this._cd.detectChanges();
+    }
+
     ctrlFn(this, 'onPageWillEnter');
   }
 
@@ -496,6 +512,10 @@ export class ViewController {
    */
   didLeave() {
     ctrlFn(this, 'onPageDidLeave');
+
+    // when this is not the active page
+    // we no longer need to detect changes
+    this._cd && this._cd.detach();
   }
 
   /**

diff --git a/packages/nocodb/docker-compose.yml b/packages/nocodb/docker-compose.yml
index 7fabf79..ba2ab7b 100644
--- a/packages/nocodb/docker-compose.yml
+++ b/packages/nocodb/docker-compose.yml
@@ -1,4 +1,4 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
     # db55:
@@ -96,8 +96,8 @@ services:
     #     - 5495:5432
     #   volumes:
     #     - ./pg-sakila-db:/docker-entrypoint-initdb.d
-    pg96:
-     image: postgres:9.6
+    pg147:
+     image: postgres:14.7
      restart: always
      environment:
        POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
index 19dfab2..97d346b 100644
--- a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
+++ b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg.yml b/tests/playwright/scripts/docker-compose-pg.yml
index 0396579..9fab10e 100644
--- a/tests/playwright/scripts/docker-compose-pg.yml
+++ b/tests/playwright/scripts/docker-compose-pg.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
",3,"[""32845e1bbd1efb5dbc16f671049509a409ba25ce"", ""b282e90e2cbb74559aab79eee8443a4d7c85502a"", ""37b1cbfd3d2c462ef4f2a131e4172c38dc8d9ddf""]","[""cicd"", ""feat"", ""build""]"
"verify checkpoint listeners are notifiedfix netty dependency

netty-bom 4.1.70 contains the changes from pull request
https://github.com/netty/netty/pull/11798, which moved the classes out
of the native modules to make sure the same classes don't end up on the
classpath multiple times. For us it means that we need to depend on both
the native and classes modules. However, since we don't use the native
module directly (only classes that were moved to this classes module),
we need to force the dependency plugin to consider the native module as
used.print errors without stacktraceadd getter for protocol id","diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }

diff --git a/atomix/cluster/pom.xml b/atomix/cluster/pom.xml
index a477873..b6db695 100644
--- a/atomix/cluster/pom.xml
+++ b/atomix/cluster/pom.xml
@@ -69,6 +69,10 @@
     </dependency>
     <dependency>
       <groupId>io.netty</groupId>
+      <artifactId>netty-transport-classes-epoll</artifactId>
+    </dependency>
+    <dependency>
+      <groupId>io.netty</groupId>
       <artifactId>netty-transport-native-epoll</artifactId>
       <classifier>linux-x86_64</classifier>
     </dependency>
@@ -278,6 +282,7 @@
             <dependency>uk.co.real-logic:sbe-tool</dependency>
             <dependency>net.jqwik:jqwik</dependency>
             <dependency>io.netty:netty-tcnative-boringssl-static</dependency>
+            <dependency>io.netty:netty-transport-native-epoll</dependency>
           </usedDependencies>
         </configuration>
       </plugin>

diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {

diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }
",4,"[""e0198f74b81da3663144cfe1d971939319f82a0f"", ""f00a4d3e307b89842250358ee432e6800bb24362"", ""d129eaf9125a967ac86c6c7276bbae6b4d50af36"", ""dc5238b2bda98a7c4f2fe9584fc3b0191a408109""]","[""test"", ""build"", ""fix"", ""feat""]"
"add a branch name to Slack notifications (#14793)assist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>skip flaky testadd comments for the Handler","diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'

diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method

diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }
",4,"[""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da"", ""1269431c8a3e7549f10fcbbb4b88ff625c8898b3"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d"", ""036a0ff49a7dade0e04c9c07071a1ff49133ee24""]","[""cicd"", ""build"", ""test"", ""docs""]"
"restructure ClusterTopology to track completed changeadd getter for protocol idadded changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284setup jest and add m.ts tests","diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(

diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }

diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });
",4,"[""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2"", ""dc5238b2bda98a7c4f2fe9584fc3b0191a408109"", ""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""229b53a632ea97d47c4be11f096bdd828fb415d8""]","[""refactor"", ""feat"", ""docs"", ""test""]"
"wrong icon reference

Signed-off-by: Pranav C <pranavxc@gmail.com>xfail on to_parquet and to_csv that use pyarrow write optionsspring version, core versionexport a modal transition preset","diff --git a/packages/nc-gui/components.d.ts b/packages/nc-gui/components.d.ts
index b7e6585..bb86478 100644
--- a/packages/nc-gui/components.d.ts
+++ b/packages/nc-gui/components.d.ts
@@ -81,7 +81,6 @@ declare module '@vue/runtime-core' {
     ClaritySuccessLine: typeof import('~icons/clarity/success-line')['default']
     EvaEmailOutline: typeof import('~icons/eva/email-outline')['default']
     IcBaselineMoreVert: typeof import('~icons/ic/baseline-more-vert')['default']
-    Icon: typeof import('~icons/ic/on')['default']
     IcOutlineInsertDriveFile: typeof import('~icons/ic/outline-insert-drive-file')['default']
     IcRoundEdit: typeof import('~icons/ic/round-edit')['default']
     IcRoundKeyboardArrowDown: typeof import('~icons/ic/round-keyboard-arrow-down')['default']

diff --git a/ibis/backends/tests/test_export.py b/ibis/backends/tests/test_export.py
index 4d536d7..5bb9775 100644
--- a/ibis/backends/tests/test_export.py
+++ b/ibis/backends/tests/test_export.py
@@ -222,18 +222,23 @@ def test_table_to_parquet(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs""), [({""version"": ""1.0""}), ({""version"": ""2.6""})])
-def test_table_to_parquet_writer_kwargs(kwargs, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.NotSupportedError,
+)
+@pytest.mark.parametrize(""version"", [""1.0"", ""2.6""])
+def test_table_to_parquet_writer_kwargs(version, tmp_path, backend, awards_players):
     outparquet = tmp_path / ""out.parquet""
-    awards_players.to_parquet(outparquet, **kwargs)
+    awards_players.to_parquet(outparquet, version=version)
 
     df = pd.read_parquet(outparquet)
 
     backend.assert_frame_equal(awards_players.to_pandas(), df)
 
-    file = pa.parquet.ParquetFile(outparquet)
+    md = pa.parquet.read_metadata(outparquet)
 
-    assert file.metadata.format_version == kwargs[""version""]
+    assert md.format_version == version
 
 
 @pytest.mark.notimpl(
@@ -316,14 +321,20 @@ def test_table_to_csv(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs"", ""delimiter""), [({""write_options"": pcsv.WriteOptions(delimiter="";"")}, "";""), ({""write_options"": pcsv.WriteOptions(delimiter=""\t"")}, ""\t"")])
-def test_table_to_csv_writer_kwargs(kwargs, delimiter, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.ProgrammingError,
+)
+@pytest.mark.parametrize(""delimiter"", ["";"", ""\t""], ids=[""semicolon"", ""tab""])
+def test_table_to_csv_writer_kwargs(delimiter, tmp_path, awards_players):
     outcsv = tmp_path / ""out.csv""
     # avoid pandas NaNonense
     awards_players = awards_players.select(""playerID"", ""awardID"", ""yearID"", ""lgID"")
 
-    awards_players.to_csv(outcsv, **kwargs)
-    pd.read_csv(outcsv, delimiter=delimiter)
+    awards_players.to_csv(outcsv, write_options=pcsv.WriteOptions(delimiter=delimiter))
+    df = pd.read_csv(outcsv, delimiter=delimiter, nrows=1)
+    assert len(df) == 1
 
 
 @pytest.mark.parametrize(

diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 

diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {
",4,"[""d1d55e787b7d07f763852602b9939a5394607fd9"", ""bedc7950b24c37809e36a585b7985d5aa5e3e458"", ""c55591ba157298a9c5816693c102a89dfd058830"", ""535708ae50aecb452560a23356fd396f99ef13a2""]","[""fix"", ""test"", ""build"", ""refactor""]"
"licensingassist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>do not use scripts and binaries from the libcc reposupport use meta key select multiple element","diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;

diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index ab68624..aeee7b7 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -277,9 +277,11 @@ export default class LogicFlow {
   }
   /**
    * 将图形选中
+   * @param id 选择元素ID
+   * @param multiple 是否允许多选，如果为true，不会将上一个选中的元素重置
    */
-  select(id: string) {
-    this.graphModel.selectElementById(id);
+  select(id: string, multiple = false) {
+    this.graphModel.selectElementById(id, multiple);
   }
   /**
    * 将图形定位到画布中心
diff --git a/packages/core/src/model/EditConfigModel.ts b/packages/core/src/model/EditConfigModel.ts
index 67e334a..83e5f16 100644
--- a/packages/core/src/model/EditConfigModel.ts
+++ b/packages/core/src/model/EditConfigModel.ts
@@ -25,6 +25,7 @@ const SilentConfig = {
   edgeTextEdit: false,
   nodeTextDraggable: false,
   edgeTextDraggable: false,
+  metaKeyMultipleSelected: false,
 };
 
 /**
@@ -42,6 +43,7 @@ export default class EditConfigModel {
   @observable edgeTextEdit = true; // 允许连线文本可以编辑
   @observable nodeTextDraggable = false; // 允许节点文本可以拖拽
   @observable edgeTextDraggable = false; // 允许连线文本可以拖拽
+  @observable metaKeyMultipleSelected = false; // 允许meta多选元素
   constructor(data) {
     const keys = [
       'stopZoomGraph',
@@ -55,6 +57,7 @@ export default class EditConfigModel {
       'edgeTextEdit',
       'nodeTextDraggable',
       'edgeTextDraggable',
+      'metaKeyMultipleSelected',
     ];
     const { isSilentMode, textEdit } = data;
     if (isSilentMode) {
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 9667f4d..310daf4 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -34,6 +34,7 @@ class GraphModel {
   height: number;
   topElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
   selectElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
+  selectElements = new Map<string, IBaseModel>(); // 多选
   @observable edgeType: string;
   @observable nodes: BaseNodeModel[] = [];
   @observable activeElement: IBaseModel;
@@ -50,7 +51,6 @@ class GraphModel {
   @observable gridSize = 1;
   @observable partial = false; // 是否开启局部渲染
   @observable fakerNode: BaseNodeModel;
-  // @observable selectElements = new Map<string, IBaseModel>(); // 多选还没有做，先不加
   constructor(config) {
     const {
       container,
@@ -456,24 +456,44 @@ class GraphModel {
   }
 
   @action
-  selectNodeById(id) {
-    this.selectElement?.setSelected(false);
+  selectNodeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.nodesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectEdgeById(id) {
-    this.selectElement?.setSelected(false);
+  selectEdgeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.edgesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectElementById(id: string) {
-    this.selectElement?.setSelected(false);
+  selectElementById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
+  }
+
+  @action
+  clearSelectElements() {
+    this.selectElements.forEach(element => {
+      element.setSelected(false);
+    });
+    this.selectElements.clear();
   }
 
   /* 修改连线类型 */
diff --git a/packages/core/src/view/edge/BaseEdge.tsx b/packages/core/src/view/edge/BaseEdge.tsx
index d45ea9e..d7c8f38 100644
--- a/packages/core/src/view/edge/BaseEdge.tsx
+++ b/packages/core/src/view/edge/BaseEdge.tsx
@@ -178,7 +178,8 @@ export default class BaseEdge extends Component<IProps> {
   handleClick = (e) => {
     const { model, graphModel, eventCenter } = this.props;
     graphModel.toFront(model.id);
-    graphModel.selectEdgeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectEdgeById(model.id, e.metaKey && metaKeyMultipleSelected);
     // 边数据
     const edgeData = model?.getData();
     const position = graphModel.getPointByClient({
diff --git a/packages/core/src/view/node/BaseNode.tsx b/packages/core/src/view/node/BaseNode.tsx
index 140889c..5ee3975 100644
--- a/packages/core/src/view/node/BaseNode.tsx
+++ b/packages/core/src/view/node/BaseNode.tsx
@@ -275,7 +275,8 @@ export default abstract class BaseNode extends Component<IProps, Istate> {
       }, 400);
     }
     graphModel.toFront(model.id);
-    graphModel.selectNodeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectNodeById(model.id, e.metaKey && metaKeyMultipleSelected);
     this.preStartTime = this.startTime;
   };
   handleContextMenu = (ev: MouseEvent) => {
diff --git a/packages/core/src/view/overlay/CanvasOverlay.tsx b/packages/core/src/view/overlay/CanvasOverlay.tsx
index ef11822..8c79fd2 100644
--- a/packages/core/src/view/overlay/CanvasOverlay.tsx
+++ b/packages/core/src/view/overlay/CanvasOverlay.tsx
@@ -104,9 +104,9 @@ class CanvasOverlay extends Component<IProps, Istate> {
     const target = ev.target as HTMLElement;
     if (target.getAttribute('name') === 'canvas-overlay') {
       const { graphModel, eventCenter } = this.props;
-      const { selectElement, textEditElement } = graphModel;
-      if (selectElement) {
-        selectElement.setSelected(false);
+      const { textEditElement, selectElements } = graphModel;
+      if (selectElements.size > 0) {
+        graphModel.clearSelectElements();
       }
       if (textEditElement) {
         textEditElement.setElementState(ElementState.DEFAULT);
diff --git a/packages/extension/examples/bpmn/index.html b/packages/extension/examples/bpmn/index.html
index 7a68d6f..f7ea87d 100644
--- a/packages/extension/examples/bpmn/index.html
+++ b/packages/extension/examples/bpmn/index.html
@@ -6,6 +6,7 @@
   <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
   <title>LOGIN FLOW</title>
   <link rel=""stylesheet"" href=""/core/dist/style/index.css"">
+  <link rel=""stylesheet"" href=""/extension/lib/style/index.css"">
   <style>
     html,body {
       padding: 0;
@@ -129,11 +130,14 @@
     </div>
   </div>
   <script src=""/core/dist/logic-flow.js""></script>
+  <!-- <script src=""http://0.0.0.0:9090/logic-flow.js""></script> -->
   <script src=""/BpmnElement.js""></script>
   <script src=""/BpmnAdapter.js""></script>
+  <script src=""/Control.js""></script>
   <script src=""/Snapshot.js""></script>
   <script>
     LogicFlow.use(BpmnElement);
+    LogicFlow.use(Control);
     LogicFlow.use(BpmnAdapter);
     LogicFlow.use(Snapshot);
   </script>
diff --git a/packages/extension/examples/bpmn/index.js b/packages/extension/examples/bpmn/index.js
index 21d2da0..6f6aa39 100644
--- a/packages/extension/examples/bpmn/index.js
+++ b/packages/extension/examples/bpmn/index.js
@@ -3,6 +3,10 @@ window.onload = function () {
     container: document.querySelector('#app'),
     // fixme: grid成为了必传的了
     edgeTextDraggable: true,
+    metaKeyMultipleSelected: true,
+    // stopScrollGraph: true,
+    // stopMoveGraph: true,
+    // stopZoomGraph: true,
     grid: {
       type: 'dot',
       size: 20,
",4,"[""a52a585d74894b3b4eeb8c784fa089ff95cddad0"", ""1269431c8a3e7549f10fcbbb4b88ff625c8898b3"", ""45837af24a33308a70a3454f0f650f9fe728e272"", ""e137f9fdbdb6bf3f85c3f7ac9323785e445844c8""]","[""docs"", ""build"", ""cicd"", ""feat""]"
add benchmark for known-slow table expressionautostart feature fixedexport a modal transition presetadd a branch name to Slack notifications (#14793),"diff --git a/.gitignore b/.gitignore
index 2e99ad3..eef9203 100644
--- a/.gitignore
+++ b/.gitignore
@@ -95,3 +95,4 @@ docs/backends/support_matrix.csv
 __pycache__
 tags
 .DS_Store
+prof/
diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index ac19aaf..36aed0e 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -602,3 +602,93 @@ def test_multiple_joins(benchmark, num_joins, num_columns):
         name=""t"",
     )
     benchmark(multiple_joins, table, num_joins)
+
+
+@pytest.fixture
+def customers():
+    return ibis.table(
+        dict(
+            customerid=""int32"",
+            name=""string"",
+            address=""string"",
+            citystatezip=""string"",
+            birthdate=""date"",
+            phone=""string"",
+            timezone=""string"",
+            lat=""float64"",
+            long=""float64"",
+        ),
+        name=""customers"",
+    )
+
+
+@pytest.fixture
+def orders():
+    return ibis.table(
+        dict(
+            orderid=""int32"",
+            customerid=""int32"",
+            ordered=""timestamp"",
+            shipped=""timestamp"",
+            items=""string"",
+            total=""float64"",
+        ),
+        name=""orders"",
+    )
+
+
+@pytest.fixture
+def orders_items():
+    return ibis.table(
+        dict(orderid=""int32"", sku=""string"", qty=""int32"", unit_price=""float64""),
+        name=""orders_items"",
+    )
+
+
+@pytest.fixture
+def products():
+    return ibis.table(
+        dict(
+            sku=""string"",
+            desc=""string"",
+            weight_kg=""float64"",
+            cost=""float64"",
+            dims_cm=""string"",
+        ),
+        name=""products"",
+    )
+
+
+@pytest.mark.benchmark(group=""compilation"")
+@pytest.mark.parametrize(
+    ""module"",
+    [
+        pytest.param(
+            mod,
+            marks=pytest.mark.xfail(
+                condition=mod in _XFAIL_COMPILE_BACKENDS,
+                reason=f""{mod} backend doesn't support compiling UnboundTable"",
+            ),
+        )
+        for mod in _backends
+    ],
+)
+def test_compile_with_drops(
+    benchmark, module, customers, orders, orders_items, products
+):
+    expr = (
+        customers.join(orders, ""customerid"")
+        .join(orders_items, ""orderid"")
+        .join(products, ""sku"")
+        .drop(""customerid"", ""qty"", ""total"", ""items"")
+        .drop(""dims_cm"", ""cost"")
+        .mutate(o_date=lambda t: t.shipped.date())
+        .filter(lambda t: t.ordered == t.shipped)
+    )
+
+    try:
+        mod = getattr(ibis, module)
+    except (AttributeError, ImportError) as e:
+        pytest.skip(str(e))
+    else:
+        benchmark(mod.compile, expr)

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();

diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {

diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'
",4,"[""e9617f0854030e70365eb264bcb3b58078e79e9e"", ""bed78248c941d57ad4cc20a455147e186e97c7a1"", ""535708ae50aecb452560a23356fd396f99ef13a2"", ""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da""]","[""test"", ""fix"", ""refactor"", ""cicd""]"
"increment failing test retriesautostart feature fixedAdd ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>added suported tuple types","diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}

diff --git a/src/List/Tuple.ts b/src/List/Tuple.ts
index 4c59caa..6e45503 100644
--- a/src/List/Tuple.ts
+++ b/src/List/Tuple.ts
@@ -1,15 +1,17 @@
-/** A [[Tuple]]
+import {NonNullable} from '../Object/NonNullable'
+
+/** A [[Tuple]] (supported)
  * @param A its type
- * @returns **`any[]`**
+ * @returns **`A[]`**
  * @example
  * ```ts
- * type list0 = [1, 2, 3]
- * type list1 = number[]
+ * type tuple0 = [1, 20, 42]
+ * type tuple1 = ['at', 420]
  * ```
  */
-export type Tuple = [
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-]
+export type Tuple<A = any> = NonNullable<[
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+]>
",4,"[""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57"", ""bed78248c941d57ad4cc20a455147e186e97c7a1"", ""f823cf28652987d43c8324b4f5b203240032383a"", ""2954a0955ce9af6acb345ed1e8328e145ad30475""]","[""cicd"", ""fix"", ""feat"", ""refactor""]"
"added changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284remove ubuntu-latest from job title where that is the only osupdate wrapping tests for v7restructure ClusterTopology to track completed change","diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false

diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });

diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(
",4,"[""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""74e9de5ec97dc013a52aa063dff0f40ac74c407b"", ""317f4eefecddfb1392ca71d551840f446feee302"", ""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2""]","[""docs"", ""cicd"", ""test"", ""refactor""]"
"fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.support use meta key select multiple elementfix build orderingupdate `cargo-make` for `v0.35.3`","diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index ab68624..aeee7b7 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -277,9 +277,11 @@ export default class LogicFlow {
   }
   /**
    * 将图形选中
+   * @param id 选择元素ID
+   * @param multiple 是否允许多选，如果为true，不会将上一个选中的元素重置
    */
-  select(id: string) {
-    this.graphModel.selectElementById(id);
+  select(id: string, multiple = false) {
+    this.graphModel.selectElementById(id, multiple);
   }
   /**
    * 将图形定位到画布中心
diff --git a/packages/core/src/model/EditConfigModel.ts b/packages/core/src/model/EditConfigModel.ts
index 67e334a..83e5f16 100644
--- a/packages/core/src/model/EditConfigModel.ts
+++ b/packages/core/src/model/EditConfigModel.ts
@@ -25,6 +25,7 @@ const SilentConfig = {
   edgeTextEdit: false,
   nodeTextDraggable: false,
   edgeTextDraggable: false,
+  metaKeyMultipleSelected: false,
 };
 
 /**
@@ -42,6 +43,7 @@ export default class EditConfigModel {
   @observable edgeTextEdit = true; // 允许连线文本可以编辑
   @observable nodeTextDraggable = false; // 允许节点文本可以拖拽
   @observable edgeTextDraggable = false; // 允许连线文本可以拖拽
+  @observable metaKeyMultipleSelected = false; // 允许meta多选元素
   constructor(data) {
     const keys = [
       'stopZoomGraph',
@@ -55,6 +57,7 @@ export default class EditConfigModel {
       'edgeTextEdit',
       'nodeTextDraggable',
       'edgeTextDraggable',
+      'metaKeyMultipleSelected',
     ];
     const { isSilentMode, textEdit } = data;
     if (isSilentMode) {
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 9667f4d..310daf4 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -34,6 +34,7 @@ class GraphModel {
   height: number;
   topElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
   selectElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
+  selectElements = new Map<string, IBaseModel>(); // 多选
   @observable edgeType: string;
   @observable nodes: BaseNodeModel[] = [];
   @observable activeElement: IBaseModel;
@@ -50,7 +51,6 @@ class GraphModel {
   @observable gridSize = 1;
   @observable partial = false; // 是否开启局部渲染
   @observable fakerNode: BaseNodeModel;
-  // @observable selectElements = new Map<string, IBaseModel>(); // 多选还没有做，先不加
   constructor(config) {
     const {
       container,
@@ -456,24 +456,44 @@ class GraphModel {
   }
 
   @action
-  selectNodeById(id) {
-    this.selectElement?.setSelected(false);
+  selectNodeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.nodesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectEdgeById(id) {
-    this.selectElement?.setSelected(false);
+  selectEdgeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.edgesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectElementById(id: string) {
-    this.selectElement?.setSelected(false);
+  selectElementById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
+  }
+
+  @action
+  clearSelectElements() {
+    this.selectElements.forEach(element => {
+      element.setSelected(false);
+    });
+    this.selectElements.clear();
   }
 
   /* 修改连线类型 */
diff --git a/packages/core/src/view/edge/BaseEdge.tsx b/packages/core/src/view/edge/BaseEdge.tsx
index d45ea9e..d7c8f38 100644
--- a/packages/core/src/view/edge/BaseEdge.tsx
+++ b/packages/core/src/view/edge/BaseEdge.tsx
@@ -178,7 +178,8 @@ export default class BaseEdge extends Component<IProps> {
   handleClick = (e) => {
     const { model, graphModel, eventCenter } = this.props;
     graphModel.toFront(model.id);
-    graphModel.selectEdgeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectEdgeById(model.id, e.metaKey && metaKeyMultipleSelected);
     // 边数据
     const edgeData = model?.getData();
     const position = graphModel.getPointByClient({
diff --git a/packages/core/src/view/node/BaseNode.tsx b/packages/core/src/view/node/BaseNode.tsx
index 140889c..5ee3975 100644
--- a/packages/core/src/view/node/BaseNode.tsx
+++ b/packages/core/src/view/node/BaseNode.tsx
@@ -275,7 +275,8 @@ export default abstract class BaseNode extends Component<IProps, Istate> {
       }, 400);
     }
     graphModel.toFront(model.id);
-    graphModel.selectNodeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectNodeById(model.id, e.metaKey && metaKeyMultipleSelected);
     this.preStartTime = this.startTime;
   };
   handleContextMenu = (ev: MouseEvent) => {
diff --git a/packages/core/src/view/overlay/CanvasOverlay.tsx b/packages/core/src/view/overlay/CanvasOverlay.tsx
index ef11822..8c79fd2 100644
--- a/packages/core/src/view/overlay/CanvasOverlay.tsx
+++ b/packages/core/src/view/overlay/CanvasOverlay.tsx
@@ -104,9 +104,9 @@ class CanvasOverlay extends Component<IProps, Istate> {
     const target = ev.target as HTMLElement;
     if (target.getAttribute('name') === 'canvas-overlay') {
       const { graphModel, eventCenter } = this.props;
-      const { selectElement, textEditElement } = graphModel;
-      if (selectElement) {
-        selectElement.setSelected(false);
+      const { textEditElement, selectElements } = graphModel;
+      if (selectElements.size > 0) {
+        graphModel.clearSelectElements();
       }
       if (textEditElement) {
         textEditElement.setElementState(ElementState.DEFAULT);
diff --git a/packages/extension/examples/bpmn/index.html b/packages/extension/examples/bpmn/index.html
index 7a68d6f..f7ea87d 100644
--- a/packages/extension/examples/bpmn/index.html
+++ b/packages/extension/examples/bpmn/index.html
@@ -6,6 +6,7 @@
   <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
   <title>LOGIN FLOW</title>
   <link rel=""stylesheet"" href=""/core/dist/style/index.css"">
+  <link rel=""stylesheet"" href=""/extension/lib/style/index.css"">
   <style>
     html,body {
       padding: 0;
@@ -129,11 +130,14 @@
     </div>
   </div>
   <script src=""/core/dist/logic-flow.js""></script>
+  <!-- <script src=""http://0.0.0.0:9090/logic-flow.js""></script> -->
   <script src=""/BpmnElement.js""></script>
   <script src=""/BpmnAdapter.js""></script>
+  <script src=""/Control.js""></script>
   <script src=""/Snapshot.js""></script>
   <script>
     LogicFlow.use(BpmnElement);
+    LogicFlow.use(Control);
     LogicFlow.use(BpmnAdapter);
     LogicFlow.use(Snapshot);
   </script>
diff --git a/packages/extension/examples/bpmn/index.js b/packages/extension/examples/bpmn/index.js
index 21d2da0..6f6aa39 100644
--- a/packages/extension/examples/bpmn/index.js
+++ b/packages/extension/examples/bpmn/index.js
@@ -3,6 +3,10 @@ window.onload = function () {
     container: document.querySelector('#app'),
     // fixme: grid成为了必传的了
     edgeTextDraggable: true,
+    metaKeyMultipleSelected: true,
+    // stopScrollGraph: true,
+    // stopMoveGraph: true,
+    // stopZoomGraph: true,
     grid: {
       type: 'dot',
       size: 20,

diff --git a/scripts/build.mjs b/scripts/build.mjs
index 204854f..b3cf067 100644
--- a/scripts/build.mjs
+++ b/scripts/build.mjs
@@ -3,8 +3,8 @@ import { write } from 'fsxx';
 import { info, success } from './helpers.mjs';
 
 await $`rm -rf dist/*`;
-await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 await $`unbuild`;
+await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 
 const packages = [
   'jsx-runtime',

diff --git a/CHANGELOG.md b/CHANGELOG.md
index 5e125e3..52d9b6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 * Fix: resizing/scrolling through heavily wrapped panes no longer hangs (https://github.com/zellij-org/zellij/pull/814)
 * Terminal compatibility: properly handle HOME/END keys in eg. vim/zsh (https://github.com/zellij-org/zellij/pull/815)
 * Fix: Typo (https://github.com/zellij-org/zellij/pull/821)
+* Fix: Update `cargo-make` instructions post `v0.35.3` (https://github.com/zellij-org/zellij/pull/819)
 
 ## [0.19.0] - 2021-10-20
 * Fix: Prevent text overwrite when scrolled up (https://github.com/zellij-org/zellij/pull/655)
",4,"[""9be725fa3906323d4bc9788f54eccf74109d632b"", ""e137f9fdbdb6bf3f85c3f7ac9323785e445844c8"", ""c323d59c607cabc91f17a78528d998f376f30b10"", ""0cfc5633d37ea06f645649138323f1820e18bdee""]","[""fix"", ""feat"", ""build"", ""docs""]"
"update `cargo-make` for `v0.35.3`terminated tasks linger for a bit

Signed-off-by: Eliza Weisman <eliza@buoyant.io>setup jest and add m.ts testsrepository creation","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 5e125e3..52d9b6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 * Fix: resizing/scrolling through heavily wrapped panes no longer hangs (https://github.com/zellij-org/zellij/pull/814)
 * Terminal compatibility: properly handle HOME/END keys in eg. vim/zsh (https://github.com/zellij-org/zellij/pull/815)
 * Fix: Typo (https://github.com/zellij-org/zellij/pull/821)
+* Fix: Update `cargo-make` instructions post `v0.35.3` (https://github.com/zellij-org/zellij/pull/819)
 
 ## [0.19.0] - 2021-10-20
 * Fix: Prevent text overwrite when scrolled up (https://github.com/zellij-org/zellij/pull/655)

diff --git a/console/src/main.rs b/console/src/main.rs
index ebfa315..5328d96 100644
--- a/console/src/main.rs
+++ b/console/src/main.rs
@@ -69,6 +69,7 @@ async fn main() -> Result<(), Box<dyn std::error::Error>> {
                 .wrap(Wrap { trim: true });
             f.render_widget(header, chunks[0]);
             tasks.render(f, chunks[1]);
+            tasks.retain_active();
         })?;
     }
 
diff --git a/console/src/tasks.rs b/console/src/tasks.rs
index 7be39a4..eb41495 100644
--- a/console/src/tasks.rs
+++ b/console/src/tasks.rs
@@ -19,6 +19,7 @@ struct Task {
     fields: String,
     kind: &'static str,
     stats: Stats,
+    completed_for: usize,
 }
 
 #[derive(Default, Debug)]
@@ -28,10 +29,15 @@ struct Stats {
     idle: Duration,
     total: Duration,
 }
+
 impl State {
+    // How many updates to retain completed tasks for
+    const RETAIN_COMPLETED_FOR: usize = 6;
+
     pub(crate) fn len(&self) -> usize {
         self.tasks.len()
     }
+
     pub(crate) fn update(&mut self, update: proto::tasks::TaskUpdate) {
         let new_tasks = update.new_tasks.into_iter().filter_map(|task| {
             if task.id.is_none() {
@@ -48,6 +54,7 @@ impl State {
                 fields: task.string_fields,
                 kind,
                 stats: Default::default(),
+                completed_for: 0,
             };
             Some((id, task))
         });
@@ -60,7 +67,10 @@ impl State {
         }
 
         for proto::SpanId { id } in update.completed {
-            if self.tasks.remove(&id).is_none() {
+            if let Some(task) = self.tasks.get_mut(&id) {
+                task.kind = ""!"";
+                task.completed_for = 1;
+            } else {
                 tracing::warn!(?id, ""tried to complete a task that didn't exist"");
             }
         }
@@ -79,7 +89,7 @@ impl State {
         const DUR_PRECISION: usize = 4;
         const POLLS_LEN: usize = 5;
         let rows = self.tasks.values().map(|task| {
-            let row = Row::new(vec![
+            let mut row = Row::new(vec![
                 Cell::from(task.id_hex.as_str()),
                 // TODO(eliza): is there a way to write a `fmt::Debug` impl
                 // directly to tui without doing an allocation?
@@ -105,6 +115,9 @@ impl State {
                 Cell::from(format!(""{:>width$}"", task.stats.polls, width = POLLS_LEN)),
                 Cell::from(task.fields.as_str()),
             ]);
+            if task.completed_for > 0 {
+                row = row.style(Style::default().add_modifier(style::Modifier::DIM));
+            }
             row
         });
         let t = Table::new(rows)
@@ -126,6 +139,16 @@ impl State {
 
         frame.render_widget(t, area)
     }
+
+    pub(crate) fn retain_active(&mut self) {
+        self.tasks.retain(|_, task| {
+            if task.completed_for == 0 {
+                return true;
+            }
+            task.completed_for += 1;
+            task.completed_for <= Self::RETAIN_COMPLETED_FOR
+        })
+    }
 }
 
 impl From<proto::tasks::Stats> for Stats {

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });

diff --git a/server/src/services/repository.service.ts b/server/src/services/repository.service.ts
index 3869c98..d675b30 100644
--- a/server/src/services/repository.service.ts
+++ b/server/src/services/repository.service.ts
@@ -19,6 +19,8 @@ export class RepositoryService {
       return;
     }
 
+    await this.createTeam(this.github, this.getTeamName(course), course.id);
+
     const studentRepo = getCustomRepository(StudentRepository);
     const students = await studentRepo.findActiveByCourseId(this.courseId);
 
@@ -31,8 +33,8 @@ export class RepositoryService {
         if (mentorGithubId) {
           await this.inviteMentor(mentorGithubId, course);
         }
-        await this.addTeamToRepository(this.github, course, student.githubId);
       }
+      await this.addTeamToRepository(this.github, course, student.githubId);
       if (record?.repository) {
         result.push({ repository: record.repository });
       }
",4,"[""0cfc5633d37ea06f645649138323f1820e18bdee"", ""1bcf88670b50155b50071e707f98f30cea0b7a24"", ""229b53a632ea97d47c4be11f096bdd828fb415d8"", ""87d5d4e55ab7149b593d29410f1fe426ba2447d4""]","[""docs"", ""feat"", ""test"", ""fix""]"
"spring version, core versionget tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.fixed docker link testsonly run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>","diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }

diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()

diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest
",4,"[""c55591ba157298a9c5816693c102a89dfd058830"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c"", ""c7b25726df94a2530c9b1c0d2b6a0acaa103822f"", ""dbb537a26e388a8d7d17faf131abc30c2f7a84e6""]","[""build"", ""refactor"", ""test"", ""cicd""]"
"add getter for protocol idnever call ""onStart"" prop when idleAdjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.remove appear css animation","diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }

diff --git a/packages/core/src/SpringValue.ts b/packages/core/src/SpringValue.ts
index 18494a8..cbc4f27 100644
--- a/packages/core/src/SpringValue.ts
+++ b/packages/core/src/SpringValue.ts
@@ -596,11 +596,11 @@ export class SpringValue<T = any> extends AnimationValue<T> {
   /** Notify change observers */
   protected _onChange(value: T, idle = false) {
     const anim = this.animation
-    if (!anim.changed) {
+    if (!anim.changed && !idle) {
       anim.changed = true
       // The ""onStart"" prop is called on the first change after entering the
       // frameloop, but never for immediate animations.
-      if (anim.onStart && !anim.immediate) {
+      if (anim.onStart) {
         anim.onStart(this)
       }
     }

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)

diff --git a/src/popup/Popup.tsx b/src/popup/Popup.tsx
index d485bb6..2abc22a 100644
--- a/src/popup/Popup.tsx
+++ b/src/popup/Popup.tsx
@@ -269,7 +269,6 @@ export class Popup extends React.Component<{ t: TranslationFunction }, PopupStat
         <CSSTransition
           classNames='fade'
           in={!!currentTabUrl}
-          appear
           timeout={500}
           exit={false}
           mountOnEnter
",4,"[""dc5238b2bda98a7c4f2fe9584fc3b0191a408109"", ""c8e0ae8612df3d6f2831acc004aaac332f6105e4"", ""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3"", ""47ef9104e4a89e80d7cc6c1950bc080841da4a7b""]","[""feat"", ""fix"", ""test"", ""refactor""]"
"add fallible peek_last_token()added changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284Adjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.increment failing test retries","diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.

diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)

diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
",4,"[""63eab619e6166eb6cab948028a7b89bf059dd878"", ""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3"", ""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57""]","[""refactor"", ""docs"", ""test"", ""cicd""]"
"added changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284get tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.ensure checksum persist flushes to diskuse `regexp_instr != 0` instead of `REGEXP` keyword","diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }

diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(
",4,"[""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c"", ""b7ce2894fd1794064bd6db4ed730bb6cb7728739"", ""06e2be4e2019b6fa714e1fcb34485860ef1ede79""]","[""docs"", ""refactor"", ""test"", ""fix""]"
"update wrapping tests for v7added changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284fix netty dependency

netty-bom 4.1.70 contains the changes from pull request
https://github.com/netty/netty/pull/11798, which moved the classes out
of the native modules to make sure the same classes don't end up on the
classpath multiple times. For us it means that we need to depend on both
the native and classes modules. However, since we don't use the native
module directly (only classes that were moved to this classes module),
we need to force the dependency plugin to consider the native module as
used.split release docs build into separate workflow","diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });

diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/atomix/cluster/pom.xml b/atomix/cluster/pom.xml
index a477873..b6db695 100644
--- a/atomix/cluster/pom.xml
+++ b/atomix/cluster/pom.xml
@@ -69,6 +69,10 @@
     </dependency>
     <dependency>
       <groupId>io.netty</groupId>
+      <artifactId>netty-transport-classes-epoll</artifactId>
+    </dependency>
+    <dependency>
+      <groupId>io.netty</groupId>
       <artifactId>netty-transport-native-epoll</artifactId>
       <classifier>linux-x86_64</classifier>
     </dependency>
@@ -278,6 +282,7 @@
             <dependency>uk.co.real-logic:sbe-tool</dependency>
             <dependency>net.jqwik:jqwik</dependency>
             <dependency>io.netty:netty-tcnative-boringssl-static</dependency>
+            <dependency>io.netty:netty-transport-native-epoll</dependency>
           </usedDependencies>
         </configuration>
       </plugin>

diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 753d57d..3e0aa15 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -88,14 +88,14 @@ jobs:
         run: poetry run pytest --benchmark-only --benchmark-json .benchmarks/output.json ibis/tests/benchmarks
 
       - uses: tibdex/github-app-token@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         id: generate-token
         with:
           app_id: ${{ secrets.SQUAWK_BOT_APP_ID }}
           private_key: ${{ secrets.SQUAWK_BOT_APP_PRIVATE_KEY }}
 
       - uses: benchmark-action/github-action-benchmark@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         with:
           tool: pytest
           github-token: ${{ steps.generate-token.outputs.token }}
@@ -107,6 +107,7 @@ jobs:
 
   docs:
     runs-on: ubuntu-latest
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
     needs:
       # wait on benchmarks to prevent a race condition when pushing to the
       # gh-pages branch
@@ -124,51 +125,25 @@ jobs:
           authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
           extraPullNames: nix-community,poetry2nix
 
-      - name: Generate a GitHub token
-        if: ${{ github.event_name == 'push' }}
-        uses: tibdex/github-app-token@v1
-        id: generate_token
-        with:
-          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
-          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
-
-      - name: checkout
-        if: ${{ github.event_name == 'push' }}
-        uses: actions/checkout@v3
-        with:
-          fetch-depth: 0
-          token: ${{ steps.generate_token.outputs.token }}
-
       - name: checkout
-        if: ${{ github.event_name != 'push' }}
         uses: actions/checkout@v3
 
-      - name: Configure git info
-        if: ${{ github.event_name == 'push' }}
-        run: |
-          set -euo pipefail
-
-          git config user.name 'ibis-docs-bot[bot]'
-          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
-
       - name: build docs
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c mkdocs build
 
       - name: verify internal links
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c just checklinks --offline --no-progress
 
-      - name: Pull gh-pages changes
+      - name: Configure git info
         if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
-          git fetch origin gh-pages
-          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
 
       - name: build and push dev docs
-        if: ${{ github.event_name == 'push' && !startsWith(github.ref, 'refs/tags/') }}
+        if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
@@ -180,19 +155,6 @@ jobs:
               --message 'docs(dev): ibis@${{ github.sha }}' \
                 dev
 
-      - name: build and push docs on tag
-        if: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/tags/') }}
-        run: |
-          set -euo pipefail
-
-          nix develop -f shell.nix --keep-going -c \
-            mic deploy \
-              --push \
-              --rebase \
-              --prefix docs \
-              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
-              ""${GITHUB_REF_NAME}"" latest
-
   simulate_release:
     runs-on: ubuntu-latest
     steps:
diff --git a/.github/workflows/ibis-docs-release.yml b/.github/workflows/ibis-docs-release.yml
new file mode 100644
index 0000000..da7ee49
--- /dev/null
+++ b/.github/workflows/ibis-docs-release.yml
@@ -0,0 +1,63 @@
+# vim: filetype=yaml
+name: Docs Release Build
+
+on:
+  release:
+    types:
+      - published
+jobs:
+  docs:
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
+    runs-on: ubuntu-latest
+    steps:
+      - name: install nix
+        uses: cachix/install-nix-action@v17
+        with:
+          nix_path: nixpkgs=channel:nixos-unstable-small
+
+      - name: setup cachix
+        uses: cachix/cachix-action@v10
+        with:
+          name: ibis
+          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
+          extraPullNames: nix-community,poetry2nix
+
+      - name: Generate a GitHub token
+        uses: tibdex/github-app-token@v1
+        id: generate_token
+        with:
+          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
+          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
+
+      - name: checkout
+        uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+          token: ${{ steps.generate_token.outputs.token }}
+
+      - name: Configure git info
+        run: |
+          set -euo pipefail
+
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
+
+      - name: Pull gh-pages changes
+        run: |
+          set -euo pipefail
+
+          git fetch origin gh-pages
+          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+
+      - name: build and push docs on tag
+        run: |
+          set -euo pipefail
+
+          nix develop -f shell.nix --keep-going -c \
+            mic deploy \
+              --push \
+              --rebase \
+              --update-aliases \
+              --prefix docs \
+              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
+              ""${GITHUB_REF_NAME}"" latest
",4,"[""317f4eefecddfb1392ca71d551840f446feee302"", ""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""f00a4d3e307b89842250358ee432e6800bb24362"", ""32845e1bbd1efb5dbc16f671049509a409ba25ce""]","[""test"", ""docs"", ""build"", ""cicd""]"
update flushed index before truncatingrestructure ClusterTopology to track completed changelicensingsetup jest and add m.ts tests,"diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });
",4,"[""933ab6bb86372913c992567cf9660009900911a7"", ""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2"", ""a52a585d74894b3b4eeb8c784fa089ff95cddad0"", ""229b53a632ea97d47c4be11f096bdd828fb415d8""]","[""fix"", ""refactor"", ""docs"", ""test""]"
"add fallible peek_last_token()publish sdks after docs/buildlicensingspring version, core version","diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;

diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 
",4,"[""63eab619e6166eb6cab948028a7b89bf059dd878"", ""6c9cb638cb4d1ecc42632fcf389c24898c5b3244"", ""a52a585d74894b3b4eeb8c784fa089ff95cddad0"", ""c55591ba157298a9c5816693c102a89dfd058830""]","[""refactor"", ""cicd"", ""docs"", ""build""]"
"add riscv64gc-unknown-linux-gnuspring version, core versionadd testsrepository creation","diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }

diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 

diff --git a/Cargo.lock b/Cargo.lock
index 84d5d07..6ad05da 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -293,6 +293,7 @@ version = ""0.1.0""
 dependencies = [
  ""git-cliff-core"",
  ""log"",
+ ""pretty_assertions"",
  ""pretty_env_logger"",
  ""structopt"",
 ]
diff --git a/git-cliff-core/src/lib.rs b/git-cliff-core/src/lib.rs
index 3b18ba0..a560c94 100644
--- a/git-cliff-core/src/lib.rs
+++ b/git-cliff-core/src/lib.rs
@@ -1,6 +1,8 @@
 //! Highly customizable Changelog Generator
 #![warn(missing_docs, clippy::unwrap_used)]
 
+/// Export regex crate.
+pub use regex;
 /// Git commit.
 pub mod commit;
 /// Config file parser.
diff --git a/git-cliff/Cargo.toml b/git-cliff/Cargo.toml
index 41eb2e9..cc64b37 100644
--- a/git-cliff/Cargo.toml
+++ b/git-cliff/Cargo.toml
@@ -20,3 +20,6 @@ log = ""0.4.14""
 version = ""0.3""
 default-features = false
 features = [""suggestions"", ""color"", ""wrap_help""]
+
+[dev-dependencies]
+pretty_assertions = ""0.7""
diff --git a/git-cliff/src/changelog.rs b/git-cliff/src/changelog.rs
index 3f9e994..23ea186 100644
--- a/git-cliff/src/changelog.rs
+++ b/git-cliff/src/changelog.rs
@@ -115,3 +115,171 @@ impl<'a> Changelog<'a> {
 		Ok(())
 	}
 }
+
+#[cfg(test)]
+mod test {
+	use super::*;
+	use git_cliff_core::config::{
+		ChangelogConfig,
+		CommitParser,
+		GitConfig,
+	};
+	use git_cliff_core::regex::Regex;
+	use pretty_assertions::assert_eq;
+	use std::str;
+	#[test]
+	fn changelog_generator() -> Result<()> {
+		let config = Config {
+			changelog: ChangelogConfig {
+				header: Some(String::from(""# Changelog"")),
+				body:   String::from(
+					r#""{% if version %}
+				## Release [{{ version }}] - {{ timestamp | date(format=""%Y-%m-%d"") }}
+				({{ commit_id }}){% else %}
+				## Unreleased{% endif %}
+				{% for group, commits in commits | group_by(attribute=""group"") %}
+				### {{ group }}{% for group, commits in commits | group_by(attribute=""scope"") %}
+				#### {{ group }}{% for commit in commits %}
+				- {{ commit.message }}{% endfor %}
+				{% endfor %}{% endfor %}""#,
+				)
+				.replace(""				"", """"),
+				footer: Some(String::from(""------------"")),
+			},
+			git:       GitConfig {
+				conventional_commits: true,
+				commit_parsers:       Some(vec![
+					CommitParser {
+						message: Regex::new(""feat*"").ok(),
+						body:    None,
+						group:   Some(String::from(""New features"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new(""fix*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Bug Fixes"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new("".*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Other"")),
+						skip:    None,
+					},
+				]),
+				filter_commits:       Some(false),
+				tag_pattern:          String::new(),
+				skip_tags:            Regex::new(""v3.*"").ok(),
+			},
+		};
+		let test_release = Release {
+			version:   Some(String::from(""v1.0.0"")),
+			commits:   vec![
+				Commit::new(
+					String::from(""0bc123""),
+					String::from(""feat(app): add cool features""),
+				),
+				Commit::new(
+					String::from(""0werty""),
+					String::from(""style(ui): make good stuff""),
+				),
+				Commit::new(
+					String::from(""0w3rty""),
+					String::from(""fix(ui): fix more stuff""),
+				),
+				Commit::new(
+					String::from(""0jkl12""),
+					String::from(""chore(app): do nothing""),
+				),
+			],
+			commit_id: Some(String::from(""0bc123"")),
+			timestamp: 50000000,
+			previous:  None,
+		};
+		let releases = vec![
+			test_release.clone(),
+			Release {
+				version: Some(String::from(""v3.0.0"")),
+				commits: vec![Commit::new(
+					String::from(""n0thin""),
+					String::from(""feat(xyz): skip commit""),
+				)],
+				..Release::default()
+			},
+			Release {
+				version:   None,
+				commits:   vec![
+					Commit::new(
+						String::from(""abc123""),
+						String::from(""feat(app): add xyz""),
+					),
+					Commit::new(
+						String::from(""abc124""),
+						String::from(""docs(app): document zyx""),
+					),
+					Commit::new(String::from(""def789""), String::from(""merge #4"")),
+					Commit::new(
+						String::from(""qwerty""),
+						String::from(""fix(app): fix abc""),
+					),
+					Commit::new(
+						String::from(""hjkl12""),
+						String::from(""chore(ui): do boring stuff""),
+					),
+				],
+				commit_id: None,
+				timestamp: 1000,
+				previous:  Some(Box::new(test_release)),
+			},
+		];
+		let changelog = Changelog::new(releases, &config)?;
+		let mut out = Vec::new();
+		changelog.generate(&mut out)?;
+		assert_eq!(
+			String::from(
+				r#""# Changelog
+
+			## Unreleased
+
+			### Bug Fixes
+			#### app
+			- fix abc
+
+			### New features
+			#### app
+			- add xyz
+
+			### Other
+			#### app
+			- document zyx
+
+			#### ui
+			- do boring stuff
+
+			## Release [v1.0.0] - 1971-08-02
+			(0bc123)
+
+			### Bug Fixes
+			#### ui
+			- fix more stuff
+
+			### New features
+			#### app
+			- add cool features
+
+			### Other
+			#### app
+			- do nothing
+
+			#### ui
+			- make good stuff
+			------------
+			""#
+			)
+			.replace(""			"", """"),
+			str::from_utf8(&out).unwrap()
+		);
+		Ok(())
+	}
+}

diff --git a/server/src/services/repository.service.ts b/server/src/services/repository.service.ts
index 3869c98..d675b30 100644
--- a/server/src/services/repository.service.ts
+++ b/server/src/services/repository.service.ts
@@ -19,6 +19,8 @@ export class RepositoryService {
       return;
     }
 
+    await this.createTeam(this.github, this.getTeamName(course), course.id);
+
     const studentRepo = getCustomRepository(StudentRepository);
     const students = await studentRepo.findActiveByCourseId(this.courseId);
 
@@ -31,8 +33,8 @@ export class RepositoryService {
         if (mentorGithubId) {
           await this.inviteMentor(mentorGithubId, course);
         }
-        await this.addTeamToRepository(this.github, course, student.githubId);
       }
+      await this.addTeamToRepository(this.github, course, student.githubId);
       if (record?.repository) {
         result.push({ repository: record.repository });
       }
",4,"[""173553c0372e66e03bdab19e0e6c2dd44daa14a0"", ""c55591ba157298a9c5816693c102a89dfd058830"", ""8ee0611fbf0cd89abe7ae588f22e6ecb843598ea"", ""87d5d4e55ab7149b593d29410f1fe426ba2447d4""]","[""cicd"", ""build"", ""test"", ""fix""]"
"split release docs build into separate workflowupdated react demo parcel commandenable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>update flushed index before truncating","diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 753d57d..3e0aa15 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -88,14 +88,14 @@ jobs:
         run: poetry run pytest --benchmark-only --benchmark-json .benchmarks/output.json ibis/tests/benchmarks
 
       - uses: tibdex/github-app-token@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         id: generate-token
         with:
           app_id: ${{ secrets.SQUAWK_BOT_APP_ID }}
           private_key: ${{ secrets.SQUAWK_BOT_APP_PRIVATE_KEY }}
 
       - uses: benchmark-action/github-action-benchmark@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         with:
           tool: pytest
           github-token: ${{ steps.generate-token.outputs.token }}
@@ -107,6 +107,7 @@ jobs:
 
   docs:
     runs-on: ubuntu-latest
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
     needs:
       # wait on benchmarks to prevent a race condition when pushing to the
       # gh-pages branch
@@ -124,51 +125,25 @@ jobs:
           authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
           extraPullNames: nix-community,poetry2nix
 
-      - name: Generate a GitHub token
-        if: ${{ github.event_name == 'push' }}
-        uses: tibdex/github-app-token@v1
-        id: generate_token
-        with:
-          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
-          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
-
-      - name: checkout
-        if: ${{ github.event_name == 'push' }}
-        uses: actions/checkout@v3
-        with:
-          fetch-depth: 0
-          token: ${{ steps.generate_token.outputs.token }}
-
       - name: checkout
-        if: ${{ github.event_name != 'push' }}
         uses: actions/checkout@v3
 
-      - name: Configure git info
-        if: ${{ github.event_name == 'push' }}
-        run: |
-          set -euo pipefail
-
-          git config user.name 'ibis-docs-bot[bot]'
-          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
-
       - name: build docs
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c mkdocs build
 
       - name: verify internal links
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c just checklinks --offline --no-progress
 
-      - name: Pull gh-pages changes
+      - name: Configure git info
         if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
-          git fetch origin gh-pages
-          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
 
       - name: build and push dev docs
-        if: ${{ github.event_name == 'push' && !startsWith(github.ref, 'refs/tags/') }}
+        if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
@@ -180,19 +155,6 @@ jobs:
               --message 'docs(dev): ibis@${{ github.sha }}' \
                 dev
 
-      - name: build and push docs on tag
-        if: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/tags/') }}
-        run: |
-          set -euo pipefail
-
-          nix develop -f shell.nix --keep-going -c \
-            mic deploy \
-              --push \
-              --rebase \
-              --prefix docs \
-              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
-              ""${GITHUB_REF_NAME}"" latest
-
   simulate_release:
     runs-on: ubuntu-latest
     steps:
diff --git a/.github/workflows/ibis-docs-release.yml b/.github/workflows/ibis-docs-release.yml
new file mode 100644
index 0000000..da7ee49
--- /dev/null
+++ b/.github/workflows/ibis-docs-release.yml
@@ -0,0 +1,63 @@
+# vim: filetype=yaml
+name: Docs Release Build
+
+on:
+  release:
+    types:
+      - published
+jobs:
+  docs:
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
+    runs-on: ubuntu-latest
+    steps:
+      - name: install nix
+        uses: cachix/install-nix-action@v17
+        with:
+          nix_path: nixpkgs=channel:nixos-unstable-small
+
+      - name: setup cachix
+        uses: cachix/cachix-action@v10
+        with:
+          name: ibis
+          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
+          extraPullNames: nix-community,poetry2nix
+
+      - name: Generate a GitHub token
+        uses: tibdex/github-app-token@v1
+        id: generate_token
+        with:
+          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
+          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
+
+      - name: checkout
+        uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+          token: ${{ steps.generate_token.outputs.token }}
+
+      - name: Configure git info
+        run: |
+          set -euo pipefail
+
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
+
+      - name: Pull gh-pages changes
+        run: |
+          set -euo pipefail
+
+          git fetch origin gh-pages
+          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+
+      - name: build and push docs on tag
+        run: |
+          set -euo pipefail
+
+          nix develop -f shell.nix --keep-going -c \
+            mic deploy \
+              --push \
+              --rebase \
+              --update-aliases \
+              --prefix docs \
+              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
+              ""${GITHUB_REF_NAME}"" latest

diff --git a/demo/react/package.json b/demo/react/package.json
index be28bf9..32d0952 100644
--- a/demo/react/package.json
+++ b/demo/react/package.json
@@ -12,7 +12,7 @@
   },
   ""scripts"": {
     ""start"": ""parcel serve public/index.html --no-cache --open"",
-    ""build"": ""parcel build -t browser -d dist public/index.html --no-source-maps""
+    ""build"": ""parcel build --target browser --dist-dir dist public/index.html --no-source-maps""
   },
   ""bugs"": {
     ""url"": ""https://github.com/matteobruni/tsparticles/issues""

diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 

diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {
",4,"[""32845e1bbd1efb5dbc16f671049509a409ba25ce"", ""32b92cfa0b74a6c25990e32ac6aab12b8496794c"", ""fd8e563cc19ca4684885d4692acee6bebcca4ada"", ""933ab6bb86372913c992567cf9660009900911a7""]","[""cicd"", ""build"", ""feat"", ""fix""]"
"update wrapping tests for v7upgrade to Flux v0.42.0

Skips a test that requires special dependencies to pass.update flushed index before truncatingbuffer assert and bpmn model api helper class

related to camunda-tngp/camunda-tngp#23","diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });

diff --git a/go.mod b/go.mod
index ea705da..8c352f7 100644
--- a/go.mod
+++ b/go.mod
@@ -38,7 +38,7 @@ require (
 	github.com/hashicorp/go-msgpack v0.0.0-20150518234257-fa3f63826f7c // indirect
 	github.com/hashicorp/raft v1.0.0 // indirect
 	github.com/hashicorp/vault/api v1.0.2
-	github.com/influxdata/flux v0.41.0
+	github.com/influxdata/flux v0.42.0
 	github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6
 	github.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368
 	github.com/jessevdk/go-flags v1.4.0
diff --git a/go.sum b/go.sum
index 4bfdf4c..634a0f1 100644
--- a/go.sum
+++ b/go.sum
@@ -206,8 +206,8 @@ github.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NH
 github.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=
 github.com/influxdata/changelog v1.0.0 h1:RstJD6H48zLQj0GdE6E6k/6RPwtUjkyzIe/T1E/xuWU=
 github.com/influxdata/changelog v1.0.0/go.mod h1:uzpGWE/qehT8L426YuXwpMQub+a63vIINhIeEI9mnSM=
-github.com/influxdata/flux v0.41.0 h1:ljbWJmE+aNx8Yoqhb04gWC4sXMV87eYUxz5vjYphLLs=
-github.com/influxdata/flux v0.41.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
+github.com/influxdata/flux v0.42.0 h1:2iEG6hLHdHEJ6LgD8OSnlHS9yoVrLO1/aM4P9ERb94U=
+github.com/influxdata/flux v0.42.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
 github.com/influxdata/goreleaser v0.97.0-influx h1:jT5OrcW7WfS0e2QxfwmTBjhLvpIC9CDLRhNgZJyhj8s=
 github.com/influxdata/goreleaser v0.97.0-influx/go.mod h1:MnjA0e0Uq6ISqjG1WxxMAl+3VS1QYjILSWVnMYDxasE=
 github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6 h1:CFx+pP90q/qg3spoiZjf8donE4WpAdjeJfPOcoNqkWo=
diff --git a/query/stdlib/testing/testing.go b/query/stdlib/testing/testing.go
index d41574a..85b0673 100644
--- a/query/stdlib/testing/testing.go
+++ b/query/stdlib/testing/testing.go
@@ -98,4 +98,6 @@ var FluxEndToEndSkipList = map[string]string{
 	""http_endpoint"": ""need ability to test side effects in e2e tests: (https://github.com/influxdata/flux/issues/1723)"",
 
 	""holt_winters_panic"": ""Expected output is an empty table which breaks the testing framework (https://github.com/influxdata/influxdb/issues/14749)"",
+
+	""secrets"": ""Cannot inject custom deps into the test framework so the secrets don't lookup correctly"",
 }

diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/test-util/pom.xml b/test-util/pom.xml
index a097651..b6518ee 100644
--- a/test-util/pom.xml
+++ b/test-util/pom.xml
@@ -20,6 +20,7 @@
     <project.build.sourceEncoding>utf-8</project.build.sourceEncoding>
     <!-- TODO: Move to common parent -->
     <agrona.version>0.4.11</agrona.version>
+    <camunda.version>7.6.0-SNAPSHOT</camunda.version>
   </properties>
 
   <dependencies>
@@ -30,6 +31,13 @@
       <version>${agrona.version}</version>
       <scope>provided</scope>
     </dependency>
+    
+    <dependency>
+      <groupId>org.camunda.bpm.model</groupId>
+      <artifactId>camunda-bpmn-model</artifactId>
+      <version>${camunda.version}</version>
+      <scope>provided</scope>
+    </dependency>
 
     <dependency>
       <groupId>junit</groupId>
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
index 37e3a6f..b8d9b26 100644
--- a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
@@ -14,7 +14,7 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         super(actual, BufferAssert.class);
     }
 
-    public static BufferAssert assertThat(DirectBuffer buffer)
+    public static BufferAssert assertThatBuffer(DirectBuffer buffer)
     {
         return new BufferAssert(buffer);
     }
@@ -41,4 +41,16 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         return hasBytes(expected, 0);
     }
 
+    public BufferAssert hasCapacity(int expectedCapacity)
+    {
+        isNotNull();
+
+        if (expectedCapacity != actual.capacity())
+        {
+            failWithMessage(""Expected capacity "" + expectedCapacity + "" but was "" + actual.capacity());
+        }
+
+        return this;
+    }
+
 }
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
new file mode 100644
index 0000000..6f0d134
--- /dev/null
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
@@ -0,0 +1,121 @@
+package org.camunda.tngp.broker.test.util.bpmn;
+
+import java.util.Collection;
+
+import org.camunda.bpm.model.bpmn.BpmnModelInstance;
+import org.camunda.bpm.model.bpmn.impl.BpmnModelConstants;
+import org.camunda.bpm.model.bpmn.instance.Definitions;
+import org.camunda.bpm.model.xml.Model;
+import org.camunda.bpm.model.xml.instance.DomDocument;
+import org.camunda.bpm.model.xml.instance.ModelElementInstance;
+import org.camunda.bpm.model.xml.type.ModelElementType;
+import org.camunda.bpm.model.xml.validation.ModelElementValidator;
+import org.camunda.bpm.model.xml.validation.ValidationResults;
+
+public class TngpModelInstance implements BpmnModelInstance
+{
+    protected BpmnModelInstance wrappedInstance;
+
+    public TngpModelInstance(BpmnModelInstance wrappedInstance)
+    {
+        this.wrappedInstance = wrappedInstance;
+    }
+
+    @Override
+    public DomDocument getDocument()
+    {
+        return wrappedInstance.getDocument();
+    }
+
+    @Override
+    public ModelElementInstance getDocumentElement()
+    {
+        return wrappedInstance.getDocumentElement();
+    }
+
+    @Override
+    public void setDocumentElement(ModelElementInstance documentElement)
+    {
+        wrappedInstance.setDocumentElement(documentElement);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(Class<T> type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(ModelElementType type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public Model getModel()
+    {
+        return wrappedInstance.getModel();
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T getModelElementById(String id)
+    {
+        return wrappedInstance.getModelElementById(id);
+    }
+
+    @Override
+    public Collection<ModelElementInstance> getModelElementsByType(ModelElementType referencingType)
+    {
+        return wrappedInstance.getModelElementsByType(referencingType);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> Collection<T> getModelElementsByType(Class<T> referencingClass)
+    {
+        return wrappedInstance.getModelElementsByType(referencingClass);
+    }
+
+    @Override
+    public ValidationResults validate(Collection<ModelElementValidator<?>> validators)
+    {
+        return wrappedInstance.validate(validators);
+    }
+
+    @Override
+    public BpmnModelInstance clone()
+    {
+        return wrappedInstance.clone();
+    }
+
+    @Override
+    public Definitions getDefinitions()
+    {
+        return wrappedInstance.getDefinitions();
+    }
+
+    @Override
+    public void setDefinitions(Definitions arg0)
+    {
+        wrappedInstance.setDefinitions(arg0);
+    }
+
+    public TngpModelInstance taskAttributes(String taskId, String taskType, int taskQueueId)
+    {
+        final ModelElementInstance task = wrappedInstance.getModelElementById(taskId);
+
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskType"", taskType);
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskQueueId"", String.valueOf(taskQueueId));
+
+        return this;
+    }
+
+    public static TngpModelInstance wrap(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance);
+    }
+
+    public static TngpModelInstance wrapCopy(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance.clone());
+    }
+}
",4,"[""317f4eefecddfb1392ca71d551840f446feee302"", ""454003841aabeb74396d73541378bfa59c75b5db"", ""933ab6bb86372913c992567cf9660009900911a7"", ""6ed56ce9ae743ba9a87e6c9643cc06b1de7b748d""]","[""test"", ""build"", ""fix"", ""feat""]"
"wrong icon reference

Signed-off-by: Pranav C <pranavxc@gmail.com>add .nullif() exampleverify checkpoint listeners are notifiedcleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.","diff --git a/packages/nc-gui/components.d.ts b/packages/nc-gui/components.d.ts
index b7e6585..bb86478 100644
--- a/packages/nc-gui/components.d.ts
+++ b/packages/nc-gui/components.d.ts
@@ -81,7 +81,6 @@ declare module '@vue/runtime-core' {
     ClaritySuccessLine: typeof import('~icons/clarity/success-line')['default']
     EvaEmailOutline: typeof import('~icons/eva/email-outline')['default']
     IcBaselineMoreVert: typeof import('~icons/ic/baseline-more-vert')['default']
-    Icon: typeof import('~icons/ic/on')['default']
     IcOutlineInsertDriveFile: typeof import('~icons/ic/outline-insert-drive-file')['default']
     IcRoundEdit: typeof import('~icons/ic/round-edit')['default']
     IcRoundKeyboardArrowDown: typeof import('~icons/ic/round-keyboard-arrow-down')['default']

diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 

diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }

diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:
",4,"[""d1d55e787b7d07f763852602b9939a5394607fd9"", ""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21"", ""e0198f74b81da3663144cfe1d971939319f82a0f"", ""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7""]","[""fix"", ""docs"", ""test"", ""refactor""]"
"increment failing test retriesadd .nullif() example[gn] fix include_dirs ordering erroradd numberOfLines prop to DataTableTitle (#863)

Closes #848","diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 

diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 

diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)

diff --git a/src/components/DataTable/DataTableTitle.js b/src/components/DataTable/DataTableTitle.js
index bfcf07e..d764fd5 100644
--- a/src/components/DataTable/DataTableTitle.js
+++ b/src/components/DataTable/DataTableTitle.js
@@ -27,6 +27,10 @@ type Props = React.ElementConfig<typeof TouchableWithoutFeedback> & {|
    */
   sortDirection?: 'ascending' | 'descending',
   /**
+   * The number of lines to show.
+   */
+  numberOfLines?: number,
+  /**
    * Function to execute on press.
    */
   onPress?: () => mixed,
@@ -44,6 +48,10 @@ type State = {
 class DataTableTitle extends React.Component<Props, State> {
   static displayName = 'DataTable.Title';
 
+  static defaultProps = {
+    numberOfLines: 1,
+  };
+
   state = {
     spinAnim: new Animated.Value(
       this.props.sortDirection === 'ascending' ? 0 : 1
@@ -70,6 +78,7 @@ class DataTableTitle extends React.Component<Props, State> {
       sortDirection,
       theme,
       style,
+      numberOfLines,
       ...rest
     } = this.props;
 
@@ -99,7 +108,7 @@ class DataTableTitle extends React.Component<Props, State> {
               styles.cell,
               sortDirection ? styles.sorted : { color: textColor },
             ]}
-            numberOfLines={1}
+            numberOfLines={numberOfLines}
           >
             {children}
           </Text>
",4,"[""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57"", ""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21"", ""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945"", ""f9a094918b62534614c47aa8a13f33aec751a1e0""]","[""cicd"", ""docs"", ""build"", ""feat""]"
"initialize threejs objects in defaultRef, to fix undefined type errorsverify checkpoint listeners are notifiedterminated tasks linger for a bit

Signed-off-by: Eliza Weisman <eliza@buoyant.io>add .nullif() example","diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number

diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }

diff --git a/console/src/main.rs b/console/src/main.rs
index ebfa315..5328d96 100644
--- a/console/src/main.rs
+++ b/console/src/main.rs
@@ -69,6 +69,7 @@ async fn main() -> Result<(), Box<dyn std::error::Error>> {
                 .wrap(Wrap { trim: true });
             f.render_widget(header, chunks[0]);
             tasks.render(f, chunks[1]);
+            tasks.retain_active();
         })?;
     }
 
diff --git a/console/src/tasks.rs b/console/src/tasks.rs
index 7be39a4..eb41495 100644
--- a/console/src/tasks.rs
+++ b/console/src/tasks.rs
@@ -19,6 +19,7 @@ struct Task {
     fields: String,
     kind: &'static str,
     stats: Stats,
+    completed_for: usize,
 }
 
 #[derive(Default, Debug)]
@@ -28,10 +29,15 @@ struct Stats {
     idle: Duration,
     total: Duration,
 }
+
 impl State {
+    // How many updates to retain completed tasks for
+    const RETAIN_COMPLETED_FOR: usize = 6;
+
     pub(crate) fn len(&self) -> usize {
         self.tasks.len()
     }
+
     pub(crate) fn update(&mut self, update: proto::tasks::TaskUpdate) {
         let new_tasks = update.new_tasks.into_iter().filter_map(|task| {
             if task.id.is_none() {
@@ -48,6 +54,7 @@ impl State {
                 fields: task.string_fields,
                 kind,
                 stats: Default::default(),
+                completed_for: 0,
             };
             Some((id, task))
         });
@@ -60,7 +67,10 @@ impl State {
         }
 
         for proto::SpanId { id } in update.completed {
-            if self.tasks.remove(&id).is_none() {
+            if let Some(task) = self.tasks.get_mut(&id) {
+                task.kind = ""!"";
+                task.completed_for = 1;
+            } else {
                 tracing::warn!(?id, ""tried to complete a task that didn't exist"");
             }
         }
@@ -79,7 +89,7 @@ impl State {
         const DUR_PRECISION: usize = 4;
         const POLLS_LEN: usize = 5;
         let rows = self.tasks.values().map(|task| {
-            let row = Row::new(vec![
+            let mut row = Row::new(vec![
                 Cell::from(task.id_hex.as_str()),
                 // TODO(eliza): is there a way to write a `fmt::Debug` impl
                 // directly to tui without doing an allocation?
@@ -105,6 +115,9 @@ impl State {
                 Cell::from(format!(""{:>width$}"", task.stats.polls, width = POLLS_LEN)),
                 Cell::from(task.fields.as_str()),
             ]);
+            if task.completed_for > 0 {
+                row = row.style(Style::default().add_modifier(style::Modifier::DIM));
+            }
             row
         });
         let t = Table::new(rows)
@@ -126,6 +139,16 @@ impl State {
 
         frame.render_widget(t, area)
     }
+
+    pub(crate) fn retain_active(&mut self) {
+        self.tasks.retain(|_, task| {
+            if task.completed_for == 0 {
+                return true;
+            }
+            task.completed_for += 1;
+            task.completed_for <= Self::RETAIN_COMPLETED_FOR
+        })
+    }
 }
 
 impl From<proto::tasks::Stats> for Stats {

diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 
",4,"[""2561f4ade46fc9d59f289f328cc77733a6443697"", ""e0198f74b81da3663144cfe1d971939319f82a0f"", ""1bcf88670b50155b50071e707f98f30cea0b7a24"", ""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21""]","[""fix"", ""test"", ""feat"", ""docs""]"
run pyspark tests in parallelupdate flushed index before truncatingensure checksum persist flushes to diskadd spacing in comment fix lint (#8555),"diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index e23088e..9708157 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -202,11 +202,11 @@ jobs:
         run: poetry install --without dev --without docs --extras ${{ matrix.backend.name }} --extras geospatial
 
       - name: ""run parallel tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name != 'pyspark' && matrix.backend.name != 'impala'
+        if: matrix.backend.name != 'impala'
         run: just ci-check -m ${{ matrix.backend.name }} --numprocesses auto --dist=loadgroup
 
       - name: ""run serial tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name == 'pyspark' || matrix.backend.name == 'impala'
+        if: matrix.backend.name == 'impala'
         run: just ci-check -m ${{ matrix.backend.name }}
         env:
           IBIS_TEST_NN_HOST: localhost

diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);

diff --git a/src/components/nav/test/basic/app-module.ts b/src/components/nav/test/basic/app-module.ts
index 467917a..375e662 100644
--- a/src/components/nav/test/basic/app-module.ts
+++ b/src/components/nav/test/basic/app-module.ts
@@ -633,7 +633,7 @@ export class Tab3 {
   }
 
   presentModal() {
-    //this.modalCtrl.create(MyModal).present();
+    // this.modalCtrl.create(MyModal).present();
   }
 
   selectPrevious() {
",4,"[""4cbbd2552ba0de273e1dfe7d453c5b3efed751a3"", ""933ab6bb86372913c992567cf9660009900911a7"", ""b7ce2894fd1794064bd6db4ed730bb6cb7728739"", ""af880ac5b4fecbc6c4f3d1eee0d95f326e8bd9d1""]","[""cicd"", ""fix"", ""test"", ""docs""]"
"Add ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>do not use scripts and binaries from the libcc repocleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.autostart feature fixed","diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();
",4,"[""f823cf28652987d43c8324b4f5b203240032383a"", ""45837af24a33308a70a3454f0f650f9fe728e272"", ""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7"", ""bed78248c941d57ad4cc20a455147e186e97c7a1""]","[""feat"", ""cicd"", ""refactor"", ""fix""]"
"add fallible peek_last_token()support use meta key select multiple elementlicensingfix netty dependency

netty-bom 4.1.70 contains the changes from pull request
https://github.com/netty/netty/pull/11798, which moved the classes out
of the native modules to make sure the same classes don't end up on the
classpath multiple times. For us it means that we need to depend on both
the native and classes modules. However, since we don't use the native
module directly (only classes that were moved to this classes module),
we need to force the dependency plugin to consider the native module as
used.","diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.

diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index ab68624..aeee7b7 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -277,9 +277,11 @@ export default class LogicFlow {
   }
   /**
    * 将图形选中
+   * @param id 选择元素ID
+   * @param multiple 是否允许多选，如果为true，不会将上一个选中的元素重置
    */
-  select(id: string) {
-    this.graphModel.selectElementById(id);
+  select(id: string, multiple = false) {
+    this.graphModel.selectElementById(id, multiple);
   }
   /**
    * 将图形定位到画布中心
diff --git a/packages/core/src/model/EditConfigModel.ts b/packages/core/src/model/EditConfigModel.ts
index 67e334a..83e5f16 100644
--- a/packages/core/src/model/EditConfigModel.ts
+++ b/packages/core/src/model/EditConfigModel.ts
@@ -25,6 +25,7 @@ const SilentConfig = {
   edgeTextEdit: false,
   nodeTextDraggable: false,
   edgeTextDraggable: false,
+  metaKeyMultipleSelected: false,
 };
 
 /**
@@ -42,6 +43,7 @@ export default class EditConfigModel {
   @observable edgeTextEdit = true; // 允许连线文本可以编辑
   @observable nodeTextDraggable = false; // 允许节点文本可以拖拽
   @observable edgeTextDraggable = false; // 允许连线文本可以拖拽
+  @observable metaKeyMultipleSelected = false; // 允许meta多选元素
   constructor(data) {
     const keys = [
       'stopZoomGraph',
@@ -55,6 +57,7 @@ export default class EditConfigModel {
       'edgeTextEdit',
       'nodeTextDraggable',
       'edgeTextDraggable',
+      'metaKeyMultipleSelected',
     ];
     const { isSilentMode, textEdit } = data;
     if (isSilentMode) {
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 9667f4d..310daf4 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -34,6 +34,7 @@ class GraphModel {
   height: number;
   topElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
   selectElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
+  selectElements = new Map<string, IBaseModel>(); // 多选
   @observable edgeType: string;
   @observable nodes: BaseNodeModel[] = [];
   @observable activeElement: IBaseModel;
@@ -50,7 +51,6 @@ class GraphModel {
   @observable gridSize = 1;
   @observable partial = false; // 是否开启局部渲染
   @observable fakerNode: BaseNodeModel;
-  // @observable selectElements = new Map<string, IBaseModel>(); // 多选还没有做，先不加
   constructor(config) {
     const {
       container,
@@ -456,24 +456,44 @@ class GraphModel {
   }
 
   @action
-  selectNodeById(id) {
-    this.selectElement?.setSelected(false);
+  selectNodeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.nodesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectEdgeById(id) {
-    this.selectElement?.setSelected(false);
+  selectEdgeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.edgesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectElementById(id: string) {
-    this.selectElement?.setSelected(false);
+  selectElementById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
+  }
+
+  @action
+  clearSelectElements() {
+    this.selectElements.forEach(element => {
+      element.setSelected(false);
+    });
+    this.selectElements.clear();
   }
 
   /* 修改连线类型 */
diff --git a/packages/core/src/view/edge/BaseEdge.tsx b/packages/core/src/view/edge/BaseEdge.tsx
index d45ea9e..d7c8f38 100644
--- a/packages/core/src/view/edge/BaseEdge.tsx
+++ b/packages/core/src/view/edge/BaseEdge.tsx
@@ -178,7 +178,8 @@ export default class BaseEdge extends Component<IProps> {
   handleClick = (e) => {
     const { model, graphModel, eventCenter } = this.props;
     graphModel.toFront(model.id);
-    graphModel.selectEdgeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectEdgeById(model.id, e.metaKey && metaKeyMultipleSelected);
     // 边数据
     const edgeData = model?.getData();
     const position = graphModel.getPointByClient({
diff --git a/packages/core/src/view/node/BaseNode.tsx b/packages/core/src/view/node/BaseNode.tsx
index 140889c..5ee3975 100644
--- a/packages/core/src/view/node/BaseNode.tsx
+++ b/packages/core/src/view/node/BaseNode.tsx
@@ -275,7 +275,8 @@ export default abstract class BaseNode extends Component<IProps, Istate> {
       }, 400);
     }
     graphModel.toFront(model.id);
-    graphModel.selectNodeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectNodeById(model.id, e.metaKey && metaKeyMultipleSelected);
     this.preStartTime = this.startTime;
   };
   handleContextMenu = (ev: MouseEvent) => {
diff --git a/packages/core/src/view/overlay/CanvasOverlay.tsx b/packages/core/src/view/overlay/CanvasOverlay.tsx
index ef11822..8c79fd2 100644
--- a/packages/core/src/view/overlay/CanvasOverlay.tsx
+++ b/packages/core/src/view/overlay/CanvasOverlay.tsx
@@ -104,9 +104,9 @@ class CanvasOverlay extends Component<IProps, Istate> {
     const target = ev.target as HTMLElement;
     if (target.getAttribute('name') === 'canvas-overlay') {
       const { graphModel, eventCenter } = this.props;
-      const { selectElement, textEditElement } = graphModel;
-      if (selectElement) {
-        selectElement.setSelected(false);
+      const { textEditElement, selectElements } = graphModel;
+      if (selectElements.size > 0) {
+        graphModel.clearSelectElements();
       }
       if (textEditElement) {
         textEditElement.setElementState(ElementState.DEFAULT);
diff --git a/packages/extension/examples/bpmn/index.html b/packages/extension/examples/bpmn/index.html
index 7a68d6f..f7ea87d 100644
--- a/packages/extension/examples/bpmn/index.html
+++ b/packages/extension/examples/bpmn/index.html
@@ -6,6 +6,7 @@
   <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
   <title>LOGIN FLOW</title>
   <link rel=""stylesheet"" href=""/core/dist/style/index.css"">
+  <link rel=""stylesheet"" href=""/extension/lib/style/index.css"">
   <style>
     html,body {
       padding: 0;
@@ -129,11 +130,14 @@
     </div>
   </div>
   <script src=""/core/dist/logic-flow.js""></script>
+  <!-- <script src=""http://0.0.0.0:9090/logic-flow.js""></script> -->
   <script src=""/BpmnElement.js""></script>
   <script src=""/BpmnAdapter.js""></script>
+  <script src=""/Control.js""></script>
   <script src=""/Snapshot.js""></script>
   <script>
     LogicFlow.use(BpmnElement);
+    LogicFlow.use(Control);
     LogicFlow.use(BpmnAdapter);
     LogicFlow.use(Snapshot);
   </script>
diff --git a/packages/extension/examples/bpmn/index.js b/packages/extension/examples/bpmn/index.js
index 21d2da0..6f6aa39 100644
--- a/packages/extension/examples/bpmn/index.js
+++ b/packages/extension/examples/bpmn/index.js
@@ -3,6 +3,10 @@ window.onload = function () {
     container: document.querySelector('#app'),
     // fixme: grid成为了必传的了
     edgeTextDraggable: true,
+    metaKeyMultipleSelected: true,
+    // stopScrollGraph: true,
+    // stopMoveGraph: true,
+    // stopZoomGraph: true,
     grid: {
       type: 'dot',
       size: 20,

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;

diff --git a/atomix/cluster/pom.xml b/atomix/cluster/pom.xml
index a477873..b6db695 100644
--- a/atomix/cluster/pom.xml
+++ b/atomix/cluster/pom.xml
@@ -69,6 +69,10 @@
     </dependency>
     <dependency>
       <groupId>io.netty</groupId>
+      <artifactId>netty-transport-classes-epoll</artifactId>
+    </dependency>
+    <dependency>
+      <groupId>io.netty</groupId>
       <artifactId>netty-transport-native-epoll</artifactId>
       <classifier>linux-x86_64</classifier>
     </dependency>
@@ -278,6 +282,7 @@
             <dependency>uk.co.real-logic:sbe-tool</dependency>
             <dependency>net.jqwik:jqwik</dependency>
             <dependency>io.netty:netty-tcnative-boringssl-static</dependency>
+            <dependency>io.netty:netty-transport-native-epoll</dependency>
           </usedDependencies>
         </configuration>
       </plugin>
",4,"[""63eab619e6166eb6cab948028a7b89bf059dd878"", ""e137f9fdbdb6bf3f85c3f7ac9323785e445844c8"", ""a52a585d74894b3b4eeb8c784fa089ff95cddad0"", ""f00a4d3e307b89842250358ee432e6800bb24362""]","[""refactor"", ""feat"", ""docs"", ""build""]"
"assist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>add testsdo not use scripts and binaries from the libcc repoadd fallible peek_last_token()","diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }

diff --git a/Cargo.lock b/Cargo.lock
index 84d5d07..6ad05da 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -293,6 +293,7 @@ version = ""0.1.0""
 dependencies = [
  ""git-cliff-core"",
  ""log"",
+ ""pretty_assertions"",
  ""pretty_env_logger"",
  ""structopt"",
 ]
diff --git a/git-cliff-core/src/lib.rs b/git-cliff-core/src/lib.rs
index 3b18ba0..a560c94 100644
--- a/git-cliff-core/src/lib.rs
+++ b/git-cliff-core/src/lib.rs
@@ -1,6 +1,8 @@
 //! Highly customizable Changelog Generator
 #![warn(missing_docs, clippy::unwrap_used)]
 
+/// Export regex crate.
+pub use regex;
 /// Git commit.
 pub mod commit;
 /// Config file parser.
diff --git a/git-cliff/Cargo.toml b/git-cliff/Cargo.toml
index 41eb2e9..cc64b37 100644
--- a/git-cliff/Cargo.toml
+++ b/git-cliff/Cargo.toml
@@ -20,3 +20,6 @@ log = ""0.4.14""
 version = ""0.3""
 default-features = false
 features = [""suggestions"", ""color"", ""wrap_help""]
+
+[dev-dependencies]
+pretty_assertions = ""0.7""
diff --git a/git-cliff/src/changelog.rs b/git-cliff/src/changelog.rs
index 3f9e994..23ea186 100644
--- a/git-cliff/src/changelog.rs
+++ b/git-cliff/src/changelog.rs
@@ -115,3 +115,171 @@ impl<'a> Changelog<'a> {
 		Ok(())
 	}
 }
+
+#[cfg(test)]
+mod test {
+	use super::*;
+	use git_cliff_core::config::{
+		ChangelogConfig,
+		CommitParser,
+		GitConfig,
+	};
+	use git_cliff_core::regex::Regex;
+	use pretty_assertions::assert_eq;
+	use std::str;
+	#[test]
+	fn changelog_generator() -> Result<()> {
+		let config = Config {
+			changelog: ChangelogConfig {
+				header: Some(String::from(""# Changelog"")),
+				body:   String::from(
+					r#""{% if version %}
+				## Release [{{ version }}] - {{ timestamp | date(format=""%Y-%m-%d"") }}
+				({{ commit_id }}){% else %}
+				## Unreleased{% endif %}
+				{% for group, commits in commits | group_by(attribute=""group"") %}
+				### {{ group }}{% for group, commits in commits | group_by(attribute=""scope"") %}
+				#### {{ group }}{% for commit in commits %}
+				- {{ commit.message }}{% endfor %}
+				{% endfor %}{% endfor %}""#,
+				)
+				.replace(""				"", """"),
+				footer: Some(String::from(""------------"")),
+			},
+			git:       GitConfig {
+				conventional_commits: true,
+				commit_parsers:       Some(vec![
+					CommitParser {
+						message: Regex::new(""feat*"").ok(),
+						body:    None,
+						group:   Some(String::from(""New features"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new(""fix*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Bug Fixes"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new("".*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Other"")),
+						skip:    None,
+					},
+				]),
+				filter_commits:       Some(false),
+				tag_pattern:          String::new(),
+				skip_tags:            Regex::new(""v3.*"").ok(),
+			},
+		};
+		let test_release = Release {
+			version:   Some(String::from(""v1.0.0"")),
+			commits:   vec![
+				Commit::new(
+					String::from(""0bc123""),
+					String::from(""feat(app): add cool features""),
+				),
+				Commit::new(
+					String::from(""0werty""),
+					String::from(""style(ui): make good stuff""),
+				),
+				Commit::new(
+					String::from(""0w3rty""),
+					String::from(""fix(ui): fix more stuff""),
+				),
+				Commit::new(
+					String::from(""0jkl12""),
+					String::from(""chore(app): do nothing""),
+				),
+			],
+			commit_id: Some(String::from(""0bc123"")),
+			timestamp: 50000000,
+			previous:  None,
+		};
+		let releases = vec![
+			test_release.clone(),
+			Release {
+				version: Some(String::from(""v3.0.0"")),
+				commits: vec![Commit::new(
+					String::from(""n0thin""),
+					String::from(""feat(xyz): skip commit""),
+				)],
+				..Release::default()
+			},
+			Release {
+				version:   None,
+				commits:   vec![
+					Commit::new(
+						String::from(""abc123""),
+						String::from(""feat(app): add xyz""),
+					),
+					Commit::new(
+						String::from(""abc124""),
+						String::from(""docs(app): document zyx""),
+					),
+					Commit::new(String::from(""def789""), String::from(""merge #4"")),
+					Commit::new(
+						String::from(""qwerty""),
+						String::from(""fix(app): fix abc""),
+					),
+					Commit::new(
+						String::from(""hjkl12""),
+						String::from(""chore(ui): do boring stuff""),
+					),
+				],
+				commit_id: None,
+				timestamp: 1000,
+				previous:  Some(Box::new(test_release)),
+			},
+		];
+		let changelog = Changelog::new(releases, &config)?;
+		let mut out = Vec::new();
+		changelog.generate(&mut out)?;
+		assert_eq!(
+			String::from(
+				r#""# Changelog
+
+			## Unreleased
+
+			### Bug Fixes
+			#### app
+			- fix abc
+
+			### New features
+			#### app
+			- add xyz
+
+			### Other
+			#### app
+			- document zyx
+
+			#### ui
+			- do boring stuff
+
+			## Release [v1.0.0] - 1971-08-02
+			(0bc123)
+
+			### Bug Fixes
+			#### ui
+			- fix more stuff
+
+			### New features
+			#### app
+			- add cool features
+
+			### Other
+			#### app
+			- do nothing
+
+			#### ui
+			- make good stuff
+			------------
+			""#
+			)
+			.replace(""			"", """"),
+			str::from_utf8(&out).unwrap()
+		);
+		Ok(())
+	}
+}

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.
",4,"[""1269431c8a3e7549f10fcbbb4b88ff625c8898b3"", ""8ee0611fbf0cd89abe7ae588f22e6ecb843598ea"", ""45837af24a33308a70a3454f0f650f9fe728e272"", ""63eab619e6166eb6cab948028a7b89bf059dd878""]","[""build"", ""test"", ""cicd"", ""refactor""]"
"docker PG version upgrade

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>add .nullif() exampledetach ViewControllers when not activeinitialize threejs objects in defaultRef, to fix undefined type errors","diff --git a/packages/nocodb/docker-compose.yml b/packages/nocodb/docker-compose.yml
index 7fabf79..ba2ab7b 100644
--- a/packages/nocodb/docker-compose.yml
+++ b/packages/nocodb/docker-compose.yml
@@ -1,4 +1,4 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
     # db55:
@@ -96,8 +96,8 @@ services:
     #     - 5495:5432
     #   volumes:
     #     - ./pg-sakila-db:/docker-entrypoint-initdb.d
-    pg96:
-     image: postgres:9.6
+    pg147:
+     image: postgres:14.7
      restart: always
      environment:
        POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
index 19dfab2..97d346b 100644
--- a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
+++ b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg.yml b/tests/playwright/scripts/docker-compose-pg.yml
index 0396579..9fab10e 100644
--- a/tests/playwright/scripts/docker-compose-pg.yml
+++ b/tests/playwright/scripts/docker-compose-pg.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password

diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 

diff --git a/ionic/components/nav/nav-controller.ts b/ionic/components/nav/nav-controller.ts
index becdd99..1cc3c31 100644
--- a/ionic/components/nav/nav-controller.ts
+++ b/ionic/components/nav/nav-controller.ts
@@ -1410,6 +1410,9 @@ export class NavController extends Ion {
       // set the ComponentRef's instance to this ViewController
       view.setInstance(component);
 
+      // remember the ChangeDetectorRef for this ViewController
+      view.setChangeDetector(hostViewRef.changeDetectorRef);
+
       // remember the ElementRef to the ion-page elementRef that was just created
       view.setPageRef(pageElementRef);
 
diff --git a/ionic/components/nav/view-controller.ts b/ionic/components/nav/view-controller.ts
index 3207fa2..069c74d 100644
--- a/ionic/components/nav/view-controller.ts
+++ b/ionic/components/nav/view-controller.ts
@@ -1,4 +1,4 @@
-import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer} from 'angular2/core';
+import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer, ChangeDetectorRef} from 'angular2/core';
 
 import {Navbar} from '../navbar/navbar';
 import {NavController, NavOptions} from './nav-controller';
@@ -33,6 +33,7 @@ export class ViewController {
   private _nbVwRef: ViewContainerRef;
   private _onDismiss: Function = null;
   private _pgRef: ElementRef;
+  private _cd: ChangeDetectorRef;
   protected _nav: NavController;
 
   /**
@@ -166,6 +167,13 @@ export class ViewController {
   /**
    * @private
    */
+  setChangeDetector(cd: ChangeDetectorRef) {
+    this._cd = cd;
+  }
+
+  /**
+   * @private
+   */
   setInstance(instance: any) {
     this.instance = instance;
   }
@@ -467,6 +475,14 @@ export class ViewController {
    * The view is about to enter and become the active view.
    */
   willEnter() {
+    if (this._cd) {
+      // ensure this has been re-attached to the change detector
+      this._cd.reattach();
+
+      // detect changes before we run any user code
+      this._cd.detectChanges();
+    }
+
     ctrlFn(this, 'onPageWillEnter');
   }
 
@@ -496,6 +512,10 @@ export class ViewController {
    */
   didLeave() {
     ctrlFn(this, 'onPageDidLeave');
+
+    // when this is not the active page
+    // we no longer need to detect changes
+    this._cd && this._cd.detach();
   }
 
   /**

diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number
",4,"[""37b1cbfd3d2c462ef4f2a131e4172c38dc8d9ddf"", ""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21"", ""b282e90e2cbb74559aab79eee8443a4d7c85502a"", ""2561f4ade46fc9d59f289f328cc77733a6443697""]","[""build"", ""docs"", ""feat"", ""fix""]"
"spring version, core versionupdate wrapping tests for v7add a branch name to Slack notifications (#14793)buffer assert and bpmn model api helper class

related to camunda-tngp/camunda-tngp#23","diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 

diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });

diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'

diff --git a/test-util/pom.xml b/test-util/pom.xml
index a097651..b6518ee 100644
--- a/test-util/pom.xml
+++ b/test-util/pom.xml
@@ -20,6 +20,7 @@
     <project.build.sourceEncoding>utf-8</project.build.sourceEncoding>
     <!-- TODO: Move to common parent -->
     <agrona.version>0.4.11</agrona.version>
+    <camunda.version>7.6.0-SNAPSHOT</camunda.version>
   </properties>
 
   <dependencies>
@@ -30,6 +31,13 @@
       <version>${agrona.version}</version>
       <scope>provided</scope>
     </dependency>
+    
+    <dependency>
+      <groupId>org.camunda.bpm.model</groupId>
+      <artifactId>camunda-bpmn-model</artifactId>
+      <version>${camunda.version}</version>
+      <scope>provided</scope>
+    </dependency>
 
     <dependency>
       <groupId>junit</groupId>
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
index 37e3a6f..b8d9b26 100644
--- a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
@@ -14,7 +14,7 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         super(actual, BufferAssert.class);
     }
 
-    public static BufferAssert assertThat(DirectBuffer buffer)
+    public static BufferAssert assertThatBuffer(DirectBuffer buffer)
     {
         return new BufferAssert(buffer);
     }
@@ -41,4 +41,16 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         return hasBytes(expected, 0);
     }
 
+    public BufferAssert hasCapacity(int expectedCapacity)
+    {
+        isNotNull();
+
+        if (expectedCapacity != actual.capacity())
+        {
+            failWithMessage(""Expected capacity "" + expectedCapacity + "" but was "" + actual.capacity());
+        }
+
+        return this;
+    }
+
 }
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
new file mode 100644
index 0000000..6f0d134
--- /dev/null
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
@@ -0,0 +1,121 @@
+package org.camunda.tngp.broker.test.util.bpmn;
+
+import java.util.Collection;
+
+import org.camunda.bpm.model.bpmn.BpmnModelInstance;
+import org.camunda.bpm.model.bpmn.impl.BpmnModelConstants;
+import org.camunda.bpm.model.bpmn.instance.Definitions;
+import org.camunda.bpm.model.xml.Model;
+import org.camunda.bpm.model.xml.instance.DomDocument;
+import org.camunda.bpm.model.xml.instance.ModelElementInstance;
+import org.camunda.bpm.model.xml.type.ModelElementType;
+import org.camunda.bpm.model.xml.validation.ModelElementValidator;
+import org.camunda.bpm.model.xml.validation.ValidationResults;
+
+public class TngpModelInstance implements BpmnModelInstance
+{
+    protected BpmnModelInstance wrappedInstance;
+
+    public TngpModelInstance(BpmnModelInstance wrappedInstance)
+    {
+        this.wrappedInstance = wrappedInstance;
+    }
+
+    @Override
+    public DomDocument getDocument()
+    {
+        return wrappedInstance.getDocument();
+    }
+
+    @Override
+    public ModelElementInstance getDocumentElement()
+    {
+        return wrappedInstance.getDocumentElement();
+    }
+
+    @Override
+    public void setDocumentElement(ModelElementInstance documentElement)
+    {
+        wrappedInstance.setDocumentElement(documentElement);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(Class<T> type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(ModelElementType type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public Model getModel()
+    {
+        return wrappedInstance.getModel();
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T getModelElementById(String id)
+    {
+        return wrappedInstance.getModelElementById(id);
+    }
+
+    @Override
+    public Collection<ModelElementInstance> getModelElementsByType(ModelElementType referencingType)
+    {
+        return wrappedInstance.getModelElementsByType(referencingType);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> Collection<T> getModelElementsByType(Class<T> referencingClass)
+    {
+        return wrappedInstance.getModelElementsByType(referencingClass);
+    }
+
+    @Override
+    public ValidationResults validate(Collection<ModelElementValidator<?>> validators)
+    {
+        return wrappedInstance.validate(validators);
+    }
+
+    @Override
+    public BpmnModelInstance clone()
+    {
+        return wrappedInstance.clone();
+    }
+
+    @Override
+    public Definitions getDefinitions()
+    {
+        return wrappedInstance.getDefinitions();
+    }
+
+    @Override
+    public void setDefinitions(Definitions arg0)
+    {
+        wrappedInstance.setDefinitions(arg0);
+    }
+
+    public TngpModelInstance taskAttributes(String taskId, String taskType, int taskQueueId)
+    {
+        final ModelElementInstance task = wrappedInstance.getModelElementById(taskId);
+
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskType"", taskType);
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskQueueId"", String.valueOf(taskQueueId));
+
+        return this;
+    }
+
+    public static TngpModelInstance wrap(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance);
+    }
+
+    public static TngpModelInstance wrapCopy(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance.clone());
+    }
+}
",4,"[""c55591ba157298a9c5816693c102a89dfd058830"", ""317f4eefecddfb1392ca71d551840f446feee302"", ""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da"", ""6ed56ce9ae743ba9a87e6c9643cc06b1de7b748d""]","[""build"", ""test"", ""cicd"", ""feat""]"
"update flushed index before truncating[gn win] link comctl32.lib to fix component buildupdate Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909restructure ClusterTopology to track completed change","diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })

diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(
",4,"[""933ab6bb86372913c992567cf9660009900911a7"", ""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""c2ee5cd5e709afd15c5565ee009a0d204403a119"", ""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2""]","[""fix"", ""build"", ""docs"", ""refactor""]"
update flushed index before truncatingadd getter for protocol idadd comments for the Handlerincrement failing test retries,"diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }

diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }

diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
",4,"[""933ab6bb86372913c992567cf9660009900911a7"", ""dc5238b2bda98a7c4f2fe9584fc3b0191a408109"", ""036a0ff49a7dade0e04c9c07071a1ff49133ee24"", ""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57""]","[""fix"", ""feat"", ""docs"", ""cicd""]"
"add spacing in comment fix lint (#8555)never call ""onStart"" prop when idleadd numberOfLines prop to DataTableTitle (#863)

Closes #848remove appear css animation","diff --git a/src/components/nav/test/basic/app-module.ts b/src/components/nav/test/basic/app-module.ts
index 467917a..375e662 100644
--- a/src/components/nav/test/basic/app-module.ts
+++ b/src/components/nav/test/basic/app-module.ts
@@ -633,7 +633,7 @@ export class Tab3 {
   }
 
   presentModal() {
-    //this.modalCtrl.create(MyModal).present();
+    // this.modalCtrl.create(MyModal).present();
   }
 
   selectPrevious() {

diff --git a/packages/core/src/SpringValue.ts b/packages/core/src/SpringValue.ts
index 18494a8..cbc4f27 100644
--- a/packages/core/src/SpringValue.ts
+++ b/packages/core/src/SpringValue.ts
@@ -596,11 +596,11 @@ export class SpringValue<T = any> extends AnimationValue<T> {
   /** Notify change observers */
   protected _onChange(value: T, idle = false) {
     const anim = this.animation
-    if (!anim.changed) {
+    if (!anim.changed && !idle) {
       anim.changed = true
       // The ""onStart"" prop is called on the first change after entering the
       // frameloop, but never for immediate animations.
-      if (anim.onStart && !anim.immediate) {
+      if (anim.onStart) {
         anim.onStart(this)
       }
     }

diff --git a/src/components/DataTable/DataTableTitle.js b/src/components/DataTable/DataTableTitle.js
index bfcf07e..d764fd5 100644
--- a/src/components/DataTable/DataTableTitle.js
+++ b/src/components/DataTable/DataTableTitle.js
@@ -27,6 +27,10 @@ type Props = React.ElementConfig<typeof TouchableWithoutFeedback> & {|
    */
   sortDirection?: 'ascending' | 'descending',
   /**
+   * The number of lines to show.
+   */
+  numberOfLines?: number,
+  /**
    * Function to execute on press.
    */
   onPress?: () => mixed,
@@ -44,6 +48,10 @@ type State = {
 class DataTableTitle extends React.Component<Props, State> {
   static displayName = 'DataTable.Title';
 
+  static defaultProps = {
+    numberOfLines: 1,
+  };
+
   state = {
     spinAnim: new Animated.Value(
       this.props.sortDirection === 'ascending' ? 0 : 1
@@ -70,6 +78,7 @@ class DataTableTitle extends React.Component<Props, State> {
       sortDirection,
       theme,
       style,
+      numberOfLines,
       ...rest
     } = this.props;
 
@@ -99,7 +108,7 @@ class DataTableTitle extends React.Component<Props, State> {
               styles.cell,
               sortDirection ? styles.sorted : { color: textColor },
             ]}
-            numberOfLines={1}
+            numberOfLines={numberOfLines}
           >
             {children}
           </Text>

diff --git a/src/popup/Popup.tsx b/src/popup/Popup.tsx
index d485bb6..2abc22a 100644
--- a/src/popup/Popup.tsx
+++ b/src/popup/Popup.tsx
@@ -269,7 +269,6 @@ export class Popup extends React.Component<{ t: TranslationFunction }, PopupStat
         <CSSTransition
           classNames='fade'
           in={!!currentTabUrl}
-          appear
           timeout={500}
           exit={false}
           mountOnEnter
",4,"[""af880ac5b4fecbc6c4f3d1eee0d95f326e8bd9d1"", ""c8e0ae8612df3d6f2831acc004aaac332f6105e4"", ""f9a094918b62534614c47aa8a13f33aec751a1e0"", ""47ef9104e4a89e80d7cc6c1950bc080841da4a7b""]","[""docs"", ""fix"", ""feat"", ""refactor""]"
"print errors without stacktraceassist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>support use meta key select multiple elementadd riscv64gc-unknown-linux-gnu","diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {

diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }

diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index ab68624..aeee7b7 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -277,9 +277,11 @@ export default class LogicFlow {
   }
   /**
    * 将图形选中
+   * @param id 选择元素ID
+   * @param multiple 是否允许多选，如果为true，不会将上一个选中的元素重置
    */
-  select(id: string) {
-    this.graphModel.selectElementById(id);
+  select(id: string, multiple = false) {
+    this.graphModel.selectElementById(id, multiple);
   }
   /**
    * 将图形定位到画布中心
diff --git a/packages/core/src/model/EditConfigModel.ts b/packages/core/src/model/EditConfigModel.ts
index 67e334a..83e5f16 100644
--- a/packages/core/src/model/EditConfigModel.ts
+++ b/packages/core/src/model/EditConfigModel.ts
@@ -25,6 +25,7 @@ const SilentConfig = {
   edgeTextEdit: false,
   nodeTextDraggable: false,
   edgeTextDraggable: false,
+  metaKeyMultipleSelected: false,
 };
 
 /**
@@ -42,6 +43,7 @@ export default class EditConfigModel {
   @observable edgeTextEdit = true; // 允许连线文本可以编辑
   @observable nodeTextDraggable = false; // 允许节点文本可以拖拽
   @observable edgeTextDraggable = false; // 允许连线文本可以拖拽
+  @observable metaKeyMultipleSelected = false; // 允许meta多选元素
   constructor(data) {
     const keys = [
       'stopZoomGraph',
@@ -55,6 +57,7 @@ export default class EditConfigModel {
       'edgeTextEdit',
       'nodeTextDraggable',
       'edgeTextDraggable',
+      'metaKeyMultipleSelected',
     ];
     const { isSilentMode, textEdit } = data;
     if (isSilentMode) {
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 9667f4d..310daf4 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -34,6 +34,7 @@ class GraphModel {
   height: number;
   topElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
   selectElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
+  selectElements = new Map<string, IBaseModel>(); // 多选
   @observable edgeType: string;
   @observable nodes: BaseNodeModel[] = [];
   @observable activeElement: IBaseModel;
@@ -50,7 +51,6 @@ class GraphModel {
   @observable gridSize = 1;
   @observable partial = false; // 是否开启局部渲染
   @observable fakerNode: BaseNodeModel;
-  // @observable selectElements = new Map<string, IBaseModel>(); // 多选还没有做，先不加
   constructor(config) {
     const {
       container,
@@ -456,24 +456,44 @@ class GraphModel {
   }
 
   @action
-  selectNodeById(id) {
-    this.selectElement?.setSelected(false);
+  selectNodeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.nodesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectEdgeById(id) {
-    this.selectElement?.setSelected(false);
+  selectEdgeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.edgesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectElementById(id: string) {
-    this.selectElement?.setSelected(false);
+  selectElementById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
+  }
+
+  @action
+  clearSelectElements() {
+    this.selectElements.forEach(element => {
+      element.setSelected(false);
+    });
+    this.selectElements.clear();
   }
 
   /* 修改连线类型 */
diff --git a/packages/core/src/view/edge/BaseEdge.tsx b/packages/core/src/view/edge/BaseEdge.tsx
index d45ea9e..d7c8f38 100644
--- a/packages/core/src/view/edge/BaseEdge.tsx
+++ b/packages/core/src/view/edge/BaseEdge.tsx
@@ -178,7 +178,8 @@ export default class BaseEdge extends Component<IProps> {
   handleClick = (e) => {
     const { model, graphModel, eventCenter } = this.props;
     graphModel.toFront(model.id);
-    graphModel.selectEdgeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectEdgeById(model.id, e.metaKey && metaKeyMultipleSelected);
     // 边数据
     const edgeData = model?.getData();
     const position = graphModel.getPointByClient({
diff --git a/packages/core/src/view/node/BaseNode.tsx b/packages/core/src/view/node/BaseNode.tsx
index 140889c..5ee3975 100644
--- a/packages/core/src/view/node/BaseNode.tsx
+++ b/packages/core/src/view/node/BaseNode.tsx
@@ -275,7 +275,8 @@ export default abstract class BaseNode extends Component<IProps, Istate> {
       }, 400);
     }
     graphModel.toFront(model.id);
-    graphModel.selectNodeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectNodeById(model.id, e.metaKey && metaKeyMultipleSelected);
     this.preStartTime = this.startTime;
   };
   handleContextMenu = (ev: MouseEvent) => {
diff --git a/packages/core/src/view/overlay/CanvasOverlay.tsx b/packages/core/src/view/overlay/CanvasOverlay.tsx
index ef11822..8c79fd2 100644
--- a/packages/core/src/view/overlay/CanvasOverlay.tsx
+++ b/packages/core/src/view/overlay/CanvasOverlay.tsx
@@ -104,9 +104,9 @@ class CanvasOverlay extends Component<IProps, Istate> {
     const target = ev.target as HTMLElement;
     if (target.getAttribute('name') === 'canvas-overlay') {
       const { graphModel, eventCenter } = this.props;
-      const { selectElement, textEditElement } = graphModel;
-      if (selectElement) {
-        selectElement.setSelected(false);
+      const { textEditElement, selectElements } = graphModel;
+      if (selectElements.size > 0) {
+        graphModel.clearSelectElements();
       }
       if (textEditElement) {
         textEditElement.setElementState(ElementState.DEFAULT);
diff --git a/packages/extension/examples/bpmn/index.html b/packages/extension/examples/bpmn/index.html
index 7a68d6f..f7ea87d 100644
--- a/packages/extension/examples/bpmn/index.html
+++ b/packages/extension/examples/bpmn/index.html
@@ -6,6 +6,7 @@
   <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
   <title>LOGIN FLOW</title>
   <link rel=""stylesheet"" href=""/core/dist/style/index.css"">
+  <link rel=""stylesheet"" href=""/extension/lib/style/index.css"">
   <style>
     html,body {
       padding: 0;
@@ -129,11 +130,14 @@
     </div>
   </div>
   <script src=""/core/dist/logic-flow.js""></script>
+  <!-- <script src=""http://0.0.0.0:9090/logic-flow.js""></script> -->
   <script src=""/BpmnElement.js""></script>
   <script src=""/BpmnAdapter.js""></script>
+  <script src=""/Control.js""></script>
   <script src=""/Snapshot.js""></script>
   <script>
     LogicFlow.use(BpmnElement);
+    LogicFlow.use(Control);
     LogicFlow.use(BpmnAdapter);
     LogicFlow.use(Snapshot);
   </script>
diff --git a/packages/extension/examples/bpmn/index.js b/packages/extension/examples/bpmn/index.js
index 21d2da0..6f6aa39 100644
--- a/packages/extension/examples/bpmn/index.js
+++ b/packages/extension/examples/bpmn/index.js
@@ -3,6 +3,10 @@ window.onload = function () {
     container: document.querySelector('#app'),
     // fixme: grid成为了必传的了
     edgeTextDraggable: true,
+    metaKeyMultipleSelected: true,
+    // stopScrollGraph: true,
+    // stopMoveGraph: true,
+    // stopZoomGraph: true,
     grid: {
       type: 'dot',
       size: 20,

diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }
",4,"[""d129eaf9125a967ac86c6c7276bbae6b4d50af36"", ""1269431c8a3e7549f10fcbbb4b88ff625c8898b3"", ""e137f9fdbdb6bf3f85c3f7ac9323785e445844c8"", ""173553c0372e66e03bdab19e0e6c2dd44daa14a0""]","[""fix"", ""build"", ""feat"", ""cicd""]"
add getter for protocol idmake it mode lessensure checksum persist flushes to diskfix build ordering,"diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }

diff --git a/core/src/components/slides/slides.tsx b/core/src/components/slides/slides.tsx
index 48fd53f..d5c2f75 100644
--- a/core/src/components/slides/slides.tsx
+++ b/core/src/components/slides/slides.tsx
@@ -1,7 +1,6 @@
 import { Component, Element, Event, EventEmitter, Method, Prop, Watch } from '@stencil/core';
 
 import { Mode } from '../../interface.js';
-import { createThemedClasses } from '../../utils/theme.js';
 
 import { Swiper } from './vendor/swiper.js';
 
@@ -15,6 +14,7 @@ import { Swiper } from './vendor/swiper.js';
   shadow: true
 })
 export class Slides {
+
   private container!: HTMLElement;
   private swiper: any;
 
@@ -391,12 +391,6 @@ export class Slides {
     return { ...swiperOptions, ...this.options, ...eventOptions };
   }
 
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'slides')
-    };
-  }
-
   render() {
     return (
       <div class=""swiper-container"" ref={el => this.container = el as HTMLElement }>
diff --git a/core/src/components/thumbnail/thumbnail.ios.scss b/core/src/components/thumbnail/thumbnail.ios.scss
deleted file mode 100644
index e3add45..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.ios.vars"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-ios-width};
-  --border-radius: #{$thumbnail-ios-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.ios.vars.scss b/core/src/components/thumbnail/thumbnail.ios.vars.scss
deleted file mode 100644
index 85d53e5..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.ios"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-ios-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-ios-height:                  $thumbnail-ios-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-ios-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.md.scss b/core/src/components/thumbnail/thumbnail.md.scss
deleted file mode 100644
index 0fbb2ca..0000000
--- a/core/src/components/thumbnail/thumbnail.md.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.md.vars"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-md-width};
-  --border-radius: #{$thumbnail-md-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.md.vars.scss b/core/src/components/thumbnail/thumbnail.md.vars.scss
deleted file mode 100644
index 94e48b2..0000000
--- a/core/src/components/thumbnail/thumbnail.md.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.md"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-md-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-md-height:                  $thumbnail-md-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-md-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.scss b/core/src/components/thumbnail/thumbnail.scss
index 8ac3a22..8af268d 100644
--- a/core/src/components/thumbnail/thumbnail.scss
+++ b/core/src/components/thumbnail/thumbnail.scss
@@ -9,6 +9,8 @@
    * @prop --border-radius: Border radius of the thumbnail
    * @prop --size: Size of the thumbnail
    */
+  --size: 48px;
+  --border-radius: 0;
 
   @include border-radius(var(--border-radius));
 
diff --git a/core/src/components/thumbnail/thumbnail.tsx b/core/src/components/thumbnail/thumbnail.tsx
index 50ff2c2..de76593 100644
--- a/core/src/components/thumbnail/thumbnail.tsx
+++ b/core/src/components/thumbnail/thumbnail.tsx
@@ -1,25 +1,11 @@
 import { Component } from '@stencil/core';
 
-import { Mode } from '../../interface';
-import { createThemedClasses } from '../../utils/theme';
-
 @Component({
   tag: 'ion-thumbnail',
-  styleUrls: {
-    ios: 'thumbnail.ios.scss',
-    md: 'thumbnail.md.scss'
-  },
+  styleUrl: 'thumbnail.scss',
   shadow: true
 })
 export class Thumbnail {
-  mode!: Mode;
-
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'thumbnail')
-    };
-  }
-
   render() {
     return <slot></slot>;
   }

diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);

diff --git a/scripts/build.mjs b/scripts/build.mjs
index 204854f..b3cf067 100644
--- a/scripts/build.mjs
+++ b/scripts/build.mjs
@@ -3,8 +3,8 @@ import { write } from 'fsxx';
 import { info, success } from './helpers.mjs';
 
 await $`rm -rf dist/*`;
-await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 await $`unbuild`;
+await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 
 const packages = [
   'jsx-runtime',
",4,"[""dc5238b2bda98a7c4f2fe9584fc3b0191a408109"", ""771857b1df9470ebc15357e8879118a72c649d5b"", ""b7ce2894fd1794064bd6db4ed730bb6cb7728739"", ""c323d59c607cabc91f17a78528d998f376f30b10""]","[""feat"", ""refactor"", ""test"", ""build""]"
[gn win] link comctl32.lib to fix component buildensure checksum persist flushes to diskremove ubuntu-latest from job title where that is the only osprint errors without stacktrace,"diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false

diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {
",4,"[""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""b7ce2894fd1794064bd6db4ed730bb6cb7728739"", ""74e9de5ec97dc013a52aa063dff0f40ac74c407b"", ""d129eaf9125a967ac86c6c7276bbae6b4d50af36""]","[""build"", ""test"", ""cicd"", ""fix""]"
"add spacing in comment fix lint (#8555)add props to get color and label from a routeupgrade to Flux v0.42.0

Skips a test that requires special dependencies to pass.run pyspark tests in parallel","diff --git a/src/components/nav/test/basic/app-module.ts b/src/components/nav/test/basic/app-module.ts
index 467917a..375e662 100644
--- a/src/components/nav/test/basic/app-module.ts
+++ b/src/components/nav/test/basic/app-module.ts
@@ -633,7 +633,7 @@ export class Tab3 {
   }
 
   presentModal() {
-    //this.modalCtrl.create(MyModal).present();
+    // this.modalCtrl.create(MyModal).present();
   }
 
   selectPrevious() {

diff --git a/src/components/BottomNavigation.js b/src/components/BottomNavigation.js
index 1b72302..7d8ea75 100644
--- a/src/components/BottomNavigation.js
+++ b/src/components/BottomNavigation.js
@@ -24,8 +24,8 @@ const AnimatedPaper = Animated.createAnimatedComponent(Paper);
 
 type Route = {
   key: string,
-  title: string,
-  icon: IconSource,
+  title?: string,
+  icon?: IconSource,
   color?: string,
 };
 
@@ -51,7 +51,7 @@ type Props<T> = {
    * - `key`: a unique key to identify the route
    * - `title`: title of the route to use as the tab label
    * - `icon`: icon to use as the tab icon, can be a string, an image source or a react component
-   * - `color`: color to use as background color for shifting bottom navigation (optional)
+   * - `color`: color to use as background color for shifting bottom navigation
    *
    * Example:
    *
@@ -115,11 +115,27 @@ type Props<T> = {
   /**
    * Callback which returns a React Element to be used as tab icon.
    */
-  renderIcon?: (props: { route: T, focused: boolean }) => React.Node,
+  renderIcon?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
   /**
    * Callback which React Element to be used as tab label.
    */
-  renderLabel?: (props: { route: T, focused: boolean }) => React.Node,
+  renderLabel?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
+  /**
+   * Get label text for the tab, uses `route.title` by default. Use `renderLabel` to replace label component.
+   */
+  getLabelText?: (props: { route: T }) => string,
+  /**
+   * Get color for the tab, uses `route.color` by default.
+   */
+  getColor?: (props: { route: T }) => string,
   /**
    * Function to execute on tab press. It receives the route for the pressed tab, useful for things like scroll to top.
    */
@@ -159,6 +175,10 @@ type State = {
    */
   ripple: Animated.Value,
   /**
+   * Animation for the touch feedback, used to determine it's scale and opacity.
+   */
+  touch: Animated.Value,
+  /**
    * Layout of the tab bar. The width is used to determine the size and position of the ripple.
    */
   layout: { height: number, width: number, measured: boolean },
@@ -173,7 +193,7 @@ const MIN_SHIFT_AMOUNT = 10;
 const MIN_TAB_WIDTH = 96;
 const MAX_TAB_WIDTH = 168;
 const BAR_HEIGHT = 56;
-const SMALL_RIPPLE_SIZE = 72;
+const SMALL_RIPPLE_SIZE = 96;
 const ACTIVE_LABEL_SIZE = 14;
 const INACTIVE_LABEL_SIZE = 12;
 
@@ -251,6 +271,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ),
       index: new Animated.Value(index),
       ripple: new Animated.Value(MIN_RIPPLE_SCALE),
+      touch: new Animated.Value(MIN_RIPPLE_SCALE),
       layout: { height: 0, width: 0, measured: false },
       previous: 0,
     };
@@ -349,6 +370,15 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
   _handleTabPress = (index: number) => {
     const { navigationState } = this.props;
 
+    this.state.touch.setValue(MIN_RIPPLE_SCALE);
+
+    Animated.timing(this.state.touch, {
+      toValue: 1,
+      duration: 300,
+      easing: Easing.in(Easing.sin),
+      useNativeDriver: true,
+    }).start();
+
     if (index !== navigationState.index) {
       this.props.onIndexChange(index);
     }
@@ -376,6 +406,8 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       renderScene,
       renderIcon,
       renderLabel,
+      getLabelText = ({ route }) => route.title,
+      getColor = ({ route }) => route.color,
       barStyle,
       style,
       theme,
@@ -400,7 +432,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ? this.state.index.interpolate({
           inputRange: routes.map((_, i) => i),
           outputRange: routes.map(
-            route => route.color || approxBackgroundColor
+            route => getColor({ route }) || approxBackgroundColor
           ),
         })
       : approxBackgroundColor;
@@ -416,7 +448,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
           .rgb()
           .string();
 
-    const rippleColor = color(textColor)
+    const touchColor = color(textColor)
       .alpha(0.12)
       .rgb()
       .string();
@@ -430,22 +462,10 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
 
     // Since we have a single ripple, we have to reposition it so that it appears to expand from active tab.
     // We need to move it from the left to the active tab and also account for how much that tab has shifted.
-    const rippleShift =
-      navigationState.index * tabWidth +
-      tabWidth / 2 +
-      this._calculateShift(
-        this.state.previous,
-        navigationState.index,
-        routes.length
-      );
 
     return (
       <View
-        style={[
-          styles.container,
-          { backgroundColor: theme.dark ? white : black },
-          style,
-        ]}
+        style={[styles.container, style]}
         onLayout={this._handleLayout}
         pointerEvents={layout.measured ? 'auto' : 'none'}
       >
@@ -485,25 +505,30 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
             style={[styles.items, { maxWidth: maxTabWidth * routes.length }]}
           >
             {shifting ? (
-              // Large ripple with the backround color
               <Animated.View
                 pointerEvents=""none""
                 style={[
                   styles.ripple,
                   {
                     // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - layout.width / 2,
-                    left: rippleShift - layout.width / 2,
-                    height: layout.width,
-                    width: layout.width,
+                    top: BAR_HEIGHT / 2 - layout.width / 8,
+                    left:
+                      navigationState.index * tabWidth +
+                      tabWidth / 2 -
+                      layout.width / 8,
+                    height: layout.width / 4,
+                    width: layout.width / 4,
                     borderRadius: layout.width / 2,
-                    backgroundColor: routes[navigationState.index].color,
+                    backgroundColor: getColor({
+                      route: routes[navigationState.index],
+                    }),
                     transform: [
+                      { translateX: this.state.shifts[navigationState.index] },
                       {
                         // Scale to twice the size  to ensure it covers the whole tab bar
                         scale: this.state.ripple.interpolate({
                           inputRange: [0, 1],
-                          outputRange: [0, 2],
+                          outputRange: [0, 8],
                         }),
                       },
                     ],
@@ -515,36 +540,36 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                 ]}
               />
             ) : null}
-            {shifting ? (
-              // Small subtle ripple on touch
-              <Animated.View
-                pointerEvents=""none""
-                style={[
-                  styles.ripple,
-                  {
-                    // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
-                    left: rippleShift - SMALL_RIPPLE_SIZE / 2,
-                    height: SMALL_RIPPLE_SIZE,
-                    width: SMALL_RIPPLE_SIZE,
-                    borderRadius: SMALL_RIPPLE_SIZE / 2,
-                    backgroundColor: rippleColor,
-                    transform: [
-                      {
-                        scale: this.state.ripple.interpolate({
-                          inputRange: [0, 0.5, 1],
-                          outputRange: [0, 1, 1],
-                        }),
-                      },
-                    ],
-                    opacity: this.state.ripple.interpolate({
-                      inputRange: [0, MIN_RIPPLE_SCALE, 0.25, 0.5],
-                      outputRange: [0, 0, 1, 0],
-                    }),
-                  },
-                ]}
-              />
-            ) : null}
+            <Animated.View
+              pointerEvents=""none""
+              style={[
+                styles.ripple,
+                {
+                  // Set top and left values so that the ripple's center is same as the tab's center
+                  top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
+                  left:
+                    navigationState.index * tabWidth +
+                    tabWidth / 2 -
+                    SMALL_RIPPLE_SIZE / 2,
+                  height: SMALL_RIPPLE_SIZE,
+                  width: SMALL_RIPPLE_SIZE,
+                  borderRadius: SMALL_RIPPLE_SIZE / 2,
+                  backgroundColor: touchColor,
+                  transform: [
+                    {
+                      translateX: shifting
+                        ? this.state.shifts[navigationState.index]
+                        : 0,
+                    },
+                    { scale: this.state.touch },
+                  ],
+                  opacity: this.state.touch.interpolate({
+                    inputRange: [0, 0.5, 1],
+                    outputRange: [0, 1, 0],
+                  }),
+                },
+              ]}
+            />
             {routes.map((route, index) => {
               const shift = this.state.shifts[index];
               const focused = this.state.tabs[index];
@@ -607,7 +632,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderIcon ? (
-                          renderIcon({ route, focused: true })
+                          renderIcon({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <Icon
                             style={styles.icon}
@@ -625,7 +654,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderIcon ? (
-                            renderIcon({ route, focused: false })
+                            renderIcon({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <Icon
                               style={styles.icon}
@@ -652,7 +685,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderLabel ? (
-                          renderLabel({ route, focused: true })
+                          renderLabel({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <AnimatedText
                             style={[
@@ -662,7 +699,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                               },
                             ]}
                           >
-                            {route.title}
+                            {getLabelText({ route })}
                           </AnimatedText>
                         )}
                       </Animated.View>
@@ -674,7 +711,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderLabel ? (
-                            renderLabel({ route, focused: false })
+                            renderLabel({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <AnimatedText
                               style={[
@@ -684,7 +725,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                                 },
                               ]}
                             >
-                              {route.title}
+                              {getLabelText({ route })}
                             </AnimatedText>
                           )}
                         </Animated.View>

diff --git a/go.mod b/go.mod
index ea705da..8c352f7 100644
--- a/go.mod
+++ b/go.mod
@@ -38,7 +38,7 @@ require (
 	github.com/hashicorp/go-msgpack v0.0.0-20150518234257-fa3f63826f7c // indirect
 	github.com/hashicorp/raft v1.0.0 // indirect
 	github.com/hashicorp/vault/api v1.0.2
-	github.com/influxdata/flux v0.41.0
+	github.com/influxdata/flux v0.42.0
 	github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6
 	github.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368
 	github.com/jessevdk/go-flags v1.4.0
diff --git a/go.sum b/go.sum
index 4bfdf4c..634a0f1 100644
--- a/go.sum
+++ b/go.sum
@@ -206,8 +206,8 @@ github.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NH
 github.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=
 github.com/influxdata/changelog v1.0.0 h1:RstJD6H48zLQj0GdE6E6k/6RPwtUjkyzIe/T1E/xuWU=
 github.com/influxdata/changelog v1.0.0/go.mod h1:uzpGWE/qehT8L426YuXwpMQub+a63vIINhIeEI9mnSM=
-github.com/influxdata/flux v0.41.0 h1:ljbWJmE+aNx8Yoqhb04gWC4sXMV87eYUxz5vjYphLLs=
-github.com/influxdata/flux v0.41.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
+github.com/influxdata/flux v0.42.0 h1:2iEG6hLHdHEJ6LgD8OSnlHS9yoVrLO1/aM4P9ERb94U=
+github.com/influxdata/flux v0.42.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
 github.com/influxdata/goreleaser v0.97.0-influx h1:jT5OrcW7WfS0e2QxfwmTBjhLvpIC9CDLRhNgZJyhj8s=
 github.com/influxdata/goreleaser v0.97.0-influx/go.mod h1:MnjA0e0Uq6ISqjG1WxxMAl+3VS1QYjILSWVnMYDxasE=
 github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6 h1:CFx+pP90q/qg3spoiZjf8donE4WpAdjeJfPOcoNqkWo=
diff --git a/query/stdlib/testing/testing.go b/query/stdlib/testing/testing.go
index d41574a..85b0673 100644
--- a/query/stdlib/testing/testing.go
+++ b/query/stdlib/testing/testing.go
@@ -98,4 +98,6 @@ var FluxEndToEndSkipList = map[string]string{
 	""http_endpoint"": ""need ability to test side effects in e2e tests: (https://github.com/influxdata/flux/issues/1723)"",
 
 	""holt_winters_panic"": ""Expected output is an empty table which breaks the testing framework (https://github.com/influxdata/influxdb/issues/14749)"",
+
+	""secrets"": ""Cannot inject custom deps into the test framework so the secrets don't lookup correctly"",
 }

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index e23088e..9708157 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -202,11 +202,11 @@ jobs:
         run: poetry install --without dev --without docs --extras ${{ matrix.backend.name }} --extras geospatial
 
       - name: ""run parallel tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name != 'pyspark' && matrix.backend.name != 'impala'
+        if: matrix.backend.name != 'impala'
         run: just ci-check -m ${{ matrix.backend.name }} --numprocesses auto --dist=loadgroup
 
       - name: ""run serial tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name == 'pyspark' || matrix.backend.name == 'impala'
+        if: matrix.backend.name == 'impala'
         run: just ci-check -m ${{ matrix.backend.name }}
         env:
           IBIS_TEST_NN_HOST: localhost
",4,"[""af880ac5b4fecbc6c4f3d1eee0d95f326e8bd9d1"", ""ded26d768ff432ad3bde3c0aa1e95ce50726100a"", ""454003841aabeb74396d73541378bfa59c75b5db"", ""4cbbd2552ba0de273e1dfe7d453c5b3efed751a3""]","[""docs"", ""feat"", ""build"", ""cicd""]"
"add comments for the Handlerexport a modal transition presetincrement failing test retriesspring version, core version","diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }

diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {

diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 

diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 
",4,"[""036a0ff49a7dade0e04c9c07071a1ff49133ee24"", ""535708ae50aecb452560a23356fd396f99ef13a2"", ""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57"", ""c55591ba157298a9c5816693c102a89dfd058830""]","[""docs"", ""refactor"", ""cicd"", ""build""]"
"added suported tuple typespublish sdks after docs/buildwrong icon reference

Signed-off-by: Pranav C <pranavxc@gmail.com>add .nullif() example","diff --git a/src/List/Tuple.ts b/src/List/Tuple.ts
index 4c59caa..6e45503 100644
--- a/src/List/Tuple.ts
+++ b/src/List/Tuple.ts
@@ -1,15 +1,17 @@
-/** A [[Tuple]]
+import {NonNullable} from '../Object/NonNullable'
+
+/** A [[Tuple]] (supported)
  * @param A its type
- * @returns **`any[]`**
+ * @returns **`A[]`**
  * @example
  * ```ts
- * type list0 = [1, 2, 3]
- * type list1 = number[]
+ * type tuple0 = [1, 20, 42]
+ * type tuple1 = ['at', 420]
  * ```
  */
-export type Tuple = [
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-]
+export type Tuple<A = any> = NonNullable<[
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+]>

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/

diff --git a/packages/nc-gui/components.d.ts b/packages/nc-gui/components.d.ts
index b7e6585..bb86478 100644
--- a/packages/nc-gui/components.d.ts
+++ b/packages/nc-gui/components.d.ts
@@ -81,7 +81,6 @@ declare module '@vue/runtime-core' {
     ClaritySuccessLine: typeof import('~icons/clarity/success-line')['default']
     EvaEmailOutline: typeof import('~icons/eva/email-outline')['default']
     IcBaselineMoreVert: typeof import('~icons/ic/baseline-more-vert')['default']
-    Icon: typeof import('~icons/ic/on')['default']
     IcOutlineInsertDriveFile: typeof import('~icons/ic/outline-insert-drive-file')['default']
     IcRoundEdit: typeof import('~icons/ic/round-edit')['default']
     IcRoundKeyboardArrowDown: typeof import('~icons/ic/round-keyboard-arrow-down')['default']

diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 
",4,"[""2954a0955ce9af6acb345ed1e8328e145ad30475"", ""6c9cb638cb4d1ecc42632fcf389c24898c5b3244"", ""d1d55e787b7d07f763852602b9939a5394607fd9"", ""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21""]","[""refactor"", ""cicd"", ""fix"", ""docs""]"
setup jest and add m.ts testsrun pyspark tests in parallelFix typoadd props to get color and label from a route,"diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index e23088e..9708157 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -202,11 +202,11 @@ jobs:
         run: poetry install --without dev --without docs --extras ${{ matrix.backend.name }} --extras geospatial
 
       - name: ""run parallel tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name != 'pyspark' && matrix.backend.name != 'impala'
+        if: matrix.backend.name != 'impala'
         run: just ci-check -m ${{ matrix.backend.name }} --numprocesses auto --dist=loadgroup
 
       - name: ""run serial tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name == 'pyspark' || matrix.backend.name == 'impala'
+        if: matrix.backend.name == 'impala'
         run: just ci-check -m ${{ matrix.backend.name }}
         env:
           IBIS_TEST_NN_HOST: localhost

diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/src/components/BottomNavigation.js b/src/components/BottomNavigation.js
index 1b72302..7d8ea75 100644
--- a/src/components/BottomNavigation.js
+++ b/src/components/BottomNavigation.js
@@ -24,8 +24,8 @@ const AnimatedPaper = Animated.createAnimatedComponent(Paper);
 
 type Route = {
   key: string,
-  title: string,
-  icon: IconSource,
+  title?: string,
+  icon?: IconSource,
   color?: string,
 };
 
@@ -51,7 +51,7 @@ type Props<T> = {
    * - `key`: a unique key to identify the route
    * - `title`: title of the route to use as the tab label
    * - `icon`: icon to use as the tab icon, can be a string, an image source or a react component
-   * - `color`: color to use as background color for shifting bottom navigation (optional)
+   * - `color`: color to use as background color for shifting bottom navigation
    *
    * Example:
    *
@@ -115,11 +115,27 @@ type Props<T> = {
   /**
    * Callback which returns a React Element to be used as tab icon.
    */
-  renderIcon?: (props: { route: T, focused: boolean }) => React.Node,
+  renderIcon?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
   /**
    * Callback which React Element to be used as tab label.
    */
-  renderLabel?: (props: { route: T, focused: boolean }) => React.Node,
+  renderLabel?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
+  /**
+   * Get label text for the tab, uses `route.title` by default. Use `renderLabel` to replace label component.
+   */
+  getLabelText?: (props: { route: T }) => string,
+  /**
+   * Get color for the tab, uses `route.color` by default.
+   */
+  getColor?: (props: { route: T }) => string,
   /**
    * Function to execute on tab press. It receives the route for the pressed tab, useful for things like scroll to top.
    */
@@ -159,6 +175,10 @@ type State = {
    */
   ripple: Animated.Value,
   /**
+   * Animation for the touch feedback, used to determine it's scale and opacity.
+   */
+  touch: Animated.Value,
+  /**
    * Layout of the tab bar. The width is used to determine the size and position of the ripple.
    */
   layout: { height: number, width: number, measured: boolean },
@@ -173,7 +193,7 @@ const MIN_SHIFT_AMOUNT = 10;
 const MIN_TAB_WIDTH = 96;
 const MAX_TAB_WIDTH = 168;
 const BAR_HEIGHT = 56;
-const SMALL_RIPPLE_SIZE = 72;
+const SMALL_RIPPLE_SIZE = 96;
 const ACTIVE_LABEL_SIZE = 14;
 const INACTIVE_LABEL_SIZE = 12;
 
@@ -251,6 +271,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ),
       index: new Animated.Value(index),
       ripple: new Animated.Value(MIN_RIPPLE_SCALE),
+      touch: new Animated.Value(MIN_RIPPLE_SCALE),
       layout: { height: 0, width: 0, measured: false },
       previous: 0,
     };
@@ -349,6 +370,15 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
   _handleTabPress = (index: number) => {
     const { navigationState } = this.props;
 
+    this.state.touch.setValue(MIN_RIPPLE_SCALE);
+
+    Animated.timing(this.state.touch, {
+      toValue: 1,
+      duration: 300,
+      easing: Easing.in(Easing.sin),
+      useNativeDriver: true,
+    }).start();
+
     if (index !== navigationState.index) {
       this.props.onIndexChange(index);
     }
@@ -376,6 +406,8 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       renderScene,
       renderIcon,
       renderLabel,
+      getLabelText = ({ route }) => route.title,
+      getColor = ({ route }) => route.color,
       barStyle,
       style,
       theme,
@@ -400,7 +432,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ? this.state.index.interpolate({
           inputRange: routes.map((_, i) => i),
           outputRange: routes.map(
-            route => route.color || approxBackgroundColor
+            route => getColor({ route }) || approxBackgroundColor
           ),
         })
       : approxBackgroundColor;
@@ -416,7 +448,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
           .rgb()
           .string();
 
-    const rippleColor = color(textColor)
+    const touchColor = color(textColor)
       .alpha(0.12)
       .rgb()
       .string();
@@ -430,22 +462,10 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
 
     // Since we have a single ripple, we have to reposition it so that it appears to expand from active tab.
     // We need to move it from the left to the active tab and also account for how much that tab has shifted.
-    const rippleShift =
-      navigationState.index * tabWidth +
-      tabWidth / 2 +
-      this._calculateShift(
-        this.state.previous,
-        navigationState.index,
-        routes.length
-      );
 
     return (
       <View
-        style={[
-          styles.container,
-          { backgroundColor: theme.dark ? white : black },
-          style,
-        ]}
+        style={[styles.container, style]}
         onLayout={this._handleLayout}
         pointerEvents={layout.measured ? 'auto' : 'none'}
       >
@@ -485,25 +505,30 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
             style={[styles.items, { maxWidth: maxTabWidth * routes.length }]}
           >
             {shifting ? (
-              // Large ripple with the backround color
               <Animated.View
                 pointerEvents=""none""
                 style={[
                   styles.ripple,
                   {
                     // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - layout.width / 2,
-                    left: rippleShift - layout.width / 2,
-                    height: layout.width,
-                    width: layout.width,
+                    top: BAR_HEIGHT / 2 - layout.width / 8,
+                    left:
+                      navigationState.index * tabWidth +
+                      tabWidth / 2 -
+                      layout.width / 8,
+                    height: layout.width / 4,
+                    width: layout.width / 4,
                     borderRadius: layout.width / 2,
-                    backgroundColor: routes[navigationState.index].color,
+                    backgroundColor: getColor({
+                      route: routes[navigationState.index],
+                    }),
                     transform: [
+                      { translateX: this.state.shifts[navigationState.index] },
                       {
                         // Scale to twice the size  to ensure it covers the whole tab bar
                         scale: this.state.ripple.interpolate({
                           inputRange: [0, 1],
-                          outputRange: [0, 2],
+                          outputRange: [0, 8],
                         }),
                       },
                     ],
@@ -515,36 +540,36 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                 ]}
               />
             ) : null}
-            {shifting ? (
-              // Small subtle ripple on touch
-              <Animated.View
-                pointerEvents=""none""
-                style={[
-                  styles.ripple,
-                  {
-                    // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
-                    left: rippleShift - SMALL_RIPPLE_SIZE / 2,
-                    height: SMALL_RIPPLE_SIZE,
-                    width: SMALL_RIPPLE_SIZE,
-                    borderRadius: SMALL_RIPPLE_SIZE / 2,
-                    backgroundColor: rippleColor,
-                    transform: [
-                      {
-                        scale: this.state.ripple.interpolate({
-                          inputRange: [0, 0.5, 1],
-                          outputRange: [0, 1, 1],
-                        }),
-                      },
-                    ],
-                    opacity: this.state.ripple.interpolate({
-                      inputRange: [0, MIN_RIPPLE_SCALE, 0.25, 0.5],
-                      outputRange: [0, 0, 1, 0],
-                    }),
-                  },
-                ]}
-              />
-            ) : null}
+            <Animated.View
+              pointerEvents=""none""
+              style={[
+                styles.ripple,
+                {
+                  // Set top and left values so that the ripple's center is same as the tab's center
+                  top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
+                  left:
+                    navigationState.index * tabWidth +
+                    tabWidth / 2 -
+                    SMALL_RIPPLE_SIZE / 2,
+                  height: SMALL_RIPPLE_SIZE,
+                  width: SMALL_RIPPLE_SIZE,
+                  borderRadius: SMALL_RIPPLE_SIZE / 2,
+                  backgroundColor: touchColor,
+                  transform: [
+                    {
+                      translateX: shifting
+                        ? this.state.shifts[navigationState.index]
+                        : 0,
+                    },
+                    { scale: this.state.touch },
+                  ],
+                  opacity: this.state.touch.interpolate({
+                    inputRange: [0, 0.5, 1],
+                    outputRange: [0, 1, 0],
+                  }),
+                },
+              ]}
+            />
             {routes.map((route, index) => {
               const shift = this.state.shifts[index];
               const focused = this.state.tabs[index];
@@ -607,7 +632,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderIcon ? (
-                          renderIcon({ route, focused: true })
+                          renderIcon({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <Icon
                             style={styles.icon}
@@ -625,7 +654,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderIcon ? (
-                            renderIcon({ route, focused: false })
+                            renderIcon({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <Icon
                               style={styles.icon}
@@ -652,7 +685,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderLabel ? (
-                          renderLabel({ route, focused: true })
+                          renderLabel({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <AnimatedText
                             style={[
@@ -662,7 +699,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                               },
                             ]}
                           >
-                            {route.title}
+                            {getLabelText({ route })}
                           </AnimatedText>
                         )}
                       </Animated.View>
@@ -674,7 +711,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderLabel ? (
-                            renderLabel({ route, focused: false })
+                            renderLabel({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <AnimatedText
                               style={[
@@ -684,7 +725,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                                 },
                               ]}
                             >
-                              {route.title}
+                              {getLabelText({ route })}
                             </AnimatedText>
                           )}
                         </Animated.View>
",4,"[""229b53a632ea97d47c4be11f096bdd828fb415d8"", ""4cbbd2552ba0de273e1dfe7d453c5b3efed751a3"", ""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""ded26d768ff432ad3bde3c0aa1e95ce50726100a""]","[""test"", ""cicd"", ""docs"", ""feat""]"
"remove appear css animationallow disabling dynamic queueensure checksum persist flushes to diskterminated tasks linger for a bit

Signed-off-by: Eliza Weisman <eliza@buoyant.io>","diff --git a/src/popup/Popup.tsx b/src/popup/Popup.tsx
index d485bb6..2abc22a 100644
--- a/src/popup/Popup.tsx
+++ b/src/popup/Popup.tsx
@@ -269,7 +269,6 @@ export class Popup extends React.Component<{ t: TranslationFunction }, PopupStat
         <CSSTransition
           classNames='fade'
           in={!!currentTabUrl}
-          appear
           timeout={500}
           exit={false}
           mountOnEnter

diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);

diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);

diff --git a/console/src/main.rs b/console/src/main.rs
index ebfa315..5328d96 100644
--- a/console/src/main.rs
+++ b/console/src/main.rs
@@ -69,6 +69,7 @@ async fn main() -> Result<(), Box<dyn std::error::Error>> {
                 .wrap(Wrap { trim: true });
             f.render_widget(header, chunks[0]);
             tasks.render(f, chunks[1]);
+            tasks.retain_active();
         })?;
     }
 
diff --git a/console/src/tasks.rs b/console/src/tasks.rs
index 7be39a4..eb41495 100644
--- a/console/src/tasks.rs
+++ b/console/src/tasks.rs
@@ -19,6 +19,7 @@ struct Task {
     fields: String,
     kind: &'static str,
     stats: Stats,
+    completed_for: usize,
 }
 
 #[derive(Default, Debug)]
@@ -28,10 +29,15 @@ struct Stats {
     idle: Duration,
     total: Duration,
 }
+
 impl State {
+    // How many updates to retain completed tasks for
+    const RETAIN_COMPLETED_FOR: usize = 6;
+
     pub(crate) fn len(&self) -> usize {
         self.tasks.len()
     }
+
     pub(crate) fn update(&mut self, update: proto::tasks::TaskUpdate) {
         let new_tasks = update.new_tasks.into_iter().filter_map(|task| {
             if task.id.is_none() {
@@ -48,6 +54,7 @@ impl State {
                 fields: task.string_fields,
                 kind,
                 stats: Default::default(),
+                completed_for: 0,
             };
             Some((id, task))
         });
@@ -60,7 +67,10 @@ impl State {
         }
 
         for proto::SpanId { id } in update.completed {
-            if self.tasks.remove(&id).is_none() {
+            if let Some(task) = self.tasks.get_mut(&id) {
+                task.kind = ""!"";
+                task.completed_for = 1;
+            } else {
                 tracing::warn!(?id, ""tried to complete a task that didn't exist"");
             }
         }
@@ -79,7 +89,7 @@ impl State {
         const DUR_PRECISION: usize = 4;
         const POLLS_LEN: usize = 5;
         let rows = self.tasks.values().map(|task| {
-            let row = Row::new(vec![
+            let mut row = Row::new(vec![
                 Cell::from(task.id_hex.as_str()),
                 // TODO(eliza): is there a way to write a `fmt::Debug` impl
                 // directly to tui without doing an allocation?
@@ -105,6 +115,9 @@ impl State {
                 Cell::from(format!(""{:>width$}"", task.stats.polls, width = POLLS_LEN)),
                 Cell::from(task.fields.as_str()),
             ]);
+            if task.completed_for > 0 {
+                row = row.style(Style::default().add_modifier(style::Modifier::DIM));
+            }
             row
         });
         let t = Table::new(rows)
@@ -126,6 +139,16 @@ impl State {
 
         frame.render_widget(t, area)
     }
+
+    pub(crate) fn retain_active(&mut self) {
+        self.tasks.retain(|_, task| {
+            if task.completed_for == 0 {
+                return true;
+            }
+            task.completed_for += 1;
+            task.completed_for <= Self::RETAIN_COMPLETED_FOR
+        })
+    }
 }
 
 impl From<proto::tasks::Stats> for Stats {
",4,"[""47ef9104e4a89e80d7cc6c1950bc080841da4a7b"", ""9ef5c0d14193a9abb09b39856f58477d1f4b0d77"", ""b7ce2894fd1794064bd6db4ed730bb6cb7728739"", ""1bcf88670b50155b50071e707f98f30cea0b7a24""]","[""refactor"", ""fix"", ""test"", ""feat""]"
"nginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>enable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>add riscv64gc-unknown-linux-gnuexport a modal transition preset","diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection

diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 

diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }

diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {
",4,"[""e12d9e77a6fd531a22325337838a841b1c67f00d"", ""fd8e563cc19ca4684885d4692acee6bebcca4ada"", ""173553c0372e66e03bdab19e0e6c2dd44daa14a0"", ""535708ae50aecb452560a23356fd396f99ef13a2""]","[""docs"", ""feat"", ""cicd"", ""refactor""]"
"convert `run_tag_values_test_case` to a functiondetach ViewControllers when not activenginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>remove ubuntu-latest from job title where that is the only os","diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]

diff --git a/ionic/components/nav/nav-controller.ts b/ionic/components/nav/nav-controller.ts
index becdd99..1cc3c31 100644
--- a/ionic/components/nav/nav-controller.ts
+++ b/ionic/components/nav/nav-controller.ts
@@ -1410,6 +1410,9 @@ export class NavController extends Ion {
       // set the ComponentRef's instance to this ViewController
       view.setInstance(component);
 
+      // remember the ChangeDetectorRef for this ViewController
+      view.setChangeDetector(hostViewRef.changeDetectorRef);
+
       // remember the ElementRef to the ion-page elementRef that was just created
       view.setPageRef(pageElementRef);
 
diff --git a/ionic/components/nav/view-controller.ts b/ionic/components/nav/view-controller.ts
index 3207fa2..069c74d 100644
--- a/ionic/components/nav/view-controller.ts
+++ b/ionic/components/nav/view-controller.ts
@@ -1,4 +1,4 @@
-import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer} from 'angular2/core';
+import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer, ChangeDetectorRef} from 'angular2/core';
 
 import {Navbar} from '../navbar/navbar';
 import {NavController, NavOptions} from './nav-controller';
@@ -33,6 +33,7 @@ export class ViewController {
   private _nbVwRef: ViewContainerRef;
   private _onDismiss: Function = null;
   private _pgRef: ElementRef;
+  private _cd: ChangeDetectorRef;
   protected _nav: NavController;
 
   /**
@@ -166,6 +167,13 @@ export class ViewController {
   /**
    * @private
    */
+  setChangeDetector(cd: ChangeDetectorRef) {
+    this._cd = cd;
+  }
+
+  /**
+   * @private
+   */
   setInstance(instance: any) {
     this.instance = instance;
   }
@@ -467,6 +475,14 @@ export class ViewController {
    * The view is about to enter and become the active view.
    */
   willEnter() {
+    if (this._cd) {
+      // ensure this has been re-attached to the change detector
+      this._cd.reattach();
+
+      // detect changes before we run any user code
+      this._cd.detectChanges();
+    }
+
     ctrlFn(this, 'onPageWillEnter');
   }
 
@@ -496,6 +512,10 @@ export class ViewController {
    */
   didLeave() {
     ctrlFn(this, 'onPageDidLeave');
+
+    // when this is not the active page
+    // we no longer need to detect changes
+    this._cd && this._cd.detach();
   }
 
   /**

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
",4,"[""1db13ec43727aca872a0f3836e4023ed85db665e"", ""b282e90e2cbb74559aab79eee8443a4d7c85502a"", ""e12d9e77a6fd531a22325337838a841b1c67f00d"", ""74e9de5ec97dc013a52aa063dff0f40ac74c407b""]","[""refactor"", ""feat"", ""docs"", ""cicd""]"
"added changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284remove ubuntu-latest from job title where that is the only osadded suported tuple typesAdjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.","diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false

diff --git a/src/List/Tuple.ts b/src/List/Tuple.ts
index 4c59caa..6e45503 100644
--- a/src/List/Tuple.ts
+++ b/src/List/Tuple.ts
@@ -1,15 +1,17 @@
-/** A [[Tuple]]
+import {NonNullable} from '../Object/NonNullable'
+
+/** A [[Tuple]] (supported)
  * @param A its type
- * @returns **`any[]`**
+ * @returns **`A[]`**
  * @example
  * ```ts
- * type list0 = [1, 2, 3]
- * type list1 = number[]
+ * type tuple0 = [1, 20, 42]
+ * type tuple1 = ['at', 420]
  * ```
  */
-export type Tuple = [
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-]
+export type Tuple<A = any> = NonNullable<[
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+]>

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)
",4,"[""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""74e9de5ec97dc013a52aa063dff0f40ac74c407b"", ""2954a0955ce9af6acb345ed1e8328e145ad30475"", ""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3""]","[""docs"", ""cicd"", ""refactor"", ""test""]"
ensure checksum persist flushes to diskadd spacing in comment fix lint (#8555)publish sdks after docs/buildprint errors without stacktrace,"diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);

diff --git a/src/components/nav/test/basic/app-module.ts b/src/components/nav/test/basic/app-module.ts
index 467917a..375e662 100644
--- a/src/components/nav/test/basic/app-module.ts
+++ b/src/components/nav/test/basic/app-module.ts
@@ -633,7 +633,7 @@ export class Tab3 {
   }
 
   presentModal() {
-    //this.modalCtrl.create(MyModal).present();
+    // this.modalCtrl.create(MyModal).present();
   }
 
   selectPrevious() {

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/

diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {
",4,"[""b7ce2894fd1794064bd6db4ed730bb6cb7728739"", ""af880ac5b4fecbc6c4f3d1eee0d95f326e8bd9d1"", ""6c9cb638cb4d1ecc42632fcf389c24898c5b3244"", ""d129eaf9125a967ac86c6c7276bbae6b4d50af36""]","[""test"", ""docs"", ""cicd"", ""fix""]"
"increment failing test retriescleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.add testsupdate Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909","diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 

diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:

diff --git a/Cargo.lock b/Cargo.lock
index 84d5d07..6ad05da 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -293,6 +293,7 @@ version = ""0.1.0""
 dependencies = [
  ""git-cliff-core"",
  ""log"",
+ ""pretty_assertions"",
  ""pretty_env_logger"",
  ""structopt"",
 ]
diff --git a/git-cliff-core/src/lib.rs b/git-cliff-core/src/lib.rs
index 3b18ba0..a560c94 100644
--- a/git-cliff-core/src/lib.rs
+++ b/git-cliff-core/src/lib.rs
@@ -1,6 +1,8 @@
 //! Highly customizable Changelog Generator
 #![warn(missing_docs, clippy::unwrap_used)]
 
+/// Export regex crate.
+pub use regex;
 /// Git commit.
 pub mod commit;
 /// Config file parser.
diff --git a/git-cliff/Cargo.toml b/git-cliff/Cargo.toml
index 41eb2e9..cc64b37 100644
--- a/git-cliff/Cargo.toml
+++ b/git-cliff/Cargo.toml
@@ -20,3 +20,6 @@ log = ""0.4.14""
 version = ""0.3""
 default-features = false
 features = [""suggestions"", ""color"", ""wrap_help""]
+
+[dev-dependencies]
+pretty_assertions = ""0.7""
diff --git a/git-cliff/src/changelog.rs b/git-cliff/src/changelog.rs
index 3f9e994..23ea186 100644
--- a/git-cliff/src/changelog.rs
+++ b/git-cliff/src/changelog.rs
@@ -115,3 +115,171 @@ impl<'a> Changelog<'a> {
 		Ok(())
 	}
 }
+
+#[cfg(test)]
+mod test {
+	use super::*;
+	use git_cliff_core::config::{
+		ChangelogConfig,
+		CommitParser,
+		GitConfig,
+	};
+	use git_cliff_core::regex::Regex;
+	use pretty_assertions::assert_eq;
+	use std::str;
+	#[test]
+	fn changelog_generator() -> Result<()> {
+		let config = Config {
+			changelog: ChangelogConfig {
+				header: Some(String::from(""# Changelog"")),
+				body:   String::from(
+					r#""{% if version %}
+				## Release [{{ version }}] - {{ timestamp | date(format=""%Y-%m-%d"") }}
+				({{ commit_id }}){% else %}
+				## Unreleased{% endif %}
+				{% for group, commits in commits | group_by(attribute=""group"") %}
+				### {{ group }}{% for group, commits in commits | group_by(attribute=""scope"") %}
+				#### {{ group }}{% for commit in commits %}
+				- {{ commit.message }}{% endfor %}
+				{% endfor %}{% endfor %}""#,
+				)
+				.replace(""				"", """"),
+				footer: Some(String::from(""------------"")),
+			},
+			git:       GitConfig {
+				conventional_commits: true,
+				commit_parsers:       Some(vec![
+					CommitParser {
+						message: Regex::new(""feat*"").ok(),
+						body:    None,
+						group:   Some(String::from(""New features"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new(""fix*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Bug Fixes"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new("".*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Other"")),
+						skip:    None,
+					},
+				]),
+				filter_commits:       Some(false),
+				tag_pattern:          String::new(),
+				skip_tags:            Regex::new(""v3.*"").ok(),
+			},
+		};
+		let test_release = Release {
+			version:   Some(String::from(""v1.0.0"")),
+			commits:   vec![
+				Commit::new(
+					String::from(""0bc123""),
+					String::from(""feat(app): add cool features""),
+				),
+				Commit::new(
+					String::from(""0werty""),
+					String::from(""style(ui): make good stuff""),
+				),
+				Commit::new(
+					String::from(""0w3rty""),
+					String::from(""fix(ui): fix more stuff""),
+				),
+				Commit::new(
+					String::from(""0jkl12""),
+					String::from(""chore(app): do nothing""),
+				),
+			],
+			commit_id: Some(String::from(""0bc123"")),
+			timestamp: 50000000,
+			previous:  None,
+		};
+		let releases = vec![
+			test_release.clone(),
+			Release {
+				version: Some(String::from(""v3.0.0"")),
+				commits: vec![Commit::new(
+					String::from(""n0thin""),
+					String::from(""feat(xyz): skip commit""),
+				)],
+				..Release::default()
+			},
+			Release {
+				version:   None,
+				commits:   vec![
+					Commit::new(
+						String::from(""abc123""),
+						String::from(""feat(app): add xyz""),
+					),
+					Commit::new(
+						String::from(""abc124""),
+						String::from(""docs(app): document zyx""),
+					),
+					Commit::new(String::from(""def789""), String::from(""merge #4"")),
+					Commit::new(
+						String::from(""qwerty""),
+						String::from(""fix(app): fix abc""),
+					),
+					Commit::new(
+						String::from(""hjkl12""),
+						String::from(""chore(ui): do boring stuff""),
+					),
+				],
+				commit_id: None,
+				timestamp: 1000,
+				previous:  Some(Box::new(test_release)),
+			},
+		];
+		let changelog = Changelog::new(releases, &config)?;
+		let mut out = Vec::new();
+		changelog.generate(&mut out)?;
+		assert_eq!(
+			String::from(
+				r#""# Changelog
+
+			## Unreleased
+
+			### Bug Fixes
+			#### app
+			- fix abc
+
+			### New features
+			#### app
+			- add xyz
+
+			### Other
+			#### app
+			- document zyx
+
+			#### ui
+			- do boring stuff
+
+			## Release [v1.0.0] - 1971-08-02
+			(0bc123)
+
+			### Bug Fixes
+			#### ui
+			- fix more stuff
+
+			### New features
+			#### app
+			- add cool features
+
+			### Other
+			#### app
+			- do nothing
+
+			#### ui
+			- make good stuff
+			------------
+			""#
+			)
+			.replace(""			"", """"),
+			str::from_utf8(&out).unwrap()
+		);
+		Ok(())
+	}
+}

diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })
",4,"[""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57"", ""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7"", ""8ee0611fbf0cd89abe7ae588f22e6ecb843598ea"", ""c2ee5cd5e709afd15c5565ee009a0d204403a119""]","[""cicd"", ""refactor"", ""test"", ""docs""]"
"update `cargo-make` for `v0.35.3`enable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>add benchmark for known-slow table expressionassist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 5e125e3..52d9b6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 * Fix: resizing/scrolling through heavily wrapped panes no longer hangs (https://github.com/zellij-org/zellij/pull/814)
 * Terminal compatibility: properly handle HOME/END keys in eg. vim/zsh (https://github.com/zellij-org/zellij/pull/815)
 * Fix: Typo (https://github.com/zellij-org/zellij/pull/821)
+* Fix: Update `cargo-make` instructions post `v0.35.3` (https://github.com/zellij-org/zellij/pull/819)
 
 ## [0.19.0] - 2021-10-20
 * Fix: Prevent text overwrite when scrolled up (https://github.com/zellij-org/zellij/pull/655)

diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 

diff --git a/.gitignore b/.gitignore
index 2e99ad3..eef9203 100644
--- a/.gitignore
+++ b/.gitignore
@@ -95,3 +95,4 @@ docs/backends/support_matrix.csv
 __pycache__
 tags
 .DS_Store
+prof/
diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index ac19aaf..36aed0e 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -602,3 +602,93 @@ def test_multiple_joins(benchmark, num_joins, num_columns):
         name=""t"",
     )
     benchmark(multiple_joins, table, num_joins)
+
+
+@pytest.fixture
+def customers():
+    return ibis.table(
+        dict(
+            customerid=""int32"",
+            name=""string"",
+            address=""string"",
+            citystatezip=""string"",
+            birthdate=""date"",
+            phone=""string"",
+            timezone=""string"",
+            lat=""float64"",
+            long=""float64"",
+        ),
+        name=""customers"",
+    )
+
+
+@pytest.fixture
+def orders():
+    return ibis.table(
+        dict(
+            orderid=""int32"",
+            customerid=""int32"",
+            ordered=""timestamp"",
+            shipped=""timestamp"",
+            items=""string"",
+            total=""float64"",
+        ),
+        name=""orders"",
+    )
+
+
+@pytest.fixture
+def orders_items():
+    return ibis.table(
+        dict(orderid=""int32"", sku=""string"", qty=""int32"", unit_price=""float64""),
+        name=""orders_items"",
+    )
+
+
+@pytest.fixture
+def products():
+    return ibis.table(
+        dict(
+            sku=""string"",
+            desc=""string"",
+            weight_kg=""float64"",
+            cost=""float64"",
+            dims_cm=""string"",
+        ),
+        name=""products"",
+    )
+
+
+@pytest.mark.benchmark(group=""compilation"")
+@pytest.mark.parametrize(
+    ""module"",
+    [
+        pytest.param(
+            mod,
+            marks=pytest.mark.xfail(
+                condition=mod in _XFAIL_COMPILE_BACKENDS,
+                reason=f""{mod} backend doesn't support compiling UnboundTable"",
+            ),
+        )
+        for mod in _backends
+    ],
+)
+def test_compile_with_drops(
+    benchmark, module, customers, orders, orders_items, products
+):
+    expr = (
+        customers.join(orders, ""customerid"")
+        .join(orders_items, ""orderid"")
+        .join(products, ""sku"")
+        .drop(""customerid"", ""qty"", ""total"", ""items"")
+        .drop(""dims_cm"", ""cost"")
+        .mutate(o_date=lambda t: t.shipped.date())
+        .filter(lambda t: t.ordered == t.shipped)
+    )
+
+    try:
+        mod = getattr(ibis, module)
+    except (AttributeError, ImportError) as e:
+        pytest.skip(str(e))
+    else:
+        benchmark(mod.compile, expr)

diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }
",4,"[""0cfc5633d37ea06f645649138323f1820e18bdee"", ""fd8e563cc19ca4684885d4692acee6bebcca4ada"", ""e9617f0854030e70365eb264bcb3b58078e79e9e"", ""1269431c8a3e7549f10fcbbb4b88ff625c8898b3""]","[""docs"", ""feat"", ""test"", ""build""]"
remove appear css animationdetach ViewControllers when not activeverify checkpoint listeners are notifiedautostart feature fixed,"diff --git a/src/popup/Popup.tsx b/src/popup/Popup.tsx
index d485bb6..2abc22a 100644
--- a/src/popup/Popup.tsx
+++ b/src/popup/Popup.tsx
@@ -269,7 +269,6 @@ export class Popup extends React.Component<{ t: TranslationFunction }, PopupStat
         <CSSTransition
           classNames='fade'
           in={!!currentTabUrl}
-          appear
           timeout={500}
           exit={false}
           mountOnEnter

diff --git a/ionic/components/nav/nav-controller.ts b/ionic/components/nav/nav-controller.ts
index becdd99..1cc3c31 100644
--- a/ionic/components/nav/nav-controller.ts
+++ b/ionic/components/nav/nav-controller.ts
@@ -1410,6 +1410,9 @@ export class NavController extends Ion {
       // set the ComponentRef's instance to this ViewController
       view.setInstance(component);
 
+      // remember the ChangeDetectorRef for this ViewController
+      view.setChangeDetector(hostViewRef.changeDetectorRef);
+
       // remember the ElementRef to the ion-page elementRef that was just created
       view.setPageRef(pageElementRef);
 
diff --git a/ionic/components/nav/view-controller.ts b/ionic/components/nav/view-controller.ts
index 3207fa2..069c74d 100644
--- a/ionic/components/nav/view-controller.ts
+++ b/ionic/components/nav/view-controller.ts
@@ -1,4 +1,4 @@
-import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer} from 'angular2/core';
+import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer, ChangeDetectorRef} from 'angular2/core';
 
 import {Navbar} from '../navbar/navbar';
 import {NavController, NavOptions} from './nav-controller';
@@ -33,6 +33,7 @@ export class ViewController {
   private _nbVwRef: ViewContainerRef;
   private _onDismiss: Function = null;
   private _pgRef: ElementRef;
+  private _cd: ChangeDetectorRef;
   protected _nav: NavController;
 
   /**
@@ -166,6 +167,13 @@ export class ViewController {
   /**
    * @private
    */
+  setChangeDetector(cd: ChangeDetectorRef) {
+    this._cd = cd;
+  }
+
+  /**
+   * @private
+   */
   setInstance(instance: any) {
     this.instance = instance;
   }
@@ -467,6 +475,14 @@ export class ViewController {
    * The view is about to enter and become the active view.
    */
   willEnter() {
+    if (this._cd) {
+      // ensure this has been re-attached to the change detector
+      this._cd.reattach();
+
+      // detect changes before we run any user code
+      this._cd.detectChanges();
+    }
+
     ctrlFn(this, 'onPageWillEnter');
   }
 
@@ -496,6 +512,10 @@ export class ViewController {
    */
   didLeave() {
     ctrlFn(this, 'onPageDidLeave');
+
+    // when this is not the active page
+    // we no longer need to detect changes
+    this._cd && this._cd.detach();
   }
 
   /**

diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();
",4,"[""47ef9104e4a89e80d7cc6c1950bc080841da4a7b"", ""b282e90e2cbb74559aab79eee8443a4d7c85502a"", ""e0198f74b81da3663144cfe1d971939319f82a0f"", ""bed78248c941d57ad4cc20a455147e186e97c7a1""]","[""refactor"", ""feat"", ""test"", ""fix""]"
"upgrade to Flux v0.42.0

Skips a test that requires special dependencies to pass.add riscv64gc-unknown-linux-gnuprint errors without stacktraceadd fallible peek_last_token()","diff --git a/go.mod b/go.mod
index ea705da..8c352f7 100644
--- a/go.mod
+++ b/go.mod
@@ -38,7 +38,7 @@ require (
 	github.com/hashicorp/go-msgpack v0.0.0-20150518234257-fa3f63826f7c // indirect
 	github.com/hashicorp/raft v1.0.0 // indirect
 	github.com/hashicorp/vault/api v1.0.2
-	github.com/influxdata/flux v0.41.0
+	github.com/influxdata/flux v0.42.0
 	github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6
 	github.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368
 	github.com/jessevdk/go-flags v1.4.0
diff --git a/go.sum b/go.sum
index 4bfdf4c..634a0f1 100644
--- a/go.sum
+++ b/go.sum
@@ -206,8 +206,8 @@ github.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NH
 github.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=
 github.com/influxdata/changelog v1.0.0 h1:RstJD6H48zLQj0GdE6E6k/6RPwtUjkyzIe/T1E/xuWU=
 github.com/influxdata/changelog v1.0.0/go.mod h1:uzpGWE/qehT8L426YuXwpMQub+a63vIINhIeEI9mnSM=
-github.com/influxdata/flux v0.41.0 h1:ljbWJmE+aNx8Yoqhb04gWC4sXMV87eYUxz5vjYphLLs=
-github.com/influxdata/flux v0.41.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
+github.com/influxdata/flux v0.42.0 h1:2iEG6hLHdHEJ6LgD8OSnlHS9yoVrLO1/aM4P9ERb94U=
+github.com/influxdata/flux v0.42.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
 github.com/influxdata/goreleaser v0.97.0-influx h1:jT5OrcW7WfS0e2QxfwmTBjhLvpIC9CDLRhNgZJyhj8s=
 github.com/influxdata/goreleaser v0.97.0-influx/go.mod h1:MnjA0e0Uq6ISqjG1WxxMAl+3VS1QYjILSWVnMYDxasE=
 github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6 h1:CFx+pP90q/qg3spoiZjf8donE4WpAdjeJfPOcoNqkWo=
diff --git a/query/stdlib/testing/testing.go b/query/stdlib/testing/testing.go
index d41574a..85b0673 100644
--- a/query/stdlib/testing/testing.go
+++ b/query/stdlib/testing/testing.go
@@ -98,4 +98,6 @@ var FluxEndToEndSkipList = map[string]string{
 	""http_endpoint"": ""need ability to test side effects in e2e tests: (https://github.com/influxdata/flux/issues/1723)"",
 
 	""holt_winters_panic"": ""Expected output is an empty table which breaks the testing framework (https://github.com/influxdata/influxdb/issues/14749)"",
+
+	""secrets"": ""Cannot inject custom deps into the test framework so the secrets don't lookup correctly"",
 }

diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }

diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {

diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.
",4,"[""454003841aabeb74396d73541378bfa59c75b5db"", ""173553c0372e66e03bdab19e0e6c2dd44daa14a0"", ""d129eaf9125a967ac86c6c7276bbae6b4d50af36"", ""63eab619e6166eb6cab948028a7b89bf059dd878""]","[""build"", ""cicd"", ""fix"", ""refactor""]"
"add benchmark for known-slow table expressionadded suported tuple typesupdate Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909buffer assert and bpmn model api helper class

related to camunda-tngp/camunda-tngp#23","diff --git a/.gitignore b/.gitignore
index 2e99ad3..eef9203 100644
--- a/.gitignore
+++ b/.gitignore
@@ -95,3 +95,4 @@ docs/backends/support_matrix.csv
 __pycache__
 tags
 .DS_Store
+prof/
diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index ac19aaf..36aed0e 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -602,3 +602,93 @@ def test_multiple_joins(benchmark, num_joins, num_columns):
         name=""t"",
     )
     benchmark(multiple_joins, table, num_joins)
+
+
+@pytest.fixture
+def customers():
+    return ibis.table(
+        dict(
+            customerid=""int32"",
+            name=""string"",
+            address=""string"",
+            citystatezip=""string"",
+            birthdate=""date"",
+            phone=""string"",
+            timezone=""string"",
+            lat=""float64"",
+            long=""float64"",
+        ),
+        name=""customers"",
+    )
+
+
+@pytest.fixture
+def orders():
+    return ibis.table(
+        dict(
+            orderid=""int32"",
+            customerid=""int32"",
+            ordered=""timestamp"",
+            shipped=""timestamp"",
+            items=""string"",
+            total=""float64"",
+        ),
+        name=""orders"",
+    )
+
+
+@pytest.fixture
+def orders_items():
+    return ibis.table(
+        dict(orderid=""int32"", sku=""string"", qty=""int32"", unit_price=""float64""),
+        name=""orders_items"",
+    )
+
+
+@pytest.fixture
+def products():
+    return ibis.table(
+        dict(
+            sku=""string"",
+            desc=""string"",
+            weight_kg=""float64"",
+            cost=""float64"",
+            dims_cm=""string"",
+        ),
+        name=""products"",
+    )
+
+
+@pytest.mark.benchmark(group=""compilation"")
+@pytest.mark.parametrize(
+    ""module"",
+    [
+        pytest.param(
+            mod,
+            marks=pytest.mark.xfail(
+                condition=mod in _XFAIL_COMPILE_BACKENDS,
+                reason=f""{mod} backend doesn't support compiling UnboundTable"",
+            ),
+        )
+        for mod in _backends
+    ],
+)
+def test_compile_with_drops(
+    benchmark, module, customers, orders, orders_items, products
+):
+    expr = (
+        customers.join(orders, ""customerid"")
+        .join(orders_items, ""orderid"")
+        .join(products, ""sku"")
+        .drop(""customerid"", ""qty"", ""total"", ""items"")
+        .drop(""dims_cm"", ""cost"")
+        .mutate(o_date=lambda t: t.shipped.date())
+        .filter(lambda t: t.ordered == t.shipped)
+    )
+
+    try:
+        mod = getattr(ibis, module)
+    except (AttributeError, ImportError) as e:
+        pytest.skip(str(e))
+    else:
+        benchmark(mod.compile, expr)

diff --git a/src/List/Tuple.ts b/src/List/Tuple.ts
index 4c59caa..6e45503 100644
--- a/src/List/Tuple.ts
+++ b/src/List/Tuple.ts
@@ -1,15 +1,17 @@
-/** A [[Tuple]]
+import {NonNullable} from '../Object/NonNullable'
+
+/** A [[Tuple]] (supported)
  * @param A its type
- * @returns **`any[]`**
+ * @returns **`A[]`**
  * @example
  * ```ts
- * type list0 = [1, 2, 3]
- * type list1 = number[]
+ * type tuple0 = [1, 20, 42]
+ * type tuple1 = ['at', 420]
  * ```
  */
-export type Tuple = [
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-]
+export type Tuple<A = any> = NonNullable<[
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+]>

diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })

diff --git a/test-util/pom.xml b/test-util/pom.xml
index a097651..b6518ee 100644
--- a/test-util/pom.xml
+++ b/test-util/pom.xml
@@ -20,6 +20,7 @@
     <project.build.sourceEncoding>utf-8</project.build.sourceEncoding>
     <!-- TODO: Move to common parent -->
     <agrona.version>0.4.11</agrona.version>
+    <camunda.version>7.6.0-SNAPSHOT</camunda.version>
   </properties>
 
   <dependencies>
@@ -30,6 +31,13 @@
       <version>${agrona.version}</version>
       <scope>provided</scope>
     </dependency>
+    
+    <dependency>
+      <groupId>org.camunda.bpm.model</groupId>
+      <artifactId>camunda-bpmn-model</artifactId>
+      <version>${camunda.version}</version>
+      <scope>provided</scope>
+    </dependency>
 
     <dependency>
       <groupId>junit</groupId>
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
index 37e3a6f..b8d9b26 100644
--- a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
@@ -14,7 +14,7 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         super(actual, BufferAssert.class);
     }
 
-    public static BufferAssert assertThat(DirectBuffer buffer)
+    public static BufferAssert assertThatBuffer(DirectBuffer buffer)
     {
         return new BufferAssert(buffer);
     }
@@ -41,4 +41,16 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         return hasBytes(expected, 0);
     }
 
+    public BufferAssert hasCapacity(int expectedCapacity)
+    {
+        isNotNull();
+
+        if (expectedCapacity != actual.capacity())
+        {
+            failWithMessage(""Expected capacity "" + expectedCapacity + "" but was "" + actual.capacity());
+        }
+
+        return this;
+    }
+
 }
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
new file mode 100644
index 0000000..6f0d134
--- /dev/null
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
@@ -0,0 +1,121 @@
+package org.camunda.tngp.broker.test.util.bpmn;
+
+import java.util.Collection;
+
+import org.camunda.bpm.model.bpmn.BpmnModelInstance;
+import org.camunda.bpm.model.bpmn.impl.BpmnModelConstants;
+import org.camunda.bpm.model.bpmn.instance.Definitions;
+import org.camunda.bpm.model.xml.Model;
+import org.camunda.bpm.model.xml.instance.DomDocument;
+import org.camunda.bpm.model.xml.instance.ModelElementInstance;
+import org.camunda.bpm.model.xml.type.ModelElementType;
+import org.camunda.bpm.model.xml.validation.ModelElementValidator;
+import org.camunda.bpm.model.xml.validation.ValidationResults;
+
+public class TngpModelInstance implements BpmnModelInstance
+{
+    protected BpmnModelInstance wrappedInstance;
+
+    public TngpModelInstance(BpmnModelInstance wrappedInstance)
+    {
+        this.wrappedInstance = wrappedInstance;
+    }
+
+    @Override
+    public DomDocument getDocument()
+    {
+        return wrappedInstance.getDocument();
+    }
+
+    @Override
+    public ModelElementInstance getDocumentElement()
+    {
+        return wrappedInstance.getDocumentElement();
+    }
+
+    @Override
+    public void setDocumentElement(ModelElementInstance documentElement)
+    {
+        wrappedInstance.setDocumentElement(documentElement);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(Class<T> type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(ModelElementType type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public Model getModel()
+    {
+        return wrappedInstance.getModel();
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T getModelElementById(String id)
+    {
+        return wrappedInstance.getModelElementById(id);
+    }
+
+    @Override
+    public Collection<ModelElementInstance> getModelElementsByType(ModelElementType referencingType)
+    {
+        return wrappedInstance.getModelElementsByType(referencingType);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> Collection<T> getModelElementsByType(Class<T> referencingClass)
+    {
+        return wrappedInstance.getModelElementsByType(referencingClass);
+    }
+
+    @Override
+    public ValidationResults validate(Collection<ModelElementValidator<?>> validators)
+    {
+        return wrappedInstance.validate(validators);
+    }
+
+    @Override
+    public BpmnModelInstance clone()
+    {
+        return wrappedInstance.clone();
+    }
+
+    @Override
+    public Definitions getDefinitions()
+    {
+        return wrappedInstance.getDefinitions();
+    }
+
+    @Override
+    public void setDefinitions(Definitions arg0)
+    {
+        wrappedInstance.setDefinitions(arg0);
+    }
+
+    public TngpModelInstance taskAttributes(String taskId, String taskType, int taskQueueId)
+    {
+        final ModelElementInstance task = wrappedInstance.getModelElementById(taskId);
+
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskType"", taskType);
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskQueueId"", String.valueOf(taskQueueId));
+
+        return this;
+    }
+
+    public static TngpModelInstance wrap(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance);
+    }
+
+    public static TngpModelInstance wrapCopy(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance.clone());
+    }
+}
",4,"[""e9617f0854030e70365eb264bcb3b58078e79e9e"", ""2954a0955ce9af6acb345ed1e8328e145ad30475"", ""c2ee5cd5e709afd15c5565ee009a0d204403a119"", ""6ed56ce9ae743ba9a87e6c9643cc06b1de7b748d""]","[""test"", ""refactor"", ""docs"", ""feat""]"
"upgrade to Flux v0.42.0

Skips a test that requires special dependencies to pass.small error msg improvement

refs #1005use `regexp_instr != 0` instead of `REGEXP` keywordrun pyspark tests in parallel","diff --git a/go.mod b/go.mod
index ea705da..8c352f7 100644
--- a/go.mod
+++ b/go.mod
@@ -38,7 +38,7 @@ require (
 	github.com/hashicorp/go-msgpack v0.0.0-20150518234257-fa3f63826f7c // indirect
 	github.com/hashicorp/raft v1.0.0 // indirect
 	github.com/hashicorp/vault/api v1.0.2
-	github.com/influxdata/flux v0.41.0
+	github.com/influxdata/flux v0.42.0
 	github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6
 	github.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368
 	github.com/jessevdk/go-flags v1.4.0
diff --git a/go.sum b/go.sum
index 4bfdf4c..634a0f1 100644
--- a/go.sum
+++ b/go.sum
@@ -206,8 +206,8 @@ github.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NH
 github.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=
 github.com/influxdata/changelog v1.0.0 h1:RstJD6H48zLQj0GdE6E6k/6RPwtUjkyzIe/T1E/xuWU=
 github.com/influxdata/changelog v1.0.0/go.mod h1:uzpGWE/qehT8L426YuXwpMQub+a63vIINhIeEI9mnSM=
-github.com/influxdata/flux v0.41.0 h1:ljbWJmE+aNx8Yoqhb04gWC4sXMV87eYUxz5vjYphLLs=
-github.com/influxdata/flux v0.41.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
+github.com/influxdata/flux v0.42.0 h1:2iEG6hLHdHEJ6LgD8OSnlHS9yoVrLO1/aM4P9ERb94U=
+github.com/influxdata/flux v0.42.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
 github.com/influxdata/goreleaser v0.97.0-influx h1:jT5OrcW7WfS0e2QxfwmTBjhLvpIC9CDLRhNgZJyhj8s=
 github.com/influxdata/goreleaser v0.97.0-influx/go.mod h1:MnjA0e0Uq6ISqjG1WxxMAl+3VS1QYjILSWVnMYDxasE=
 github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6 h1:CFx+pP90q/qg3spoiZjf8donE4WpAdjeJfPOcoNqkWo=
diff --git a/query/stdlib/testing/testing.go b/query/stdlib/testing/testing.go
index d41574a..85b0673 100644
--- a/query/stdlib/testing/testing.go
+++ b/query/stdlib/testing/testing.go
@@ -98,4 +98,6 @@ var FluxEndToEndSkipList = map[string]string{
 	""http_endpoint"": ""need ability to test side effects in e2e tests: (https://github.com/influxdata/flux/issues/1723)"",
 
 	""holt_winters_panic"": ""Expected output is an empty table which breaks the testing framework (https://github.com/influxdata/influxdb/issues/14749)"",
+
+	""secrets"": ""Cannot inject custom deps into the test framework so the secrets don't lookup correctly"",
 }

diff --git a/internal/pipe/git/errors.go b/internal/pipe/git/errors.go
index a8c15d5..13dfb56 100644
--- a/internal/pipe/git/errors.go
+++ b/internal/pipe/git/errors.go
@@ -11,7 +11,7 @@ type ErrDirty struct {
 }
 
 func (e ErrDirty) Error() string {
-	return fmt.Sprintf(""git is currently in a dirty state:\n%v"", e.status)
+	return fmt.Sprintf(""git is currently in a dirty state, please check in your pipeline what can be changing the following files:\n%v"", e.status)
 }
 
 // ErrWrongRef happens when the HEAD reference is different from the tag being built

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index e23088e..9708157 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -202,11 +202,11 @@ jobs:
         run: poetry install --without dev --without docs --extras ${{ matrix.backend.name }} --extras geospatial
 
       - name: ""run parallel tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name != 'pyspark' && matrix.backend.name != 'impala'
+        if: matrix.backend.name != 'impala'
         run: just ci-check -m ${{ matrix.backend.name }} --numprocesses auto --dist=loadgroup
 
       - name: ""run serial tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name == 'pyspark' || matrix.backend.name == 'impala'
+        if: matrix.backend.name == 'impala'
         run: just ci-check -m ${{ matrix.backend.name }}
         env:
           IBIS_TEST_NN_HOST: localhost
",4,"[""454003841aabeb74396d73541378bfa59c75b5db"", ""a62314d9bb632be6af026686615d14b912250512"", ""06e2be4e2019b6fa714e1fcb34485860ef1ede79"", ""4cbbd2552ba0de273e1dfe7d453c5b3efed751a3""]","[""build"", ""refactor"", ""fix"", ""cicd""]"
detach ViewControllers when not activeskip flaky testadd fallible peek_last_token()publish sdks after docs/build,"diff --git a/ionic/components/nav/nav-controller.ts b/ionic/components/nav/nav-controller.ts
index becdd99..1cc3c31 100644
--- a/ionic/components/nav/nav-controller.ts
+++ b/ionic/components/nav/nav-controller.ts
@@ -1410,6 +1410,9 @@ export class NavController extends Ion {
       // set the ComponentRef's instance to this ViewController
       view.setInstance(component);
 
+      // remember the ChangeDetectorRef for this ViewController
+      view.setChangeDetector(hostViewRef.changeDetectorRef);
+
       // remember the ElementRef to the ion-page elementRef that was just created
       view.setPageRef(pageElementRef);
 
diff --git a/ionic/components/nav/view-controller.ts b/ionic/components/nav/view-controller.ts
index 3207fa2..069c74d 100644
--- a/ionic/components/nav/view-controller.ts
+++ b/ionic/components/nav/view-controller.ts
@@ -1,4 +1,4 @@
-import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer} from 'angular2/core';
+import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer, ChangeDetectorRef} from 'angular2/core';
 
 import {Navbar} from '../navbar/navbar';
 import {NavController, NavOptions} from './nav-controller';
@@ -33,6 +33,7 @@ export class ViewController {
   private _nbVwRef: ViewContainerRef;
   private _onDismiss: Function = null;
   private _pgRef: ElementRef;
+  private _cd: ChangeDetectorRef;
   protected _nav: NavController;
 
   /**
@@ -166,6 +167,13 @@ export class ViewController {
   /**
    * @private
    */
+  setChangeDetector(cd: ChangeDetectorRef) {
+    this._cd = cd;
+  }
+
+  /**
+   * @private
+   */
   setInstance(instance: any) {
     this.instance = instance;
   }
@@ -467,6 +475,14 @@ export class ViewController {
    * The view is about to enter and become the active view.
    */
   willEnter() {
+    if (this._cd) {
+      // ensure this has been re-attached to the change detector
+      this._cd.reattach();
+
+      // detect changes before we run any user code
+      this._cd.detectChanges();
+    }
+
     ctrlFn(this, 'onPageWillEnter');
   }
 
@@ -496,6 +512,10 @@ export class ViewController {
    */
   didLeave() {
     ctrlFn(this, 'onPageDidLeave');
+
+    // when this is not the active page
+    // we no longer need to detect changes
+    this._cd && this._cd.detach();
   }
 
   /**

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method

diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/
",4,"[""b282e90e2cbb74559aab79eee8443a4d7c85502a"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d"", ""63eab619e6166eb6cab948028a7b89bf059dd878"", ""6c9cb638cb4d1ecc42632fcf389c24898c5b3244""]","[""feat"", ""test"", ""refactor"", ""cicd""]"
"update `cargo-make` for `v0.35.3`wrong icon reference

Signed-off-by: Pranav C <pranavxc@gmail.com>skip flaky testget tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 5e125e3..52d9b6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 * Fix: resizing/scrolling through heavily wrapped panes no longer hangs (https://github.com/zellij-org/zellij/pull/814)
 * Terminal compatibility: properly handle HOME/END keys in eg. vim/zsh (https://github.com/zellij-org/zellij/pull/815)
 * Fix: Typo (https://github.com/zellij-org/zellij/pull/821)
+* Fix: Update `cargo-make` instructions post `v0.35.3` (https://github.com/zellij-org/zellij/pull/819)
 
 ## [0.19.0] - 2021-10-20
 * Fix: Prevent text overwrite when scrolled up (https://github.com/zellij-org/zellij/pull/655)

diff --git a/packages/nc-gui/components.d.ts b/packages/nc-gui/components.d.ts
index b7e6585..bb86478 100644
--- a/packages/nc-gui/components.d.ts
+++ b/packages/nc-gui/components.d.ts
@@ -81,7 +81,6 @@ declare module '@vue/runtime-core' {
     ClaritySuccessLine: typeof import('~icons/clarity/success-line')['default']
     EvaEmailOutline: typeof import('~icons/eva/email-outline')['default']
     IcBaselineMoreVert: typeof import('~icons/ic/baseline-more-vert')['default']
-    Icon: typeof import('~icons/ic/on')['default']
     IcOutlineInsertDriveFile: typeof import('~icons/ic/outline-insert-drive-file')['default']
     IcRoundEdit: typeof import('~icons/ic/round-edit')['default']
     IcRoundKeyboardArrowDown: typeof import('~icons/ic/round-keyboard-arrow-down')['default']

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }
",4,"[""0cfc5633d37ea06f645649138323f1820e18bdee"", ""d1d55e787b7d07f763852602b9939a5394607fd9"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c""]","[""docs"", ""fix"", ""test"", ""refactor""]"
remove appear css animationprint errors without stacktraceupdate `cargo-make` for `v0.35.3`do not use scripts and binaries from the libcc repo,"diff --git a/src/popup/Popup.tsx b/src/popup/Popup.tsx
index d485bb6..2abc22a 100644
--- a/src/popup/Popup.tsx
+++ b/src/popup/Popup.tsx
@@ -269,7 +269,6 @@ export class Popup extends React.Component<{ t: TranslationFunction }, PopupStat
         <CSSTransition
           classNames='fade'
           in={!!currentTabUrl}
-          appear
           timeout={500}
           exit={false}
           mountOnEnter

diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {

diff --git a/CHANGELOG.md b/CHANGELOG.md
index 5e125e3..52d9b6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 * Fix: resizing/scrolling through heavily wrapped panes no longer hangs (https://github.com/zellij-org/zellij/pull/814)
 * Terminal compatibility: properly handle HOME/END keys in eg. vim/zsh (https://github.com/zellij-org/zellij/pull/815)
 * Fix: Typo (https://github.com/zellij-org/zellij/pull/821)
+* Fix: Update `cargo-make` instructions post `v0.35.3` (https://github.com/zellij-org/zellij/pull/819)
 
 ## [0.19.0] - 2021-10-20
 * Fix: Prevent text overwrite when scrolled up (https://github.com/zellij-org/zellij/pull/655)

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |
",4,"[""47ef9104e4a89e80d7cc6c1950bc080841da4a7b"", ""d129eaf9125a967ac86c6c7276bbae6b4d50af36"", ""0cfc5633d37ea06f645649138323f1820e18bdee"", ""45837af24a33308a70a3454f0f650f9fe728e272""]","[""refactor"", ""fix"", ""docs"", ""cicd""]"
"autostart feature fixedassist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>do not use scripts and binaries from the libcc repoadd tests","diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();

diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/Cargo.lock b/Cargo.lock
index 84d5d07..6ad05da 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -293,6 +293,7 @@ version = ""0.1.0""
 dependencies = [
  ""git-cliff-core"",
  ""log"",
+ ""pretty_assertions"",
  ""pretty_env_logger"",
  ""structopt"",
 ]
diff --git a/git-cliff-core/src/lib.rs b/git-cliff-core/src/lib.rs
index 3b18ba0..a560c94 100644
--- a/git-cliff-core/src/lib.rs
+++ b/git-cliff-core/src/lib.rs
@@ -1,6 +1,8 @@
 //! Highly customizable Changelog Generator
 #![warn(missing_docs, clippy::unwrap_used)]
 
+/// Export regex crate.
+pub use regex;
 /// Git commit.
 pub mod commit;
 /// Config file parser.
diff --git a/git-cliff/Cargo.toml b/git-cliff/Cargo.toml
index 41eb2e9..cc64b37 100644
--- a/git-cliff/Cargo.toml
+++ b/git-cliff/Cargo.toml
@@ -20,3 +20,6 @@ log = ""0.4.14""
 version = ""0.3""
 default-features = false
 features = [""suggestions"", ""color"", ""wrap_help""]
+
+[dev-dependencies]
+pretty_assertions = ""0.7""
diff --git a/git-cliff/src/changelog.rs b/git-cliff/src/changelog.rs
index 3f9e994..23ea186 100644
--- a/git-cliff/src/changelog.rs
+++ b/git-cliff/src/changelog.rs
@@ -115,3 +115,171 @@ impl<'a> Changelog<'a> {
 		Ok(())
 	}
 }
+
+#[cfg(test)]
+mod test {
+	use super::*;
+	use git_cliff_core::config::{
+		ChangelogConfig,
+		CommitParser,
+		GitConfig,
+	};
+	use git_cliff_core::regex::Regex;
+	use pretty_assertions::assert_eq;
+	use std::str;
+	#[test]
+	fn changelog_generator() -> Result<()> {
+		let config = Config {
+			changelog: ChangelogConfig {
+				header: Some(String::from(""# Changelog"")),
+				body:   String::from(
+					r#""{% if version %}
+				## Release [{{ version }}] - {{ timestamp | date(format=""%Y-%m-%d"") }}
+				({{ commit_id }}){% else %}
+				## Unreleased{% endif %}
+				{% for group, commits in commits | group_by(attribute=""group"") %}
+				### {{ group }}{% for group, commits in commits | group_by(attribute=""scope"") %}
+				#### {{ group }}{% for commit in commits %}
+				- {{ commit.message }}{% endfor %}
+				{% endfor %}{% endfor %}""#,
+				)
+				.replace(""				"", """"),
+				footer: Some(String::from(""------------"")),
+			},
+			git:       GitConfig {
+				conventional_commits: true,
+				commit_parsers:       Some(vec![
+					CommitParser {
+						message: Regex::new(""feat*"").ok(),
+						body:    None,
+						group:   Some(String::from(""New features"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new(""fix*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Bug Fixes"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new("".*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Other"")),
+						skip:    None,
+					},
+				]),
+				filter_commits:       Some(false),
+				tag_pattern:          String::new(),
+				skip_tags:            Regex::new(""v3.*"").ok(),
+			},
+		};
+		let test_release = Release {
+			version:   Some(String::from(""v1.0.0"")),
+			commits:   vec![
+				Commit::new(
+					String::from(""0bc123""),
+					String::from(""feat(app): add cool features""),
+				),
+				Commit::new(
+					String::from(""0werty""),
+					String::from(""style(ui): make good stuff""),
+				),
+				Commit::new(
+					String::from(""0w3rty""),
+					String::from(""fix(ui): fix more stuff""),
+				),
+				Commit::new(
+					String::from(""0jkl12""),
+					String::from(""chore(app): do nothing""),
+				),
+			],
+			commit_id: Some(String::from(""0bc123"")),
+			timestamp: 50000000,
+			previous:  None,
+		};
+		let releases = vec![
+			test_release.clone(),
+			Release {
+				version: Some(String::from(""v3.0.0"")),
+				commits: vec![Commit::new(
+					String::from(""n0thin""),
+					String::from(""feat(xyz): skip commit""),
+				)],
+				..Release::default()
+			},
+			Release {
+				version:   None,
+				commits:   vec![
+					Commit::new(
+						String::from(""abc123""),
+						String::from(""feat(app): add xyz""),
+					),
+					Commit::new(
+						String::from(""abc124""),
+						String::from(""docs(app): document zyx""),
+					),
+					Commit::new(String::from(""def789""), String::from(""merge #4"")),
+					Commit::new(
+						String::from(""qwerty""),
+						String::from(""fix(app): fix abc""),
+					),
+					Commit::new(
+						String::from(""hjkl12""),
+						String::from(""chore(ui): do boring stuff""),
+					),
+				],
+				commit_id: None,
+				timestamp: 1000,
+				previous:  Some(Box::new(test_release)),
+			},
+		];
+		let changelog = Changelog::new(releases, &config)?;
+		let mut out = Vec::new();
+		changelog.generate(&mut out)?;
+		assert_eq!(
+			String::from(
+				r#""# Changelog
+
+			## Unreleased
+
+			### Bug Fixes
+			#### app
+			- fix abc
+
+			### New features
+			#### app
+			- add xyz
+
+			### Other
+			#### app
+			- document zyx
+
+			#### ui
+			- do boring stuff
+
+			## Release [v1.0.0] - 1971-08-02
+			(0bc123)
+
+			### Bug Fixes
+			#### ui
+			- fix more stuff
+
+			### New features
+			#### app
+			- add cool features
+
+			### Other
+			#### app
+			- do nothing
+
+			#### ui
+			- make good stuff
+			------------
+			""#
+			)
+			.replace(""			"", """"),
+			str::from_utf8(&out).unwrap()
+		);
+		Ok(())
+	}
+}
",4,"[""bed78248c941d57ad4cc20a455147e186e97c7a1"", ""1269431c8a3e7549f10fcbbb4b88ff625c8898b3"", ""45837af24a33308a70a3454f0f650f9fe728e272"", ""8ee0611fbf0cd89abe7ae588f22e6ecb843598ea""]","[""fix"", ""build"", ""cicd"", ""test""]"
"upgrade to Flux v0.42.0

Skips a test that requires special dependencies to pass.autostart feature fixeddo not use scripts and binaries from the libcc repoupdate Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909","diff --git a/go.mod b/go.mod
index ea705da..8c352f7 100644
--- a/go.mod
+++ b/go.mod
@@ -38,7 +38,7 @@ require (
 	github.com/hashicorp/go-msgpack v0.0.0-20150518234257-fa3f63826f7c // indirect
 	github.com/hashicorp/raft v1.0.0 // indirect
 	github.com/hashicorp/vault/api v1.0.2
-	github.com/influxdata/flux v0.41.0
+	github.com/influxdata/flux v0.42.0
 	github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6
 	github.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368
 	github.com/jessevdk/go-flags v1.4.0
diff --git a/go.sum b/go.sum
index 4bfdf4c..634a0f1 100644
--- a/go.sum
+++ b/go.sum
@@ -206,8 +206,8 @@ github.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NH
 github.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=
 github.com/influxdata/changelog v1.0.0 h1:RstJD6H48zLQj0GdE6E6k/6RPwtUjkyzIe/T1E/xuWU=
 github.com/influxdata/changelog v1.0.0/go.mod h1:uzpGWE/qehT8L426YuXwpMQub+a63vIINhIeEI9mnSM=
-github.com/influxdata/flux v0.41.0 h1:ljbWJmE+aNx8Yoqhb04gWC4sXMV87eYUxz5vjYphLLs=
-github.com/influxdata/flux v0.41.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
+github.com/influxdata/flux v0.42.0 h1:2iEG6hLHdHEJ6LgD8OSnlHS9yoVrLO1/aM4P9ERb94U=
+github.com/influxdata/flux v0.42.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
 github.com/influxdata/goreleaser v0.97.0-influx h1:jT5OrcW7WfS0e2QxfwmTBjhLvpIC9CDLRhNgZJyhj8s=
 github.com/influxdata/goreleaser v0.97.0-influx/go.mod h1:MnjA0e0Uq6ISqjG1WxxMAl+3VS1QYjILSWVnMYDxasE=
 github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6 h1:CFx+pP90q/qg3spoiZjf8donE4WpAdjeJfPOcoNqkWo=
diff --git a/query/stdlib/testing/testing.go b/query/stdlib/testing/testing.go
index d41574a..85b0673 100644
--- a/query/stdlib/testing/testing.go
+++ b/query/stdlib/testing/testing.go
@@ -98,4 +98,6 @@ var FluxEndToEndSkipList = map[string]string{
 	""http_endpoint"": ""need ability to test side effects in e2e tests: (https://github.com/influxdata/flux/issues/1723)"",
 
 	""holt_winters_panic"": ""Expected output is an empty table which breaks the testing framework (https://github.com/influxdata/influxdb/issues/14749)"",
+
+	""secrets"": ""Cannot inject custom deps into the test framework so the secrets don't lookup correctly"",
 }

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })
",4,"[""454003841aabeb74396d73541378bfa59c75b5db"", ""bed78248c941d57ad4cc20a455147e186e97c7a1"", ""45837af24a33308a70a3454f0f650f9fe728e272"", ""c2ee5cd5e709afd15c5565ee009a0d204403a119""]","[""build"", ""fix"", ""cicd"", ""docs""]"
"only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>restructure ClusterTopology to track completed changewrong icon reference

Signed-off-by: Pranav C <pranavxc@gmail.com>add .nullif() example","diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(

diff --git a/packages/nc-gui/components.d.ts b/packages/nc-gui/components.d.ts
index b7e6585..bb86478 100644
--- a/packages/nc-gui/components.d.ts
+++ b/packages/nc-gui/components.d.ts
@@ -81,7 +81,6 @@ declare module '@vue/runtime-core' {
     ClaritySuccessLine: typeof import('~icons/clarity/success-line')['default']
     EvaEmailOutline: typeof import('~icons/eva/email-outline')['default']
     IcBaselineMoreVert: typeof import('~icons/ic/baseline-more-vert')['default']
-    Icon: typeof import('~icons/ic/on')['default']
     IcOutlineInsertDriveFile: typeof import('~icons/ic/outline-insert-drive-file')['default']
     IcRoundEdit: typeof import('~icons/ic/round-edit')['default']
     IcRoundKeyboardArrowDown: typeof import('~icons/ic/round-keyboard-arrow-down')['default']

diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 
",4,"[""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2"", ""d1d55e787b7d07f763852602b9939a5394607fd9"", ""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21""]","[""cicd"", ""refactor"", ""fix"", ""docs""]"
"initialize threejs objects in defaultRef, to fix undefined type errorspublish sdks after docs/buildFix typomake it mode less","diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/

diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/core/src/components/slides/slides.tsx b/core/src/components/slides/slides.tsx
index 48fd53f..d5c2f75 100644
--- a/core/src/components/slides/slides.tsx
+++ b/core/src/components/slides/slides.tsx
@@ -1,7 +1,6 @@
 import { Component, Element, Event, EventEmitter, Method, Prop, Watch } from '@stencil/core';
 
 import { Mode } from '../../interface.js';
-import { createThemedClasses } from '../../utils/theme.js';
 
 import { Swiper } from './vendor/swiper.js';
 
@@ -15,6 +14,7 @@ import { Swiper } from './vendor/swiper.js';
   shadow: true
 })
 export class Slides {
+
   private container!: HTMLElement;
   private swiper: any;
 
@@ -391,12 +391,6 @@ export class Slides {
     return { ...swiperOptions, ...this.options, ...eventOptions };
   }
 
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'slides')
-    };
-  }
-
   render() {
     return (
       <div class=""swiper-container"" ref={el => this.container = el as HTMLElement }>
diff --git a/core/src/components/thumbnail/thumbnail.ios.scss b/core/src/components/thumbnail/thumbnail.ios.scss
deleted file mode 100644
index e3add45..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.ios.vars"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-ios-width};
-  --border-radius: #{$thumbnail-ios-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.ios.vars.scss b/core/src/components/thumbnail/thumbnail.ios.vars.scss
deleted file mode 100644
index 85d53e5..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.ios"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-ios-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-ios-height:                  $thumbnail-ios-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-ios-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.md.scss b/core/src/components/thumbnail/thumbnail.md.scss
deleted file mode 100644
index 0fbb2ca..0000000
--- a/core/src/components/thumbnail/thumbnail.md.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.md.vars"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-md-width};
-  --border-radius: #{$thumbnail-md-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.md.vars.scss b/core/src/components/thumbnail/thumbnail.md.vars.scss
deleted file mode 100644
index 94e48b2..0000000
--- a/core/src/components/thumbnail/thumbnail.md.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.md"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-md-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-md-height:                  $thumbnail-md-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-md-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.scss b/core/src/components/thumbnail/thumbnail.scss
index 8ac3a22..8af268d 100644
--- a/core/src/components/thumbnail/thumbnail.scss
+++ b/core/src/components/thumbnail/thumbnail.scss
@@ -9,6 +9,8 @@
    * @prop --border-radius: Border radius of the thumbnail
    * @prop --size: Size of the thumbnail
    */
+  --size: 48px;
+  --border-radius: 0;
 
   @include border-radius(var(--border-radius));
 
diff --git a/core/src/components/thumbnail/thumbnail.tsx b/core/src/components/thumbnail/thumbnail.tsx
index 50ff2c2..de76593 100644
--- a/core/src/components/thumbnail/thumbnail.tsx
+++ b/core/src/components/thumbnail/thumbnail.tsx
@@ -1,25 +1,11 @@
 import { Component } from '@stencil/core';
 
-import { Mode } from '../../interface';
-import { createThemedClasses } from '../../utils/theme';
-
 @Component({
   tag: 'ion-thumbnail',
-  styleUrls: {
-    ios: 'thumbnail.ios.scss',
-    md: 'thumbnail.md.scss'
-  },
+  styleUrl: 'thumbnail.scss',
   shadow: true
 })
 export class Thumbnail {
-  mode!: Mode;
-
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'thumbnail')
-    };
-  }
-
   render() {
     return <slot></slot>;
   }
",4,"[""2561f4ade46fc9d59f289f328cc77733a6443697"", ""6c9cb638cb4d1ecc42632fcf389c24898c5b3244"", ""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""771857b1df9470ebc15357e8879118a72c649d5b""]","[""fix"", ""cicd"", ""docs"", ""refactor""]"
"use `regexp_instr != 0` instead of `REGEXP` keywordenable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>updated react demo parcel commandadd .nullif() example","diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(

diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 

diff --git a/demo/react/package.json b/demo/react/package.json
index be28bf9..32d0952 100644
--- a/demo/react/package.json
+++ b/demo/react/package.json
@@ -12,7 +12,7 @@
   },
   ""scripts"": {
     ""start"": ""parcel serve public/index.html --no-cache --open"",
-    ""build"": ""parcel build -t browser -d dist public/index.html --no-source-maps""
+    ""build"": ""parcel build --target browser --dist-dir dist public/index.html --no-source-maps""
   },
   ""bugs"": {
     ""url"": ""https://github.com/matteobruni/tsparticles/issues""

diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 
",4,"[""06e2be4e2019b6fa714e1fcb34485860ef1ede79"", ""fd8e563cc19ca4684885d4692acee6bebcca4ada"", ""32b92cfa0b74a6c25990e32ac6aab12b8496794c"", ""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21""]","[""fix"", ""feat"", ""build"", ""docs""]"
"spring version, core versiondo not use scripts and binaries from the libcc repoensure checksum persist flushes to diskadd getter for protocol id","diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);

diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }
",4,"[""c55591ba157298a9c5816693c102a89dfd058830"", ""45837af24a33308a70a3454f0f650f9fe728e272"", ""b7ce2894fd1794064bd6db4ed730bb6cb7728739"", ""dc5238b2bda98a7c4f2fe9584fc3b0191a408109""]","[""build"", ""cicd"", ""test"", ""feat""]"
"add riscv64gc-unknown-linux-gnunginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>Add ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>setup jest and add m.ts tests","diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });
",4,"[""173553c0372e66e03bdab19e0e6c2dd44daa14a0"", ""e12d9e77a6fd531a22325337838a841b1c67f00d"", ""f823cf28652987d43c8324b4f5b203240032383a"", ""229b53a632ea97d47c4be11f096bdd828fb415d8""]","[""cicd"", ""docs"", ""feat"", ""test""]"
"cleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.added changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>setup jest and add m.ts tests","diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:

diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });
",4,"[""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7"", ""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""229b53a632ea97d47c4be11f096bdd828fb415d8""]","[""refactor"", ""docs"", ""cicd"", ""test""]"
"update `cargo-make` for `v0.35.3`convert `run_tag_values_test_case` to a functionsetup jest and add m.ts testsfix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 5e125e3..52d9b6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 * Fix: resizing/scrolling through heavily wrapped panes no longer hangs (https://github.com/zellij-org/zellij/pull/814)
 * Terminal compatibility: properly handle HOME/END keys in eg. vim/zsh (https://github.com/zellij-org/zellij/pull/815)
 * Fix: Typo (https://github.com/zellij-org/zellij/pull/821)
+* Fix: Update `cargo-make` instructions post `v0.35.3` (https://github.com/zellij-org/zellij/pull/819)
 
 ## [0.19.0] - 2021-10-20
 * Fix: Prevent text overwrite when scrolled up (https://github.com/zellij-org/zellij/pull/655)

diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });

diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 
",4,"[""0cfc5633d37ea06f645649138323f1820e18bdee"", ""1db13ec43727aca872a0f3836e4023ed85db665e"", ""229b53a632ea97d47c4be11f096bdd828fb415d8"", ""9be725fa3906323d4bc9788f54eccf74109d632b""]","[""docs"", ""refactor"", ""test"", ""fix""]"
"add a branch name to Slack notifications (#14793)Fix typoget tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.xfail on to_parquet and to_csv that use pyarrow write options","diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'

diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }

diff --git a/ibis/backends/tests/test_export.py b/ibis/backends/tests/test_export.py
index 4d536d7..5bb9775 100644
--- a/ibis/backends/tests/test_export.py
+++ b/ibis/backends/tests/test_export.py
@@ -222,18 +222,23 @@ def test_table_to_parquet(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs""), [({""version"": ""1.0""}), ({""version"": ""2.6""})])
-def test_table_to_parquet_writer_kwargs(kwargs, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.NotSupportedError,
+)
+@pytest.mark.parametrize(""version"", [""1.0"", ""2.6""])
+def test_table_to_parquet_writer_kwargs(version, tmp_path, backend, awards_players):
     outparquet = tmp_path / ""out.parquet""
-    awards_players.to_parquet(outparquet, **kwargs)
+    awards_players.to_parquet(outparquet, version=version)
 
     df = pd.read_parquet(outparquet)
 
     backend.assert_frame_equal(awards_players.to_pandas(), df)
 
-    file = pa.parquet.ParquetFile(outparquet)
+    md = pa.parquet.read_metadata(outparquet)
 
-    assert file.metadata.format_version == kwargs[""version""]
+    assert md.format_version == version
 
 
 @pytest.mark.notimpl(
@@ -316,14 +321,20 @@ def test_table_to_csv(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs"", ""delimiter""), [({""write_options"": pcsv.WriteOptions(delimiter="";"")}, "";""), ({""write_options"": pcsv.WriteOptions(delimiter=""\t"")}, ""\t"")])
-def test_table_to_csv_writer_kwargs(kwargs, delimiter, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.ProgrammingError,
+)
+@pytest.mark.parametrize(""delimiter"", ["";"", ""\t""], ids=[""semicolon"", ""tab""])
+def test_table_to_csv_writer_kwargs(delimiter, tmp_path, awards_players):
     outcsv = tmp_path / ""out.csv""
     # avoid pandas NaNonense
     awards_players = awards_players.select(""playerID"", ""awardID"", ""yearID"", ""lgID"")
 
-    awards_players.to_csv(outcsv, **kwargs)
-    pd.read_csv(outcsv, delimiter=delimiter)
+    awards_players.to_csv(outcsv, write_options=pcsv.WriteOptions(delimiter=delimiter))
+    df = pd.read_csv(outcsv, delimiter=delimiter, nrows=1)
+    assert len(df) == 1
 
 
 @pytest.mark.parametrize(
",4,"[""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da"", ""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c"", ""bedc7950b24c37809e36a585b7985d5aa5e3e458""]","[""cicd"", ""docs"", ""refactor"", ""test""]"
"fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.add comments for the Handlerdo not use scripts and binaries from the libcc repoAdd ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>","diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}
",4,"[""9be725fa3906323d4bc9788f54eccf74109d632b"", ""036a0ff49a7dade0e04c9c07071a1ff49133ee24"", ""45837af24a33308a70a3454f0f650f9fe728e272"", ""f823cf28652987d43c8324b4f5b203240032383a""]","[""fix"", ""docs"", ""cicd"", ""feat""]"
"Fix typoverify checkpoint listeners are notifiedfix netty dependency

netty-bom 4.1.70 contains the changes from pull request
https://github.com/netty/netty/pull/11798, which moved the classes out
of the native modules to make sure the same classes don't end up on the
classpath multiple times. For us it means that we need to depend on both
the native and classes modules. However, since we don't use the native
module directly (only classes that were moved to this classes module),
we need to force the dependency plugin to consider the native module as
used.add props to get color and label from a route","diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }

diff --git a/atomix/cluster/pom.xml b/atomix/cluster/pom.xml
index a477873..b6db695 100644
--- a/atomix/cluster/pom.xml
+++ b/atomix/cluster/pom.xml
@@ -69,6 +69,10 @@
     </dependency>
     <dependency>
       <groupId>io.netty</groupId>
+      <artifactId>netty-transport-classes-epoll</artifactId>
+    </dependency>
+    <dependency>
+      <groupId>io.netty</groupId>
       <artifactId>netty-transport-native-epoll</artifactId>
       <classifier>linux-x86_64</classifier>
     </dependency>
@@ -278,6 +282,7 @@
             <dependency>uk.co.real-logic:sbe-tool</dependency>
             <dependency>net.jqwik:jqwik</dependency>
             <dependency>io.netty:netty-tcnative-boringssl-static</dependency>
+            <dependency>io.netty:netty-transport-native-epoll</dependency>
           </usedDependencies>
         </configuration>
       </plugin>

diff --git a/src/components/BottomNavigation.js b/src/components/BottomNavigation.js
index 1b72302..7d8ea75 100644
--- a/src/components/BottomNavigation.js
+++ b/src/components/BottomNavigation.js
@@ -24,8 +24,8 @@ const AnimatedPaper = Animated.createAnimatedComponent(Paper);
 
 type Route = {
   key: string,
-  title: string,
-  icon: IconSource,
+  title?: string,
+  icon?: IconSource,
   color?: string,
 };
 
@@ -51,7 +51,7 @@ type Props<T> = {
    * - `key`: a unique key to identify the route
    * - `title`: title of the route to use as the tab label
    * - `icon`: icon to use as the tab icon, can be a string, an image source or a react component
-   * - `color`: color to use as background color for shifting bottom navigation (optional)
+   * - `color`: color to use as background color for shifting bottom navigation
    *
    * Example:
    *
@@ -115,11 +115,27 @@ type Props<T> = {
   /**
    * Callback which returns a React Element to be used as tab icon.
    */
-  renderIcon?: (props: { route: T, focused: boolean }) => React.Node,
+  renderIcon?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
   /**
    * Callback which React Element to be used as tab label.
    */
-  renderLabel?: (props: { route: T, focused: boolean }) => React.Node,
+  renderLabel?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
+  /**
+   * Get label text for the tab, uses `route.title` by default. Use `renderLabel` to replace label component.
+   */
+  getLabelText?: (props: { route: T }) => string,
+  /**
+   * Get color for the tab, uses `route.color` by default.
+   */
+  getColor?: (props: { route: T }) => string,
   /**
    * Function to execute on tab press. It receives the route for the pressed tab, useful for things like scroll to top.
    */
@@ -159,6 +175,10 @@ type State = {
    */
   ripple: Animated.Value,
   /**
+   * Animation for the touch feedback, used to determine it's scale and opacity.
+   */
+  touch: Animated.Value,
+  /**
    * Layout of the tab bar. The width is used to determine the size and position of the ripple.
    */
   layout: { height: number, width: number, measured: boolean },
@@ -173,7 +193,7 @@ const MIN_SHIFT_AMOUNT = 10;
 const MIN_TAB_WIDTH = 96;
 const MAX_TAB_WIDTH = 168;
 const BAR_HEIGHT = 56;
-const SMALL_RIPPLE_SIZE = 72;
+const SMALL_RIPPLE_SIZE = 96;
 const ACTIVE_LABEL_SIZE = 14;
 const INACTIVE_LABEL_SIZE = 12;
 
@@ -251,6 +271,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ),
       index: new Animated.Value(index),
       ripple: new Animated.Value(MIN_RIPPLE_SCALE),
+      touch: new Animated.Value(MIN_RIPPLE_SCALE),
       layout: { height: 0, width: 0, measured: false },
       previous: 0,
     };
@@ -349,6 +370,15 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
   _handleTabPress = (index: number) => {
     const { navigationState } = this.props;
 
+    this.state.touch.setValue(MIN_RIPPLE_SCALE);
+
+    Animated.timing(this.state.touch, {
+      toValue: 1,
+      duration: 300,
+      easing: Easing.in(Easing.sin),
+      useNativeDriver: true,
+    }).start();
+
     if (index !== navigationState.index) {
       this.props.onIndexChange(index);
     }
@@ -376,6 +406,8 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       renderScene,
       renderIcon,
       renderLabel,
+      getLabelText = ({ route }) => route.title,
+      getColor = ({ route }) => route.color,
       barStyle,
       style,
       theme,
@@ -400,7 +432,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ? this.state.index.interpolate({
           inputRange: routes.map((_, i) => i),
           outputRange: routes.map(
-            route => route.color || approxBackgroundColor
+            route => getColor({ route }) || approxBackgroundColor
           ),
         })
       : approxBackgroundColor;
@@ -416,7 +448,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
           .rgb()
           .string();
 
-    const rippleColor = color(textColor)
+    const touchColor = color(textColor)
       .alpha(0.12)
       .rgb()
       .string();
@@ -430,22 +462,10 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
 
     // Since we have a single ripple, we have to reposition it so that it appears to expand from active tab.
     // We need to move it from the left to the active tab and also account for how much that tab has shifted.
-    const rippleShift =
-      navigationState.index * tabWidth +
-      tabWidth / 2 +
-      this._calculateShift(
-        this.state.previous,
-        navigationState.index,
-        routes.length
-      );
 
     return (
       <View
-        style={[
-          styles.container,
-          { backgroundColor: theme.dark ? white : black },
-          style,
-        ]}
+        style={[styles.container, style]}
         onLayout={this._handleLayout}
         pointerEvents={layout.measured ? 'auto' : 'none'}
       >
@@ -485,25 +505,30 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
             style={[styles.items, { maxWidth: maxTabWidth * routes.length }]}
           >
             {shifting ? (
-              // Large ripple with the backround color
               <Animated.View
                 pointerEvents=""none""
                 style={[
                   styles.ripple,
                   {
                     // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - layout.width / 2,
-                    left: rippleShift - layout.width / 2,
-                    height: layout.width,
-                    width: layout.width,
+                    top: BAR_HEIGHT / 2 - layout.width / 8,
+                    left:
+                      navigationState.index * tabWidth +
+                      tabWidth / 2 -
+                      layout.width / 8,
+                    height: layout.width / 4,
+                    width: layout.width / 4,
                     borderRadius: layout.width / 2,
-                    backgroundColor: routes[navigationState.index].color,
+                    backgroundColor: getColor({
+                      route: routes[navigationState.index],
+                    }),
                     transform: [
+                      { translateX: this.state.shifts[navigationState.index] },
                       {
                         // Scale to twice the size  to ensure it covers the whole tab bar
                         scale: this.state.ripple.interpolate({
                           inputRange: [0, 1],
-                          outputRange: [0, 2],
+                          outputRange: [0, 8],
                         }),
                       },
                     ],
@@ -515,36 +540,36 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                 ]}
               />
             ) : null}
-            {shifting ? (
-              // Small subtle ripple on touch
-              <Animated.View
-                pointerEvents=""none""
-                style={[
-                  styles.ripple,
-                  {
-                    // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
-                    left: rippleShift - SMALL_RIPPLE_SIZE / 2,
-                    height: SMALL_RIPPLE_SIZE,
-                    width: SMALL_RIPPLE_SIZE,
-                    borderRadius: SMALL_RIPPLE_SIZE / 2,
-                    backgroundColor: rippleColor,
-                    transform: [
-                      {
-                        scale: this.state.ripple.interpolate({
-                          inputRange: [0, 0.5, 1],
-                          outputRange: [0, 1, 1],
-                        }),
-                      },
-                    ],
-                    opacity: this.state.ripple.interpolate({
-                      inputRange: [0, MIN_RIPPLE_SCALE, 0.25, 0.5],
-                      outputRange: [0, 0, 1, 0],
-                    }),
-                  },
-                ]}
-              />
-            ) : null}
+            <Animated.View
+              pointerEvents=""none""
+              style={[
+                styles.ripple,
+                {
+                  // Set top and left values so that the ripple's center is same as the tab's center
+                  top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
+                  left:
+                    navigationState.index * tabWidth +
+                    tabWidth / 2 -
+                    SMALL_RIPPLE_SIZE / 2,
+                  height: SMALL_RIPPLE_SIZE,
+                  width: SMALL_RIPPLE_SIZE,
+                  borderRadius: SMALL_RIPPLE_SIZE / 2,
+                  backgroundColor: touchColor,
+                  transform: [
+                    {
+                      translateX: shifting
+                        ? this.state.shifts[navigationState.index]
+                        : 0,
+                    },
+                    { scale: this.state.touch },
+                  ],
+                  opacity: this.state.touch.interpolate({
+                    inputRange: [0, 0.5, 1],
+                    outputRange: [0, 1, 0],
+                  }),
+                },
+              ]}
+            />
             {routes.map((route, index) => {
               const shift = this.state.shifts[index];
               const focused = this.state.tabs[index];
@@ -607,7 +632,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderIcon ? (
-                          renderIcon({ route, focused: true })
+                          renderIcon({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <Icon
                             style={styles.icon}
@@ -625,7 +654,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderIcon ? (
-                            renderIcon({ route, focused: false })
+                            renderIcon({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <Icon
                               style={styles.icon}
@@ -652,7 +685,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderLabel ? (
-                          renderLabel({ route, focused: true })
+                          renderLabel({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <AnimatedText
                             style={[
@@ -662,7 +699,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                               },
                             ]}
                           >
-                            {route.title}
+                            {getLabelText({ route })}
                           </AnimatedText>
                         )}
                       </Animated.View>
@@ -674,7 +711,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderLabel ? (
-                            renderLabel({ route, focused: false })
+                            renderLabel({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <AnimatedText
                               style={[
@@ -684,7 +725,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                                 },
                               ]}
                             >
-                              {route.title}
+                              {getLabelText({ route })}
                             </AnimatedText>
                           )}
                         </Animated.View>
",4,"[""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""e0198f74b81da3663144cfe1d971939319f82a0f"", ""f00a4d3e307b89842250358ee432e6800bb24362"", ""ded26d768ff432ad3bde3c0aa1e95ce50726100a""]","[""docs"", ""test"", ""build"", ""feat""]"
"added changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284convert `run_tag_values_test_case` to a functionAdjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.initialize threejs objects in defaultRef, to fix undefined type errors","diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)

diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number
",4,"[""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""1db13ec43727aca872a0f3836e4023ed85db665e"", ""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3"", ""2561f4ade46fc9d59f289f328cc77733a6443697""]","[""docs"", ""refactor"", ""test"", ""fix""]"
"verify checkpoint listeners are notifiedAdd ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>added changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284add remote [skip ci]","diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}

diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 06c9003..e19c703 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -47,7 +47,10 @@ jobs:
           git config --global user.email 'ibis-squawk-bot[bot]@users.noreply.github.com'
 
       - name: fetch and rebase on top of upstream
-        run: git pull --rebase -X ours https://github.com/ibis-project/ibis master
+        run: |
+          git remote add upstream https://github.com/ibis-project/ibis
+          git fetch upstream
+          git rebase -X ours upstream/master
 
       - uses: tibdex/github-app-token@v1
         id: generate_pr_token
",4,"[""e0198f74b81da3663144cfe1d971939319f82a0f"", ""f823cf28652987d43c8324b4f5b203240032383a"", ""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""e96487ad7ce90b141219d9032fa2bed68d5dae6a""]","[""test"", ""feat"", ""docs"", ""cicd""]"
"add fallible peek_last_token()updated react demo parcel commandenable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>licensing","diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.

diff --git a/demo/react/package.json b/demo/react/package.json
index be28bf9..32d0952 100644
--- a/demo/react/package.json
+++ b/demo/react/package.json
@@ -12,7 +12,7 @@
   },
   ""scripts"": {
     ""start"": ""parcel serve public/index.html --no-cache --open"",
-    ""build"": ""parcel build -t browser -d dist public/index.html --no-source-maps""
+    ""build"": ""parcel build --target browser --dist-dir dist public/index.html --no-source-maps""
   },
   ""bugs"": {
     ""url"": ""https://github.com/matteobruni/tsparticles/issues""

diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;
",4,"[""63eab619e6166eb6cab948028a7b89bf059dd878"", ""32b92cfa0b74a6c25990e32ac6aab12b8496794c"", ""fd8e563cc19ca4684885d4692acee6bebcca4ada"", ""a52a585d74894b3b4eeb8c784fa089ff95cddad0""]","[""refactor"", ""build"", ""feat"", ""docs""]"
"docker PG version upgrade

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>never call ""onStart"" prop when idlefixed docker link teststerminated tasks linger for a bit

Signed-off-by: Eliza Weisman <eliza@buoyant.io>","diff --git a/packages/nocodb/docker-compose.yml b/packages/nocodb/docker-compose.yml
index 7fabf79..ba2ab7b 100644
--- a/packages/nocodb/docker-compose.yml
+++ b/packages/nocodb/docker-compose.yml
@@ -1,4 +1,4 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
     # db55:
@@ -96,8 +96,8 @@ services:
     #     - 5495:5432
     #   volumes:
     #     - ./pg-sakila-db:/docker-entrypoint-initdb.d
-    pg96:
-     image: postgres:9.6
+    pg147:
+     image: postgres:14.7
      restart: always
      environment:
        POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
index 19dfab2..97d346b 100644
--- a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
+++ b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg.yml b/tests/playwright/scripts/docker-compose-pg.yml
index 0396579..9fab10e 100644
--- a/tests/playwright/scripts/docker-compose-pg.yml
+++ b/tests/playwright/scripts/docker-compose-pg.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password

diff --git a/packages/core/src/SpringValue.ts b/packages/core/src/SpringValue.ts
index 18494a8..cbc4f27 100644
--- a/packages/core/src/SpringValue.ts
+++ b/packages/core/src/SpringValue.ts
@@ -596,11 +596,11 @@ export class SpringValue<T = any> extends AnimationValue<T> {
   /** Notify change observers */
   protected _onChange(value: T, idle = false) {
     const anim = this.animation
-    if (!anim.changed) {
+    if (!anim.changed && !idle) {
       anim.changed = true
       // The ""onStart"" prop is called on the first change after entering the
       // frameloop, but never for immediate animations.
-      if (anim.onStart && !anim.immediate) {
+      if (anim.onStart) {
         anim.onStart(this)
       }
     }

diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()

diff --git a/console/src/main.rs b/console/src/main.rs
index ebfa315..5328d96 100644
--- a/console/src/main.rs
+++ b/console/src/main.rs
@@ -69,6 +69,7 @@ async fn main() -> Result<(), Box<dyn std::error::Error>> {
                 .wrap(Wrap { trim: true });
             f.render_widget(header, chunks[0]);
             tasks.render(f, chunks[1]);
+            tasks.retain_active();
         })?;
     }
 
diff --git a/console/src/tasks.rs b/console/src/tasks.rs
index 7be39a4..eb41495 100644
--- a/console/src/tasks.rs
+++ b/console/src/tasks.rs
@@ -19,6 +19,7 @@ struct Task {
     fields: String,
     kind: &'static str,
     stats: Stats,
+    completed_for: usize,
 }
 
 #[derive(Default, Debug)]
@@ -28,10 +29,15 @@ struct Stats {
     idle: Duration,
     total: Duration,
 }
+
 impl State {
+    // How many updates to retain completed tasks for
+    const RETAIN_COMPLETED_FOR: usize = 6;
+
     pub(crate) fn len(&self) -> usize {
         self.tasks.len()
     }
+
     pub(crate) fn update(&mut self, update: proto::tasks::TaskUpdate) {
         let new_tasks = update.new_tasks.into_iter().filter_map(|task| {
             if task.id.is_none() {
@@ -48,6 +54,7 @@ impl State {
                 fields: task.string_fields,
                 kind,
                 stats: Default::default(),
+                completed_for: 0,
             };
             Some((id, task))
         });
@@ -60,7 +67,10 @@ impl State {
         }
 
         for proto::SpanId { id } in update.completed {
-            if self.tasks.remove(&id).is_none() {
+            if let Some(task) = self.tasks.get_mut(&id) {
+                task.kind = ""!"";
+                task.completed_for = 1;
+            } else {
                 tracing::warn!(?id, ""tried to complete a task that didn't exist"");
             }
         }
@@ -79,7 +89,7 @@ impl State {
         const DUR_PRECISION: usize = 4;
         const POLLS_LEN: usize = 5;
         let rows = self.tasks.values().map(|task| {
-            let row = Row::new(vec![
+            let mut row = Row::new(vec![
                 Cell::from(task.id_hex.as_str()),
                 // TODO(eliza): is there a way to write a `fmt::Debug` impl
                 // directly to tui without doing an allocation?
@@ -105,6 +115,9 @@ impl State {
                 Cell::from(format!(""{:>width$}"", task.stats.polls, width = POLLS_LEN)),
                 Cell::from(task.fields.as_str()),
             ]);
+            if task.completed_for > 0 {
+                row = row.style(Style::default().add_modifier(style::Modifier::DIM));
+            }
             row
         });
         let t = Table::new(rows)
@@ -126,6 +139,16 @@ impl State {
 
         frame.render_widget(t, area)
     }
+
+    pub(crate) fn retain_active(&mut self) {
+        self.tasks.retain(|_, task| {
+            if task.completed_for == 0 {
+                return true;
+            }
+            task.completed_for += 1;
+            task.completed_for <= Self::RETAIN_COMPLETED_FOR
+        })
+    }
 }
 
 impl From<proto::tasks::Stats> for Stats {
",4,"[""37b1cbfd3d2c462ef4f2a131e4172c38dc8d9ddf"", ""c8e0ae8612df3d6f2831acc004aaac332f6105e4"", ""c7b25726df94a2530c9b1c0d2b6a0acaa103822f"", ""1bcf88670b50155b50071e707f98f30cea0b7a24""]","[""build"", ""fix"", ""test"", ""feat""]"
"make it mode lesspublish sdks after docs/buildadd .nullif() exampleupgrade to Flux v0.42.0

Skips a test that requires special dependencies to pass.","diff --git a/core/src/components/slides/slides.tsx b/core/src/components/slides/slides.tsx
index 48fd53f..d5c2f75 100644
--- a/core/src/components/slides/slides.tsx
+++ b/core/src/components/slides/slides.tsx
@@ -1,7 +1,6 @@
 import { Component, Element, Event, EventEmitter, Method, Prop, Watch } from '@stencil/core';
 
 import { Mode } from '../../interface.js';
-import { createThemedClasses } from '../../utils/theme.js';
 
 import { Swiper } from './vendor/swiper.js';
 
@@ -15,6 +14,7 @@ import { Swiper } from './vendor/swiper.js';
   shadow: true
 })
 export class Slides {
+
   private container!: HTMLElement;
   private swiper: any;
 
@@ -391,12 +391,6 @@ export class Slides {
     return { ...swiperOptions, ...this.options, ...eventOptions };
   }
 
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'slides')
-    };
-  }
-
   render() {
     return (
       <div class=""swiper-container"" ref={el => this.container = el as HTMLElement }>
diff --git a/core/src/components/thumbnail/thumbnail.ios.scss b/core/src/components/thumbnail/thumbnail.ios.scss
deleted file mode 100644
index e3add45..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.ios.vars"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-ios-width};
-  --border-radius: #{$thumbnail-ios-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.ios.vars.scss b/core/src/components/thumbnail/thumbnail.ios.vars.scss
deleted file mode 100644
index 85d53e5..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.ios"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-ios-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-ios-height:                  $thumbnail-ios-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-ios-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.md.scss b/core/src/components/thumbnail/thumbnail.md.scss
deleted file mode 100644
index 0fbb2ca..0000000
--- a/core/src/components/thumbnail/thumbnail.md.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.md.vars"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-md-width};
-  --border-radius: #{$thumbnail-md-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.md.vars.scss b/core/src/components/thumbnail/thumbnail.md.vars.scss
deleted file mode 100644
index 94e48b2..0000000
--- a/core/src/components/thumbnail/thumbnail.md.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.md"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-md-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-md-height:                  $thumbnail-md-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-md-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.scss b/core/src/components/thumbnail/thumbnail.scss
index 8ac3a22..8af268d 100644
--- a/core/src/components/thumbnail/thumbnail.scss
+++ b/core/src/components/thumbnail/thumbnail.scss
@@ -9,6 +9,8 @@
    * @prop --border-radius: Border radius of the thumbnail
    * @prop --size: Size of the thumbnail
    */
+  --size: 48px;
+  --border-radius: 0;
 
   @include border-radius(var(--border-radius));
 
diff --git a/core/src/components/thumbnail/thumbnail.tsx b/core/src/components/thumbnail/thumbnail.tsx
index 50ff2c2..de76593 100644
--- a/core/src/components/thumbnail/thumbnail.tsx
+++ b/core/src/components/thumbnail/thumbnail.tsx
@@ -1,25 +1,11 @@
 import { Component } from '@stencil/core';
 
-import { Mode } from '../../interface';
-import { createThemedClasses } from '../../utils/theme';
-
 @Component({
   tag: 'ion-thumbnail',
-  styleUrls: {
-    ios: 'thumbnail.ios.scss',
-    md: 'thumbnail.md.scss'
-  },
+  styleUrl: 'thumbnail.scss',
   shadow: true
 })
 export class Thumbnail {
-  mode!: Mode;
-
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'thumbnail')
-    };
-  }
-
   render() {
     return <slot></slot>;
   }

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/

diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 

diff --git a/go.mod b/go.mod
index ea705da..8c352f7 100644
--- a/go.mod
+++ b/go.mod
@@ -38,7 +38,7 @@ require (
 	github.com/hashicorp/go-msgpack v0.0.0-20150518234257-fa3f63826f7c // indirect
 	github.com/hashicorp/raft v1.0.0 // indirect
 	github.com/hashicorp/vault/api v1.0.2
-	github.com/influxdata/flux v0.41.0
+	github.com/influxdata/flux v0.42.0
 	github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6
 	github.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368
 	github.com/jessevdk/go-flags v1.4.0
diff --git a/go.sum b/go.sum
index 4bfdf4c..634a0f1 100644
--- a/go.sum
+++ b/go.sum
@@ -206,8 +206,8 @@ github.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NH
 github.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=
 github.com/influxdata/changelog v1.0.0 h1:RstJD6H48zLQj0GdE6E6k/6RPwtUjkyzIe/T1E/xuWU=
 github.com/influxdata/changelog v1.0.0/go.mod h1:uzpGWE/qehT8L426YuXwpMQub+a63vIINhIeEI9mnSM=
-github.com/influxdata/flux v0.41.0 h1:ljbWJmE+aNx8Yoqhb04gWC4sXMV87eYUxz5vjYphLLs=
-github.com/influxdata/flux v0.41.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
+github.com/influxdata/flux v0.42.0 h1:2iEG6hLHdHEJ6LgD8OSnlHS9yoVrLO1/aM4P9ERb94U=
+github.com/influxdata/flux v0.42.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
 github.com/influxdata/goreleaser v0.97.0-influx h1:jT5OrcW7WfS0e2QxfwmTBjhLvpIC9CDLRhNgZJyhj8s=
 github.com/influxdata/goreleaser v0.97.0-influx/go.mod h1:MnjA0e0Uq6ISqjG1WxxMAl+3VS1QYjILSWVnMYDxasE=
 github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6 h1:CFx+pP90q/qg3spoiZjf8donE4WpAdjeJfPOcoNqkWo=
diff --git a/query/stdlib/testing/testing.go b/query/stdlib/testing/testing.go
index d41574a..85b0673 100644
--- a/query/stdlib/testing/testing.go
+++ b/query/stdlib/testing/testing.go
@@ -98,4 +98,6 @@ var FluxEndToEndSkipList = map[string]string{
 	""http_endpoint"": ""need ability to test side effects in e2e tests: (https://github.com/influxdata/flux/issues/1723)"",
 
 	""holt_winters_panic"": ""Expected output is an empty table which breaks the testing framework (https://github.com/influxdata/influxdb/issues/14749)"",
+
+	""secrets"": ""Cannot inject custom deps into the test framework so the secrets don't lookup correctly"",
 }
",4,"[""771857b1df9470ebc15357e8879118a72c649d5b"", ""6c9cb638cb4d1ecc42632fcf389c24898c5b3244"", ""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21"", ""454003841aabeb74396d73541378bfa59c75b5db""]","[""refactor"", ""cicd"", ""docs"", ""build""]"
"fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.Fix typoexport a modal transition presetrun pyspark tests in parallelxfail on to_parquet and to_csv that use pyarrow write options","diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index e23088e..9708157 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -202,11 +202,11 @@ jobs:
         run: poetry install --without dev --without docs --extras ${{ matrix.backend.name }} --extras geospatial
 
       - name: ""run parallel tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name != 'pyspark' && matrix.backend.name != 'impala'
+        if: matrix.backend.name != 'impala'
         run: just ci-check -m ${{ matrix.backend.name }} --numprocesses auto --dist=loadgroup
 
       - name: ""run serial tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name == 'pyspark' || matrix.backend.name == 'impala'
+        if: matrix.backend.name == 'impala'
         run: just ci-check -m ${{ matrix.backend.name }}
         env:
           IBIS_TEST_NN_HOST: localhost

diff --git a/ibis/backends/tests/test_export.py b/ibis/backends/tests/test_export.py
index 4d536d7..5bb9775 100644
--- a/ibis/backends/tests/test_export.py
+++ b/ibis/backends/tests/test_export.py
@@ -222,18 +222,23 @@ def test_table_to_parquet(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs""), [({""version"": ""1.0""}), ({""version"": ""2.6""})])
-def test_table_to_parquet_writer_kwargs(kwargs, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.NotSupportedError,
+)
+@pytest.mark.parametrize(""version"", [""1.0"", ""2.6""])
+def test_table_to_parquet_writer_kwargs(version, tmp_path, backend, awards_players):
     outparquet = tmp_path / ""out.parquet""
-    awards_players.to_parquet(outparquet, **kwargs)
+    awards_players.to_parquet(outparquet, version=version)
 
     df = pd.read_parquet(outparquet)
 
     backend.assert_frame_equal(awards_players.to_pandas(), df)
 
-    file = pa.parquet.ParquetFile(outparquet)
+    md = pa.parquet.read_metadata(outparquet)
 
-    assert file.metadata.format_version == kwargs[""version""]
+    assert md.format_version == version
 
 
 @pytest.mark.notimpl(
@@ -316,14 +321,20 @@ def test_table_to_csv(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs"", ""delimiter""), [({""write_options"": pcsv.WriteOptions(delimiter="";"")}, "";""), ({""write_options"": pcsv.WriteOptions(delimiter=""\t"")}, ""\t"")])
-def test_table_to_csv_writer_kwargs(kwargs, delimiter, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.ProgrammingError,
+)
+@pytest.mark.parametrize(""delimiter"", ["";"", ""\t""], ids=[""semicolon"", ""tab""])
+def test_table_to_csv_writer_kwargs(delimiter, tmp_path, awards_players):
     outcsv = tmp_path / ""out.csv""
     # avoid pandas NaNonense
     awards_players = awards_players.select(""playerID"", ""awardID"", ""yearID"", ""lgID"")
 
-    awards_players.to_csv(outcsv, **kwargs)
-    pd.read_csv(outcsv, delimiter=delimiter)
+    awards_players.to_csv(outcsv, write_options=pcsv.WriteOptions(delimiter=delimiter))
+    df = pd.read_csv(outcsv, delimiter=delimiter, nrows=1)
+    assert len(df) == 1
 
 
 @pytest.mark.parametrize(
",5,"[""9be725fa3906323d4bc9788f54eccf74109d632b"", ""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""535708ae50aecb452560a23356fd396f99ef13a2"", ""4cbbd2552ba0de273e1dfe7d453c5b3efed751a3"", ""bedc7950b24c37809e36a585b7985d5aa5e3e458""]","[""fix"", ""docs"", ""refactor"", ""cicd"", ""test""]"
"setup jest and add m.ts testsFix typoget tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.remove deprecated settings

Removes deprecated ZEEBE_HOST environment variable, and removes
unnecessary log level environment variable, since it's already the
default in the log fileenable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });

diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }

diff --git a/Dockerfile b/Dockerfile
index 6762a39..7f380cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -34,7 +34,6 @@ RUN wget -O - https://github.com/jvm-profiling-tools/async-profiler/releases/dow
 FROM ${APP_ENV} as app
 
 ENV ZB_HOME=/usr/local/zeebe \
-    ZEEBE_LOG_LEVEL=info \
     ZEEBE_BROKER_GATEWAY_NETWORK_HOST=0.0.0.0 \
     ZEEBE_STANDALONE_GATEWAY=false
 ENV PATH ""${ZB_HOME}/bin:${PATH}""
diff --git a/docker/utils/startup.sh b/docker/utils/startup.sh
index bc8d2fc..0fcde2b 100755
--- a/docker/utils/startup.sh
+++ b/docker/utils/startup.sh
@@ -1,17 +1,14 @@
 #!/bin/bash -xeu
 
-# legacy support
-# This environment variable was used to set the gatewway cluster host in standalone and embedded mode.
-# Now, there are two dedicated environment variables for the two different deployment scenarios.
-export ZEEBE_HOST=${ZEEBE_HOST:-$(hostname -i)}
-# Legacy support
+HOST=$(hostname -i)
 
 if [ ""$ZEEBE_STANDALONE_GATEWAY"" = ""true"" ]; then
-    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_GATEWAY_NETWORK_HOST=${ZEEBE_GATEWAY_NETWORK_HOST:-${HOST}}
+    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${HOST}}
 
     exec /usr/local/zeebe/bin/gateway
 else
-    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${HOST}}
     export ZEEBE_BROKER_GATEWAY_CLUSTER_HOST=${ZEEBE_BROKER_GATEWAY_CLUSTER_HOST:-${ZEEBE_BROKER_NETWORK_HOST}}
 
     exec /usr/local/zeebe/bin/broker

diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 
",5,"[""229b53a632ea97d47c4be11f096bdd828fb415d8"", ""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c"", ""e4a11fd5c34942ba12737f1c8c084489428ee274"", ""fd8e563cc19ca4684885d4692acee6bebcca4ada""]","[""test"", ""docs"", ""refactor"", ""build"", ""feat""]"
"update wrapping tests for v7increment failing test retrieswrong icon reference

Signed-off-by: Pranav C <pranavxc@gmail.com>fix netty dependency

netty-bom 4.1.70 contains the changes from pull request
https://github.com/netty/netty/pull/11798, which moved the classes out
of the native modules to make sure the same classes don't end up on the
classpath multiple times. For us it means that we need to depend on both
the native and classes modules. However, since we don't use the native
module directly (only classes that were moved to this classes module),
we need to force the dependency plugin to consider the native module as
used.make it mode less","diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });

diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 

diff --git a/packages/nc-gui/components.d.ts b/packages/nc-gui/components.d.ts
index b7e6585..bb86478 100644
--- a/packages/nc-gui/components.d.ts
+++ b/packages/nc-gui/components.d.ts
@@ -81,7 +81,6 @@ declare module '@vue/runtime-core' {
     ClaritySuccessLine: typeof import('~icons/clarity/success-line')['default']
     EvaEmailOutline: typeof import('~icons/eva/email-outline')['default']
     IcBaselineMoreVert: typeof import('~icons/ic/baseline-more-vert')['default']
-    Icon: typeof import('~icons/ic/on')['default']
     IcOutlineInsertDriveFile: typeof import('~icons/ic/outline-insert-drive-file')['default']
     IcRoundEdit: typeof import('~icons/ic/round-edit')['default']
     IcRoundKeyboardArrowDown: typeof import('~icons/ic/round-keyboard-arrow-down')['default']

diff --git a/atomix/cluster/pom.xml b/atomix/cluster/pom.xml
index a477873..b6db695 100644
--- a/atomix/cluster/pom.xml
+++ b/atomix/cluster/pom.xml
@@ -69,6 +69,10 @@
     </dependency>
     <dependency>
       <groupId>io.netty</groupId>
+      <artifactId>netty-transport-classes-epoll</artifactId>
+    </dependency>
+    <dependency>
+      <groupId>io.netty</groupId>
       <artifactId>netty-transport-native-epoll</artifactId>
       <classifier>linux-x86_64</classifier>
     </dependency>
@@ -278,6 +282,7 @@
             <dependency>uk.co.real-logic:sbe-tool</dependency>
             <dependency>net.jqwik:jqwik</dependency>
             <dependency>io.netty:netty-tcnative-boringssl-static</dependency>
+            <dependency>io.netty:netty-transport-native-epoll</dependency>
           </usedDependencies>
         </configuration>
       </plugin>

diff --git a/core/src/components/slides/slides.tsx b/core/src/components/slides/slides.tsx
index 48fd53f..d5c2f75 100644
--- a/core/src/components/slides/slides.tsx
+++ b/core/src/components/slides/slides.tsx
@@ -1,7 +1,6 @@
 import { Component, Element, Event, EventEmitter, Method, Prop, Watch } from '@stencil/core';
 
 import { Mode } from '../../interface.js';
-import { createThemedClasses } from '../../utils/theme.js';
 
 import { Swiper } from './vendor/swiper.js';
 
@@ -15,6 +14,7 @@ import { Swiper } from './vendor/swiper.js';
   shadow: true
 })
 export class Slides {
+
   private container!: HTMLElement;
   private swiper: any;
 
@@ -391,12 +391,6 @@ export class Slides {
     return { ...swiperOptions, ...this.options, ...eventOptions };
   }
 
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'slides')
-    };
-  }
-
   render() {
     return (
       <div class=""swiper-container"" ref={el => this.container = el as HTMLElement }>
diff --git a/core/src/components/thumbnail/thumbnail.ios.scss b/core/src/components/thumbnail/thumbnail.ios.scss
deleted file mode 100644
index e3add45..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.ios.vars"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-ios-width};
-  --border-radius: #{$thumbnail-ios-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.ios.vars.scss b/core/src/components/thumbnail/thumbnail.ios.vars.scss
deleted file mode 100644
index 85d53e5..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.ios"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-ios-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-ios-height:                  $thumbnail-ios-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-ios-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.md.scss b/core/src/components/thumbnail/thumbnail.md.scss
deleted file mode 100644
index 0fbb2ca..0000000
--- a/core/src/components/thumbnail/thumbnail.md.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.md.vars"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-md-width};
-  --border-radius: #{$thumbnail-md-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.md.vars.scss b/core/src/components/thumbnail/thumbnail.md.vars.scss
deleted file mode 100644
index 94e48b2..0000000
--- a/core/src/components/thumbnail/thumbnail.md.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.md"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-md-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-md-height:                  $thumbnail-md-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-md-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.scss b/core/src/components/thumbnail/thumbnail.scss
index 8ac3a22..8af268d 100644
--- a/core/src/components/thumbnail/thumbnail.scss
+++ b/core/src/components/thumbnail/thumbnail.scss
@@ -9,6 +9,8 @@
    * @prop --border-radius: Border radius of the thumbnail
    * @prop --size: Size of the thumbnail
    */
+  --size: 48px;
+  --border-radius: 0;
 
   @include border-radius(var(--border-radius));
 
diff --git a/core/src/components/thumbnail/thumbnail.tsx b/core/src/components/thumbnail/thumbnail.tsx
index 50ff2c2..de76593 100644
--- a/core/src/components/thumbnail/thumbnail.tsx
+++ b/core/src/components/thumbnail/thumbnail.tsx
@@ -1,25 +1,11 @@
 import { Component } from '@stencil/core';
 
-import { Mode } from '../../interface';
-import { createThemedClasses } from '../../utils/theme';
-
 @Component({
   tag: 'ion-thumbnail',
-  styleUrls: {
-    ios: 'thumbnail.ios.scss',
-    md: 'thumbnail.md.scss'
-  },
+  styleUrl: 'thumbnail.scss',
   shadow: true
 })
 export class Thumbnail {
-  mode!: Mode;
-
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'thumbnail')
-    };
-  }
-
   render() {
     return <slot></slot>;
   }
",5,"[""317f4eefecddfb1392ca71d551840f446feee302"", ""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57"", ""d1d55e787b7d07f763852602b9939a5394607fd9"", ""f00a4d3e307b89842250358ee432e6800bb24362"", ""771857b1df9470ebc15357e8879118a72c649d5b""]","[""test"", ""cicd"", ""fix"", ""build"", ""refactor""]"
increment failing test retriesremove appear css animation[gn win] link comctl32.lib to fix component buildxfail on to_parquet and to_csv that use pyarrow write optionsallow disabling dynamic queue,"diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 

diff --git a/src/popup/Popup.tsx b/src/popup/Popup.tsx
index d485bb6..2abc22a 100644
--- a/src/popup/Popup.tsx
+++ b/src/popup/Popup.tsx
@@ -269,7 +269,6 @@ export class Popup extends React.Component<{ t: TranslationFunction }, PopupStat
         <CSSTransition
           classNames='fade'
           in={!!currentTabUrl}
-          appear
           timeout={500}
           exit={false}
           mountOnEnter

diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/ibis/backends/tests/test_export.py b/ibis/backends/tests/test_export.py
index 4d536d7..5bb9775 100644
--- a/ibis/backends/tests/test_export.py
+++ b/ibis/backends/tests/test_export.py
@@ -222,18 +222,23 @@ def test_table_to_parquet(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs""), [({""version"": ""1.0""}), ({""version"": ""2.6""})])
-def test_table_to_parquet_writer_kwargs(kwargs, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.NotSupportedError,
+)
+@pytest.mark.parametrize(""version"", [""1.0"", ""2.6""])
+def test_table_to_parquet_writer_kwargs(version, tmp_path, backend, awards_players):
     outparquet = tmp_path / ""out.parquet""
-    awards_players.to_parquet(outparquet, **kwargs)
+    awards_players.to_parquet(outparquet, version=version)
 
     df = pd.read_parquet(outparquet)
 
     backend.assert_frame_equal(awards_players.to_pandas(), df)
 
-    file = pa.parquet.ParquetFile(outparquet)
+    md = pa.parquet.read_metadata(outparquet)
 
-    assert file.metadata.format_version == kwargs[""version""]
+    assert md.format_version == version
 
 
 @pytest.mark.notimpl(
@@ -316,14 +321,20 @@ def test_table_to_csv(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs"", ""delimiter""), [({""write_options"": pcsv.WriteOptions(delimiter="";"")}, "";""), ({""write_options"": pcsv.WriteOptions(delimiter=""\t"")}, ""\t"")])
-def test_table_to_csv_writer_kwargs(kwargs, delimiter, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.ProgrammingError,
+)
+@pytest.mark.parametrize(""delimiter"", ["";"", ""\t""], ids=[""semicolon"", ""tab""])
+def test_table_to_csv_writer_kwargs(delimiter, tmp_path, awards_players):
     outcsv = tmp_path / ""out.csv""
     # avoid pandas NaNonense
     awards_players = awards_players.select(""playerID"", ""awardID"", ""yearID"", ""lgID"")
 
-    awards_players.to_csv(outcsv, **kwargs)
-    pd.read_csv(outcsv, delimiter=delimiter)
+    awards_players.to_csv(outcsv, write_options=pcsv.WriteOptions(delimiter=delimiter))
+    df = pd.read_csv(outcsv, delimiter=delimiter, nrows=1)
+    assert len(df) == 1
 
 
 @pytest.mark.parametrize(

diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);
",5,"[""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57"", ""47ef9104e4a89e80d7cc6c1950bc080841da4a7b"", ""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""bedc7950b24c37809e36a585b7985d5aa5e3e458"", ""9ef5c0d14193a9abb09b39856f58477d1f4b0d77""]","[""cicd"", ""refactor"", ""build"", ""test"", ""fix""]"
"remove deprecated settings

Removes deprecated ZEEBE_HOST environment variable, and removes
unnecessary log level environment variable, since it's already the
default in the log fileallow disabling dynamic queueadd getter for protocol idmake it mode lessupdate Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909","diff --git a/Dockerfile b/Dockerfile
index 6762a39..7f380cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -34,7 +34,6 @@ RUN wget -O - https://github.com/jvm-profiling-tools/async-profiler/releases/dow
 FROM ${APP_ENV} as app
 
 ENV ZB_HOME=/usr/local/zeebe \
-    ZEEBE_LOG_LEVEL=info \
     ZEEBE_BROKER_GATEWAY_NETWORK_HOST=0.0.0.0 \
     ZEEBE_STANDALONE_GATEWAY=false
 ENV PATH ""${ZB_HOME}/bin:${PATH}""
diff --git a/docker/utils/startup.sh b/docker/utils/startup.sh
index bc8d2fc..0fcde2b 100755
--- a/docker/utils/startup.sh
+++ b/docker/utils/startup.sh
@@ -1,17 +1,14 @@
 #!/bin/bash -xeu
 
-# legacy support
-# This environment variable was used to set the gatewway cluster host in standalone and embedded mode.
-# Now, there are two dedicated environment variables for the two different deployment scenarios.
-export ZEEBE_HOST=${ZEEBE_HOST:-$(hostname -i)}
-# Legacy support
+HOST=$(hostname -i)
 
 if [ ""$ZEEBE_STANDALONE_GATEWAY"" = ""true"" ]; then
-    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_GATEWAY_NETWORK_HOST=${ZEEBE_GATEWAY_NETWORK_HOST:-${HOST}}
+    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${HOST}}
 
     exec /usr/local/zeebe/bin/gateway
 else
-    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${HOST}}
     export ZEEBE_BROKER_GATEWAY_CLUSTER_HOST=${ZEEBE_BROKER_GATEWAY_CLUSTER_HOST:-${ZEEBE_BROKER_NETWORK_HOST}}
 
     exec /usr/local/zeebe/bin/broker

diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);

diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }

diff --git a/core/src/components/slides/slides.tsx b/core/src/components/slides/slides.tsx
index 48fd53f..d5c2f75 100644
--- a/core/src/components/slides/slides.tsx
+++ b/core/src/components/slides/slides.tsx
@@ -1,7 +1,6 @@
 import { Component, Element, Event, EventEmitter, Method, Prop, Watch } from '@stencil/core';
 
 import { Mode } from '../../interface.js';
-import { createThemedClasses } from '../../utils/theme.js';
 
 import { Swiper } from './vendor/swiper.js';
 
@@ -15,6 +14,7 @@ import { Swiper } from './vendor/swiper.js';
   shadow: true
 })
 export class Slides {
+
   private container!: HTMLElement;
   private swiper: any;
 
@@ -391,12 +391,6 @@ export class Slides {
     return { ...swiperOptions, ...this.options, ...eventOptions };
   }
 
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'slides')
-    };
-  }
-
   render() {
     return (
       <div class=""swiper-container"" ref={el => this.container = el as HTMLElement }>
diff --git a/core/src/components/thumbnail/thumbnail.ios.scss b/core/src/components/thumbnail/thumbnail.ios.scss
deleted file mode 100644
index e3add45..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.ios.vars"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-ios-width};
-  --border-radius: #{$thumbnail-ios-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.ios.vars.scss b/core/src/components/thumbnail/thumbnail.ios.vars.scss
deleted file mode 100644
index 85d53e5..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.ios"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-ios-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-ios-height:                  $thumbnail-ios-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-ios-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.md.scss b/core/src/components/thumbnail/thumbnail.md.scss
deleted file mode 100644
index 0fbb2ca..0000000
--- a/core/src/components/thumbnail/thumbnail.md.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.md.vars"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-md-width};
-  --border-radius: #{$thumbnail-md-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.md.vars.scss b/core/src/components/thumbnail/thumbnail.md.vars.scss
deleted file mode 100644
index 94e48b2..0000000
--- a/core/src/components/thumbnail/thumbnail.md.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.md"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-md-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-md-height:                  $thumbnail-md-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-md-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.scss b/core/src/components/thumbnail/thumbnail.scss
index 8ac3a22..8af268d 100644
--- a/core/src/components/thumbnail/thumbnail.scss
+++ b/core/src/components/thumbnail/thumbnail.scss
@@ -9,6 +9,8 @@
    * @prop --border-radius: Border radius of the thumbnail
    * @prop --size: Size of the thumbnail
    */
+  --size: 48px;
+  --border-radius: 0;
 
   @include border-radius(var(--border-radius));
 
diff --git a/core/src/components/thumbnail/thumbnail.tsx b/core/src/components/thumbnail/thumbnail.tsx
index 50ff2c2..de76593 100644
--- a/core/src/components/thumbnail/thumbnail.tsx
+++ b/core/src/components/thumbnail/thumbnail.tsx
@@ -1,25 +1,11 @@
 import { Component } from '@stencil/core';
 
-import { Mode } from '../../interface';
-import { createThemedClasses } from '../../utils/theme';
-
 @Component({
   tag: 'ion-thumbnail',
-  styleUrls: {
-    ios: 'thumbnail.ios.scss',
-    md: 'thumbnail.md.scss'
-  },
+  styleUrl: 'thumbnail.scss',
   shadow: true
 })
 export class Thumbnail {
-  mode!: Mode;
-
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'thumbnail')
-    };
-  }
-
   render() {
     return <slot></slot>;
   }

diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })
",5,"[""e4a11fd5c34942ba12737f1c8c084489428ee274"", ""9ef5c0d14193a9abb09b39856f58477d1f4b0d77"", ""dc5238b2bda98a7c4f2fe9584fc3b0191a408109"", ""771857b1df9470ebc15357e8879118a72c649d5b"", ""c2ee5cd5e709afd15c5565ee009a0d204403a119""]","[""build"", ""fix"", ""feat"", ""refactor"", ""docs""]"
"Fix typosetup jest and add m.ts testsspring version, core versionuse `regexp_instr != 0` instead of `REGEXP` keywordAdd ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>","diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });

diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}
",5,"[""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""229b53a632ea97d47c4be11f096bdd828fb415d8"", ""c55591ba157298a9c5816693c102a89dfd058830"", ""06e2be4e2019b6fa714e1fcb34485860ef1ede79"", ""f823cf28652987d43c8324b4f5b203240032383a""]","[""docs"", ""test"", ""build"", ""fix"", ""feat""]"
"increment failing test retriesspring version, core versionprint errors without stacktracesetup jest and add m.ts teststerminated tasks linger for a bit

Signed-off-by: Eliza Weisman <eliza@buoyant.io>","diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 

diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 

diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });

diff --git a/console/src/main.rs b/console/src/main.rs
index ebfa315..5328d96 100644
--- a/console/src/main.rs
+++ b/console/src/main.rs
@@ -69,6 +69,7 @@ async fn main() -> Result<(), Box<dyn std::error::Error>> {
                 .wrap(Wrap { trim: true });
             f.render_widget(header, chunks[0]);
             tasks.render(f, chunks[1]);
+            tasks.retain_active();
         })?;
     }
 
diff --git a/console/src/tasks.rs b/console/src/tasks.rs
index 7be39a4..eb41495 100644
--- a/console/src/tasks.rs
+++ b/console/src/tasks.rs
@@ -19,6 +19,7 @@ struct Task {
     fields: String,
     kind: &'static str,
     stats: Stats,
+    completed_for: usize,
 }
 
 #[derive(Default, Debug)]
@@ -28,10 +29,15 @@ struct Stats {
     idle: Duration,
     total: Duration,
 }
+
 impl State {
+    // How many updates to retain completed tasks for
+    const RETAIN_COMPLETED_FOR: usize = 6;
+
     pub(crate) fn len(&self) -> usize {
         self.tasks.len()
     }
+
     pub(crate) fn update(&mut self, update: proto::tasks::TaskUpdate) {
         let new_tasks = update.new_tasks.into_iter().filter_map(|task| {
             if task.id.is_none() {
@@ -48,6 +54,7 @@ impl State {
                 fields: task.string_fields,
                 kind,
                 stats: Default::default(),
+                completed_for: 0,
             };
             Some((id, task))
         });
@@ -60,7 +67,10 @@ impl State {
         }
 
         for proto::SpanId { id } in update.completed {
-            if self.tasks.remove(&id).is_none() {
+            if let Some(task) = self.tasks.get_mut(&id) {
+                task.kind = ""!"";
+                task.completed_for = 1;
+            } else {
                 tracing::warn!(?id, ""tried to complete a task that didn't exist"");
             }
         }
@@ -79,7 +89,7 @@ impl State {
         const DUR_PRECISION: usize = 4;
         const POLLS_LEN: usize = 5;
         let rows = self.tasks.values().map(|task| {
-            let row = Row::new(vec![
+            let mut row = Row::new(vec![
                 Cell::from(task.id_hex.as_str()),
                 // TODO(eliza): is there a way to write a `fmt::Debug` impl
                 // directly to tui without doing an allocation?
@@ -105,6 +115,9 @@ impl State {
                 Cell::from(format!(""{:>width$}"", task.stats.polls, width = POLLS_LEN)),
                 Cell::from(task.fields.as_str()),
             ]);
+            if task.completed_for > 0 {
+                row = row.style(Style::default().add_modifier(style::Modifier::DIM));
+            }
             row
         });
         let t = Table::new(rows)
@@ -126,6 +139,16 @@ impl State {
 
         frame.render_widget(t, area)
     }
+
+    pub(crate) fn retain_active(&mut self) {
+        self.tasks.retain(|_, task| {
+            if task.completed_for == 0 {
+                return true;
+            }
+            task.completed_for += 1;
+            task.completed_for <= Self::RETAIN_COMPLETED_FOR
+        })
+    }
 }
 
 impl From<proto::tasks::Stats> for Stats {
",5,"[""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57"", ""c55591ba157298a9c5816693c102a89dfd058830"", ""d129eaf9125a967ac86c6c7276bbae6b4d50af36"", ""229b53a632ea97d47c4be11f096bdd828fb415d8"", ""1bcf88670b50155b50071e707f98f30cea0b7a24""]","[""cicd"", ""build"", ""fix"", ""test"", ""feat""]"
"initialize threejs objects in defaultRef, to fix undefined type errorsensure checksum persist flushes to diskassist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>add remote [skip ci]cleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.","diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number

diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);

diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }

diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 06c9003..e19c703 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -47,7 +47,10 @@ jobs:
           git config --global user.email 'ibis-squawk-bot[bot]@users.noreply.github.com'
 
       - name: fetch and rebase on top of upstream
-        run: git pull --rebase -X ours https://github.com/ibis-project/ibis master
+        run: |
+          git remote add upstream https://github.com/ibis-project/ibis
+          git fetch upstream
+          git rebase -X ours upstream/master
 
       - uses: tibdex/github-app-token@v1
         id: generate_pr_token

diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:
",5,"[""2561f4ade46fc9d59f289f328cc77733a6443697"", ""b7ce2894fd1794064bd6db4ed730bb6cb7728739"", ""1269431c8a3e7549f10fcbbb4b88ff625c8898b3"", ""e96487ad7ce90b141219d9032fa2bed68d5dae6a"", ""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7""]","[""fix"", ""test"", ""build"", ""cicd"", ""refactor""]"
Fix typoincrement failing test retriesexport a modal transition presetfixed docker link testsuse `regexp_instr != 0` instead of `REGEXP` keyword,"diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 

diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {

diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(
",5,"[""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57"", ""535708ae50aecb452560a23356fd396f99ef13a2"", ""c7b25726df94a2530c9b1c0d2b6a0acaa103822f"", ""06e2be4e2019b6fa714e1fcb34485860ef1ede79""]","[""docs"", ""cicd"", ""refactor"", ""test"", ""fix""]"
"cleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.update Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909spring version, core versionadd hardware back button

Closes #5071allow disabling dynamic queue","diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:

diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })

diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 

diff --git a/ionic/components/app/app.ts b/ionic/components/app/app.ts
index 04d8c57..08aab92 100644
--- a/ionic/components/app/app.ts
+++ b/ionic/components/app/app.ts
@@ -3,8 +3,7 @@ import {Title} from 'angular2/platform/browser';
 
 import {Config} from '../../config/config';
 import {ClickBlock} from '../../util/click-block';
-import {Nav} from '../nav/nav';
-import {Tabs} from '../tabs/tabs';
+import {Platform} from '../../platform/platform';
 
 
 /**
@@ -23,8 +22,20 @@ export class IonicApp {
 
   constructor(
     private _config: Config,
-    private _clickBlock: ClickBlock
-  ) {}
+    private _clickBlock: ClickBlock,
+    platform: Platform
+  ) {
+    platform.backButton.subscribe(() => {
+      let activeNav = this.getActiveNav();
+      if (activeNav) {
+        if (activeNav.length() === 1) {
+          platform.exitApp();
+        } else {
+          activeNav.pop();
+        }
+      }
+    });
+  }
 
   /**
    * Sets the document title.
@@ -102,7 +113,7 @@ export class IonicApp {
   /**
    * @private
    */
-  getActiveNav(): Nav | Tabs {
+  getActiveNav(): any {
     var nav = this._rootNav || null;
     var activeChildNav;
 

diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);
",5,"[""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7"", ""c2ee5cd5e709afd15c5565ee009a0d204403a119"", ""c55591ba157298a9c5816693c102a89dfd058830"", ""68278b00450f2679761a2999500f6d87a579376b"", ""9ef5c0d14193a9abb09b39856f58477d1f4b0d77""]","[""refactor"", ""docs"", ""build"", ""feat"", ""fix""]"
"add props to get color and label from a routefix build orderinginitialize threejs objects in defaultRef, to fix undefined type errorsdo not use scripts and binaries from the libcc repoverify checkpoint listeners are notified","diff --git a/src/components/BottomNavigation.js b/src/components/BottomNavigation.js
index 1b72302..7d8ea75 100644
--- a/src/components/BottomNavigation.js
+++ b/src/components/BottomNavigation.js
@@ -24,8 +24,8 @@ const AnimatedPaper = Animated.createAnimatedComponent(Paper);
 
 type Route = {
   key: string,
-  title: string,
-  icon: IconSource,
+  title?: string,
+  icon?: IconSource,
   color?: string,
 };
 
@@ -51,7 +51,7 @@ type Props<T> = {
    * - `key`: a unique key to identify the route
    * - `title`: title of the route to use as the tab label
    * - `icon`: icon to use as the tab icon, can be a string, an image source or a react component
-   * - `color`: color to use as background color for shifting bottom navigation (optional)
+   * - `color`: color to use as background color for shifting bottom navigation
    *
    * Example:
    *
@@ -115,11 +115,27 @@ type Props<T> = {
   /**
    * Callback which returns a React Element to be used as tab icon.
    */
-  renderIcon?: (props: { route: T, focused: boolean }) => React.Node,
+  renderIcon?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
   /**
    * Callback which React Element to be used as tab label.
    */
-  renderLabel?: (props: { route: T, focused: boolean }) => React.Node,
+  renderLabel?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
+  /**
+   * Get label text for the tab, uses `route.title` by default. Use `renderLabel` to replace label component.
+   */
+  getLabelText?: (props: { route: T }) => string,
+  /**
+   * Get color for the tab, uses `route.color` by default.
+   */
+  getColor?: (props: { route: T }) => string,
   /**
    * Function to execute on tab press. It receives the route for the pressed tab, useful for things like scroll to top.
    */
@@ -159,6 +175,10 @@ type State = {
    */
   ripple: Animated.Value,
   /**
+   * Animation for the touch feedback, used to determine it's scale and opacity.
+   */
+  touch: Animated.Value,
+  /**
    * Layout of the tab bar. The width is used to determine the size and position of the ripple.
    */
   layout: { height: number, width: number, measured: boolean },
@@ -173,7 +193,7 @@ const MIN_SHIFT_AMOUNT = 10;
 const MIN_TAB_WIDTH = 96;
 const MAX_TAB_WIDTH = 168;
 const BAR_HEIGHT = 56;
-const SMALL_RIPPLE_SIZE = 72;
+const SMALL_RIPPLE_SIZE = 96;
 const ACTIVE_LABEL_SIZE = 14;
 const INACTIVE_LABEL_SIZE = 12;
 
@@ -251,6 +271,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ),
       index: new Animated.Value(index),
       ripple: new Animated.Value(MIN_RIPPLE_SCALE),
+      touch: new Animated.Value(MIN_RIPPLE_SCALE),
       layout: { height: 0, width: 0, measured: false },
       previous: 0,
     };
@@ -349,6 +370,15 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
   _handleTabPress = (index: number) => {
     const { navigationState } = this.props;
 
+    this.state.touch.setValue(MIN_RIPPLE_SCALE);
+
+    Animated.timing(this.state.touch, {
+      toValue: 1,
+      duration: 300,
+      easing: Easing.in(Easing.sin),
+      useNativeDriver: true,
+    }).start();
+
     if (index !== navigationState.index) {
       this.props.onIndexChange(index);
     }
@@ -376,6 +406,8 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       renderScene,
       renderIcon,
       renderLabel,
+      getLabelText = ({ route }) => route.title,
+      getColor = ({ route }) => route.color,
       barStyle,
       style,
       theme,
@@ -400,7 +432,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ? this.state.index.interpolate({
           inputRange: routes.map((_, i) => i),
           outputRange: routes.map(
-            route => route.color || approxBackgroundColor
+            route => getColor({ route }) || approxBackgroundColor
           ),
         })
       : approxBackgroundColor;
@@ -416,7 +448,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
           .rgb()
           .string();
 
-    const rippleColor = color(textColor)
+    const touchColor = color(textColor)
       .alpha(0.12)
       .rgb()
       .string();
@@ -430,22 +462,10 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
 
     // Since we have a single ripple, we have to reposition it so that it appears to expand from active tab.
     // We need to move it from the left to the active tab and also account for how much that tab has shifted.
-    const rippleShift =
-      navigationState.index * tabWidth +
-      tabWidth / 2 +
-      this._calculateShift(
-        this.state.previous,
-        navigationState.index,
-        routes.length
-      );
 
     return (
       <View
-        style={[
-          styles.container,
-          { backgroundColor: theme.dark ? white : black },
-          style,
-        ]}
+        style={[styles.container, style]}
         onLayout={this._handleLayout}
         pointerEvents={layout.measured ? 'auto' : 'none'}
       >
@@ -485,25 +505,30 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
             style={[styles.items, { maxWidth: maxTabWidth * routes.length }]}
           >
             {shifting ? (
-              // Large ripple with the backround color
               <Animated.View
                 pointerEvents=""none""
                 style={[
                   styles.ripple,
                   {
                     // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - layout.width / 2,
-                    left: rippleShift - layout.width / 2,
-                    height: layout.width,
-                    width: layout.width,
+                    top: BAR_HEIGHT / 2 - layout.width / 8,
+                    left:
+                      navigationState.index * tabWidth +
+                      tabWidth / 2 -
+                      layout.width / 8,
+                    height: layout.width / 4,
+                    width: layout.width / 4,
                     borderRadius: layout.width / 2,
-                    backgroundColor: routes[navigationState.index].color,
+                    backgroundColor: getColor({
+                      route: routes[navigationState.index],
+                    }),
                     transform: [
+                      { translateX: this.state.shifts[navigationState.index] },
                       {
                         // Scale to twice the size  to ensure it covers the whole tab bar
                         scale: this.state.ripple.interpolate({
                           inputRange: [0, 1],
-                          outputRange: [0, 2],
+                          outputRange: [0, 8],
                         }),
                       },
                     ],
@@ -515,36 +540,36 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                 ]}
               />
             ) : null}
-            {shifting ? (
-              // Small subtle ripple on touch
-              <Animated.View
-                pointerEvents=""none""
-                style={[
-                  styles.ripple,
-                  {
-                    // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
-                    left: rippleShift - SMALL_RIPPLE_SIZE / 2,
-                    height: SMALL_RIPPLE_SIZE,
-                    width: SMALL_RIPPLE_SIZE,
-                    borderRadius: SMALL_RIPPLE_SIZE / 2,
-                    backgroundColor: rippleColor,
-                    transform: [
-                      {
-                        scale: this.state.ripple.interpolate({
-                          inputRange: [0, 0.5, 1],
-                          outputRange: [0, 1, 1],
-                        }),
-                      },
-                    ],
-                    opacity: this.state.ripple.interpolate({
-                      inputRange: [0, MIN_RIPPLE_SCALE, 0.25, 0.5],
-                      outputRange: [0, 0, 1, 0],
-                    }),
-                  },
-                ]}
-              />
-            ) : null}
+            <Animated.View
+              pointerEvents=""none""
+              style={[
+                styles.ripple,
+                {
+                  // Set top and left values so that the ripple's center is same as the tab's center
+                  top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
+                  left:
+                    navigationState.index * tabWidth +
+                    tabWidth / 2 -
+                    SMALL_RIPPLE_SIZE / 2,
+                  height: SMALL_RIPPLE_SIZE,
+                  width: SMALL_RIPPLE_SIZE,
+                  borderRadius: SMALL_RIPPLE_SIZE / 2,
+                  backgroundColor: touchColor,
+                  transform: [
+                    {
+                      translateX: shifting
+                        ? this.state.shifts[navigationState.index]
+                        : 0,
+                    },
+                    { scale: this.state.touch },
+                  ],
+                  opacity: this.state.touch.interpolate({
+                    inputRange: [0, 0.5, 1],
+                    outputRange: [0, 1, 0],
+                  }),
+                },
+              ]}
+            />
             {routes.map((route, index) => {
               const shift = this.state.shifts[index];
               const focused = this.state.tabs[index];
@@ -607,7 +632,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderIcon ? (
-                          renderIcon({ route, focused: true })
+                          renderIcon({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <Icon
                             style={styles.icon}
@@ -625,7 +654,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderIcon ? (
-                            renderIcon({ route, focused: false })
+                            renderIcon({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <Icon
                               style={styles.icon}
@@ -652,7 +685,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderLabel ? (
-                          renderLabel({ route, focused: true })
+                          renderLabel({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <AnimatedText
                             style={[
@@ -662,7 +699,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                               },
                             ]}
                           >
-                            {route.title}
+                            {getLabelText({ route })}
                           </AnimatedText>
                         )}
                       </Animated.View>
@@ -674,7 +711,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderLabel ? (
-                            renderLabel({ route, focused: false })
+                            renderLabel({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <AnimatedText
                               style={[
@@ -684,7 +725,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                                 },
                               ]}
                             >
-                              {route.title}
+                              {getLabelText({ route })}
                             </AnimatedText>
                           )}
                         </Animated.View>

diff --git a/scripts/build.mjs b/scripts/build.mjs
index 204854f..b3cf067 100644
--- a/scripts/build.mjs
+++ b/scripts/build.mjs
@@ -3,8 +3,8 @@ import { write } from 'fsxx';
 import { info, success } from './helpers.mjs';
 
 await $`rm -rf dist/*`;
-await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 await $`unbuild`;
+await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 
 const packages = [
   'jsx-runtime',

diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }
",5,"[""ded26d768ff432ad3bde3c0aa1e95ce50726100a"", ""c323d59c607cabc91f17a78528d998f376f30b10"", ""2561f4ade46fc9d59f289f328cc77733a6443697"", ""45837af24a33308a70a3454f0f650f9fe728e272"", ""e0198f74b81da3663144cfe1d971939319f82a0f""]","[""feat"", ""build"", ""fix"", ""cicd"", ""test""]"
"add remote [skip ci]small error msg improvement

refs #1005fixed docker link testsbuffer assert and bpmn model api helper class

related to camunda-tngp/camunda-tngp#23allow disabling dynamic queue","diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 06c9003..e19c703 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -47,7 +47,10 @@ jobs:
           git config --global user.email 'ibis-squawk-bot[bot]@users.noreply.github.com'
 
       - name: fetch and rebase on top of upstream
-        run: git pull --rebase -X ours https://github.com/ibis-project/ibis master
+        run: |
+          git remote add upstream https://github.com/ibis-project/ibis
+          git fetch upstream
+          git rebase -X ours upstream/master
 
       - uses: tibdex/github-app-token@v1
         id: generate_pr_token

diff --git a/internal/pipe/git/errors.go b/internal/pipe/git/errors.go
index a8c15d5..13dfb56 100644
--- a/internal/pipe/git/errors.go
+++ b/internal/pipe/git/errors.go
@@ -11,7 +11,7 @@ type ErrDirty struct {
 }
 
 func (e ErrDirty) Error() string {
-	return fmt.Sprintf(""git is currently in a dirty state:\n%v"", e.status)
+	return fmt.Sprintf(""git is currently in a dirty state, please check in your pipeline what can be changing the following files:\n%v"", e.status)
 }
 
 // ErrWrongRef happens when the HEAD reference is different from the tag being built

diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()

diff --git a/test-util/pom.xml b/test-util/pom.xml
index a097651..b6518ee 100644
--- a/test-util/pom.xml
+++ b/test-util/pom.xml
@@ -20,6 +20,7 @@
     <project.build.sourceEncoding>utf-8</project.build.sourceEncoding>
     <!-- TODO: Move to common parent -->
     <agrona.version>0.4.11</agrona.version>
+    <camunda.version>7.6.0-SNAPSHOT</camunda.version>
   </properties>
 
   <dependencies>
@@ -30,6 +31,13 @@
       <version>${agrona.version}</version>
       <scope>provided</scope>
     </dependency>
+    
+    <dependency>
+      <groupId>org.camunda.bpm.model</groupId>
+      <artifactId>camunda-bpmn-model</artifactId>
+      <version>${camunda.version}</version>
+      <scope>provided</scope>
+    </dependency>
 
     <dependency>
       <groupId>junit</groupId>
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
index 37e3a6f..b8d9b26 100644
--- a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
@@ -14,7 +14,7 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         super(actual, BufferAssert.class);
     }
 
-    public static BufferAssert assertThat(DirectBuffer buffer)
+    public static BufferAssert assertThatBuffer(DirectBuffer buffer)
     {
         return new BufferAssert(buffer);
     }
@@ -41,4 +41,16 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         return hasBytes(expected, 0);
     }
 
+    public BufferAssert hasCapacity(int expectedCapacity)
+    {
+        isNotNull();
+
+        if (expectedCapacity != actual.capacity())
+        {
+            failWithMessage(""Expected capacity "" + expectedCapacity + "" but was "" + actual.capacity());
+        }
+
+        return this;
+    }
+
 }
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
new file mode 100644
index 0000000..6f0d134
--- /dev/null
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
@@ -0,0 +1,121 @@
+package org.camunda.tngp.broker.test.util.bpmn;
+
+import java.util.Collection;
+
+import org.camunda.bpm.model.bpmn.BpmnModelInstance;
+import org.camunda.bpm.model.bpmn.impl.BpmnModelConstants;
+import org.camunda.bpm.model.bpmn.instance.Definitions;
+import org.camunda.bpm.model.xml.Model;
+import org.camunda.bpm.model.xml.instance.DomDocument;
+import org.camunda.bpm.model.xml.instance.ModelElementInstance;
+import org.camunda.bpm.model.xml.type.ModelElementType;
+import org.camunda.bpm.model.xml.validation.ModelElementValidator;
+import org.camunda.bpm.model.xml.validation.ValidationResults;
+
+public class TngpModelInstance implements BpmnModelInstance
+{
+    protected BpmnModelInstance wrappedInstance;
+
+    public TngpModelInstance(BpmnModelInstance wrappedInstance)
+    {
+        this.wrappedInstance = wrappedInstance;
+    }
+
+    @Override
+    public DomDocument getDocument()
+    {
+        return wrappedInstance.getDocument();
+    }
+
+    @Override
+    public ModelElementInstance getDocumentElement()
+    {
+        return wrappedInstance.getDocumentElement();
+    }
+
+    @Override
+    public void setDocumentElement(ModelElementInstance documentElement)
+    {
+        wrappedInstance.setDocumentElement(documentElement);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(Class<T> type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(ModelElementType type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public Model getModel()
+    {
+        return wrappedInstance.getModel();
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T getModelElementById(String id)
+    {
+        return wrappedInstance.getModelElementById(id);
+    }
+
+    @Override
+    public Collection<ModelElementInstance> getModelElementsByType(ModelElementType referencingType)
+    {
+        return wrappedInstance.getModelElementsByType(referencingType);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> Collection<T> getModelElementsByType(Class<T> referencingClass)
+    {
+        return wrappedInstance.getModelElementsByType(referencingClass);
+    }
+
+    @Override
+    public ValidationResults validate(Collection<ModelElementValidator<?>> validators)
+    {
+        return wrappedInstance.validate(validators);
+    }
+
+    @Override
+    public BpmnModelInstance clone()
+    {
+        return wrappedInstance.clone();
+    }
+
+    @Override
+    public Definitions getDefinitions()
+    {
+        return wrappedInstance.getDefinitions();
+    }
+
+    @Override
+    public void setDefinitions(Definitions arg0)
+    {
+        wrappedInstance.setDefinitions(arg0);
+    }
+
+    public TngpModelInstance taskAttributes(String taskId, String taskType, int taskQueueId)
+    {
+        final ModelElementInstance task = wrappedInstance.getModelElementById(taskId);
+
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskType"", taskType);
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskQueueId"", String.valueOf(taskQueueId));
+
+        return this;
+    }
+
+    public static TngpModelInstance wrap(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance);
+    }
+
+    public static TngpModelInstance wrapCopy(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance.clone());
+    }
+}

diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);
",5,"[""e96487ad7ce90b141219d9032fa2bed68d5dae6a"", ""a62314d9bb632be6af026686615d14b912250512"", ""c7b25726df94a2530c9b1c0d2b6a0acaa103822f"", ""6ed56ce9ae743ba9a87e6c9643cc06b1de7b748d"", ""9ef5c0d14193a9abb09b39856f58477d1f4b0d77""]","[""cicd"", ""refactor"", ""test"", ""feat"", ""fix""]"
"spring version, core versionadd fallible peek_last_token()add a branch name to Slack notifications (#14793)add comments for the Handlerfix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.","diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 

diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.

diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'

diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }

diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 
",5,"[""c55591ba157298a9c5816693c102a89dfd058830"", ""63eab619e6166eb6cab948028a7b89bf059dd878"", ""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da"", ""036a0ff49a7dade0e04c9c07071a1ff49133ee24"", ""9be725fa3906323d4bc9788f54eccf74109d632b""]","[""build"", ""refactor"", ""cicd"", ""docs"", ""fix""]"
"Fix typoadd riscv64gc-unknown-linux-gnuexport a modal transition presetassist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>Add ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>","diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }

diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {

diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}
",5,"[""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""173553c0372e66e03bdab19e0e6c2dd44daa14a0"", ""535708ae50aecb452560a23356fd396f99ef13a2"", ""1269431c8a3e7549f10fcbbb4b88ff625c8898b3"", ""f823cf28652987d43c8324b4f5b203240032383a""]","[""docs"", ""cicd"", ""refactor"", ""build"", ""feat""]"
"xfail on to_parquet and to_csv that use pyarrow write optionsenable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>get tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.never call ""onStart"" prop when idleadd comments for the Handler","diff --git a/ibis/backends/tests/test_export.py b/ibis/backends/tests/test_export.py
index 4d536d7..5bb9775 100644
--- a/ibis/backends/tests/test_export.py
+++ b/ibis/backends/tests/test_export.py
@@ -222,18 +222,23 @@ def test_table_to_parquet(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs""), [({""version"": ""1.0""}), ({""version"": ""2.6""})])
-def test_table_to_parquet_writer_kwargs(kwargs, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.NotSupportedError,
+)
+@pytest.mark.parametrize(""version"", [""1.0"", ""2.6""])
+def test_table_to_parquet_writer_kwargs(version, tmp_path, backend, awards_players):
     outparquet = tmp_path / ""out.parquet""
-    awards_players.to_parquet(outparquet, **kwargs)
+    awards_players.to_parquet(outparquet, version=version)
 
     df = pd.read_parquet(outparquet)
 
     backend.assert_frame_equal(awards_players.to_pandas(), df)
 
-    file = pa.parquet.ParquetFile(outparquet)
+    md = pa.parquet.read_metadata(outparquet)
 
-    assert file.metadata.format_version == kwargs[""version""]
+    assert md.format_version == version
 
 
 @pytest.mark.notimpl(
@@ -316,14 +321,20 @@ def test_table_to_csv(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs"", ""delimiter""), [({""write_options"": pcsv.WriteOptions(delimiter="";"")}, "";""), ({""write_options"": pcsv.WriteOptions(delimiter=""\t"")}, ""\t"")])
-def test_table_to_csv_writer_kwargs(kwargs, delimiter, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.ProgrammingError,
+)
+@pytest.mark.parametrize(""delimiter"", ["";"", ""\t""], ids=[""semicolon"", ""tab""])
+def test_table_to_csv_writer_kwargs(delimiter, tmp_path, awards_players):
     outcsv = tmp_path / ""out.csv""
     # avoid pandas NaNonense
     awards_players = awards_players.select(""playerID"", ""awardID"", ""yearID"", ""lgID"")
 
-    awards_players.to_csv(outcsv, **kwargs)
-    pd.read_csv(outcsv, delimiter=delimiter)
+    awards_players.to_csv(outcsv, write_options=pcsv.WriteOptions(delimiter=delimiter))
+    df = pd.read_csv(outcsv, delimiter=delimiter, nrows=1)
+    assert len(df) == 1
 
 
 @pytest.mark.parametrize(

diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }

diff --git a/packages/core/src/SpringValue.ts b/packages/core/src/SpringValue.ts
index 18494a8..cbc4f27 100644
--- a/packages/core/src/SpringValue.ts
+++ b/packages/core/src/SpringValue.ts
@@ -596,11 +596,11 @@ export class SpringValue<T = any> extends AnimationValue<T> {
   /** Notify change observers */
   protected _onChange(value: T, idle = false) {
     const anim = this.animation
-    if (!anim.changed) {
+    if (!anim.changed && !idle) {
       anim.changed = true
       // The ""onStart"" prop is called on the first change after entering the
       // frameloop, but never for immediate animations.
-      if (anim.onStart && !anim.immediate) {
+      if (anim.onStart) {
         anim.onStart(this)
       }
     }

diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }
",5,"[""bedc7950b24c37809e36a585b7985d5aa5e3e458"", ""fd8e563cc19ca4684885d4692acee6bebcca4ada"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c"", ""c8e0ae8612df3d6f2831acc004aaac332f6105e4"", ""036a0ff49a7dade0e04c9c07071a1ff49133ee24""]","[""test"", ""feat"", ""refactor"", ""fix"", ""docs""]"
"update Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909assist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>increment failing test retriesautostart feature fixedadd benchmark for known-slow table expression","diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })

diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }

diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();

diff --git a/.gitignore b/.gitignore
index 2e99ad3..eef9203 100644
--- a/.gitignore
+++ b/.gitignore
@@ -95,3 +95,4 @@ docs/backends/support_matrix.csv
 __pycache__
 tags
 .DS_Store
+prof/
diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index ac19aaf..36aed0e 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -602,3 +602,93 @@ def test_multiple_joins(benchmark, num_joins, num_columns):
         name=""t"",
     )
     benchmark(multiple_joins, table, num_joins)
+
+
+@pytest.fixture
+def customers():
+    return ibis.table(
+        dict(
+            customerid=""int32"",
+            name=""string"",
+            address=""string"",
+            citystatezip=""string"",
+            birthdate=""date"",
+            phone=""string"",
+            timezone=""string"",
+            lat=""float64"",
+            long=""float64"",
+        ),
+        name=""customers"",
+    )
+
+
+@pytest.fixture
+def orders():
+    return ibis.table(
+        dict(
+            orderid=""int32"",
+            customerid=""int32"",
+            ordered=""timestamp"",
+            shipped=""timestamp"",
+            items=""string"",
+            total=""float64"",
+        ),
+        name=""orders"",
+    )
+
+
+@pytest.fixture
+def orders_items():
+    return ibis.table(
+        dict(orderid=""int32"", sku=""string"", qty=""int32"", unit_price=""float64""),
+        name=""orders_items"",
+    )
+
+
+@pytest.fixture
+def products():
+    return ibis.table(
+        dict(
+            sku=""string"",
+            desc=""string"",
+            weight_kg=""float64"",
+            cost=""float64"",
+            dims_cm=""string"",
+        ),
+        name=""products"",
+    )
+
+
+@pytest.mark.benchmark(group=""compilation"")
+@pytest.mark.parametrize(
+    ""module"",
+    [
+        pytest.param(
+            mod,
+            marks=pytest.mark.xfail(
+                condition=mod in _XFAIL_COMPILE_BACKENDS,
+                reason=f""{mod} backend doesn't support compiling UnboundTable"",
+            ),
+        )
+        for mod in _backends
+    ],
+)
+def test_compile_with_drops(
+    benchmark, module, customers, orders, orders_items, products
+):
+    expr = (
+        customers.join(orders, ""customerid"")
+        .join(orders_items, ""orderid"")
+        .join(products, ""sku"")
+        .drop(""customerid"", ""qty"", ""total"", ""items"")
+        .drop(""dims_cm"", ""cost"")
+        .mutate(o_date=lambda t: t.shipped.date())
+        .filter(lambda t: t.ordered == t.shipped)
+    )
+
+    try:
+        mod = getattr(ibis, module)
+    except (AttributeError, ImportError) as e:
+        pytest.skip(str(e))
+    else:
+        benchmark(mod.compile, expr)
",5,"[""c2ee5cd5e709afd15c5565ee009a0d204403a119"", ""1269431c8a3e7549f10fcbbb4b88ff625c8898b3"", ""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57"", ""bed78248c941d57ad4cc20a455147e186e97c7a1"", ""e9617f0854030e70365eb264bcb3b58078e79e9e""]","[""docs"", ""build"", ""cicd"", ""fix"", ""test""]"
"restructure ClusterTopology to track completed changeonly run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>nginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>fixed docker link testsdocker PG version upgrade

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>","diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(

diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection

diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()

diff --git a/packages/nocodb/docker-compose.yml b/packages/nocodb/docker-compose.yml
index 7fabf79..ba2ab7b 100644
--- a/packages/nocodb/docker-compose.yml
+++ b/packages/nocodb/docker-compose.yml
@@ -1,4 +1,4 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
     # db55:
@@ -96,8 +96,8 @@ services:
     #     - 5495:5432
     #   volumes:
     #     - ./pg-sakila-db:/docker-entrypoint-initdb.d
-    pg96:
-     image: postgres:9.6
+    pg147:
+     image: postgres:14.7
      restart: always
      environment:
        POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
index 19dfab2..97d346b 100644
--- a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
+++ b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg.yml b/tests/playwright/scripts/docker-compose-pg.yml
index 0396579..9fab10e 100644
--- a/tests/playwright/scripts/docker-compose-pg.yml
+++ b/tests/playwright/scripts/docker-compose-pg.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
",5,"[""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2"", ""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""e12d9e77a6fd531a22325337838a841b1c67f00d"", ""c7b25726df94a2530c9b1c0d2b6a0acaa103822f"", ""37b1cbfd3d2c462ef4f2a131e4172c38dc8d9ddf""]","[""refactor"", ""cicd"", ""docs"", ""test"", ""build""]"
"setup jest and add m.ts testsdetach ViewControllers when not activeonly run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>restructure ClusterTopology to track completed changeupdate flushed index before truncating","diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });

diff --git a/ionic/components/nav/nav-controller.ts b/ionic/components/nav/nav-controller.ts
index becdd99..1cc3c31 100644
--- a/ionic/components/nav/nav-controller.ts
+++ b/ionic/components/nav/nav-controller.ts
@@ -1410,6 +1410,9 @@ export class NavController extends Ion {
       // set the ComponentRef's instance to this ViewController
       view.setInstance(component);
 
+      // remember the ChangeDetectorRef for this ViewController
+      view.setChangeDetector(hostViewRef.changeDetectorRef);
+
       // remember the ElementRef to the ion-page elementRef that was just created
       view.setPageRef(pageElementRef);
 
diff --git a/ionic/components/nav/view-controller.ts b/ionic/components/nav/view-controller.ts
index 3207fa2..069c74d 100644
--- a/ionic/components/nav/view-controller.ts
+++ b/ionic/components/nav/view-controller.ts
@@ -1,4 +1,4 @@
-import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer} from 'angular2/core';
+import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer, ChangeDetectorRef} from 'angular2/core';
 
 import {Navbar} from '../navbar/navbar';
 import {NavController, NavOptions} from './nav-controller';
@@ -33,6 +33,7 @@ export class ViewController {
   private _nbVwRef: ViewContainerRef;
   private _onDismiss: Function = null;
   private _pgRef: ElementRef;
+  private _cd: ChangeDetectorRef;
   protected _nav: NavController;
 
   /**
@@ -166,6 +167,13 @@ export class ViewController {
   /**
    * @private
    */
+  setChangeDetector(cd: ChangeDetectorRef) {
+    this._cd = cd;
+  }
+
+  /**
+   * @private
+   */
   setInstance(instance: any) {
     this.instance = instance;
   }
@@ -467,6 +475,14 @@ export class ViewController {
    * The view is about to enter and become the active view.
    */
   willEnter() {
+    if (this._cd) {
+      // ensure this has been re-attached to the change detector
+      this._cd.reattach();
+
+      // detect changes before we run any user code
+      this._cd.detectChanges();
+    }
+
     ctrlFn(this, 'onPageWillEnter');
   }
 
@@ -496,6 +512,10 @@ export class ViewController {
    */
   didLeave() {
     ctrlFn(this, 'onPageDidLeave');
+
+    // when this is not the active page
+    // we no longer need to detect changes
+    this._cd && this._cd.detach();
   }
 
   /**

diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(

diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {
",5,"[""229b53a632ea97d47c4be11f096bdd828fb415d8"", ""b282e90e2cbb74559aab79eee8443a4d7c85502a"", ""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2"", ""933ab6bb86372913c992567cf9660009900911a7""]","[""test"", ""feat"", ""cicd"", ""refactor"", ""fix""]"
"docker PG version upgrade

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>use `regexp_instr != 0` instead of `REGEXP` keywordadd a branch name to Slack notifications (#14793)convert `run_tag_values_test_case` to a functionlicensing","diff --git a/packages/nocodb/docker-compose.yml b/packages/nocodb/docker-compose.yml
index 7fabf79..ba2ab7b 100644
--- a/packages/nocodb/docker-compose.yml
+++ b/packages/nocodb/docker-compose.yml
@@ -1,4 +1,4 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
     # db55:
@@ -96,8 +96,8 @@ services:
     #     - 5495:5432
     #   volumes:
     #     - ./pg-sakila-db:/docker-entrypoint-initdb.d
-    pg96:
-     image: postgres:9.6
+    pg147:
+     image: postgres:14.7
      restart: always
      environment:
        POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
index 19dfab2..97d346b 100644
--- a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
+++ b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg.yml b/tests/playwright/scripts/docker-compose-pg.yml
index 0396579..9fab10e 100644
--- a/tests/playwright/scripts/docker-compose-pg.yml
+++ b/tests/playwright/scripts/docker-compose-pg.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(

diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'

diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;
",5,"[""37b1cbfd3d2c462ef4f2a131e4172c38dc8d9ddf"", ""06e2be4e2019b6fa714e1fcb34485860ef1ede79"", ""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da"", ""1db13ec43727aca872a0f3836e4023ed85db665e"", ""a52a585d74894b3b4eeb8c784fa089ff95cddad0""]","[""build"", ""fix"", ""cicd"", ""refactor"", ""docs""]"
"[gn] fix include_dirs ordering erroradd .nullif() exampleincrement failing test retriesAdjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.Add ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>","diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)

diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 

diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}
",5,"[""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945"", ""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21"", ""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57"", ""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3"", ""f823cf28652987d43c8324b4f5b203240032383a""]","[""build"", ""docs"", ""cicd"", ""test"", ""feat""]"
"Add ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>never call ""onStart"" prop when idleremove appear css animationremove deprecated settings

Removes deprecated ZEEBE_HOST environment variable, and removes
unnecessary log level environment variable, since it's already the
default in the log filefixed docker link tests","diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}

diff --git a/packages/core/src/SpringValue.ts b/packages/core/src/SpringValue.ts
index 18494a8..cbc4f27 100644
--- a/packages/core/src/SpringValue.ts
+++ b/packages/core/src/SpringValue.ts
@@ -596,11 +596,11 @@ export class SpringValue<T = any> extends AnimationValue<T> {
   /** Notify change observers */
   protected _onChange(value: T, idle = false) {
     const anim = this.animation
-    if (!anim.changed) {
+    if (!anim.changed && !idle) {
       anim.changed = true
       // The ""onStart"" prop is called on the first change after entering the
       // frameloop, but never for immediate animations.
-      if (anim.onStart && !anim.immediate) {
+      if (anim.onStart) {
         anim.onStart(this)
       }
     }

diff --git a/src/popup/Popup.tsx b/src/popup/Popup.tsx
index d485bb6..2abc22a 100644
--- a/src/popup/Popup.tsx
+++ b/src/popup/Popup.tsx
@@ -269,7 +269,6 @@ export class Popup extends React.Component<{ t: TranslationFunction }, PopupStat
         <CSSTransition
           classNames='fade'
           in={!!currentTabUrl}
-          appear
           timeout={500}
           exit={false}
           mountOnEnter

diff --git a/Dockerfile b/Dockerfile
index 6762a39..7f380cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -34,7 +34,6 @@ RUN wget -O - https://github.com/jvm-profiling-tools/async-profiler/releases/dow
 FROM ${APP_ENV} as app
 
 ENV ZB_HOME=/usr/local/zeebe \
-    ZEEBE_LOG_LEVEL=info \
     ZEEBE_BROKER_GATEWAY_NETWORK_HOST=0.0.0.0 \
     ZEEBE_STANDALONE_GATEWAY=false
 ENV PATH ""${ZB_HOME}/bin:${PATH}""
diff --git a/docker/utils/startup.sh b/docker/utils/startup.sh
index bc8d2fc..0fcde2b 100755
--- a/docker/utils/startup.sh
+++ b/docker/utils/startup.sh
@@ -1,17 +1,14 @@
 #!/bin/bash -xeu
 
-# legacy support
-# This environment variable was used to set the gatewway cluster host in standalone and embedded mode.
-# Now, there are two dedicated environment variables for the two different deployment scenarios.
-export ZEEBE_HOST=${ZEEBE_HOST:-$(hostname -i)}
-# Legacy support
+HOST=$(hostname -i)
 
 if [ ""$ZEEBE_STANDALONE_GATEWAY"" = ""true"" ]; then
-    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_GATEWAY_NETWORK_HOST=${ZEEBE_GATEWAY_NETWORK_HOST:-${HOST}}
+    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${HOST}}
 
     exec /usr/local/zeebe/bin/gateway
 else
-    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${HOST}}
     export ZEEBE_BROKER_GATEWAY_CLUSTER_HOST=${ZEEBE_BROKER_GATEWAY_CLUSTER_HOST:-${ZEEBE_BROKER_NETWORK_HOST}}
 
     exec /usr/local/zeebe/bin/broker

diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
",5,"[""f823cf28652987d43c8324b4f5b203240032383a"", ""c8e0ae8612df3d6f2831acc004aaac332f6105e4"", ""47ef9104e4a89e80d7cc6c1950bc080841da4a7b"", ""e4a11fd5c34942ba12737f1c8c084489428ee274"", ""c7b25726df94a2530c9b1c0d2b6a0acaa103822f""]","[""feat"", ""fix"", ""refactor"", ""build"", ""test""]"
convert `run_tag_values_test_case` to a functionupdated react demo parcel commandadd remote [skip ci]add .nullif() exampleskip flaky test,"diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]

diff --git a/demo/react/package.json b/demo/react/package.json
index be28bf9..32d0952 100644
--- a/demo/react/package.json
+++ b/demo/react/package.json
@@ -12,7 +12,7 @@
   },
   ""scripts"": {
     ""start"": ""parcel serve public/index.html --no-cache --open"",
-    ""build"": ""parcel build -t browser -d dist public/index.html --no-source-maps""
+    ""build"": ""parcel build --target browser --dist-dir dist public/index.html --no-source-maps""
   },
   ""bugs"": {
     ""url"": ""https://github.com/matteobruni/tsparticles/issues""

diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 06c9003..e19c703 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -47,7 +47,10 @@ jobs:
           git config --global user.email 'ibis-squawk-bot[bot]@users.noreply.github.com'
 
       - name: fetch and rebase on top of upstream
-        run: git pull --rebase -X ours https://github.com/ibis-project/ibis master
+        run: |
+          git remote add upstream https://github.com/ibis-project/ibis
+          git fetch upstream
+          git rebase -X ours upstream/master
 
       - uses: tibdex/github-app-token@v1
         id: generate_pr_token

diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method
",5,"[""1db13ec43727aca872a0f3836e4023ed85db665e"", ""32b92cfa0b74a6c25990e32ac6aab12b8496794c"", ""e96487ad7ce90b141219d9032fa2bed68d5dae6a"", ""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d""]","[""refactor"", ""build"", ""cicd"", ""docs"", ""test""]"
"docker PG version upgrade

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>Adjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.convert `run_tag_values_test_case` to a functionadd a branch name to Slack notifications (#14793)print errors without stacktrace","diff --git a/packages/nocodb/docker-compose.yml b/packages/nocodb/docker-compose.yml
index 7fabf79..ba2ab7b 100644
--- a/packages/nocodb/docker-compose.yml
+++ b/packages/nocodb/docker-compose.yml
@@ -1,4 +1,4 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
     # db55:
@@ -96,8 +96,8 @@ services:
     #     - 5495:5432
     #   volumes:
     #     - ./pg-sakila-db:/docker-entrypoint-initdb.d
-    pg96:
-     image: postgres:9.6
+    pg147:
+     image: postgres:14.7
      restart: always
      environment:
        POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
index 19dfab2..97d346b 100644
--- a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
+++ b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg.yml b/tests/playwright/scripts/docker-compose-pg.yml
index 0396579..9fab10e 100644
--- a/tests/playwright/scripts/docker-compose-pg.yml
+++ b/tests/playwright/scripts/docker-compose-pg.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)

diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]

diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'

diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {
",5,"[""37b1cbfd3d2c462ef4f2a131e4172c38dc8d9ddf"", ""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3"", ""1db13ec43727aca872a0f3836e4023ed85db665e"", ""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da"", ""d129eaf9125a967ac86c6c7276bbae6b4d50af36""]","[""build"", ""test"", ""refactor"", ""cicd"", ""fix""]"
"spring version, core versionlicensingpublish sdks after docs/buildfixed docker link testsautostart feature fixed","diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/

diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();
",5,"[""c55591ba157298a9c5816693c102a89dfd058830"", ""a52a585d74894b3b4eeb8c784fa089ff95cddad0"", ""6c9cb638cb4d1ecc42632fcf389c24898c5b3244"", ""c7b25726df94a2530c9b1c0d2b6a0acaa103822f"", ""bed78248c941d57ad4cc20a455147e186e97c7a1""]","[""build"", ""docs"", ""cicd"", ""test"", ""fix""]"
"allow disabling dynamic queueonly run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>buffer assert and bpmn model api helper class

related to camunda-tngp/camunda-tngp#23remove deprecated settings

Removes deprecated ZEEBE_HOST environment variable, and removes
unnecessary log level environment variable, since it's already the
default in the log fileconvert `run_tag_values_test_case` to a function","diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);

diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/test-util/pom.xml b/test-util/pom.xml
index a097651..b6518ee 100644
--- a/test-util/pom.xml
+++ b/test-util/pom.xml
@@ -20,6 +20,7 @@
     <project.build.sourceEncoding>utf-8</project.build.sourceEncoding>
     <!-- TODO: Move to common parent -->
     <agrona.version>0.4.11</agrona.version>
+    <camunda.version>7.6.0-SNAPSHOT</camunda.version>
   </properties>
 
   <dependencies>
@@ -30,6 +31,13 @@
       <version>${agrona.version}</version>
       <scope>provided</scope>
     </dependency>
+    
+    <dependency>
+      <groupId>org.camunda.bpm.model</groupId>
+      <artifactId>camunda-bpmn-model</artifactId>
+      <version>${camunda.version}</version>
+      <scope>provided</scope>
+    </dependency>
 
     <dependency>
       <groupId>junit</groupId>
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
index 37e3a6f..b8d9b26 100644
--- a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
@@ -14,7 +14,7 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         super(actual, BufferAssert.class);
     }
 
-    public static BufferAssert assertThat(DirectBuffer buffer)
+    public static BufferAssert assertThatBuffer(DirectBuffer buffer)
     {
         return new BufferAssert(buffer);
     }
@@ -41,4 +41,16 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         return hasBytes(expected, 0);
     }
 
+    public BufferAssert hasCapacity(int expectedCapacity)
+    {
+        isNotNull();
+
+        if (expectedCapacity != actual.capacity())
+        {
+            failWithMessage(""Expected capacity "" + expectedCapacity + "" but was "" + actual.capacity());
+        }
+
+        return this;
+    }
+
 }
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
new file mode 100644
index 0000000..6f0d134
--- /dev/null
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
@@ -0,0 +1,121 @@
+package org.camunda.tngp.broker.test.util.bpmn;
+
+import java.util.Collection;
+
+import org.camunda.bpm.model.bpmn.BpmnModelInstance;
+import org.camunda.bpm.model.bpmn.impl.BpmnModelConstants;
+import org.camunda.bpm.model.bpmn.instance.Definitions;
+import org.camunda.bpm.model.xml.Model;
+import org.camunda.bpm.model.xml.instance.DomDocument;
+import org.camunda.bpm.model.xml.instance.ModelElementInstance;
+import org.camunda.bpm.model.xml.type.ModelElementType;
+import org.camunda.bpm.model.xml.validation.ModelElementValidator;
+import org.camunda.bpm.model.xml.validation.ValidationResults;
+
+public class TngpModelInstance implements BpmnModelInstance
+{
+    protected BpmnModelInstance wrappedInstance;
+
+    public TngpModelInstance(BpmnModelInstance wrappedInstance)
+    {
+        this.wrappedInstance = wrappedInstance;
+    }
+
+    @Override
+    public DomDocument getDocument()
+    {
+        return wrappedInstance.getDocument();
+    }
+
+    @Override
+    public ModelElementInstance getDocumentElement()
+    {
+        return wrappedInstance.getDocumentElement();
+    }
+
+    @Override
+    public void setDocumentElement(ModelElementInstance documentElement)
+    {
+        wrappedInstance.setDocumentElement(documentElement);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(Class<T> type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(ModelElementType type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public Model getModel()
+    {
+        return wrappedInstance.getModel();
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T getModelElementById(String id)
+    {
+        return wrappedInstance.getModelElementById(id);
+    }
+
+    @Override
+    public Collection<ModelElementInstance> getModelElementsByType(ModelElementType referencingType)
+    {
+        return wrappedInstance.getModelElementsByType(referencingType);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> Collection<T> getModelElementsByType(Class<T> referencingClass)
+    {
+        return wrappedInstance.getModelElementsByType(referencingClass);
+    }
+
+    @Override
+    public ValidationResults validate(Collection<ModelElementValidator<?>> validators)
+    {
+        return wrappedInstance.validate(validators);
+    }
+
+    @Override
+    public BpmnModelInstance clone()
+    {
+        return wrappedInstance.clone();
+    }
+
+    @Override
+    public Definitions getDefinitions()
+    {
+        return wrappedInstance.getDefinitions();
+    }
+
+    @Override
+    public void setDefinitions(Definitions arg0)
+    {
+        wrappedInstance.setDefinitions(arg0);
+    }
+
+    public TngpModelInstance taskAttributes(String taskId, String taskType, int taskQueueId)
+    {
+        final ModelElementInstance task = wrappedInstance.getModelElementById(taskId);
+
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskType"", taskType);
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskQueueId"", String.valueOf(taskQueueId));
+
+        return this;
+    }
+
+    public static TngpModelInstance wrap(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance);
+    }
+
+    public static TngpModelInstance wrapCopy(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance.clone());
+    }
+}

diff --git a/Dockerfile b/Dockerfile
index 6762a39..7f380cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -34,7 +34,6 @@ RUN wget -O - https://github.com/jvm-profiling-tools/async-profiler/releases/dow
 FROM ${APP_ENV} as app
 
 ENV ZB_HOME=/usr/local/zeebe \
-    ZEEBE_LOG_LEVEL=info \
     ZEEBE_BROKER_GATEWAY_NETWORK_HOST=0.0.0.0 \
     ZEEBE_STANDALONE_GATEWAY=false
 ENV PATH ""${ZB_HOME}/bin:${PATH}""
diff --git a/docker/utils/startup.sh b/docker/utils/startup.sh
index bc8d2fc..0fcde2b 100755
--- a/docker/utils/startup.sh
+++ b/docker/utils/startup.sh
@@ -1,17 +1,14 @@
 #!/bin/bash -xeu
 
-# legacy support
-# This environment variable was used to set the gatewway cluster host in standalone and embedded mode.
-# Now, there are two dedicated environment variables for the two different deployment scenarios.
-export ZEEBE_HOST=${ZEEBE_HOST:-$(hostname -i)}
-# Legacy support
+HOST=$(hostname -i)
 
 if [ ""$ZEEBE_STANDALONE_GATEWAY"" = ""true"" ]; then
-    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_GATEWAY_NETWORK_HOST=${ZEEBE_GATEWAY_NETWORK_HOST:-${HOST}}
+    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${HOST}}
 
     exec /usr/local/zeebe/bin/gateway
 else
-    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${HOST}}
     export ZEEBE_BROKER_GATEWAY_CLUSTER_HOST=${ZEEBE_BROKER_GATEWAY_CLUSTER_HOST:-${ZEEBE_BROKER_NETWORK_HOST}}
 
     exec /usr/local/zeebe/bin/broker

diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
",5,"[""9ef5c0d14193a9abb09b39856f58477d1f4b0d77"", ""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""6ed56ce9ae743ba9a87e6c9643cc06b1de7b748d"", ""e4a11fd5c34942ba12737f1c8c084489428ee274"", ""1db13ec43727aca872a0f3836e4023ed85db665e""]","[""fix"", ""cicd"", ""feat"", ""build"", ""refactor""]"
"autostart feature fixedremove deprecated settings

Removes deprecated ZEEBE_HOST environment variable, and removes
unnecessary log level environment variable, since it's already the
default in the log fileget tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.Add ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>fixed docker link tests","diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();

diff --git a/Dockerfile b/Dockerfile
index 6762a39..7f380cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -34,7 +34,6 @@ RUN wget -O - https://github.com/jvm-profiling-tools/async-profiler/releases/dow
 FROM ${APP_ENV} as app
 
 ENV ZB_HOME=/usr/local/zeebe \
-    ZEEBE_LOG_LEVEL=info \
     ZEEBE_BROKER_GATEWAY_NETWORK_HOST=0.0.0.0 \
     ZEEBE_STANDALONE_GATEWAY=false
 ENV PATH ""${ZB_HOME}/bin:${PATH}""
diff --git a/docker/utils/startup.sh b/docker/utils/startup.sh
index bc8d2fc..0fcde2b 100755
--- a/docker/utils/startup.sh
+++ b/docker/utils/startup.sh
@@ -1,17 +1,14 @@
 #!/bin/bash -xeu
 
-# legacy support
-# This environment variable was used to set the gatewway cluster host in standalone and embedded mode.
-# Now, there are two dedicated environment variables for the two different deployment scenarios.
-export ZEEBE_HOST=${ZEEBE_HOST:-$(hostname -i)}
-# Legacy support
+HOST=$(hostname -i)
 
 if [ ""$ZEEBE_STANDALONE_GATEWAY"" = ""true"" ]; then
-    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_GATEWAY_NETWORK_HOST=${ZEEBE_GATEWAY_NETWORK_HOST:-${HOST}}
+    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${HOST}}
 
     exec /usr/local/zeebe/bin/gateway
 else
-    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${HOST}}
     export ZEEBE_BROKER_GATEWAY_CLUSTER_HOST=${ZEEBE_BROKER_GATEWAY_CLUSTER_HOST:-${ZEEBE_BROKER_NETWORK_HOST}}
 
     exec /usr/local/zeebe/bin/broker

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}

diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
",5,"[""bed78248c941d57ad4cc20a455147e186e97c7a1"", ""e4a11fd5c34942ba12737f1c8c084489428ee274"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c"", ""f823cf28652987d43c8324b4f5b203240032383a"", ""c7b25726df94a2530c9b1c0d2b6a0acaa103822f""]","[""fix"", ""build"", ""refactor"", ""feat"", ""test""]"
repository creationxfail on to_parquet and to_csv that use pyarrow write optionsadd props to get color and label from a routelicensingfix build ordering,"diff --git a/server/src/services/repository.service.ts b/server/src/services/repository.service.ts
index 3869c98..d675b30 100644
--- a/server/src/services/repository.service.ts
+++ b/server/src/services/repository.service.ts
@@ -19,6 +19,8 @@ export class RepositoryService {
       return;
     }
 
+    await this.createTeam(this.github, this.getTeamName(course), course.id);
+
     const studentRepo = getCustomRepository(StudentRepository);
     const students = await studentRepo.findActiveByCourseId(this.courseId);
 
@@ -31,8 +33,8 @@ export class RepositoryService {
         if (mentorGithubId) {
           await this.inviteMentor(mentorGithubId, course);
         }
-        await this.addTeamToRepository(this.github, course, student.githubId);
       }
+      await this.addTeamToRepository(this.github, course, student.githubId);
       if (record?.repository) {
         result.push({ repository: record.repository });
       }

diff --git a/ibis/backends/tests/test_export.py b/ibis/backends/tests/test_export.py
index 4d536d7..5bb9775 100644
--- a/ibis/backends/tests/test_export.py
+++ b/ibis/backends/tests/test_export.py
@@ -222,18 +222,23 @@ def test_table_to_parquet(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs""), [({""version"": ""1.0""}), ({""version"": ""2.6""})])
-def test_table_to_parquet_writer_kwargs(kwargs, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.NotSupportedError,
+)
+@pytest.mark.parametrize(""version"", [""1.0"", ""2.6""])
+def test_table_to_parquet_writer_kwargs(version, tmp_path, backend, awards_players):
     outparquet = tmp_path / ""out.parquet""
-    awards_players.to_parquet(outparquet, **kwargs)
+    awards_players.to_parquet(outparquet, version=version)
 
     df = pd.read_parquet(outparquet)
 
     backend.assert_frame_equal(awards_players.to_pandas(), df)
 
-    file = pa.parquet.ParquetFile(outparquet)
+    md = pa.parquet.read_metadata(outparquet)
 
-    assert file.metadata.format_version == kwargs[""version""]
+    assert md.format_version == version
 
 
 @pytest.mark.notimpl(
@@ -316,14 +321,20 @@ def test_table_to_csv(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs"", ""delimiter""), [({""write_options"": pcsv.WriteOptions(delimiter="";"")}, "";""), ({""write_options"": pcsv.WriteOptions(delimiter=""\t"")}, ""\t"")])
-def test_table_to_csv_writer_kwargs(kwargs, delimiter, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.ProgrammingError,
+)
+@pytest.mark.parametrize(""delimiter"", ["";"", ""\t""], ids=[""semicolon"", ""tab""])
+def test_table_to_csv_writer_kwargs(delimiter, tmp_path, awards_players):
     outcsv = tmp_path / ""out.csv""
     # avoid pandas NaNonense
     awards_players = awards_players.select(""playerID"", ""awardID"", ""yearID"", ""lgID"")
 
-    awards_players.to_csv(outcsv, **kwargs)
-    pd.read_csv(outcsv, delimiter=delimiter)
+    awards_players.to_csv(outcsv, write_options=pcsv.WriteOptions(delimiter=delimiter))
+    df = pd.read_csv(outcsv, delimiter=delimiter, nrows=1)
+    assert len(df) == 1
 
 
 @pytest.mark.parametrize(

diff --git a/src/components/BottomNavigation.js b/src/components/BottomNavigation.js
index 1b72302..7d8ea75 100644
--- a/src/components/BottomNavigation.js
+++ b/src/components/BottomNavigation.js
@@ -24,8 +24,8 @@ const AnimatedPaper = Animated.createAnimatedComponent(Paper);
 
 type Route = {
   key: string,
-  title: string,
-  icon: IconSource,
+  title?: string,
+  icon?: IconSource,
   color?: string,
 };
 
@@ -51,7 +51,7 @@ type Props<T> = {
    * - `key`: a unique key to identify the route
    * - `title`: title of the route to use as the tab label
    * - `icon`: icon to use as the tab icon, can be a string, an image source or a react component
-   * - `color`: color to use as background color for shifting bottom navigation (optional)
+   * - `color`: color to use as background color for shifting bottom navigation
    *
    * Example:
    *
@@ -115,11 +115,27 @@ type Props<T> = {
   /**
    * Callback which returns a React Element to be used as tab icon.
    */
-  renderIcon?: (props: { route: T, focused: boolean }) => React.Node,
+  renderIcon?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
   /**
    * Callback which React Element to be used as tab label.
    */
-  renderLabel?: (props: { route: T, focused: boolean }) => React.Node,
+  renderLabel?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
+  /**
+   * Get label text for the tab, uses `route.title` by default. Use `renderLabel` to replace label component.
+   */
+  getLabelText?: (props: { route: T }) => string,
+  /**
+   * Get color for the tab, uses `route.color` by default.
+   */
+  getColor?: (props: { route: T }) => string,
   /**
    * Function to execute on tab press. It receives the route for the pressed tab, useful for things like scroll to top.
    */
@@ -159,6 +175,10 @@ type State = {
    */
   ripple: Animated.Value,
   /**
+   * Animation for the touch feedback, used to determine it's scale and opacity.
+   */
+  touch: Animated.Value,
+  /**
    * Layout of the tab bar. The width is used to determine the size and position of the ripple.
    */
   layout: { height: number, width: number, measured: boolean },
@@ -173,7 +193,7 @@ const MIN_SHIFT_AMOUNT = 10;
 const MIN_TAB_WIDTH = 96;
 const MAX_TAB_WIDTH = 168;
 const BAR_HEIGHT = 56;
-const SMALL_RIPPLE_SIZE = 72;
+const SMALL_RIPPLE_SIZE = 96;
 const ACTIVE_LABEL_SIZE = 14;
 const INACTIVE_LABEL_SIZE = 12;
 
@@ -251,6 +271,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ),
       index: new Animated.Value(index),
       ripple: new Animated.Value(MIN_RIPPLE_SCALE),
+      touch: new Animated.Value(MIN_RIPPLE_SCALE),
       layout: { height: 0, width: 0, measured: false },
       previous: 0,
     };
@@ -349,6 +370,15 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
   _handleTabPress = (index: number) => {
     const { navigationState } = this.props;
 
+    this.state.touch.setValue(MIN_RIPPLE_SCALE);
+
+    Animated.timing(this.state.touch, {
+      toValue: 1,
+      duration: 300,
+      easing: Easing.in(Easing.sin),
+      useNativeDriver: true,
+    }).start();
+
     if (index !== navigationState.index) {
       this.props.onIndexChange(index);
     }
@@ -376,6 +406,8 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       renderScene,
       renderIcon,
       renderLabel,
+      getLabelText = ({ route }) => route.title,
+      getColor = ({ route }) => route.color,
       barStyle,
       style,
       theme,
@@ -400,7 +432,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ? this.state.index.interpolate({
           inputRange: routes.map((_, i) => i),
           outputRange: routes.map(
-            route => route.color || approxBackgroundColor
+            route => getColor({ route }) || approxBackgroundColor
           ),
         })
       : approxBackgroundColor;
@@ -416,7 +448,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
           .rgb()
           .string();
 
-    const rippleColor = color(textColor)
+    const touchColor = color(textColor)
       .alpha(0.12)
       .rgb()
       .string();
@@ -430,22 +462,10 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
 
     // Since we have a single ripple, we have to reposition it so that it appears to expand from active tab.
     // We need to move it from the left to the active tab and also account for how much that tab has shifted.
-    const rippleShift =
-      navigationState.index * tabWidth +
-      tabWidth / 2 +
-      this._calculateShift(
-        this.state.previous,
-        navigationState.index,
-        routes.length
-      );
 
     return (
       <View
-        style={[
-          styles.container,
-          { backgroundColor: theme.dark ? white : black },
-          style,
-        ]}
+        style={[styles.container, style]}
         onLayout={this._handleLayout}
         pointerEvents={layout.measured ? 'auto' : 'none'}
       >
@@ -485,25 +505,30 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
             style={[styles.items, { maxWidth: maxTabWidth * routes.length }]}
           >
             {shifting ? (
-              // Large ripple with the backround color
               <Animated.View
                 pointerEvents=""none""
                 style={[
                   styles.ripple,
                   {
                     // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - layout.width / 2,
-                    left: rippleShift - layout.width / 2,
-                    height: layout.width,
-                    width: layout.width,
+                    top: BAR_HEIGHT / 2 - layout.width / 8,
+                    left:
+                      navigationState.index * tabWidth +
+                      tabWidth / 2 -
+                      layout.width / 8,
+                    height: layout.width / 4,
+                    width: layout.width / 4,
                     borderRadius: layout.width / 2,
-                    backgroundColor: routes[navigationState.index].color,
+                    backgroundColor: getColor({
+                      route: routes[navigationState.index],
+                    }),
                     transform: [
+                      { translateX: this.state.shifts[navigationState.index] },
                       {
                         // Scale to twice the size  to ensure it covers the whole tab bar
                         scale: this.state.ripple.interpolate({
                           inputRange: [0, 1],
-                          outputRange: [0, 2],
+                          outputRange: [0, 8],
                         }),
                       },
                     ],
@@ -515,36 +540,36 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                 ]}
               />
             ) : null}
-            {shifting ? (
-              // Small subtle ripple on touch
-              <Animated.View
-                pointerEvents=""none""
-                style={[
-                  styles.ripple,
-                  {
-                    // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
-                    left: rippleShift - SMALL_RIPPLE_SIZE / 2,
-                    height: SMALL_RIPPLE_SIZE,
-                    width: SMALL_RIPPLE_SIZE,
-                    borderRadius: SMALL_RIPPLE_SIZE / 2,
-                    backgroundColor: rippleColor,
-                    transform: [
-                      {
-                        scale: this.state.ripple.interpolate({
-                          inputRange: [0, 0.5, 1],
-                          outputRange: [0, 1, 1],
-                        }),
-                      },
-                    ],
-                    opacity: this.state.ripple.interpolate({
-                      inputRange: [0, MIN_RIPPLE_SCALE, 0.25, 0.5],
-                      outputRange: [0, 0, 1, 0],
-                    }),
-                  },
-                ]}
-              />
-            ) : null}
+            <Animated.View
+              pointerEvents=""none""
+              style={[
+                styles.ripple,
+                {
+                  // Set top and left values so that the ripple's center is same as the tab's center
+                  top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
+                  left:
+                    navigationState.index * tabWidth +
+                    tabWidth / 2 -
+                    SMALL_RIPPLE_SIZE / 2,
+                  height: SMALL_RIPPLE_SIZE,
+                  width: SMALL_RIPPLE_SIZE,
+                  borderRadius: SMALL_RIPPLE_SIZE / 2,
+                  backgroundColor: touchColor,
+                  transform: [
+                    {
+                      translateX: shifting
+                        ? this.state.shifts[navigationState.index]
+                        : 0,
+                    },
+                    { scale: this.state.touch },
+                  ],
+                  opacity: this.state.touch.interpolate({
+                    inputRange: [0, 0.5, 1],
+                    outputRange: [0, 1, 0],
+                  }),
+                },
+              ]}
+            />
             {routes.map((route, index) => {
               const shift = this.state.shifts[index];
               const focused = this.state.tabs[index];
@@ -607,7 +632,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderIcon ? (
-                          renderIcon({ route, focused: true })
+                          renderIcon({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <Icon
                             style={styles.icon}
@@ -625,7 +654,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderIcon ? (
-                            renderIcon({ route, focused: false })
+                            renderIcon({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <Icon
                               style={styles.icon}
@@ -652,7 +685,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderLabel ? (
-                          renderLabel({ route, focused: true })
+                          renderLabel({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <AnimatedText
                             style={[
@@ -662,7 +699,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                               },
                             ]}
                           >
-                            {route.title}
+                            {getLabelText({ route })}
                           </AnimatedText>
                         )}
                       </Animated.View>
@@ -674,7 +711,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderLabel ? (
-                            renderLabel({ route, focused: false })
+                            renderLabel({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <AnimatedText
                               style={[
@@ -684,7 +725,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                                 },
                               ]}
                             >
-                              {route.title}
+                              {getLabelText({ route })}
                             </AnimatedText>
                           )}
                         </Animated.View>

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;

diff --git a/scripts/build.mjs b/scripts/build.mjs
index 204854f..b3cf067 100644
--- a/scripts/build.mjs
+++ b/scripts/build.mjs
@@ -3,8 +3,8 @@ import { write } from 'fsxx';
 import { info, success } from './helpers.mjs';
 
 await $`rm -rf dist/*`;
-await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 await $`unbuild`;
+await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 
 const packages = [
   'jsx-runtime',
",5,"[""87d5d4e55ab7149b593d29410f1fe426ba2447d4"", ""bedc7950b24c37809e36a585b7985d5aa5e3e458"", ""ded26d768ff432ad3bde3c0aa1e95ce50726100a"", ""a52a585d74894b3b4eeb8c784fa089ff95cddad0"", ""c323d59c607cabc91f17a78528d998f376f30b10""]","[""fix"", ""test"", ""feat"", ""docs"", ""build""]"
"add testsupdate Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909enable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>assist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>use `regexp_instr != 0` instead of `REGEXP` keyword","diff --git a/Cargo.lock b/Cargo.lock
index 84d5d07..6ad05da 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -293,6 +293,7 @@ version = ""0.1.0""
 dependencies = [
  ""git-cliff-core"",
  ""log"",
+ ""pretty_assertions"",
  ""pretty_env_logger"",
  ""structopt"",
 ]
diff --git a/git-cliff-core/src/lib.rs b/git-cliff-core/src/lib.rs
index 3b18ba0..a560c94 100644
--- a/git-cliff-core/src/lib.rs
+++ b/git-cliff-core/src/lib.rs
@@ -1,6 +1,8 @@
 //! Highly customizable Changelog Generator
 #![warn(missing_docs, clippy::unwrap_used)]
 
+/// Export regex crate.
+pub use regex;
 /// Git commit.
 pub mod commit;
 /// Config file parser.
diff --git a/git-cliff/Cargo.toml b/git-cliff/Cargo.toml
index 41eb2e9..cc64b37 100644
--- a/git-cliff/Cargo.toml
+++ b/git-cliff/Cargo.toml
@@ -20,3 +20,6 @@ log = ""0.4.14""
 version = ""0.3""
 default-features = false
 features = [""suggestions"", ""color"", ""wrap_help""]
+
+[dev-dependencies]
+pretty_assertions = ""0.7""
diff --git a/git-cliff/src/changelog.rs b/git-cliff/src/changelog.rs
index 3f9e994..23ea186 100644
--- a/git-cliff/src/changelog.rs
+++ b/git-cliff/src/changelog.rs
@@ -115,3 +115,171 @@ impl<'a> Changelog<'a> {
 		Ok(())
 	}
 }
+
+#[cfg(test)]
+mod test {
+	use super::*;
+	use git_cliff_core::config::{
+		ChangelogConfig,
+		CommitParser,
+		GitConfig,
+	};
+	use git_cliff_core::regex::Regex;
+	use pretty_assertions::assert_eq;
+	use std::str;
+	#[test]
+	fn changelog_generator() -> Result<()> {
+		let config = Config {
+			changelog: ChangelogConfig {
+				header: Some(String::from(""# Changelog"")),
+				body:   String::from(
+					r#""{% if version %}
+				## Release [{{ version }}] - {{ timestamp | date(format=""%Y-%m-%d"") }}
+				({{ commit_id }}){% else %}
+				## Unreleased{% endif %}
+				{% for group, commits in commits | group_by(attribute=""group"") %}
+				### {{ group }}{% for group, commits in commits | group_by(attribute=""scope"") %}
+				#### {{ group }}{% for commit in commits %}
+				- {{ commit.message }}{% endfor %}
+				{% endfor %}{% endfor %}""#,
+				)
+				.replace(""				"", """"),
+				footer: Some(String::from(""------------"")),
+			},
+			git:       GitConfig {
+				conventional_commits: true,
+				commit_parsers:       Some(vec![
+					CommitParser {
+						message: Regex::new(""feat*"").ok(),
+						body:    None,
+						group:   Some(String::from(""New features"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new(""fix*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Bug Fixes"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new("".*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Other"")),
+						skip:    None,
+					},
+				]),
+				filter_commits:       Some(false),
+				tag_pattern:          String::new(),
+				skip_tags:            Regex::new(""v3.*"").ok(),
+			},
+		};
+		let test_release = Release {
+			version:   Some(String::from(""v1.0.0"")),
+			commits:   vec![
+				Commit::new(
+					String::from(""0bc123""),
+					String::from(""feat(app): add cool features""),
+				),
+				Commit::new(
+					String::from(""0werty""),
+					String::from(""style(ui): make good stuff""),
+				),
+				Commit::new(
+					String::from(""0w3rty""),
+					String::from(""fix(ui): fix more stuff""),
+				),
+				Commit::new(
+					String::from(""0jkl12""),
+					String::from(""chore(app): do nothing""),
+				),
+			],
+			commit_id: Some(String::from(""0bc123"")),
+			timestamp: 50000000,
+			previous:  None,
+		};
+		let releases = vec![
+			test_release.clone(),
+			Release {
+				version: Some(String::from(""v3.0.0"")),
+				commits: vec![Commit::new(
+					String::from(""n0thin""),
+					String::from(""feat(xyz): skip commit""),
+				)],
+				..Release::default()
+			},
+			Release {
+				version:   None,
+				commits:   vec![
+					Commit::new(
+						String::from(""abc123""),
+						String::from(""feat(app): add xyz""),
+					),
+					Commit::new(
+						String::from(""abc124""),
+						String::from(""docs(app): document zyx""),
+					),
+					Commit::new(String::from(""def789""), String::from(""merge #4"")),
+					Commit::new(
+						String::from(""qwerty""),
+						String::from(""fix(app): fix abc""),
+					),
+					Commit::new(
+						String::from(""hjkl12""),
+						String::from(""chore(ui): do boring stuff""),
+					),
+				],
+				commit_id: None,
+				timestamp: 1000,
+				previous:  Some(Box::new(test_release)),
+			},
+		];
+		let changelog = Changelog::new(releases, &config)?;
+		let mut out = Vec::new();
+		changelog.generate(&mut out)?;
+		assert_eq!(
+			String::from(
+				r#""# Changelog
+
+			## Unreleased
+
+			### Bug Fixes
+			#### app
+			- fix abc
+
+			### New features
+			#### app
+			- add xyz
+
+			### Other
+			#### app
+			- document zyx
+
+			#### ui
+			- do boring stuff
+
+			## Release [v1.0.0] - 1971-08-02
+			(0bc123)
+
+			### Bug Fixes
+			#### ui
+			- fix more stuff
+
+			### New features
+			#### app
+			- add cool features
+
+			### Other
+			#### app
+			- do nothing
+
+			#### ui
+			- make good stuff
+			------------
+			""#
+			)
+			.replace(""			"", """"),
+			str::from_utf8(&out).unwrap()
+		);
+		Ok(())
+	}
+}

diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })

diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 

diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(
",5,"[""8ee0611fbf0cd89abe7ae588f22e6ecb843598ea"", ""c2ee5cd5e709afd15c5565ee009a0d204403a119"", ""fd8e563cc19ca4684885d4692acee6bebcca4ada"", ""1269431c8a3e7549f10fcbbb4b88ff625c8898b3"", ""06e2be4e2019b6fa714e1fcb34485860ef1ede79""]","[""test"", ""docs"", ""feat"", ""build"", ""fix""]"
"licensingadd numberOfLines prop to DataTableTitle (#863)

Closes #848assist build

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>export a modal transition presetverify checkpoint listeners are notified","diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;

diff --git a/src/components/DataTable/DataTableTitle.js b/src/components/DataTable/DataTableTitle.js
index bfcf07e..d764fd5 100644
--- a/src/components/DataTable/DataTableTitle.js
+++ b/src/components/DataTable/DataTableTitle.js
@@ -27,6 +27,10 @@ type Props = React.ElementConfig<typeof TouchableWithoutFeedback> & {|
    */
   sortDirection?: 'ascending' | 'descending',
   /**
+   * The number of lines to show.
+   */
+  numberOfLines?: number,
+  /**
    * Function to execute on press.
    */
   onPress?: () => mixed,
@@ -44,6 +48,10 @@ type State = {
 class DataTableTitle extends React.Component<Props, State> {
   static displayName = 'DataTable.Title';
 
+  static defaultProps = {
+    numberOfLines: 1,
+  };
+
   state = {
     spinAnim: new Animated.Value(
       this.props.sortDirection === 'ascending' ? 0 : 1
@@ -70,6 +78,7 @@ class DataTableTitle extends React.Component<Props, State> {
       sortDirection,
       theme,
       style,
+      numberOfLines,
       ...rest
     } = this.props;
 
@@ -99,7 +108,7 @@ class DataTableTitle extends React.Component<Props, State> {
               styles.cell,
               sortDirection ? styles.sorted : { color: textColor },
             ]}
-            numberOfLines={1}
+            numberOfLines={numberOfLines}
           >
             {children}
           </Text>

diff --git a/scripts/helmcharts/build_deploy.sh b/scripts/helmcharts/build_deploy.sh
index 4a484f2..f9f8f9f 100644
--- a/scripts/helmcharts/build_deploy.sh
+++ b/scripts/helmcharts/build_deploy.sh
@@ -24,7 +24,7 @@ echo $DOCKER_REPO
     docker login $DOCKER_REPO
     cd ../../backend
     bash build.sh $@
-    cd ../../assist-stats/
+    cd ../assist-stats/
     bash build.sh $@
     cd ../assist
     bash build.sh $@
diff --git a/scripts/helmcharts/build_deploy_parallel.sh b/scripts/helmcharts/build_deploy_parallel.sh
index 47ada0c..cb4e3f4 100644
--- a/scripts/helmcharts/build_deploy_parallel.sh
+++ b/scripts/helmcharts/build_deploy_parallel.sh
@@ -15,7 +15,7 @@ export PUSH_IMAGE=1
 export AWS_DEFAULT_REGION=""eu-central-1""
 export SIGN_KEY=""awskms:///alias/openreplay-container-sign""
 echo $DOCKER_REPO
-[[ -z DOCKER_REPO ]] && {
+[[ -z $DOCKER_REPO ]] && {
     echo Set DOCKER_REPO=""your docker registry""
     exit 1
 } || {
@@ -30,7 +30,8 @@ echo $DOCKER_REPO
     tmux split-window ""cd ../../sourcemap-reader && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux split-window ""cd ../../api && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@ \
       && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_alerts.sh $@ \
-      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@""
+      && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build_crons.sh $@ \
+      && cd ../assist-stats && IMAGE_TAG=$IMAGE_TAG DOCKER_REPO=$DOCKER_REPO PUSH_IMAGE=1 bash build.sh $@""
     tmux select-layout tiled
 
 }

diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {

diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }
",5,"[""a52a585d74894b3b4eeb8c784fa089ff95cddad0"", ""f9a094918b62534614c47aa8a13f33aec751a1e0"", ""1269431c8a3e7549f10fcbbb4b88ff625c8898b3"", ""535708ae50aecb452560a23356fd396f99ef13a2"", ""e0198f74b81da3663144cfe1d971939319f82a0f""]","[""docs"", ""feat"", ""build"", ""refactor"", ""test""]"
"print errors without stacktraceadd hardware back button

Closes #5071skip flaky testmake it mode lessfix netty dependency

netty-bom 4.1.70 contains the changes from pull request
https://github.com/netty/netty/pull/11798, which moved the classes out
of the native modules to make sure the same classes don't end up on the
classpath multiple times. For us it means that we need to depend on both
the native and classes modules. However, since we don't use the native
module directly (only classes that were moved to this classes module),
we need to force the dependency plugin to consider the native module as
used.","diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {

diff --git a/ionic/components/app/app.ts b/ionic/components/app/app.ts
index 04d8c57..08aab92 100644
--- a/ionic/components/app/app.ts
+++ b/ionic/components/app/app.ts
@@ -3,8 +3,7 @@ import {Title} from 'angular2/platform/browser';
 
 import {Config} from '../../config/config';
 import {ClickBlock} from '../../util/click-block';
-import {Nav} from '../nav/nav';
-import {Tabs} from '../tabs/tabs';
+import {Platform} from '../../platform/platform';
 
 
 /**
@@ -23,8 +22,20 @@ export class IonicApp {
 
   constructor(
     private _config: Config,
-    private _clickBlock: ClickBlock
-  ) {}
+    private _clickBlock: ClickBlock,
+    platform: Platform
+  ) {
+    platform.backButton.subscribe(() => {
+      let activeNav = this.getActiveNav();
+      if (activeNav) {
+        if (activeNav.length() === 1) {
+          platform.exitApp();
+        } else {
+          activeNav.pop();
+        }
+      }
+    });
+  }
 
   /**
    * Sets the document title.
@@ -102,7 +113,7 @@ export class IonicApp {
   /**
    * @private
    */
-  getActiveNav(): Nav | Tabs {
+  getActiveNav(): any {
     var nav = this._rootNav || null;
     var activeChildNav;
 

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method

diff --git a/core/src/components/slides/slides.tsx b/core/src/components/slides/slides.tsx
index 48fd53f..d5c2f75 100644
--- a/core/src/components/slides/slides.tsx
+++ b/core/src/components/slides/slides.tsx
@@ -1,7 +1,6 @@
 import { Component, Element, Event, EventEmitter, Method, Prop, Watch } from '@stencil/core';
 
 import { Mode } from '../../interface.js';
-import { createThemedClasses } from '../../utils/theme.js';
 
 import { Swiper } from './vendor/swiper.js';
 
@@ -15,6 +14,7 @@ import { Swiper } from './vendor/swiper.js';
   shadow: true
 })
 export class Slides {
+
   private container!: HTMLElement;
   private swiper: any;
 
@@ -391,12 +391,6 @@ export class Slides {
     return { ...swiperOptions, ...this.options, ...eventOptions };
   }
 
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'slides')
-    };
-  }
-
   render() {
     return (
       <div class=""swiper-container"" ref={el => this.container = el as HTMLElement }>
diff --git a/core/src/components/thumbnail/thumbnail.ios.scss b/core/src/components/thumbnail/thumbnail.ios.scss
deleted file mode 100644
index e3add45..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.ios.vars"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-ios-width};
-  --border-radius: #{$thumbnail-ios-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.ios.vars.scss b/core/src/components/thumbnail/thumbnail.ios.vars.scss
deleted file mode 100644
index 85d53e5..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.ios"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-ios-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-ios-height:                  $thumbnail-ios-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-ios-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.md.scss b/core/src/components/thumbnail/thumbnail.md.scss
deleted file mode 100644
index 0fbb2ca..0000000
--- a/core/src/components/thumbnail/thumbnail.md.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.md.vars"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-md-width};
-  --border-radius: #{$thumbnail-md-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.md.vars.scss b/core/src/components/thumbnail/thumbnail.md.vars.scss
deleted file mode 100644
index 94e48b2..0000000
--- a/core/src/components/thumbnail/thumbnail.md.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.md"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-md-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-md-height:                  $thumbnail-md-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-md-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.scss b/core/src/components/thumbnail/thumbnail.scss
index 8ac3a22..8af268d 100644
--- a/core/src/components/thumbnail/thumbnail.scss
+++ b/core/src/components/thumbnail/thumbnail.scss
@@ -9,6 +9,8 @@
    * @prop --border-radius: Border radius of the thumbnail
    * @prop --size: Size of the thumbnail
    */
+  --size: 48px;
+  --border-radius: 0;
 
   @include border-radius(var(--border-radius));
 
diff --git a/core/src/components/thumbnail/thumbnail.tsx b/core/src/components/thumbnail/thumbnail.tsx
index 50ff2c2..de76593 100644
--- a/core/src/components/thumbnail/thumbnail.tsx
+++ b/core/src/components/thumbnail/thumbnail.tsx
@@ -1,25 +1,11 @@
 import { Component } from '@stencil/core';
 
-import { Mode } from '../../interface';
-import { createThemedClasses } from '../../utils/theme';
-
 @Component({
   tag: 'ion-thumbnail',
-  styleUrls: {
-    ios: 'thumbnail.ios.scss',
-    md: 'thumbnail.md.scss'
-  },
+  styleUrl: 'thumbnail.scss',
   shadow: true
 })
 export class Thumbnail {
-  mode!: Mode;
-
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'thumbnail')
-    };
-  }
-
   render() {
     return <slot></slot>;
   }

diff --git a/atomix/cluster/pom.xml b/atomix/cluster/pom.xml
index a477873..b6db695 100644
--- a/atomix/cluster/pom.xml
+++ b/atomix/cluster/pom.xml
@@ -69,6 +69,10 @@
     </dependency>
     <dependency>
       <groupId>io.netty</groupId>
+      <artifactId>netty-transport-classes-epoll</artifactId>
+    </dependency>
+    <dependency>
+      <groupId>io.netty</groupId>
       <artifactId>netty-transport-native-epoll</artifactId>
       <classifier>linux-x86_64</classifier>
     </dependency>
@@ -278,6 +282,7 @@
             <dependency>uk.co.real-logic:sbe-tool</dependency>
             <dependency>net.jqwik:jqwik</dependency>
             <dependency>io.netty:netty-tcnative-boringssl-static</dependency>
+            <dependency>io.netty:netty-transport-native-epoll</dependency>
           </usedDependencies>
         </configuration>
       </plugin>
",5,"[""d129eaf9125a967ac86c6c7276bbae6b4d50af36"", ""68278b00450f2679761a2999500f6d87a579376b"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d"", ""771857b1df9470ebc15357e8879118a72c649d5b"", ""f00a4d3e307b89842250358ee432e6800bb24362""]","[""fix"", ""feat"", ""test"", ""refactor"", ""build""]"
"update flushed index before truncatingdocker PG version upgrade

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>convert `run_tag_values_test_case` to a functionfixed docker link testsnginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>","diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/packages/nocodb/docker-compose.yml b/packages/nocodb/docker-compose.yml
index 7fabf79..ba2ab7b 100644
--- a/packages/nocodb/docker-compose.yml
+++ b/packages/nocodb/docker-compose.yml
@@ -1,4 +1,4 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
     # db55:
@@ -96,8 +96,8 @@ services:
     #     - 5495:5432
     #   volumes:
     #     - ./pg-sakila-db:/docker-entrypoint-initdb.d
-    pg96:
-     image: postgres:9.6
+    pg147:
+     image: postgres:14.7
      restart: always
      environment:
        POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
index 19dfab2..97d346b 100644
--- a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
+++ b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg.yml b/tests/playwright/scripts/docker-compose-pg.yml
index 0396579..9fab10e 100644
--- a/tests/playwright/scripts/docker-compose-pg.yml
+++ b/tests/playwright/scripts/docker-compose-pg.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password

diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]

diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection
",5,"[""933ab6bb86372913c992567cf9660009900911a7"", ""37b1cbfd3d2c462ef4f2a131e4172c38dc8d9ddf"", ""1db13ec43727aca872a0f3836e4023ed85db665e"", ""c7b25726df94a2530c9b1c0d2b6a0acaa103822f"", ""e12d9e77a6fd531a22325337838a841b1c67f00d""]","[""fix"", ""build"", ""refactor"", ""test"", ""docs""]"
"use `regexp_instr != 0` instead of `REGEXP` keywordrun pyspark tests in parallelbetter layout for block and segmentfix build orderingadd numberOfLines prop to DataTableTitle (#863)

Closes #848","diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index e23088e..9708157 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -202,11 +202,11 @@ jobs:
         run: poetry install --without dev --without docs --extras ${{ matrix.backend.name }} --extras geospatial
 
       - name: ""run parallel tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name != 'pyspark' && matrix.backend.name != 'impala'
+        if: matrix.backend.name != 'impala'
         run: just ci-check -m ${{ matrix.backend.name }} --numprocesses auto --dist=loadgroup
 
       - name: ""run serial tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name == 'pyspark' || matrix.backend.name == 'impala'
+        if: matrix.backend.name == 'impala'
         run: just ci-check -m ${{ matrix.backend.name }}
         env:
           IBIS_TEST_NN_HOST: localhost

diff --git a/docs/docs/config-block.md b/docs/docs/config-block.md
new file mode 100644
index 0000000..df1ee54
--- /dev/null
+++ b/docs/docs/config-block.md
@@ -0,0 +1,60 @@
+---
+id: config-block
+title: Block
+sidebar_label: Block
+---
+
+Let's take a closer look at what defines a block.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""segments"": [
+        ...
+      ]
+    }
+  ]
+}
+```
+
+- type: `prompt` | `rprompt`
+- newline: `boolean`
+- alignment: `left` | `right`
+- vertical_offset: `int`
+- horizontal_offset: `int`
+- segments: `array` of one or more `segments`
+
+### Type
+
+Tells the engine what to do with the block. There are three options:
+
+- `prompt` renders one or more segments
+- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
+Supported on [ZSH][rprompt], Bash and Powershell.
+
+### Newline
+
+Start the block on a new line. Defaults to `false`.
+
+### Alignment
+
+Tell the engine if the block should be left or right-aligned.
+
+### Vertical offset
+
+Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
+moves it up one line.
+
+### Horizontal offset
+
+Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
+but on a horizontal level where a negative number moves the block left and a positive number right.
+
+### Segments
+
+Array of one or more segments.
diff --git a/docs/docs/config-example.md b/docs/docs/config-example.md
new file mode 100644
index 0000000..c180c4f
--- /dev/null
+++ b/docs/docs/config-example.md
@@ -0,0 +1,96 @@
+---
+id: config-sample
+title: Sample
+sidebar_label: Sample
+---
+
+```json
+{
+  ""final_space"": true,
+  ""blocks"": [
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""right"",
+      ""vertical_offset"": -1,
+      ""segments"": [
+        {
+          ""type"": ""time"",
+          ""style"": ""plain"",
+          ""foreground"": ""#007ACC"",
+          ""properties"": {
+            ""time_format"": ""15:04:05""
+          }
+        }
+      ]
+    },
+    {
+      ""type"": ""prompt"",
+      ""alignment"": ""left"",
+      ""newline"": true,
+      ""segments"": [
+        {
+          ""type"": ""session"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#ffb300"",
+          ""leading_diamond"": ""\uE0B6"",
+          ""trailing_diamond"": ""\uE0B0"",
+          ""properties"": {
+            ""postfix"": "" ""
+          }
+        },
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ""prefix"": "" \uE5FF "",
+            ""style"": ""folder"",
+            ""exclude_folders"": [
+              ""/super/secret/project""
+            ],
+            ""enable_hyperlink"": false
+          }
+        },
+        {
+          ""type"": ""git"",
+          ""style"": ""powerline"",
+          ""foreground"": ""#193549"",
+          ""foreground_templates"": [
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
+          ],
+          ""background"": ""#2e9599"",
+          ""background_templates"": [
+            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
+            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
+            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
+            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
+          ],
+          ""powerline_symbol"": ""\uE0B0"",
+          ""properties"": {
+            ""fetch_status"": true,
+            ""branch_max_length"": 25,
+            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
+          }
+        },
+        {
+          ""type"": ""exit"",
+          ""style"": ""diamond"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#00897b"",
+          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
+          ""leading_diamond"": """",
+          ""trailing_diamond"": ""\uE0B4"",
+          ""properties"": {
+            ""always_enabled"": true,
+            ""template"": ""\uE23A"",
+            ""prefix"": ""<parentBackground>\uE0B0</> ""
+          }
+        }
+      ]
+    }
+  ]
+}
+```
diff --git a/docs/docs/config-overview.md b/docs/docs/config-overview.md
index 1fdbcba..b554869 100644
--- a/docs/docs/config-overview.md
+++ b/docs/docs/config-overview.md
@@ -1,7 +1,7 @@
 ---
 id: config-overview
-title: Overview
-sidebar_label: Overview
+title: General
+sidebar_label: General
 ---
 
 Oh My Posh renders your prompt based on the definition of _blocks_ (like Lego) which contain one or more _segments_.
@@ -64,332 +64,7 @@ boxes with question marks, set up your terminal to use a [supported font][font] 
 - terminal_background: `string` [color][colors] - terminal background color, set to your terminal's background color when
 you notice black elements in Windows Terminal or the Visual Studio Code integrated terminal
 
-## Block
-
-Let's take a closer look at what defines a block.
-
-- type: `prompt` | `rprompt`
-- newline: `boolean`
-- alignment: `left` | `right`
-- vertical_offset: `int`
-- horizontal_offset: `int`
-- segments: `array` of one or more `segments`
-
-### Type
-
-Tells the engine what to do with the block. There are three options:
-
-- `prompt` renders one or more segments
-- `rprompt` renders one or more segments aligned to the right of the cursor. Only one `rprompt` block is permitted.
-Supported on [ZSH][rprompt], Bash and Powershell.
-
-### Newline
-
-Start the block on a new line. Defaults to `false`.
-
-### Alignment
-
-Tell the engine if the block should be left or right-aligned.
-
-### Vertical offset
-
-Move the block up or down x lines. For example, `vertical_offset: 1` moves the prompt down one line, `vertical_offset: -1`
-moves it up one line.
-
-### Horizontal offset
-
-Moves the segment to the left or the right to have it exactly where you want it to be. Works like `vertical_offset`
-but on a horizontal level where a negative number moves the block left and a positive number right.
-
-### Segments
-
-Array of one or more segments.
-
-## Segment
-
-A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
-looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
-understand how to configure a segment.
-
-- type: `string` any of the included [segments][segments]
-- style: `powerline` | `plain` | `diamond`
-- powerline_symbol: `string`
-- invert_powerline: `boolean`
-- leading_diamond: `string`
-- trailing_diamond: `string`
-- foreground: `string` [color][colors]
-- foreground_templates: `array` of `string` values
-- background: `string` [color][colors]
-- background_templates: `array` of `string` values
-- properties: `array` of `Property`: `string`
-
-### Type
-
-Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
-
-### Style
-
-Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
-themes out there, we identified 3 types. All of these require a different configuration and depending on the look
-you want to achieve you might need to understand/use them all.
-
-#### Powerline
-
-What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
-background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
-if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
-
-#### Plain
-
-Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
-Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
-
-#### Diamond
-
-While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
-Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
-segment background as their foreground color.
-
-### Powerline symbol
-
-Text character to use when `""style"": ""powerline""`.
-
-### Invert Powerline
-
-If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
-in the perfectly mirrored variant for example.
-
-### Leading diamond
-
-Text character to use at the start of the segment. Will take the background color of the segment as
-its foreground color.
-
-### Trailing diamond
-
-Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
-
-### Foreground
-
-[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
-
-### Foreground Templates
-
-Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
-Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
-offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
-the documentation.
-
-The following sample is based on the [AWS Segment][aws].
-
-```json
-{
-  ""type"": ""aws"",
-  ""style"": ""powerline"",
-  ""powerline_symbol"": ""\uE0B0"",
-  ""foreground"": ""#ffffff"",
-  ""background"": ""#111111"",
-  ""foreground_templates"": [
-    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
-    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
-  ],
-  ""properties"": {
-    ""prefix"": "" \uE7AD ""
-  }
-}
-```
-
-The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
-one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
-returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
-templates returns a value, the foreground value `#ffffff` is used.
-
-### Background
-
-[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
-
-### Background Templates
-
-Same as [Foreground Templates][fg-templ] but for the background color.
-
-### Properties
-
-An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
-will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
-engine which allow you to customize the output even more.
-
-#### General-purpose properties
-
-You can use these on any segment, the engine is responsible for adding them correctly.
-
-- prefix: `string`
-- postfix: `string`
-- include_folders: `[]string`
-- exclude_folders: `[]string`
-
-##### Prefix
-
-The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
-specify this as `''`.
-
-##### Postfix
-
-The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
-If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
-specify this as `''`.
-
-##### Include / Exclude Folders
-
-Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
-the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
-will not be rendered when in one of the excluded locations.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-```json
-""exclude_folders"": [
-  ""/Users/posh/Projects""
-]
-```
-
-The strings specified in these properties are evaluated as [regular expressions][regex]. You
-can use any valid regular expression construct, but the regular expression must match the entire directory
-name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-]
-```
-
-You can also combine these properties:
-
-```json
-""include_folders"": [
-  ""/Users/posh/Projects.*""
-],
-""exclude_folders"": [
-  ""/Users/posh/Projects/secret-project.*""
-]
-```
-
-##### Notes
-
-- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
-is used by the current operating system.
-- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
-directory name, you need to specify it as `\\\\`.
-- The character `~` at the start of a specified folder will match the user's home directory.
-- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
-
-This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
-`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
-
-## Full Sample
-
-```json
-{
-  ""final_space"": true,
-  ""blocks"": [
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""right"",
-      ""vertical_offset"": -1,
-      ""segments"": [
-        {
-          ""type"": ""time"",
-          ""style"": ""plain"",
-          ""foreground"": ""#007ACC"",
-          ""properties"": {
-            ""time_format"": ""15:04:05""
-          }
-        }
-      ]
-    },
-    {
-      ""type"": ""prompt"",
-      ""alignment"": ""left"",
-      ""newline"": true,
-      ""segments"": [
-        {
-          ""type"": ""session"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#ffb300"",
-          ""leading_diamond"": ""\uE0B6"",
-          ""trailing_diamond"": ""\uE0B0"",
-          ""properties"": {
-            ""postfix"": "" ""
-          }
-        },
-        {
-          ""type"": ""path"",
-          ""style"": ""powerline"",
-          ""powerline_symbol"": ""\uE0B0"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#61AFEF"",
-          ""properties"": {
-            ""prefix"": "" \uE5FF "",
-            ""style"": ""folder"",
-            ""exclude_folders"": [
-              ""/super/secret/project""
-            ],
-            ""enable_hyperlink"": false
-          }
-        },
-        {
-          ""type"": ""git"",
-          ""style"": ""powerline"",
-          ""foreground"": ""#193549"",
-          ""foreground_templates"": [
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#ffffff{{ end }}""
-          ],
-          ""background"": ""#2e9599"",
-          ""background_templates"": [
-            ""{{ if or (.Working.Changed) (.Staging.Changed) }}#f36943{{ end }}"",
-            ""{{ if and (gt .Ahead 0) (gt .Behind 0) }}#a8216b{{ end }}"",
-            ""{{ if gt .Ahead 0 }}#35b5ff{{ end }}"",
-            ""{{ if gt .Behind 0 }}#f89cfa{{ end }}""
-          ],
-          ""powerline_symbol"": ""\uE0B0"",
-          ""properties"": {
-            ""fetch_status"": true,
-            ""branch_max_length"": 25,
-            ""template"": ""{{ .HEAD }}{{ .BranchStatus }}""
-          }
-        },
-        {
-          ""type"": ""exit"",
-          ""style"": ""diamond"",
-          ""foreground"": ""#ffffff"",
-          ""background"": ""#00897b"",
-          ""background_templates"": [""{{ if gt .Code 0 }}#e91e63{{ end }}""],
-          ""leading_diamond"": """",
-          ""trailing_diamond"": ""\uE0B4"",
-          ""properties"": {
-            ""always_enabled"": true,
-            ""template"": ""\uE23A"",
-            ""prefix"": ""<parentBackground>\uE0B0</> ""
-          }
-        }
-      ]
-    }
-  ]
-}
-```
-
 [releases]: https://github.com/JanDeDobbeleer/oh-my-posh/releases/latest
 [font]: /docs/config-fonts
 [schema]: https://github.com/JanDeDobbeleer/oh-my-posh/blob/main/themes/schema.json
 [themes]: https://github.com/JanDeDobbeleer/oh-my-posh/tree/main/themes
-[segments]: /docs/battery
-[colors]: /docs/config-colors
-[go-text-template]: https://golang.org/pkg/text/template/
-[sprig]: https://masterminds.github.io/sprig/
-[fg-templ]: /docs/config-overview#foreground-templates
-[regex]: https://www.regular-expressions.info/tutorial.html
-[aws]: /docs/aws
diff --git a/docs/docs/config-segment.md b/docs/docs/config-segment.md
new file mode 100644
index 0000000..08a66e4
--- /dev/null
+++ b/docs/docs/config-segment.md
@@ -0,0 +1,219 @@
+---
+id: config-segment
+title: Segment
+sidebar_label: Segment
+---
+
+A segment is a part of the prompt with a certain context. There are different types available out-of-the-box, if you're
+looking for what's included, feel free to skip this part and browse through the [segments][segments]. Keep reading to
+understand how to configure a segment.
+
+```json
+{
+  ""$schema"": ""https://raw.githubusercontent.com/JanDeDobbeleer/oh-my-posh/main/themes/schema.json"",
+  ...
+  ""blocks"": [
+    {
+      ...
+      ""segments"": [
+        {
+          ""type"": ""path"",
+          ""style"": ""powerline"",
+          ""powerline_symbol"": ""\uE0B0"",
+          ""foreground"": ""#ffffff"",
+          ""background"": ""#61AFEF"",
+          ""properties"": {
+            ...
+          }
+        }
+      ]
+    }
+  ]
+}
+```
+
+- type: `string` any of the included [segments][segments]
+- style: `powerline` | `plain` | `diamond`
+- powerline_symbol: `string`
+- invert_powerline: `boolean`
+- leading_diamond: `string`
+- trailing_diamond: `string`
+- foreground: `string` [color][colors]
+- foreground_templates: `array` of `string` values
+- background: `string` [color][colors]
+- background_templates: `array` of `string` values
+- properties: `array` of `Property`: `string`
+
+## Type
+
+Takes the `string` value referencing which segment logic it needs to run (see [segments][segments] for possible values).
+
+## Style
+
+Oh Hi! You made it to a really interesting part, great! Style defines how a prompt is rendered. Looking at the most prompt
+themes out there, we identified 3 types. All of these require a different configuration and depending on the look
+you want to achieve you might need to understand/use them all.
+
+### Powerline
+
+What started it all for us. Makes use of a single symbol (`powerline_symbol`) to separate the segments. It takes the
+background color of the previous segment (or transparent if none) and the foreground of the current one (or transparent
+if we're at the last segment). Expects segments to have a colored background, else there little use for this one.
+
+### Plain
+
+Simple. Colored text on a transparent background. Make sure to set `foreground` for maximum enjoyment.
+Segments will be separated by empty spaces unless you specify `''` for the `prefix` and `postfix` settings for the segment.
+
+### Diamond
+
+While Powerline works great with a single symbol, sometimes you want a segment to have a different start and end symbol.
+Just like a diamond: `< my segment text >`. The difference between this and plain is that the diamond symbols take the
+segment background as their foreground color.
+
+## Powerline symbol
+
+Text character to use when `""style"": ""powerline""`.
+
+## Invert Powerline
+
+If `true` this swaps the foreground and background colors. Can be useful when the character you want does not exist
+in the perfectly mirrored variant for example.
+
+## Leading diamond
+
+Text character to use at the start of the segment. Will take the background color of the segment as
+its foreground color.
+
+## Trailing diamond
+
+Text character to use at the end of the segment. Will take the background color of the segment as its foreground color.
+
+## Foreground
+
+[Color][colors] to use as the segment text foreground color. Also supports transparency using the `transparent` keyword.
+
+## Foreground Templates
+
+Array if string templates to define the foreground color for the given Segment based on the Segment's Template Properties.
+Under the hood this uses go's [text/template][go-text-template] feature extended with [sprig][sprig] and
+offers a few standard properties to work with. For supported Segments, look for the **Template Properties** section in
+the documentation.
+
+The following sample is based on the [AWS Segment][aws].
+
+```json
+{
+  ""type"": ""aws"",
+  ""style"": ""powerline"",
+  ""powerline_symbol"": ""\uE0B0"",
+  ""foreground"": ""#ffffff"",
+  ""background"": ""#111111"",
+  ""foreground_templates"": [
+    ""{{if contains \""default\"" .Profile}}#FFA400{{end}}"",
+    ""{{if contains \""jan\"" .Profile}}#f1184c{{end}}""
+  ],
+  ""properties"": {
+    ""prefix"": "" \uE7AD ""
+  }
+}
+```
+
+The logic is as follows: when `background_templates` contains an array, we will check every template line until there's
+one that returns a non-empty string. So, when the contents of `.Profile` contain the word `default`, the first template
+returns `#FFA400` and that's the color that will be used. If it contains `jan`, it returns `#f1184c`. When none of the
+templates returns a value, the foreground value `#ffffff` is used.
+
+## Background
+
+[Color][colors] to use as the segment text background color. Also supports transparency using the `transparent` keyword.
+
+## Background Templates
+
+Same as [Foreground Templates][fg-templ] but for the background color.
+
+## Properties
+
+An array of **Properties** with a value. This is used inside of the segment logic to tweak what the output of the segment
+will be. Segments have the ability to define their own Properties, but there are some general ones being used by the
+engine which allow you to customize the output even more.
+
+### General-purpose properties
+
+You can use these on any segment, the engine is responsible for adding them correctly.
+
+- prefix: `string`
+- postfix: `string`
+- include_folders: `[]string`
+- exclude_folders: `[]string`
+
+#### Prefix
+
+The string content will be put in front of the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will be an empty space in `plain` mode. If you want to remove the space before the segment,
+specify this as `''`.
+
+#### Postfix
+
+The string content will be put after the segment's output text. Useful for symbols, text or other customizations.
+If this is not set, it will default to an empty space in `plain` mode. If you want to remove the space after the segment,
+specify this as `''`.
+
+#### Include / Exclude Folders
+
+Sometimes you might want to have a segment only rendered in certain folders. If `include_folders` is specified,
+the segment will only be rendered when in one of those locations. If `exclude_folders` is specified, the segment
+will not be rendered when in one of the excluded locations.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+```json
+""exclude_folders"": [
+  ""/Users/posh/Projects""
+]
+```
+
+The strings specified in these properties are evaluated as [regular expressions][regex]. You
+can use any valid regular expression construct, but the regular expression must match the entire directory
+name. The following will match `/Users/posh/Projects/Foo` but not `/home/Users/posh/Projects/Foo`.
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+]
+```
+
+You can also combine these properties:
+
+```json
+""include_folders"": [
+  ""/Users/posh/Projects.*""
+],
+""exclude_folders"": [
+  ""/Users/posh/Projects/secret-project.*""
+]
+```
+
+#### Notes
+
+- Oh My Posh will accept both `/` and `\` as path separators for a folder and will match regardless of which
+is used by the current operating system.
+- Because the strings are evaluated as regular expressions, if you want to use a `\` in a Windows
+directory name, you need to specify it as `\\\\`.
+- The character `~` at the start of a specified folder will match the user's home directory.
+- The comparison is case-insensitive on Windows and macOS, but case-sensitive on other operating systems.
+
+This means that for user Bill, who has a user account `Bill` on Windows and `bill` on Linux,  `~/Foo` might match
+`C:\Users\Bill\Foo` or `C:\Users\Bill\foo` on Windows but only `/home/bill/Foo` on Linux.
+
+[segments]: /docs/battery
+[colors]: /docs/config-colors
+[go-text-template]: https://golang.org/pkg/text/template/
+[sprig]: https://masterminds.github.io/sprig/
+[fg-templ]: /docs/config-overview#foreground-templates
+[regex]: https://www.regular-expressions.info/tutorial.html
+[aws]: /docs/aws
diff --git a/docs/docs/segment-environment.md b/docs/docs/segment-environment.md
index f35bc87..982a0a5 100644
--- a/docs/docs/segment-environment.md
+++ b/docs/docs/segment-environment.md
@@ -34,7 +34,7 @@ New-Alias -Name 'Set-PoshContext' -Value 'Set-EnvVar' -Scope Global -Force
 
 The segment will show when the value of the environment variable isn't empty.
 
-## Sample Configuration
+## Sample *Configuration*
 
 ```json
 {
diff --git a/docs/sidebars.js b/docs/sidebars.js
index a75163e..8f151a2 100644
--- a/docs/sidebars.js
+++ b/docs/sidebars.js
@@ -20,6 +20,9 @@ module.exports = {
       label: ""⚙️ Configuration"",
       items: [
         ""config-overview"",
+        ""config-block"",
+        ""config-segment"",
+        ""config-sample"",
         ""config-title"",
         ""config-colors"",
         ""config-text-style"",

diff --git a/scripts/build.mjs b/scripts/build.mjs
index 204854f..b3cf067 100644
--- a/scripts/build.mjs
+++ b/scripts/build.mjs
@@ -3,8 +3,8 @@ import { write } from 'fsxx';
 import { info, success } from './helpers.mjs';
 
 await $`rm -rf dist/*`;
-await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 await $`unbuild`;
+await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 
 const packages = [
   'jsx-runtime',

diff --git a/src/components/DataTable/DataTableTitle.js b/src/components/DataTable/DataTableTitle.js
index bfcf07e..d764fd5 100644
--- a/src/components/DataTable/DataTableTitle.js
+++ b/src/components/DataTable/DataTableTitle.js
@@ -27,6 +27,10 @@ type Props = React.ElementConfig<typeof TouchableWithoutFeedback> & {|
    */
   sortDirection?: 'ascending' | 'descending',
   /**
+   * The number of lines to show.
+   */
+  numberOfLines?: number,
+  /**
    * Function to execute on press.
    */
   onPress?: () => mixed,
@@ -44,6 +48,10 @@ type State = {
 class DataTableTitle extends React.Component<Props, State> {
   static displayName = 'DataTable.Title';
 
+  static defaultProps = {
+    numberOfLines: 1,
+  };
+
   state = {
     spinAnim: new Animated.Value(
       this.props.sortDirection === 'ascending' ? 0 : 1
@@ -70,6 +78,7 @@ class DataTableTitle extends React.Component<Props, State> {
       sortDirection,
       theme,
       style,
+      numberOfLines,
       ...rest
     } = this.props;
 
@@ -99,7 +108,7 @@ class DataTableTitle extends React.Component<Props, State> {
               styles.cell,
               sortDirection ? styles.sorted : { color: textColor },
             ]}
-            numberOfLines={1}
+            numberOfLines={numberOfLines}
           >
             {children}
           </Text>
",5,"[""06e2be4e2019b6fa714e1fcb34485860ef1ede79"", ""4cbbd2552ba0de273e1dfe7d453c5b3efed751a3"", ""cb1f48b56ae0de93acb72e48726c7d610a1d538e"", ""c323d59c607cabc91f17a78528d998f376f30b10"", ""f9a094918b62534614c47aa8a13f33aec751a1e0""]","[""fix"", ""cicd"", ""docs"", ""build"", ""feat""]"
"enable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>fix netty dependency

netty-bom 4.1.70 contains the changes from pull request
https://github.com/netty/netty/pull/11798, which moved the classes out
of the native modules to make sure the same classes don't end up on the
classpath multiple times. For us it means that we need to depend on both
the native and classes modules. However, since we don't use the native
module directly (only classes that were moved to this classes module),
we need to force the dependency plugin to consider the native module as
used.export a modal transition presetnginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.","diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 

diff --git a/atomix/cluster/pom.xml b/atomix/cluster/pom.xml
index a477873..b6db695 100644
--- a/atomix/cluster/pom.xml
+++ b/atomix/cluster/pom.xml
@@ -69,6 +69,10 @@
     </dependency>
     <dependency>
       <groupId>io.netty</groupId>
+      <artifactId>netty-transport-classes-epoll</artifactId>
+    </dependency>
+    <dependency>
+      <groupId>io.netty</groupId>
       <artifactId>netty-transport-native-epoll</artifactId>
       <classifier>linux-x86_64</classifier>
     </dependency>
@@ -278,6 +282,7 @@
             <dependency>uk.co.real-logic:sbe-tool</dependency>
             <dependency>net.jqwik:jqwik</dependency>
             <dependency>io.netty:netty-tcnative-boringssl-static</dependency>
+            <dependency>io.netty:netty-transport-native-epoll</dependency>
           </usedDependencies>
         </configuration>
       </plugin>

diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection

diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 
",5,"[""fd8e563cc19ca4684885d4692acee6bebcca4ada"", ""f00a4d3e307b89842250358ee432e6800bb24362"", ""535708ae50aecb452560a23356fd396f99ef13a2"", ""e12d9e77a6fd531a22325337838a841b1c67f00d"", ""9be725fa3906323d4bc9788f54eccf74109d632b""]","[""feat"", ""build"", ""refactor"", ""docs"", ""fix""]"
"setup jest and add m.ts testsFix typoget tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.split release docs build into separate workflowadd getter for protocol id","diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });

diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }

diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 753d57d..3e0aa15 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -88,14 +88,14 @@ jobs:
         run: poetry run pytest --benchmark-only --benchmark-json .benchmarks/output.json ibis/tests/benchmarks
 
       - uses: tibdex/github-app-token@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         id: generate-token
         with:
           app_id: ${{ secrets.SQUAWK_BOT_APP_ID }}
           private_key: ${{ secrets.SQUAWK_BOT_APP_PRIVATE_KEY }}
 
       - uses: benchmark-action/github-action-benchmark@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         with:
           tool: pytest
           github-token: ${{ steps.generate-token.outputs.token }}
@@ -107,6 +107,7 @@ jobs:
 
   docs:
     runs-on: ubuntu-latest
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
     needs:
       # wait on benchmarks to prevent a race condition when pushing to the
       # gh-pages branch
@@ -124,51 +125,25 @@ jobs:
           authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
           extraPullNames: nix-community,poetry2nix
 
-      - name: Generate a GitHub token
-        if: ${{ github.event_name == 'push' }}
-        uses: tibdex/github-app-token@v1
-        id: generate_token
-        with:
-          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
-          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
-
-      - name: checkout
-        if: ${{ github.event_name == 'push' }}
-        uses: actions/checkout@v3
-        with:
-          fetch-depth: 0
-          token: ${{ steps.generate_token.outputs.token }}
-
       - name: checkout
-        if: ${{ github.event_name != 'push' }}
         uses: actions/checkout@v3
 
-      - name: Configure git info
-        if: ${{ github.event_name == 'push' }}
-        run: |
-          set -euo pipefail
-
-          git config user.name 'ibis-docs-bot[bot]'
-          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
-
       - name: build docs
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c mkdocs build
 
       - name: verify internal links
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c just checklinks --offline --no-progress
 
-      - name: Pull gh-pages changes
+      - name: Configure git info
         if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
-          git fetch origin gh-pages
-          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
 
       - name: build and push dev docs
-        if: ${{ github.event_name == 'push' && !startsWith(github.ref, 'refs/tags/') }}
+        if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
@@ -180,19 +155,6 @@ jobs:
               --message 'docs(dev): ibis@${{ github.sha }}' \
                 dev
 
-      - name: build and push docs on tag
-        if: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/tags/') }}
-        run: |
-          set -euo pipefail
-
-          nix develop -f shell.nix --keep-going -c \
-            mic deploy \
-              --push \
-              --rebase \
-              --prefix docs \
-              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
-              ""${GITHUB_REF_NAME}"" latest
-
   simulate_release:
     runs-on: ubuntu-latest
     steps:
diff --git a/.github/workflows/ibis-docs-release.yml b/.github/workflows/ibis-docs-release.yml
new file mode 100644
index 0000000..da7ee49
--- /dev/null
+++ b/.github/workflows/ibis-docs-release.yml
@@ -0,0 +1,63 @@
+# vim: filetype=yaml
+name: Docs Release Build
+
+on:
+  release:
+    types:
+      - published
+jobs:
+  docs:
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
+    runs-on: ubuntu-latest
+    steps:
+      - name: install nix
+        uses: cachix/install-nix-action@v17
+        with:
+          nix_path: nixpkgs=channel:nixos-unstable-small
+
+      - name: setup cachix
+        uses: cachix/cachix-action@v10
+        with:
+          name: ibis
+          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
+          extraPullNames: nix-community,poetry2nix
+
+      - name: Generate a GitHub token
+        uses: tibdex/github-app-token@v1
+        id: generate_token
+        with:
+          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
+          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
+
+      - name: checkout
+        uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+          token: ${{ steps.generate_token.outputs.token }}
+
+      - name: Configure git info
+        run: |
+          set -euo pipefail
+
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
+
+      - name: Pull gh-pages changes
+        run: |
+          set -euo pipefail
+
+          git fetch origin gh-pages
+          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+
+      - name: build and push docs on tag
+        run: |
+          set -euo pipefail
+
+          nix develop -f shell.nix --keep-going -c \
+            mic deploy \
+              --push \
+              --rebase \
+              --update-aliases \
+              --prefix docs \
+              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
+              ""${GITHUB_REF_NAME}"" latest

diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }
",5,"[""229b53a632ea97d47c4be11f096bdd828fb415d8"", ""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c"", ""32845e1bbd1efb5dbc16f671049509a409ba25ce"", ""dc5238b2bda98a7c4f2fe9584fc3b0191a408109""]","[""test"", ""docs"", ""refactor"", ""cicd"", ""feat""]"
"upgrade to Flux v0.42.0

Skips a test that requires special dependencies to pass.nginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>autostart feature fixedAdjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.get tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.","diff --git a/go.mod b/go.mod
index ea705da..8c352f7 100644
--- a/go.mod
+++ b/go.mod
@@ -38,7 +38,7 @@ require (
 	github.com/hashicorp/go-msgpack v0.0.0-20150518234257-fa3f63826f7c // indirect
 	github.com/hashicorp/raft v1.0.0 // indirect
 	github.com/hashicorp/vault/api v1.0.2
-	github.com/influxdata/flux v0.41.0
+	github.com/influxdata/flux v0.42.0
 	github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6
 	github.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368
 	github.com/jessevdk/go-flags v1.4.0
diff --git a/go.sum b/go.sum
index 4bfdf4c..634a0f1 100644
--- a/go.sum
+++ b/go.sum
@@ -206,8 +206,8 @@ github.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NH
 github.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=
 github.com/influxdata/changelog v1.0.0 h1:RstJD6H48zLQj0GdE6E6k/6RPwtUjkyzIe/T1E/xuWU=
 github.com/influxdata/changelog v1.0.0/go.mod h1:uzpGWE/qehT8L426YuXwpMQub+a63vIINhIeEI9mnSM=
-github.com/influxdata/flux v0.41.0 h1:ljbWJmE+aNx8Yoqhb04gWC4sXMV87eYUxz5vjYphLLs=
-github.com/influxdata/flux v0.41.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
+github.com/influxdata/flux v0.42.0 h1:2iEG6hLHdHEJ6LgD8OSnlHS9yoVrLO1/aM4P9ERb94U=
+github.com/influxdata/flux v0.42.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
 github.com/influxdata/goreleaser v0.97.0-influx h1:jT5OrcW7WfS0e2QxfwmTBjhLvpIC9CDLRhNgZJyhj8s=
 github.com/influxdata/goreleaser v0.97.0-influx/go.mod h1:MnjA0e0Uq6ISqjG1WxxMAl+3VS1QYjILSWVnMYDxasE=
 github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6 h1:CFx+pP90q/qg3spoiZjf8donE4WpAdjeJfPOcoNqkWo=
diff --git a/query/stdlib/testing/testing.go b/query/stdlib/testing/testing.go
index d41574a..85b0673 100644
--- a/query/stdlib/testing/testing.go
+++ b/query/stdlib/testing/testing.go
@@ -98,4 +98,6 @@ var FluxEndToEndSkipList = map[string]string{
 	""http_endpoint"": ""need ability to test side effects in e2e tests: (https://github.com/influxdata/flux/issues/1723)"",
 
 	""holt_winters_panic"": ""Expected output is an empty table which breaks the testing framework (https://github.com/influxdata/influxdb/issues/14749)"",
+
+	""secrets"": ""Cannot inject custom deps into the test framework so the secrets don't lookup correctly"",
 }

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();

diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }
",5,"[""454003841aabeb74396d73541378bfa59c75b5db"", ""e12d9e77a6fd531a22325337838a841b1c67f00d"", ""bed78248c941d57ad4cc20a455147e186e97c7a1"", ""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c""]","[""build"", ""docs"", ""fix"", ""test"", ""refactor""]"
"[gn win] link comctl32.lib to fix component buildremove ubuntu-latest from job title where that is the only oslicensingverify checkpoint listeners are notifiedget tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.","diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;

diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }
",5,"[""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""74e9de5ec97dc013a52aa063dff0f40ac74c407b"", ""a52a585d74894b3b4eeb8c784fa089ff95cddad0"", ""e0198f74b81da3663144cfe1d971939319f82a0f"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c""]","[""build"", ""cicd"", ""docs"", ""test"", ""refactor""]"
"updated react demo parcel commandpublish sdks after docs/buildadded changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284remove appear css animationinitialize threejs objects in defaultRef, to fix undefined type errors","diff --git a/demo/react/package.json b/demo/react/package.json
index be28bf9..32d0952 100644
--- a/demo/react/package.json
+++ b/demo/react/package.json
@@ -12,7 +12,7 @@
   },
   ""scripts"": {
     ""start"": ""parcel serve public/index.html --no-cache --open"",
-    ""build"": ""parcel build -t browser -d dist public/index.html --no-source-maps""
+    ""build"": ""parcel build --target browser --dist-dir dist public/index.html --no-source-maps""
   },
   ""bugs"": {
     ""url"": ""https://github.com/matteobruni/tsparticles/issues""

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 4ac01cf..cfea1ae 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -213,6 +213,7 @@ workflows:
             - test-e2e-mysql
             - test-e2e-cockroach
             - test-e2e-plugin
+            - docs/build
 #            - test-legacy-migrations-mysql
 #            - test-legacy-migrations-cockroach
           filters:
@@ -246,6 +247,7 @@ workflows:
             - golangci/lint
             - sdk/generate
             - goreleaser/release
+            - docs/build
           filters:
             tags:
               only: /.*/

diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/src/popup/Popup.tsx b/src/popup/Popup.tsx
index d485bb6..2abc22a 100644
--- a/src/popup/Popup.tsx
+++ b/src/popup/Popup.tsx
@@ -269,7 +269,6 @@ export class Popup extends React.Component<{ t: TranslationFunction }, PopupStat
         <CSSTransition
           classNames='fade'
           in={!!currentTabUrl}
-          appear
           timeout={500}
           exit={false}
           mountOnEnter

diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number
",5,"[""32b92cfa0b74a6c25990e32ac6aab12b8496794c"", ""6c9cb638cb4d1ecc42632fcf389c24898c5b3244"", ""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""47ef9104e4a89e80d7cc6c1950bc080841da4a7b"", ""2561f4ade46fc9d59f289f328cc77733a6443697""]","[""build"", ""cicd"", ""docs"", ""refactor"", ""fix""]"
"verify checkpoint listeners are notifiedupdate Java get-started guide

- handle payload as map instead of JSON string

related to zeebe-io/zeebe#909allow disabling dynamic queueAdd ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>[gn] fix include_dirs ordering error","diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }

diff --git a/docs/src/java-client/get-started.md b/docs/src/java-client/get-started.md
index efd3182..f531cd0 100755
--- a/docs/src/java-client/get-started.md
+++ b/docs/src/java-client/get-started.md
@@ -262,7 +262,6 @@ public class Application
                 // ...
 
                 jobClient.newCompleteCommand(job)
-                    .withoutPayload()
                     .send()
                     .join();
             })
@@ -323,6 +322,10 @@ public class Application
     public static void main(String[] args)
     {
         // after the workflow is deployed
+        
+        final Map<String, Object> data = new HashMap<>();
+        data.put(""orderId"", 31243);
+        data.put(""orderItems"", Arrays.asList(435, 182, 376));
 
         final WorkflowInstanceEvent wfInstance = client.topicClient().workflowClient()
             .newCreateInstanceCommand()
@@ -342,15 +345,17 @@ public class Application
                 final Map<String, Object> headers = job.getCustomHeaders();
                 final String method = (String) headers.get(""method"");
 
-                final String orderId = job.getPayload();
+                final Map<String, Object> payload = job.getPayloadAsMap();
 
-                System.out.println(""Process order: "" + orderId);
+                System.out.println(""Process order: "" + payload.get(""orderId""));
                 System.out.println(""Collect money using payment method: "" + method);
 
                 // ...
 
+                payload.put(""totalPrice"", 46.50);
+
                 jobClient.newCompleteCommand(job)
-                    .payload(""{ \""totalPrice\"": 46.50 }"")
+                    .payload(payload)
                     .send()
                     .join();
             })

diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}

diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)
",5,"[""e0198f74b81da3663144cfe1d971939319f82a0f"", ""c2ee5cd5e709afd15c5565ee009a0d204403a119"", ""9ef5c0d14193a9abb09b39856f58477d1f4b0d77"", ""f823cf28652987d43c8324b4f5b203240032383a"", ""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945""]","[""test"", ""docs"", ""fix"", ""feat"", ""build""]"
"restructure ClusterTopology to track completed changesplit release docs build into separate workflowadd benchmark for known-slow table expressionupgrade to Flux v0.42.0

Skips a test that requires special dependencies to pass.enable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(

diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 753d57d..3e0aa15 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -88,14 +88,14 @@ jobs:
         run: poetry run pytest --benchmark-only --benchmark-json .benchmarks/output.json ibis/tests/benchmarks
 
       - uses: tibdex/github-app-token@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         id: generate-token
         with:
           app_id: ${{ secrets.SQUAWK_BOT_APP_ID }}
           private_key: ${{ secrets.SQUAWK_BOT_APP_PRIVATE_KEY }}
 
       - uses: benchmark-action/github-action-benchmark@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         with:
           tool: pytest
           github-token: ${{ steps.generate-token.outputs.token }}
@@ -107,6 +107,7 @@ jobs:
 
   docs:
     runs-on: ubuntu-latest
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
     needs:
       # wait on benchmarks to prevent a race condition when pushing to the
       # gh-pages branch
@@ -124,51 +125,25 @@ jobs:
           authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
           extraPullNames: nix-community,poetry2nix
 
-      - name: Generate a GitHub token
-        if: ${{ github.event_name == 'push' }}
-        uses: tibdex/github-app-token@v1
-        id: generate_token
-        with:
-          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
-          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
-
-      - name: checkout
-        if: ${{ github.event_name == 'push' }}
-        uses: actions/checkout@v3
-        with:
-          fetch-depth: 0
-          token: ${{ steps.generate_token.outputs.token }}
-
       - name: checkout
-        if: ${{ github.event_name != 'push' }}
         uses: actions/checkout@v3
 
-      - name: Configure git info
-        if: ${{ github.event_name == 'push' }}
-        run: |
-          set -euo pipefail
-
-          git config user.name 'ibis-docs-bot[bot]'
-          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
-
       - name: build docs
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c mkdocs build
 
       - name: verify internal links
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c just checklinks --offline --no-progress
 
-      - name: Pull gh-pages changes
+      - name: Configure git info
         if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
-          git fetch origin gh-pages
-          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
 
       - name: build and push dev docs
-        if: ${{ github.event_name == 'push' && !startsWith(github.ref, 'refs/tags/') }}
+        if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
@@ -180,19 +155,6 @@ jobs:
               --message 'docs(dev): ibis@${{ github.sha }}' \
                 dev
 
-      - name: build and push docs on tag
-        if: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/tags/') }}
-        run: |
-          set -euo pipefail
-
-          nix develop -f shell.nix --keep-going -c \
-            mic deploy \
-              --push \
-              --rebase \
-              --prefix docs \
-              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
-              ""${GITHUB_REF_NAME}"" latest
-
   simulate_release:
     runs-on: ubuntu-latest
     steps:
diff --git a/.github/workflows/ibis-docs-release.yml b/.github/workflows/ibis-docs-release.yml
new file mode 100644
index 0000000..da7ee49
--- /dev/null
+++ b/.github/workflows/ibis-docs-release.yml
@@ -0,0 +1,63 @@
+# vim: filetype=yaml
+name: Docs Release Build
+
+on:
+  release:
+    types:
+      - published
+jobs:
+  docs:
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
+    runs-on: ubuntu-latest
+    steps:
+      - name: install nix
+        uses: cachix/install-nix-action@v17
+        with:
+          nix_path: nixpkgs=channel:nixos-unstable-small
+
+      - name: setup cachix
+        uses: cachix/cachix-action@v10
+        with:
+          name: ibis
+          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
+          extraPullNames: nix-community,poetry2nix
+
+      - name: Generate a GitHub token
+        uses: tibdex/github-app-token@v1
+        id: generate_token
+        with:
+          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
+          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
+
+      - name: checkout
+        uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+          token: ${{ steps.generate_token.outputs.token }}
+
+      - name: Configure git info
+        run: |
+          set -euo pipefail
+
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
+
+      - name: Pull gh-pages changes
+        run: |
+          set -euo pipefail
+
+          git fetch origin gh-pages
+          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+
+      - name: build and push docs on tag
+        run: |
+          set -euo pipefail
+
+          nix develop -f shell.nix --keep-going -c \
+            mic deploy \
+              --push \
+              --rebase \
+              --update-aliases \
+              --prefix docs \
+              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
+              ""${GITHUB_REF_NAME}"" latest

diff --git a/.gitignore b/.gitignore
index 2e99ad3..eef9203 100644
--- a/.gitignore
+++ b/.gitignore
@@ -95,3 +95,4 @@ docs/backends/support_matrix.csv
 __pycache__
 tags
 .DS_Store
+prof/
diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index ac19aaf..36aed0e 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -602,3 +602,93 @@ def test_multiple_joins(benchmark, num_joins, num_columns):
         name=""t"",
     )
     benchmark(multiple_joins, table, num_joins)
+
+
+@pytest.fixture
+def customers():
+    return ibis.table(
+        dict(
+            customerid=""int32"",
+            name=""string"",
+            address=""string"",
+            citystatezip=""string"",
+            birthdate=""date"",
+            phone=""string"",
+            timezone=""string"",
+            lat=""float64"",
+            long=""float64"",
+        ),
+        name=""customers"",
+    )
+
+
+@pytest.fixture
+def orders():
+    return ibis.table(
+        dict(
+            orderid=""int32"",
+            customerid=""int32"",
+            ordered=""timestamp"",
+            shipped=""timestamp"",
+            items=""string"",
+            total=""float64"",
+        ),
+        name=""orders"",
+    )
+
+
+@pytest.fixture
+def orders_items():
+    return ibis.table(
+        dict(orderid=""int32"", sku=""string"", qty=""int32"", unit_price=""float64""),
+        name=""orders_items"",
+    )
+
+
+@pytest.fixture
+def products():
+    return ibis.table(
+        dict(
+            sku=""string"",
+            desc=""string"",
+            weight_kg=""float64"",
+            cost=""float64"",
+            dims_cm=""string"",
+        ),
+        name=""products"",
+    )
+
+
+@pytest.mark.benchmark(group=""compilation"")
+@pytest.mark.parametrize(
+    ""module"",
+    [
+        pytest.param(
+            mod,
+            marks=pytest.mark.xfail(
+                condition=mod in _XFAIL_COMPILE_BACKENDS,
+                reason=f""{mod} backend doesn't support compiling UnboundTable"",
+            ),
+        )
+        for mod in _backends
+    ],
+)
+def test_compile_with_drops(
+    benchmark, module, customers, orders, orders_items, products
+):
+    expr = (
+        customers.join(orders, ""customerid"")
+        .join(orders_items, ""orderid"")
+        .join(products, ""sku"")
+        .drop(""customerid"", ""qty"", ""total"", ""items"")
+        .drop(""dims_cm"", ""cost"")
+        .mutate(o_date=lambda t: t.shipped.date())
+        .filter(lambda t: t.ordered == t.shipped)
+    )
+
+    try:
+        mod = getattr(ibis, module)
+    except (AttributeError, ImportError) as e:
+        pytest.skip(str(e))
+    else:
+        benchmark(mod.compile, expr)

diff --git a/go.mod b/go.mod
index ea705da..8c352f7 100644
--- a/go.mod
+++ b/go.mod
@@ -38,7 +38,7 @@ require (
 	github.com/hashicorp/go-msgpack v0.0.0-20150518234257-fa3f63826f7c // indirect
 	github.com/hashicorp/raft v1.0.0 // indirect
 	github.com/hashicorp/vault/api v1.0.2
-	github.com/influxdata/flux v0.41.0
+	github.com/influxdata/flux v0.42.0
 	github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6
 	github.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368
 	github.com/jessevdk/go-flags v1.4.0
diff --git a/go.sum b/go.sum
index 4bfdf4c..634a0f1 100644
--- a/go.sum
+++ b/go.sum
@@ -206,8 +206,8 @@ github.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NH
 github.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=
 github.com/influxdata/changelog v1.0.0 h1:RstJD6H48zLQj0GdE6E6k/6RPwtUjkyzIe/T1E/xuWU=
 github.com/influxdata/changelog v1.0.0/go.mod h1:uzpGWE/qehT8L426YuXwpMQub+a63vIINhIeEI9mnSM=
-github.com/influxdata/flux v0.41.0 h1:ljbWJmE+aNx8Yoqhb04gWC4sXMV87eYUxz5vjYphLLs=
-github.com/influxdata/flux v0.41.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
+github.com/influxdata/flux v0.42.0 h1:2iEG6hLHdHEJ6LgD8OSnlHS9yoVrLO1/aM4P9ERb94U=
+github.com/influxdata/flux v0.42.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
 github.com/influxdata/goreleaser v0.97.0-influx h1:jT5OrcW7WfS0e2QxfwmTBjhLvpIC9CDLRhNgZJyhj8s=
 github.com/influxdata/goreleaser v0.97.0-influx/go.mod h1:MnjA0e0Uq6ISqjG1WxxMAl+3VS1QYjILSWVnMYDxasE=
 github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6 h1:CFx+pP90q/qg3spoiZjf8donE4WpAdjeJfPOcoNqkWo=
diff --git a/query/stdlib/testing/testing.go b/query/stdlib/testing/testing.go
index d41574a..85b0673 100644
--- a/query/stdlib/testing/testing.go
+++ b/query/stdlib/testing/testing.go
@@ -98,4 +98,6 @@ var FluxEndToEndSkipList = map[string]string{
 	""http_endpoint"": ""need ability to test side effects in e2e tests: (https://github.com/influxdata/flux/issues/1723)"",
 
 	""holt_winters_panic"": ""Expected output is an empty table which breaks the testing framework (https://github.com/influxdata/influxdb/issues/14749)"",
+
+	""secrets"": ""Cannot inject custom deps into the test framework so the secrets don't lookup correctly"",
 }

diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 
",5,"[""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2"", ""32845e1bbd1efb5dbc16f671049509a409ba25ce"", ""e9617f0854030e70365eb264bcb3b58078e79e9e"", ""454003841aabeb74396d73541378bfa59c75b5db"", ""fd8e563cc19ca4684885d4692acee6bebcca4ada""]","[""refactor"", ""cicd"", ""test"", ""build"", ""feat""]"
"get tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.Add ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>[gn] fix include_dirs ordering errorupdate flushed index before truncatingadd tests","diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}

diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)

diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/Cargo.lock b/Cargo.lock
index 84d5d07..6ad05da 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -293,6 +293,7 @@ version = ""0.1.0""
 dependencies = [
  ""git-cliff-core"",
  ""log"",
+ ""pretty_assertions"",
  ""pretty_env_logger"",
  ""structopt"",
 ]
diff --git a/git-cliff-core/src/lib.rs b/git-cliff-core/src/lib.rs
index 3b18ba0..a560c94 100644
--- a/git-cliff-core/src/lib.rs
+++ b/git-cliff-core/src/lib.rs
@@ -1,6 +1,8 @@
 //! Highly customizable Changelog Generator
 #![warn(missing_docs, clippy::unwrap_used)]
 
+/// Export regex crate.
+pub use regex;
 /// Git commit.
 pub mod commit;
 /// Config file parser.
diff --git a/git-cliff/Cargo.toml b/git-cliff/Cargo.toml
index 41eb2e9..cc64b37 100644
--- a/git-cliff/Cargo.toml
+++ b/git-cliff/Cargo.toml
@@ -20,3 +20,6 @@ log = ""0.4.14""
 version = ""0.3""
 default-features = false
 features = [""suggestions"", ""color"", ""wrap_help""]
+
+[dev-dependencies]
+pretty_assertions = ""0.7""
diff --git a/git-cliff/src/changelog.rs b/git-cliff/src/changelog.rs
index 3f9e994..23ea186 100644
--- a/git-cliff/src/changelog.rs
+++ b/git-cliff/src/changelog.rs
@@ -115,3 +115,171 @@ impl<'a> Changelog<'a> {
 		Ok(())
 	}
 }
+
+#[cfg(test)]
+mod test {
+	use super::*;
+	use git_cliff_core::config::{
+		ChangelogConfig,
+		CommitParser,
+		GitConfig,
+	};
+	use git_cliff_core::regex::Regex;
+	use pretty_assertions::assert_eq;
+	use std::str;
+	#[test]
+	fn changelog_generator() -> Result<()> {
+		let config = Config {
+			changelog: ChangelogConfig {
+				header: Some(String::from(""# Changelog"")),
+				body:   String::from(
+					r#""{% if version %}
+				## Release [{{ version }}] - {{ timestamp | date(format=""%Y-%m-%d"") }}
+				({{ commit_id }}){% else %}
+				## Unreleased{% endif %}
+				{% for group, commits in commits | group_by(attribute=""group"") %}
+				### {{ group }}{% for group, commits in commits | group_by(attribute=""scope"") %}
+				#### {{ group }}{% for commit in commits %}
+				- {{ commit.message }}{% endfor %}
+				{% endfor %}{% endfor %}""#,
+				)
+				.replace(""				"", """"),
+				footer: Some(String::from(""------------"")),
+			},
+			git:       GitConfig {
+				conventional_commits: true,
+				commit_parsers:       Some(vec![
+					CommitParser {
+						message: Regex::new(""feat*"").ok(),
+						body:    None,
+						group:   Some(String::from(""New features"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new(""fix*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Bug Fixes"")),
+						skip:    None,
+					},
+					CommitParser {
+						message: Regex::new("".*"").ok(),
+						body:    None,
+						group:   Some(String::from(""Other"")),
+						skip:    None,
+					},
+				]),
+				filter_commits:       Some(false),
+				tag_pattern:          String::new(),
+				skip_tags:            Regex::new(""v3.*"").ok(),
+			},
+		};
+		let test_release = Release {
+			version:   Some(String::from(""v1.0.0"")),
+			commits:   vec![
+				Commit::new(
+					String::from(""0bc123""),
+					String::from(""feat(app): add cool features""),
+				),
+				Commit::new(
+					String::from(""0werty""),
+					String::from(""style(ui): make good stuff""),
+				),
+				Commit::new(
+					String::from(""0w3rty""),
+					String::from(""fix(ui): fix more stuff""),
+				),
+				Commit::new(
+					String::from(""0jkl12""),
+					String::from(""chore(app): do nothing""),
+				),
+			],
+			commit_id: Some(String::from(""0bc123"")),
+			timestamp: 50000000,
+			previous:  None,
+		};
+		let releases = vec![
+			test_release.clone(),
+			Release {
+				version: Some(String::from(""v3.0.0"")),
+				commits: vec![Commit::new(
+					String::from(""n0thin""),
+					String::from(""feat(xyz): skip commit""),
+				)],
+				..Release::default()
+			},
+			Release {
+				version:   None,
+				commits:   vec![
+					Commit::new(
+						String::from(""abc123""),
+						String::from(""feat(app): add xyz""),
+					),
+					Commit::new(
+						String::from(""abc124""),
+						String::from(""docs(app): document zyx""),
+					),
+					Commit::new(String::from(""def789""), String::from(""merge #4"")),
+					Commit::new(
+						String::from(""qwerty""),
+						String::from(""fix(app): fix abc""),
+					),
+					Commit::new(
+						String::from(""hjkl12""),
+						String::from(""chore(ui): do boring stuff""),
+					),
+				],
+				commit_id: None,
+				timestamp: 1000,
+				previous:  Some(Box::new(test_release)),
+			},
+		];
+		let changelog = Changelog::new(releases, &config)?;
+		let mut out = Vec::new();
+		changelog.generate(&mut out)?;
+		assert_eq!(
+			String::from(
+				r#""# Changelog
+
+			## Unreleased
+
+			### Bug Fixes
+			#### app
+			- fix abc
+
+			### New features
+			#### app
+			- add xyz
+
+			### Other
+			#### app
+			- document zyx
+
+			#### ui
+			- do boring stuff
+
+			## Release [v1.0.0] - 1971-08-02
+			(0bc123)
+
+			### Bug Fixes
+			#### ui
+			- fix more stuff
+
+			### New features
+			#### app
+			- add cool features
+
+			### Other
+			#### app
+			- do nothing
+
+			#### ui
+			- make good stuff
+			------------
+			""#
+			)
+			.replace(""			"", """"),
+			str::from_utf8(&out).unwrap()
+		);
+		Ok(())
+	}
+}
",5,"[""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c"", ""f823cf28652987d43c8324b4f5b203240032383a"", ""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945"", ""933ab6bb86372913c992567cf9660009900911a7"", ""8ee0611fbf0cd89abe7ae588f22e6ecb843598ea""]","[""refactor"", ""feat"", ""build"", ""fix"", ""test""]"
"cleanup of some if boolean logic

I always get confused reading this code. Lets make it more clear, if
flush then flush; else don't flush.update wrapping tests for v7add comments for the Handlersupport use meta key select multiple elementincrement failing test retries","diff --git a/peer.go b/peer.go
index 68695c2..b7ab84f 100644
--- a/peer.go
+++ b/peer.go
@@ -123,15 +123,15 @@ func (p *Peer) heartbeat(c chan bool) {
 	for {
 		select {
 		case flush := <-stopChan:
-			if !flush {
-				debugln(""peer.heartbeat.stop: "", p.Name)
-				return
-			} else {
+			if flush {
 				// before we can safely remove a node
 				// we must flush the remove command to the node first
 				p.flush()
 				debugln(""peer.heartbeat.stop.with.flush: "", p.Name)
 				return
+			} else {
+				debugln(""peer.heartbeat.stop: "", p.Name)
+				return
 			}
 
 		case <-ticker:

diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });

diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }

diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index ab68624..aeee7b7 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -277,9 +277,11 @@ export default class LogicFlow {
   }
   /**
    * 将图形选中
+   * @param id 选择元素ID
+   * @param multiple 是否允许多选，如果为true，不会将上一个选中的元素重置
    */
-  select(id: string) {
-    this.graphModel.selectElementById(id);
+  select(id: string, multiple = false) {
+    this.graphModel.selectElementById(id, multiple);
   }
   /**
    * 将图形定位到画布中心
diff --git a/packages/core/src/model/EditConfigModel.ts b/packages/core/src/model/EditConfigModel.ts
index 67e334a..83e5f16 100644
--- a/packages/core/src/model/EditConfigModel.ts
+++ b/packages/core/src/model/EditConfigModel.ts
@@ -25,6 +25,7 @@ const SilentConfig = {
   edgeTextEdit: false,
   nodeTextDraggable: false,
   edgeTextDraggable: false,
+  metaKeyMultipleSelected: false,
 };
 
 /**
@@ -42,6 +43,7 @@ export default class EditConfigModel {
   @observable edgeTextEdit = true; // 允许连线文本可以编辑
   @observable nodeTextDraggable = false; // 允许节点文本可以拖拽
   @observable edgeTextDraggable = false; // 允许连线文本可以拖拽
+  @observable metaKeyMultipleSelected = false; // 允许meta多选元素
   constructor(data) {
     const keys = [
       'stopZoomGraph',
@@ -55,6 +57,7 @@ export default class EditConfigModel {
       'edgeTextEdit',
       'nodeTextDraggable',
       'edgeTextDraggable',
+      'metaKeyMultipleSelected',
     ];
     const { isSilentMode, textEdit } = data;
     if (isSilentMode) {
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 9667f4d..310daf4 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -34,6 +34,7 @@ class GraphModel {
   height: number;
   topElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
   selectElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
+  selectElements = new Map<string, IBaseModel>(); // 多选
   @observable edgeType: string;
   @observable nodes: BaseNodeModel[] = [];
   @observable activeElement: IBaseModel;
@@ -50,7 +51,6 @@ class GraphModel {
   @observable gridSize = 1;
   @observable partial = false; // 是否开启局部渲染
   @observable fakerNode: BaseNodeModel;
-  // @observable selectElements = new Map<string, IBaseModel>(); // 多选还没有做，先不加
   constructor(config) {
     const {
       container,
@@ -456,24 +456,44 @@ class GraphModel {
   }
 
   @action
-  selectNodeById(id) {
-    this.selectElement?.setSelected(false);
+  selectNodeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.nodesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectEdgeById(id) {
-    this.selectElement?.setSelected(false);
+  selectEdgeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.edgesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectElementById(id: string) {
-    this.selectElement?.setSelected(false);
+  selectElementById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
+  }
+
+  @action
+  clearSelectElements() {
+    this.selectElements.forEach(element => {
+      element.setSelected(false);
+    });
+    this.selectElements.clear();
   }
 
   /* 修改连线类型 */
diff --git a/packages/core/src/view/edge/BaseEdge.tsx b/packages/core/src/view/edge/BaseEdge.tsx
index d45ea9e..d7c8f38 100644
--- a/packages/core/src/view/edge/BaseEdge.tsx
+++ b/packages/core/src/view/edge/BaseEdge.tsx
@@ -178,7 +178,8 @@ export default class BaseEdge extends Component<IProps> {
   handleClick = (e) => {
     const { model, graphModel, eventCenter } = this.props;
     graphModel.toFront(model.id);
-    graphModel.selectEdgeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectEdgeById(model.id, e.metaKey && metaKeyMultipleSelected);
     // 边数据
     const edgeData = model?.getData();
     const position = graphModel.getPointByClient({
diff --git a/packages/core/src/view/node/BaseNode.tsx b/packages/core/src/view/node/BaseNode.tsx
index 140889c..5ee3975 100644
--- a/packages/core/src/view/node/BaseNode.tsx
+++ b/packages/core/src/view/node/BaseNode.tsx
@@ -275,7 +275,8 @@ export default abstract class BaseNode extends Component<IProps, Istate> {
       }, 400);
     }
     graphModel.toFront(model.id);
-    graphModel.selectNodeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectNodeById(model.id, e.metaKey && metaKeyMultipleSelected);
     this.preStartTime = this.startTime;
   };
   handleContextMenu = (ev: MouseEvent) => {
diff --git a/packages/core/src/view/overlay/CanvasOverlay.tsx b/packages/core/src/view/overlay/CanvasOverlay.tsx
index ef11822..8c79fd2 100644
--- a/packages/core/src/view/overlay/CanvasOverlay.tsx
+++ b/packages/core/src/view/overlay/CanvasOverlay.tsx
@@ -104,9 +104,9 @@ class CanvasOverlay extends Component<IProps, Istate> {
     const target = ev.target as HTMLElement;
     if (target.getAttribute('name') === 'canvas-overlay') {
       const { graphModel, eventCenter } = this.props;
-      const { selectElement, textEditElement } = graphModel;
-      if (selectElement) {
-        selectElement.setSelected(false);
+      const { textEditElement, selectElements } = graphModel;
+      if (selectElements.size > 0) {
+        graphModel.clearSelectElements();
       }
       if (textEditElement) {
         textEditElement.setElementState(ElementState.DEFAULT);
diff --git a/packages/extension/examples/bpmn/index.html b/packages/extension/examples/bpmn/index.html
index 7a68d6f..f7ea87d 100644
--- a/packages/extension/examples/bpmn/index.html
+++ b/packages/extension/examples/bpmn/index.html
@@ -6,6 +6,7 @@
   <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
   <title>LOGIN FLOW</title>
   <link rel=""stylesheet"" href=""/core/dist/style/index.css"">
+  <link rel=""stylesheet"" href=""/extension/lib/style/index.css"">
   <style>
     html,body {
       padding: 0;
@@ -129,11 +130,14 @@
     </div>
   </div>
   <script src=""/core/dist/logic-flow.js""></script>
+  <!-- <script src=""http://0.0.0.0:9090/logic-flow.js""></script> -->
   <script src=""/BpmnElement.js""></script>
   <script src=""/BpmnAdapter.js""></script>
+  <script src=""/Control.js""></script>
   <script src=""/Snapshot.js""></script>
   <script>
     LogicFlow.use(BpmnElement);
+    LogicFlow.use(Control);
     LogicFlow.use(BpmnAdapter);
     LogicFlow.use(Snapshot);
   </script>
diff --git a/packages/extension/examples/bpmn/index.js b/packages/extension/examples/bpmn/index.js
index 21d2da0..6f6aa39 100644
--- a/packages/extension/examples/bpmn/index.js
+++ b/packages/extension/examples/bpmn/index.js
@@ -3,6 +3,10 @@ window.onload = function () {
     container: document.querySelector('#app'),
     // fixme: grid成为了必传的了
     edgeTextDraggable: true,
+    metaKeyMultipleSelected: true,
+    // stopScrollGraph: true,
+    // stopMoveGraph: true,
+    // stopZoomGraph: true,
     grid: {
       type: 'dot',
       size: 20,

diff --git a/.ci/scripts/distribution/it-java.sh b/.ci/scripts/distribution/it-java.sh
index 679674b..ee150c2 100755
--- a/.ci/scripts/distribution/it-java.sh
+++ b/.ci/scripts/distribution/it-java.sh
@@ -5,7 +5,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -pl qa/integration-tests -pl upgrade-tests -DtestMavenId=2 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java.sh b/.ci/scripts/distribution/test-java.sh
index 43e4947..768c965 100755
--- a/.ci/scripts/distribution/test-java.sh
+++ b/.ci/scripts/distribution/test-java.sh
@@ -4,7 +4,7 @@ export JAVA_TOOL_OPTIONS=""$JAVA_TOOL_OPTIONS -XX:MaxRAMFraction=$((LIMITS_CPU))""
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -P skip-unstable-ci,parallel-tests -Dzeebe.it.skip -DtestMavenId=1 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
diff --git a/.ci/scripts/distribution/test-java8.sh b/.ci/scripts/distribution/test-java8.sh
index d56cccb..0f20f95 100755
--- a/.ci/scripts/distribution/test-java8.sh
+++ b/.ci/scripts/distribution/test-java8.sh
@@ -6,7 +6,7 @@ mvn -v
 
 tmpfile=$(mktemp)
 
-mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=5 | tee ${tmpfile}
+mvn -o -B --fail-never -T$LIMITS_CPU -s ${MAVEN_SETTINGS_XML} verify -pl clients/java -DtestMavenId=3 -Dsurefire.rerunFailingTestsCount=7 | tee ${tmpfile}
 
 status=${PIPESTATUS[0]}
 
",5,"[""36556bf8e0bce4ab6d26eafacbdad04d9614a5d7"", ""317f4eefecddfb1392ca71d551840f446feee302"", ""036a0ff49a7dade0e04c9c07071a1ff49133ee24"", ""e137f9fdbdb6bf3f85c3f7ac9323785e445844c8"", ""e7a67d88173566be3cd3aed7e9eeb7e29aabbc57""]","[""refactor"", ""test"", ""docs"", ""feat"", ""cicd""]"
"verify checkpoint listeners are notifiedadd riscv64gc-unknown-linux-gnuget tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.Add ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>autostart feature fixed","diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }

diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();
",5,"[""e0198f74b81da3663144cfe1d971939319f82a0f"", ""173553c0372e66e03bdab19e0e6c2dd44daa14a0"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c"", ""f823cf28652987d43c8324b4f5b203240032383a"", ""bed78248c941d57ad4cc20a455147e186e97c7a1""]","[""test"", ""cicd"", ""refactor"", ""feat"", ""fix""]"
"split release docs build into separate workflowadd fallible peek_last_token()add spacing in comment fix lint (#8555)fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.enable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>","diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 753d57d..3e0aa15 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -88,14 +88,14 @@ jobs:
         run: poetry run pytest --benchmark-only --benchmark-json .benchmarks/output.json ibis/tests/benchmarks
 
       - uses: tibdex/github-app-token@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         id: generate-token
         with:
           app_id: ${{ secrets.SQUAWK_BOT_APP_ID }}
           private_key: ${{ secrets.SQUAWK_BOT_APP_PRIVATE_KEY }}
 
       - uses: benchmark-action/github-action-benchmark@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         with:
           tool: pytest
           github-token: ${{ steps.generate-token.outputs.token }}
@@ -107,6 +107,7 @@ jobs:
 
   docs:
     runs-on: ubuntu-latest
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
     needs:
       # wait on benchmarks to prevent a race condition when pushing to the
       # gh-pages branch
@@ -124,51 +125,25 @@ jobs:
           authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
           extraPullNames: nix-community,poetry2nix
 
-      - name: Generate a GitHub token
-        if: ${{ github.event_name == 'push' }}
-        uses: tibdex/github-app-token@v1
-        id: generate_token
-        with:
-          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
-          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
-
-      - name: checkout
-        if: ${{ github.event_name == 'push' }}
-        uses: actions/checkout@v3
-        with:
-          fetch-depth: 0
-          token: ${{ steps.generate_token.outputs.token }}
-
       - name: checkout
-        if: ${{ github.event_name != 'push' }}
         uses: actions/checkout@v3
 
-      - name: Configure git info
-        if: ${{ github.event_name == 'push' }}
-        run: |
-          set -euo pipefail
-
-          git config user.name 'ibis-docs-bot[bot]'
-          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
-
       - name: build docs
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c mkdocs build
 
       - name: verify internal links
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c just checklinks --offline --no-progress
 
-      - name: Pull gh-pages changes
+      - name: Configure git info
         if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
-          git fetch origin gh-pages
-          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
 
       - name: build and push dev docs
-        if: ${{ github.event_name == 'push' && !startsWith(github.ref, 'refs/tags/') }}
+        if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
@@ -180,19 +155,6 @@ jobs:
               --message 'docs(dev): ibis@${{ github.sha }}' \
                 dev
 
-      - name: build and push docs on tag
-        if: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/tags/') }}
-        run: |
-          set -euo pipefail
-
-          nix develop -f shell.nix --keep-going -c \
-            mic deploy \
-              --push \
-              --rebase \
-              --prefix docs \
-              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
-              ""${GITHUB_REF_NAME}"" latest
-
   simulate_release:
     runs-on: ubuntu-latest
     steps:
diff --git a/.github/workflows/ibis-docs-release.yml b/.github/workflows/ibis-docs-release.yml
new file mode 100644
index 0000000..da7ee49
--- /dev/null
+++ b/.github/workflows/ibis-docs-release.yml
@@ -0,0 +1,63 @@
+# vim: filetype=yaml
+name: Docs Release Build
+
+on:
+  release:
+    types:
+      - published
+jobs:
+  docs:
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
+    runs-on: ubuntu-latest
+    steps:
+      - name: install nix
+        uses: cachix/install-nix-action@v17
+        with:
+          nix_path: nixpkgs=channel:nixos-unstable-small
+
+      - name: setup cachix
+        uses: cachix/cachix-action@v10
+        with:
+          name: ibis
+          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
+          extraPullNames: nix-community,poetry2nix
+
+      - name: Generate a GitHub token
+        uses: tibdex/github-app-token@v1
+        id: generate_token
+        with:
+          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
+          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
+
+      - name: checkout
+        uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+          token: ${{ steps.generate_token.outputs.token }}
+
+      - name: Configure git info
+        run: |
+          set -euo pipefail
+
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
+
+      - name: Pull gh-pages changes
+        run: |
+          set -euo pipefail
+
+          git fetch origin gh-pages
+          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+
+      - name: build and push docs on tag
+        run: |
+          set -euo pipefail
+
+          nix develop -f shell.nix --keep-going -c \
+            mic deploy \
+              --push \
+              --rebase \
+              --update-aliases \
+              --prefix docs \
+              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
+              ""${GITHUB_REF_NAME}"" latest

diff --git a/clarity/src/vm/ast/errors.rs b/clarity/src/vm/ast/errors.rs
index 1b8cbd1..8903e6a 100644
--- a/clarity/src/vm/ast/errors.rs
+++ b/clarity/src/vm/ast/errors.rs
@@ -88,6 +88,9 @@ pub enum ParseErrors {
     ExpectedWhitespace,
     // Notes
     NoteToMatchThis(Token),
+
+    /// Should be an unreachable error
+    UnexpectedParserFailure,
 }
 
 #[derive(Debug, PartialEq)]
@@ -294,6 +297,7 @@ impl DiagnosableError for ParseErrors {
             ParseErrors::IllegalUtf8String(s) => format!(""illegal UTF8 string \""{}\"""", s),
             ParseErrors::ExpectedWhitespace => ""expected whitespace before expression"".to_string(),
             ParseErrors::NoteToMatchThis(token) => format!(""to match this '{}'"", token),
+            ParseErrors::UnexpectedParserFailure => ""unexpected failure while parsing"".to_string(),
         }
     }
 
diff --git a/clarity/src/vm/ast/parser/v2/mod.rs b/clarity/src/vm/ast/parser/v2/mod.rs
index 14b9b17..3114a69 100644
--- a/clarity/src/vm/ast/parser/v2/mod.rs
+++ b/clarity/src/vm/ast/parser/v2/mod.rs
@@ -153,6 +153,17 @@ impl<'a> Parser<'a> {
         }
     }
 
+    /// Get a reference to the last processed token. If there is no last token,
+    ///  raises an UnexpectedParserFailure.
+    fn peek_last_token(&self) -> ParseResult<&PlacedToken> {
+        if self.next_token == 0 {
+            return Err(ParseError::new(ParseErrors::UnexpectedParserFailure));
+        }
+        self.tokens
+            .get(self.next_token - 1)
+            .ok_or_else(|| ParseError::new(ParseErrors::UnexpectedParserFailure))
+    }
+
     fn skip_to_end(&mut self) {
         self.next_token = self.tokens.len();
     }
@@ -220,7 +231,7 @@ impl<'a> Parser<'a> {
                     *whitespace = self.ignore_whitespace();
                     Ok(None)
                 } else {
-                    let token = self.tokens[self.next_token - 1].clone();
+                    let token = self.peek_last_token()?.clone();
                     match token.token {
                         Token::Rparen => {
                             span.end_line = token.span.end_line;
@@ -279,7 +290,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 self.add_diagnostic(
@@ -359,7 +370,7 @@ impl<'a> Parser<'a> {
                         // mimic parse_node_or_eof() behavior
                         //  if last token was an EOF, error out the tuple
                         //  if the last token was something else, just yield back to the parse loop
-                        let last_token = self.tokens[self.next_token - 1].clone();
+                        let last_token = self.peek_last_token()?.clone();
                         match last_token.token {
                             Token::Eof => {
                                 // This indicates we have reached the end of the input.

diff --git a/src/components/nav/test/basic/app-module.ts b/src/components/nav/test/basic/app-module.ts
index 467917a..375e662 100644
--- a/src/components/nav/test/basic/app-module.ts
+++ b/src/components/nav/test/basic/app-module.ts
@@ -633,7 +633,7 @@ export class Tab3 {
   }
 
   presentModal() {
-    //this.modalCtrl.create(MyModal).present();
+    // this.modalCtrl.create(MyModal).present();
   }
 
   selectPrevious() {

diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 
",5,"[""32845e1bbd1efb5dbc16f671049509a409ba25ce"", ""63eab619e6166eb6cab948028a7b89bf059dd878"", ""af880ac5b4fecbc6c4f3d1eee0d95f326e8bd9d1"", ""9be725fa3906323d4bc9788f54eccf74109d632b"", ""fd8e563cc19ca4684885d4692acee6bebcca4ada""]","[""cicd"", ""refactor"", ""docs"", ""fix"", ""feat""]"
"Fix typorestructure ClusterTopology to track completed changeinitialize threejs objects in defaultRef, to fix undefined type errorsupdate wrapping tests for v7upgrade to Flux v0.42.0

Skips a test that requires special dependencies to pass.","diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(

diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number

diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });

diff --git a/go.mod b/go.mod
index ea705da..8c352f7 100644
--- a/go.mod
+++ b/go.mod
@@ -38,7 +38,7 @@ require (
 	github.com/hashicorp/go-msgpack v0.0.0-20150518234257-fa3f63826f7c // indirect
 	github.com/hashicorp/raft v1.0.0 // indirect
 	github.com/hashicorp/vault/api v1.0.2
-	github.com/influxdata/flux v0.41.0
+	github.com/influxdata/flux v0.42.0
 	github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6
 	github.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368
 	github.com/jessevdk/go-flags v1.4.0
diff --git a/go.sum b/go.sum
index 4bfdf4c..634a0f1 100644
--- a/go.sum
+++ b/go.sum
@@ -206,8 +206,8 @@ github.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NH
 github.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=
 github.com/influxdata/changelog v1.0.0 h1:RstJD6H48zLQj0GdE6E6k/6RPwtUjkyzIe/T1E/xuWU=
 github.com/influxdata/changelog v1.0.0/go.mod h1:uzpGWE/qehT8L426YuXwpMQub+a63vIINhIeEI9mnSM=
-github.com/influxdata/flux v0.41.0 h1:ljbWJmE+aNx8Yoqhb04gWC4sXMV87eYUxz5vjYphLLs=
-github.com/influxdata/flux v0.41.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
+github.com/influxdata/flux v0.42.0 h1:2iEG6hLHdHEJ6LgD8OSnlHS9yoVrLO1/aM4P9ERb94U=
+github.com/influxdata/flux v0.42.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
 github.com/influxdata/goreleaser v0.97.0-influx h1:jT5OrcW7WfS0e2QxfwmTBjhLvpIC9CDLRhNgZJyhj8s=
 github.com/influxdata/goreleaser v0.97.0-influx/go.mod h1:MnjA0e0Uq6ISqjG1WxxMAl+3VS1QYjILSWVnMYDxasE=
 github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6 h1:CFx+pP90q/qg3spoiZjf8donE4WpAdjeJfPOcoNqkWo=
diff --git a/query/stdlib/testing/testing.go b/query/stdlib/testing/testing.go
index d41574a..85b0673 100644
--- a/query/stdlib/testing/testing.go
+++ b/query/stdlib/testing/testing.go
@@ -98,4 +98,6 @@ var FluxEndToEndSkipList = map[string]string{
 	""http_endpoint"": ""need ability to test side effects in e2e tests: (https://github.com/influxdata/flux/issues/1723)"",
 
 	""holt_winters_panic"": ""Expected output is an empty table which breaks the testing framework (https://github.com/influxdata/influxdb/issues/14749)"",
+
+	""secrets"": ""Cannot inject custom deps into the test framework so the secrets don't lookup correctly"",
 }
",5,"[""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2"", ""2561f4ade46fc9d59f289f328cc77733a6443697"", ""317f4eefecddfb1392ca71d551840f446feee302"", ""454003841aabeb74396d73541378bfa59c75b5db""]","[""docs"", ""refactor"", ""fix"", ""test"", ""build""]"
"update wrapping tests for v7split release docs build into separate workflownever call ""onStart"" prop when idleadd .nullif() exampleget tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.","diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });

diff --git a/.github/workflows/ibis-docs-lint.yml b/.github/workflows/ibis-docs-lint.yml
index 753d57d..3e0aa15 100644
--- a/.github/workflows/ibis-docs-lint.yml
+++ b/.github/workflows/ibis-docs-lint.yml
@@ -88,14 +88,14 @@ jobs:
         run: poetry run pytest --benchmark-only --benchmark-json .benchmarks/output.json ibis/tests/benchmarks
 
       - uses: tibdex/github-app-token@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         id: generate-token
         with:
           app_id: ${{ secrets.SQUAWK_BOT_APP_ID }}
           private_key: ${{ secrets.SQUAWK_BOT_APP_PRIVATE_KEY }}
 
       - uses: benchmark-action/github-action-benchmark@v1
-        if: ${{ github.event_name != 'pull_request' }}
+        if: ${{ github.event_name == 'push' }}
         with:
           tool: pytest
           github-token: ${{ steps.generate-token.outputs.token }}
@@ -107,6 +107,7 @@ jobs:
 
   docs:
     runs-on: ubuntu-latest
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
     needs:
       # wait on benchmarks to prevent a race condition when pushing to the
       # gh-pages branch
@@ -124,51 +125,25 @@ jobs:
           authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
           extraPullNames: nix-community,poetry2nix
 
-      - name: Generate a GitHub token
-        if: ${{ github.event_name == 'push' }}
-        uses: tibdex/github-app-token@v1
-        id: generate_token
-        with:
-          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
-          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
-
-      - name: checkout
-        if: ${{ github.event_name == 'push' }}
-        uses: actions/checkout@v3
-        with:
-          fetch-depth: 0
-          token: ${{ steps.generate_token.outputs.token }}
-
       - name: checkout
-        if: ${{ github.event_name != 'push' }}
         uses: actions/checkout@v3
 
-      - name: Configure git info
-        if: ${{ github.event_name == 'push' }}
-        run: |
-          set -euo pipefail
-
-          git config user.name 'ibis-docs-bot[bot]'
-          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
-
       - name: build docs
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c mkdocs build
 
       - name: verify internal links
-        if: ${{ github.event_name != 'push' }}
         run: nix develop -f shell.nix --ignore-environment --keep-going -c just checklinks --offline --no-progress
 
-      - name: Pull gh-pages changes
+      - name: Configure git info
         if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
-          git fetch origin gh-pages
-          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
 
       - name: build and push dev docs
-        if: ${{ github.event_name == 'push' && !startsWith(github.ref, 'refs/tags/') }}
+        if: ${{ github.event_name == 'push' }}
         run: |
           set -euo pipefail
 
@@ -180,19 +155,6 @@ jobs:
               --message 'docs(dev): ibis@${{ github.sha }}' \
                 dev
 
-      - name: build and push docs on tag
-        if: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/tags/') }}
-        run: |
-          set -euo pipefail
-
-          nix develop -f shell.nix --keep-going -c \
-            mic deploy \
-              --push \
-              --rebase \
-              --prefix docs \
-              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
-              ""${GITHUB_REF_NAME}"" latest
-
   simulate_release:
     runs-on: ubuntu-latest
     steps:
diff --git a/.github/workflows/ibis-docs-release.yml b/.github/workflows/ibis-docs-release.yml
new file mode 100644
index 0000000..da7ee49
--- /dev/null
+++ b/.github/workflows/ibis-docs-release.yml
@@ -0,0 +1,63 @@
+# vim: filetype=yaml
+name: Docs Release Build
+
+on:
+  release:
+    types:
+      - published
+jobs:
+  docs:
+    concurrency: docs-${{ github.repository }}-${{ github.head_ref || github.sha }}
+    runs-on: ubuntu-latest
+    steps:
+      - name: install nix
+        uses: cachix/install-nix-action@v17
+        with:
+          nix_path: nixpkgs=channel:nixos-unstable-small
+
+      - name: setup cachix
+        uses: cachix/cachix-action@v10
+        with:
+          name: ibis
+          authToken: ${{ secrets.CACHIX_AUTH_TOKEN }}
+          extraPullNames: nix-community,poetry2nix
+
+      - name: Generate a GitHub token
+        uses: tibdex/github-app-token@v1
+        id: generate_token
+        with:
+          app_id: ${{ secrets.DOCS_BOT_APP_ID }}
+          private_key: ${{ secrets.DOCS_BOT_APP_PRIVATE_KEY }}
+
+      - name: checkout
+        uses: actions/checkout@v3
+        with:
+          fetch-depth: 0
+          token: ${{ steps.generate_token.outputs.token }}
+
+      - name: Configure git info
+        run: |
+          set -euo pipefail
+
+          git config user.name 'ibis-docs-bot[bot]'
+          git config user.email 'ibis-docs-bot[bot]@users.noreply.github.com'
+
+      - name: Pull gh-pages changes
+        run: |
+          set -euo pipefail
+
+          git fetch origin gh-pages
+          git update-ref refs/heads/gh-pages ""$(git rev-parse origin/gh-pages)""
+
+      - name: build and push docs on tag
+        run: |
+          set -euo pipefail
+
+          nix develop -f shell.nix --keep-going -c \
+            mic deploy \
+              --push \
+              --rebase \
+              --update-aliases \
+              --prefix docs \
+              --message ""docs(release): ibis@${GITHUB_REF_NAME}"" \
+              ""${GITHUB_REF_NAME}"" latest

diff --git a/packages/core/src/SpringValue.ts b/packages/core/src/SpringValue.ts
index 18494a8..cbc4f27 100644
--- a/packages/core/src/SpringValue.ts
+++ b/packages/core/src/SpringValue.ts
@@ -596,11 +596,11 @@ export class SpringValue<T = any> extends AnimationValue<T> {
   /** Notify change observers */
   protected _onChange(value: T, idle = false) {
     const anim = this.animation
-    if (!anim.changed) {
+    if (!anim.changed && !idle) {
       anim.changed = true
       // The ""onStart"" prop is called on the first change after entering the
       // frameloop, but never for immediate animations.
-      if (anim.onStart && !anim.immediate) {
+      if (anim.onStart) {
         anim.onStart(this)
       }
     }

diff --git a/ibis/expr/types/generic.py b/ibis/expr/types/generic.py
index 8dcbbe8..6ab52fe 100644
--- a/ibis/expr/types/generic.py
+++ b/ibis/expr/types/generic.py
@@ -370,6 +370,8 @@ class Value(Expr):
         Commonly used to avoid divide-by-zero problems by replacing zero with
         `NULL` in the divisor.
 
+        Equivalent to `(self == null_if_expr).ifelse(ibis.null(), self)`.
+
         Parameters
         ----------
         null_if_expr
@@ -379,6 +381,36 @@ class Value(Expr):
         -------
         Value
             Value expression
+
+        Examples
+        --------
+        >>> import ibis
+        >>> ibis.options.interactive = True
+        >>> vals = ibis.examples.penguins.fetch().head(5).sex
+        >>> vals
+        ┏━━━━━━━━┓
+        ┃ sex    ┃
+        ┡━━━━━━━━┩
+        │ string │
+        ├────────┤
+        │ male   │
+        │ female │
+        │ female │
+        │ NULL   │
+        │ female │
+        └────────┘
+        >>> vals.nullif(""male"")
+        ┏━━━━━━━━━━━━━━━━━━━━━┓
+        ┃ NullIf(sex, 'male') ┃
+        ┡━━━━━━━━━━━━━━━━━━━━━┩
+        │ string              │
+        ├─────────────────────┤
+        │ NULL                │
+        │ female              │
+        │ female              │
+        │ NULL                │
+        │ female              │
+        └─────────────────────┘
         """"""
         return ops.NullIf(self, null_if_expr).to_expr()
 

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }
",5,"[""317f4eefecddfb1392ca71d551840f446feee302"", ""32845e1bbd1efb5dbc16f671049509a409ba25ce"", ""c8e0ae8612df3d6f2831acc004aaac332f6105e4"", ""6d405dfc1675dcad64a2dfac0c0cb0fb28381d21"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c""]","[""test"", ""cicd"", ""fix"", ""docs"", ""refactor""]"
"spring version, core versiononly run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>verify checkpoint listeners are notifiedupdate `cargo-make` for `v0.35.3`add getter for protocol id","diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 

diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }

diff --git a/CHANGELOG.md b/CHANGELOG.md
index 5e125e3..52d9b6f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -14,6 +14,7 @@ The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/)
 * Fix: resizing/scrolling through heavily wrapped panes no longer hangs (https://github.com/zellij-org/zellij/pull/814)
 * Terminal compatibility: properly handle HOME/END keys in eg. vim/zsh (https://github.com/zellij-org/zellij/pull/815)
 * Fix: Typo (https://github.com/zellij-org/zellij/pull/821)
+* Fix: Update `cargo-make` instructions post `v0.35.3` (https://github.com/zellij-org/zellij/pull/819)
 
 ## [0.19.0] - 2021-10-20
 * Fix: Prevent text overwrite when scrolled up (https://github.com/zellij-org/zellij/pull/655)

diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }
",5,"[""c55591ba157298a9c5816693c102a89dfd058830"", ""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""e0198f74b81da3663144cfe1d971939319f82a0f"", ""0cfc5633d37ea06f645649138323f1820e18bdee"", ""dc5238b2bda98a7c4f2fe9584fc3b0191a408109""]","[""build"", ""cicd"", ""test"", ""docs"", ""feat""]"
"export a modal transition presetadd getter for protocol idskip flaky testinitialize threejs objects in defaultRef, to fix undefined type errorsadd a branch name to Slack notifications (#14793)","diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {

diff --git a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
index ad0015f..68624d8 100644
--- a/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
+++ b/transport/src/main/java/org/camunda/tngp/transport/protocol/TransportHeaderDescriptor.java
@@ -50,4 +50,9 @@ public class TransportHeaderDescriptor
         return this;
     }
 
+    public int protocolId()
+    {
+        return buffer.getShort(PROTOCOL_ID_OFFSET);
+    }
+
 }

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method

diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number

diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'
",5,"[""535708ae50aecb452560a23356fd396f99ef13a2"", ""dc5238b2bda98a7c4f2fe9584fc3b0191a408109"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d"", ""2561f4ade46fc9d59f289f328cc77733a6443697"", ""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da""]","[""refactor"", ""feat"", ""test"", ""fix"", ""cicd""]"
"add a branch name to Slack notifications (#14793)add spacing in comment fix lint (#8555)remove appear css animationdocker PG version upgrade

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>fixed docker link tests","diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'

diff --git a/src/components/nav/test/basic/app-module.ts b/src/components/nav/test/basic/app-module.ts
index 467917a..375e662 100644
--- a/src/components/nav/test/basic/app-module.ts
+++ b/src/components/nav/test/basic/app-module.ts
@@ -633,7 +633,7 @@ export class Tab3 {
   }
 
   presentModal() {
-    //this.modalCtrl.create(MyModal).present();
+    // this.modalCtrl.create(MyModal).present();
   }
 
   selectPrevious() {

diff --git a/src/popup/Popup.tsx b/src/popup/Popup.tsx
index d485bb6..2abc22a 100644
--- a/src/popup/Popup.tsx
+++ b/src/popup/Popup.tsx
@@ -269,7 +269,6 @@ export class Popup extends React.Component<{ t: TranslationFunction }, PopupStat
         <CSSTransition
           classNames='fade'
           in={!!currentTabUrl}
-          appear
           timeout={500}
           exit={false}
           mountOnEnter

diff --git a/packages/nocodb/docker-compose.yml b/packages/nocodb/docker-compose.yml
index 7fabf79..ba2ab7b 100644
--- a/packages/nocodb/docker-compose.yml
+++ b/packages/nocodb/docker-compose.yml
@@ -1,4 +1,4 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
     # db55:
@@ -96,8 +96,8 @@ services:
     #     - 5495:5432
     #   volumes:
     #     - ./pg-sakila-db:/docker-entrypoint-initdb.d
-    pg96:
-     image: postgres:9.6
+    pg147:
+     image: postgres:14.7
      restart: always
      environment:
        POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
index 19dfab2..97d346b 100644
--- a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
+++ b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg.yml b/tests/playwright/scripts/docker-compose-pg.yml
index 0396579..9fab10e 100644
--- a/tests/playwright/scripts/docker-compose-pg.yml
+++ b/tests/playwright/scripts/docker-compose-pg.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password

diff --git a/pipeline/docker/docker_test.go b/pipeline/docker/docker_test.go
index 2be176f..b43c12b 100644
--- a/pipeline/docker/docker_test.go
+++ b/pipeline/docker/docker_test.go
@@ -271,7 +271,7 @@ func TestLinkDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
@@ -304,7 +304,7 @@ func TestLinkTwoLevelDirectory(t *testing.T) {
 		t.Log(""Cannot setup test file"")
 		t.Fail()
 	}
-	err = directoryLink(srcDir, dstDir, nil)
+	err = link(srcDir, dstDir)
 	if err != nil {
 		t.Log(""Failed to link: "", err)
 		t.Fail()
",5,"[""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da"", ""af880ac5b4fecbc6c4f3d1eee0d95f326e8bd9d1"", ""47ef9104e4a89e80d7cc6c1950bc080841da4a7b"", ""37b1cbfd3d2c462ef4f2a131e4172c38dc8d9ddf"", ""c7b25726df94a2530c9b1c0d2b6a0acaa103822f""]","[""cicd"", ""docs"", ""refactor"", ""build"", ""test""]"
"upgrade to Flux v0.42.0

Skips a test that requires special dependencies to pass.added changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284make it mode lessxfail on to_parquet and to_csv that use pyarrow write optionssupport use meta key select multiple element","diff --git a/go.mod b/go.mod
index ea705da..8c352f7 100644
--- a/go.mod
+++ b/go.mod
@@ -38,7 +38,7 @@ require (
 	github.com/hashicorp/go-msgpack v0.0.0-20150518234257-fa3f63826f7c // indirect
 	github.com/hashicorp/raft v1.0.0 // indirect
 	github.com/hashicorp/vault/api v1.0.2
-	github.com/influxdata/flux v0.41.0
+	github.com/influxdata/flux v0.42.0
 	github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6
 	github.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368
 	github.com/jessevdk/go-flags v1.4.0
diff --git a/go.sum b/go.sum
index 4bfdf4c..634a0f1 100644
--- a/go.sum
+++ b/go.sum
@@ -206,8 +206,8 @@ github.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NH
 github.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=
 github.com/influxdata/changelog v1.0.0 h1:RstJD6H48zLQj0GdE6E6k/6RPwtUjkyzIe/T1E/xuWU=
 github.com/influxdata/changelog v1.0.0/go.mod h1:uzpGWE/qehT8L426YuXwpMQub+a63vIINhIeEI9mnSM=
-github.com/influxdata/flux v0.41.0 h1:ljbWJmE+aNx8Yoqhb04gWC4sXMV87eYUxz5vjYphLLs=
-github.com/influxdata/flux v0.41.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
+github.com/influxdata/flux v0.42.0 h1:2iEG6hLHdHEJ6LgD8OSnlHS9yoVrLO1/aM4P9ERb94U=
+github.com/influxdata/flux v0.42.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
 github.com/influxdata/goreleaser v0.97.0-influx h1:jT5OrcW7WfS0e2QxfwmTBjhLvpIC9CDLRhNgZJyhj8s=
 github.com/influxdata/goreleaser v0.97.0-influx/go.mod h1:MnjA0e0Uq6ISqjG1WxxMAl+3VS1QYjILSWVnMYDxasE=
 github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6 h1:CFx+pP90q/qg3spoiZjf8donE4WpAdjeJfPOcoNqkWo=
diff --git a/query/stdlib/testing/testing.go b/query/stdlib/testing/testing.go
index d41574a..85b0673 100644
--- a/query/stdlib/testing/testing.go
+++ b/query/stdlib/testing/testing.go
@@ -98,4 +98,6 @@ var FluxEndToEndSkipList = map[string]string{
 	""http_endpoint"": ""need ability to test side effects in e2e tests: (https://github.com/influxdata/flux/issues/1723)"",
 
 	""holt_winters_panic"": ""Expected output is an empty table which breaks the testing framework (https://github.com/influxdata/influxdb/issues/14749)"",
+
+	""secrets"": ""Cannot inject custom deps into the test framework so the secrets don't lookup correctly"",
 }

diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/core/src/components/slides/slides.tsx b/core/src/components/slides/slides.tsx
index 48fd53f..d5c2f75 100644
--- a/core/src/components/slides/slides.tsx
+++ b/core/src/components/slides/slides.tsx
@@ -1,7 +1,6 @@
 import { Component, Element, Event, EventEmitter, Method, Prop, Watch } from '@stencil/core';
 
 import { Mode } from '../../interface.js';
-import { createThemedClasses } from '../../utils/theme.js';
 
 import { Swiper } from './vendor/swiper.js';
 
@@ -15,6 +14,7 @@ import { Swiper } from './vendor/swiper.js';
   shadow: true
 })
 export class Slides {
+
   private container!: HTMLElement;
   private swiper: any;
 
@@ -391,12 +391,6 @@ export class Slides {
     return { ...swiperOptions, ...this.options, ...eventOptions };
   }
 
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'slides')
-    };
-  }
-
   render() {
     return (
       <div class=""swiper-container"" ref={el => this.container = el as HTMLElement }>
diff --git a/core/src/components/thumbnail/thumbnail.ios.scss b/core/src/components/thumbnail/thumbnail.ios.scss
deleted file mode 100644
index e3add45..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.ios.vars"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-ios-width};
-  --border-radius: #{$thumbnail-ios-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.ios.vars.scss b/core/src/components/thumbnail/thumbnail.ios.vars.scss
deleted file mode 100644
index 85d53e5..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.ios"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-ios-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-ios-height:                  $thumbnail-ios-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-ios-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.md.scss b/core/src/components/thumbnail/thumbnail.md.scss
deleted file mode 100644
index 0fbb2ca..0000000
--- a/core/src/components/thumbnail/thumbnail.md.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.md.vars"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-md-width};
-  --border-radius: #{$thumbnail-md-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.md.vars.scss b/core/src/components/thumbnail/thumbnail.md.vars.scss
deleted file mode 100644
index 94e48b2..0000000
--- a/core/src/components/thumbnail/thumbnail.md.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.md"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-md-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-md-height:                  $thumbnail-md-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-md-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.scss b/core/src/components/thumbnail/thumbnail.scss
index 8ac3a22..8af268d 100644
--- a/core/src/components/thumbnail/thumbnail.scss
+++ b/core/src/components/thumbnail/thumbnail.scss
@@ -9,6 +9,8 @@
    * @prop --border-radius: Border radius of the thumbnail
    * @prop --size: Size of the thumbnail
    */
+  --size: 48px;
+  --border-radius: 0;
 
   @include border-radius(var(--border-radius));
 
diff --git a/core/src/components/thumbnail/thumbnail.tsx b/core/src/components/thumbnail/thumbnail.tsx
index 50ff2c2..de76593 100644
--- a/core/src/components/thumbnail/thumbnail.tsx
+++ b/core/src/components/thumbnail/thumbnail.tsx
@@ -1,25 +1,11 @@
 import { Component } from '@stencil/core';
 
-import { Mode } from '../../interface';
-import { createThemedClasses } from '../../utils/theme';
-
 @Component({
   tag: 'ion-thumbnail',
-  styleUrls: {
-    ios: 'thumbnail.ios.scss',
-    md: 'thumbnail.md.scss'
-  },
+  styleUrl: 'thumbnail.scss',
   shadow: true
 })
 export class Thumbnail {
-  mode!: Mode;
-
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'thumbnail')
-    };
-  }
-
   render() {
     return <slot></slot>;
   }

diff --git a/ibis/backends/tests/test_export.py b/ibis/backends/tests/test_export.py
index 4d536d7..5bb9775 100644
--- a/ibis/backends/tests/test_export.py
+++ b/ibis/backends/tests/test_export.py
@@ -222,18 +222,23 @@ def test_table_to_parquet(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs""), [({""version"": ""1.0""}), ({""version"": ""2.6""})])
-def test_table_to_parquet_writer_kwargs(kwargs, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.NotSupportedError,
+)
+@pytest.mark.parametrize(""version"", [""1.0"", ""2.6""])
+def test_table_to_parquet_writer_kwargs(version, tmp_path, backend, awards_players):
     outparquet = tmp_path / ""out.parquet""
-    awards_players.to_parquet(outparquet, **kwargs)
+    awards_players.to_parquet(outparquet, version=version)
 
     df = pd.read_parquet(outparquet)
 
     backend.assert_frame_equal(awards_players.to_pandas(), df)
 
-    file = pa.parquet.ParquetFile(outparquet)
+    md = pa.parquet.read_metadata(outparquet)
 
-    assert file.metadata.format_version == kwargs[""version""]
+    assert md.format_version == version
 
 
 @pytest.mark.notimpl(
@@ -316,14 +321,20 @@ def test_table_to_csv(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs"", ""delimiter""), [({""write_options"": pcsv.WriteOptions(delimiter="";"")}, "";""), ({""write_options"": pcsv.WriteOptions(delimiter=""\t"")}, ""\t"")])
-def test_table_to_csv_writer_kwargs(kwargs, delimiter, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.ProgrammingError,
+)
+@pytest.mark.parametrize(""delimiter"", ["";"", ""\t""], ids=[""semicolon"", ""tab""])
+def test_table_to_csv_writer_kwargs(delimiter, tmp_path, awards_players):
     outcsv = tmp_path / ""out.csv""
     # avoid pandas NaNonense
     awards_players = awards_players.select(""playerID"", ""awardID"", ""yearID"", ""lgID"")
 
-    awards_players.to_csv(outcsv, **kwargs)
-    pd.read_csv(outcsv, delimiter=delimiter)
+    awards_players.to_csv(outcsv, write_options=pcsv.WriteOptions(delimiter=delimiter))
+    df = pd.read_csv(outcsv, delimiter=delimiter, nrows=1)
+    assert len(df) == 1
 
 
 @pytest.mark.parametrize(

diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index ab68624..aeee7b7 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -277,9 +277,11 @@ export default class LogicFlow {
   }
   /**
    * 将图形选中
+   * @param id 选择元素ID
+   * @param multiple 是否允许多选，如果为true，不会将上一个选中的元素重置
    */
-  select(id: string) {
-    this.graphModel.selectElementById(id);
+  select(id: string, multiple = false) {
+    this.graphModel.selectElementById(id, multiple);
   }
   /**
    * 将图形定位到画布中心
diff --git a/packages/core/src/model/EditConfigModel.ts b/packages/core/src/model/EditConfigModel.ts
index 67e334a..83e5f16 100644
--- a/packages/core/src/model/EditConfigModel.ts
+++ b/packages/core/src/model/EditConfigModel.ts
@@ -25,6 +25,7 @@ const SilentConfig = {
   edgeTextEdit: false,
   nodeTextDraggable: false,
   edgeTextDraggable: false,
+  metaKeyMultipleSelected: false,
 };
 
 /**
@@ -42,6 +43,7 @@ export default class EditConfigModel {
   @observable edgeTextEdit = true; // 允许连线文本可以编辑
   @observable nodeTextDraggable = false; // 允许节点文本可以拖拽
   @observable edgeTextDraggable = false; // 允许连线文本可以拖拽
+  @observable metaKeyMultipleSelected = false; // 允许meta多选元素
   constructor(data) {
     const keys = [
       'stopZoomGraph',
@@ -55,6 +57,7 @@ export default class EditConfigModel {
       'edgeTextEdit',
       'nodeTextDraggable',
       'edgeTextDraggable',
+      'metaKeyMultipleSelected',
     ];
     const { isSilentMode, textEdit } = data;
     if (isSilentMode) {
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 9667f4d..310daf4 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -34,6 +34,7 @@ class GraphModel {
   height: number;
   topElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
   selectElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
+  selectElements = new Map<string, IBaseModel>(); // 多选
   @observable edgeType: string;
   @observable nodes: BaseNodeModel[] = [];
   @observable activeElement: IBaseModel;
@@ -50,7 +51,6 @@ class GraphModel {
   @observable gridSize = 1;
   @observable partial = false; // 是否开启局部渲染
   @observable fakerNode: BaseNodeModel;
-  // @observable selectElements = new Map<string, IBaseModel>(); // 多选还没有做，先不加
   constructor(config) {
     const {
       container,
@@ -456,24 +456,44 @@ class GraphModel {
   }
 
   @action
-  selectNodeById(id) {
-    this.selectElement?.setSelected(false);
+  selectNodeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.nodesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectEdgeById(id) {
-    this.selectElement?.setSelected(false);
+  selectEdgeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.edgesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectElementById(id: string) {
-    this.selectElement?.setSelected(false);
+  selectElementById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
+  }
+
+  @action
+  clearSelectElements() {
+    this.selectElements.forEach(element => {
+      element.setSelected(false);
+    });
+    this.selectElements.clear();
   }
 
   /* 修改连线类型 */
diff --git a/packages/core/src/view/edge/BaseEdge.tsx b/packages/core/src/view/edge/BaseEdge.tsx
index d45ea9e..d7c8f38 100644
--- a/packages/core/src/view/edge/BaseEdge.tsx
+++ b/packages/core/src/view/edge/BaseEdge.tsx
@@ -178,7 +178,8 @@ export default class BaseEdge extends Component<IProps> {
   handleClick = (e) => {
     const { model, graphModel, eventCenter } = this.props;
     graphModel.toFront(model.id);
-    graphModel.selectEdgeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectEdgeById(model.id, e.metaKey && metaKeyMultipleSelected);
     // 边数据
     const edgeData = model?.getData();
     const position = graphModel.getPointByClient({
diff --git a/packages/core/src/view/node/BaseNode.tsx b/packages/core/src/view/node/BaseNode.tsx
index 140889c..5ee3975 100644
--- a/packages/core/src/view/node/BaseNode.tsx
+++ b/packages/core/src/view/node/BaseNode.tsx
@@ -275,7 +275,8 @@ export default abstract class BaseNode extends Component<IProps, Istate> {
       }, 400);
     }
     graphModel.toFront(model.id);
-    graphModel.selectNodeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectNodeById(model.id, e.metaKey && metaKeyMultipleSelected);
     this.preStartTime = this.startTime;
   };
   handleContextMenu = (ev: MouseEvent) => {
diff --git a/packages/core/src/view/overlay/CanvasOverlay.tsx b/packages/core/src/view/overlay/CanvasOverlay.tsx
index ef11822..8c79fd2 100644
--- a/packages/core/src/view/overlay/CanvasOverlay.tsx
+++ b/packages/core/src/view/overlay/CanvasOverlay.tsx
@@ -104,9 +104,9 @@ class CanvasOverlay extends Component<IProps, Istate> {
     const target = ev.target as HTMLElement;
     if (target.getAttribute('name') === 'canvas-overlay') {
       const { graphModel, eventCenter } = this.props;
-      const { selectElement, textEditElement } = graphModel;
-      if (selectElement) {
-        selectElement.setSelected(false);
+      const { textEditElement, selectElements } = graphModel;
+      if (selectElements.size > 0) {
+        graphModel.clearSelectElements();
       }
       if (textEditElement) {
         textEditElement.setElementState(ElementState.DEFAULT);
diff --git a/packages/extension/examples/bpmn/index.html b/packages/extension/examples/bpmn/index.html
index 7a68d6f..f7ea87d 100644
--- a/packages/extension/examples/bpmn/index.html
+++ b/packages/extension/examples/bpmn/index.html
@@ -6,6 +6,7 @@
   <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
   <title>LOGIN FLOW</title>
   <link rel=""stylesheet"" href=""/core/dist/style/index.css"">
+  <link rel=""stylesheet"" href=""/extension/lib/style/index.css"">
   <style>
     html,body {
       padding: 0;
@@ -129,11 +130,14 @@
     </div>
   </div>
   <script src=""/core/dist/logic-flow.js""></script>
+  <!-- <script src=""http://0.0.0.0:9090/logic-flow.js""></script> -->
   <script src=""/BpmnElement.js""></script>
   <script src=""/BpmnAdapter.js""></script>
+  <script src=""/Control.js""></script>
   <script src=""/Snapshot.js""></script>
   <script>
     LogicFlow.use(BpmnElement);
+    LogicFlow.use(Control);
     LogicFlow.use(BpmnAdapter);
     LogicFlow.use(Snapshot);
   </script>
diff --git a/packages/extension/examples/bpmn/index.js b/packages/extension/examples/bpmn/index.js
index 21d2da0..6f6aa39 100644
--- a/packages/extension/examples/bpmn/index.js
+++ b/packages/extension/examples/bpmn/index.js
@@ -3,6 +3,10 @@ window.onload = function () {
     container: document.querySelector('#app'),
     // fixme: grid成为了必传的了
     edgeTextDraggable: true,
+    metaKeyMultipleSelected: true,
+    // stopScrollGraph: true,
+    // stopMoveGraph: true,
+    // stopZoomGraph: true,
     grid: {
       type: 'dot',
       size: 20,
",5,"[""454003841aabeb74396d73541378bfa59c75b5db"", ""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""771857b1df9470ebc15357e8879118a72c649d5b"", ""bedc7950b24c37809e36a585b7985d5aa5e3e458"", ""e137f9fdbdb6bf3f85c3f7ac9323785e445844c8""]","[""build"", ""docs"", ""refactor"", ""test"", ""feat""]"
"remove ubuntu-latest from job title where that is the only osadd props to get color and label from a routefix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.licensingadd benchmark for known-slow table expression","diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false

diff --git a/src/components/BottomNavigation.js b/src/components/BottomNavigation.js
index 1b72302..7d8ea75 100644
--- a/src/components/BottomNavigation.js
+++ b/src/components/BottomNavigation.js
@@ -24,8 +24,8 @@ const AnimatedPaper = Animated.createAnimatedComponent(Paper);
 
 type Route = {
   key: string,
-  title: string,
-  icon: IconSource,
+  title?: string,
+  icon?: IconSource,
   color?: string,
 };
 
@@ -51,7 +51,7 @@ type Props<T> = {
    * - `key`: a unique key to identify the route
    * - `title`: title of the route to use as the tab label
    * - `icon`: icon to use as the tab icon, can be a string, an image source or a react component
-   * - `color`: color to use as background color for shifting bottom navigation (optional)
+   * - `color`: color to use as background color for shifting bottom navigation
    *
    * Example:
    *
@@ -115,11 +115,27 @@ type Props<T> = {
   /**
    * Callback which returns a React Element to be used as tab icon.
    */
-  renderIcon?: (props: { route: T, focused: boolean }) => React.Node,
+  renderIcon?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
   /**
    * Callback which React Element to be used as tab label.
    */
-  renderLabel?: (props: { route: T, focused: boolean }) => React.Node,
+  renderLabel?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
+  /**
+   * Get label text for the tab, uses `route.title` by default. Use `renderLabel` to replace label component.
+   */
+  getLabelText?: (props: { route: T }) => string,
+  /**
+   * Get color for the tab, uses `route.color` by default.
+   */
+  getColor?: (props: { route: T }) => string,
   /**
    * Function to execute on tab press. It receives the route for the pressed tab, useful for things like scroll to top.
    */
@@ -159,6 +175,10 @@ type State = {
    */
   ripple: Animated.Value,
   /**
+   * Animation for the touch feedback, used to determine it's scale and opacity.
+   */
+  touch: Animated.Value,
+  /**
    * Layout of the tab bar. The width is used to determine the size and position of the ripple.
    */
   layout: { height: number, width: number, measured: boolean },
@@ -173,7 +193,7 @@ const MIN_SHIFT_AMOUNT = 10;
 const MIN_TAB_WIDTH = 96;
 const MAX_TAB_WIDTH = 168;
 const BAR_HEIGHT = 56;
-const SMALL_RIPPLE_SIZE = 72;
+const SMALL_RIPPLE_SIZE = 96;
 const ACTIVE_LABEL_SIZE = 14;
 const INACTIVE_LABEL_SIZE = 12;
 
@@ -251,6 +271,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ),
       index: new Animated.Value(index),
       ripple: new Animated.Value(MIN_RIPPLE_SCALE),
+      touch: new Animated.Value(MIN_RIPPLE_SCALE),
       layout: { height: 0, width: 0, measured: false },
       previous: 0,
     };
@@ -349,6 +370,15 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
   _handleTabPress = (index: number) => {
     const { navigationState } = this.props;
 
+    this.state.touch.setValue(MIN_RIPPLE_SCALE);
+
+    Animated.timing(this.state.touch, {
+      toValue: 1,
+      duration: 300,
+      easing: Easing.in(Easing.sin),
+      useNativeDriver: true,
+    }).start();
+
     if (index !== navigationState.index) {
       this.props.onIndexChange(index);
     }
@@ -376,6 +406,8 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       renderScene,
       renderIcon,
       renderLabel,
+      getLabelText = ({ route }) => route.title,
+      getColor = ({ route }) => route.color,
       barStyle,
       style,
       theme,
@@ -400,7 +432,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ? this.state.index.interpolate({
           inputRange: routes.map((_, i) => i),
           outputRange: routes.map(
-            route => route.color || approxBackgroundColor
+            route => getColor({ route }) || approxBackgroundColor
           ),
         })
       : approxBackgroundColor;
@@ -416,7 +448,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
           .rgb()
           .string();
 
-    const rippleColor = color(textColor)
+    const touchColor = color(textColor)
       .alpha(0.12)
       .rgb()
       .string();
@@ -430,22 +462,10 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
 
     // Since we have a single ripple, we have to reposition it so that it appears to expand from active tab.
     // We need to move it from the left to the active tab and also account for how much that tab has shifted.
-    const rippleShift =
-      navigationState.index * tabWidth +
-      tabWidth / 2 +
-      this._calculateShift(
-        this.state.previous,
-        navigationState.index,
-        routes.length
-      );
 
     return (
       <View
-        style={[
-          styles.container,
-          { backgroundColor: theme.dark ? white : black },
-          style,
-        ]}
+        style={[styles.container, style]}
         onLayout={this._handleLayout}
         pointerEvents={layout.measured ? 'auto' : 'none'}
       >
@@ -485,25 +505,30 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
             style={[styles.items, { maxWidth: maxTabWidth * routes.length }]}
           >
             {shifting ? (
-              // Large ripple with the backround color
               <Animated.View
                 pointerEvents=""none""
                 style={[
                   styles.ripple,
                   {
                     // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - layout.width / 2,
-                    left: rippleShift - layout.width / 2,
-                    height: layout.width,
-                    width: layout.width,
+                    top: BAR_HEIGHT / 2 - layout.width / 8,
+                    left:
+                      navigationState.index * tabWidth +
+                      tabWidth / 2 -
+                      layout.width / 8,
+                    height: layout.width / 4,
+                    width: layout.width / 4,
                     borderRadius: layout.width / 2,
-                    backgroundColor: routes[navigationState.index].color,
+                    backgroundColor: getColor({
+                      route: routes[navigationState.index],
+                    }),
                     transform: [
+                      { translateX: this.state.shifts[navigationState.index] },
                       {
                         // Scale to twice the size  to ensure it covers the whole tab bar
                         scale: this.state.ripple.interpolate({
                           inputRange: [0, 1],
-                          outputRange: [0, 2],
+                          outputRange: [0, 8],
                         }),
                       },
                     ],
@@ -515,36 +540,36 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                 ]}
               />
             ) : null}
-            {shifting ? (
-              // Small subtle ripple on touch
-              <Animated.View
-                pointerEvents=""none""
-                style={[
-                  styles.ripple,
-                  {
-                    // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
-                    left: rippleShift - SMALL_RIPPLE_SIZE / 2,
-                    height: SMALL_RIPPLE_SIZE,
-                    width: SMALL_RIPPLE_SIZE,
-                    borderRadius: SMALL_RIPPLE_SIZE / 2,
-                    backgroundColor: rippleColor,
-                    transform: [
-                      {
-                        scale: this.state.ripple.interpolate({
-                          inputRange: [0, 0.5, 1],
-                          outputRange: [0, 1, 1],
-                        }),
-                      },
-                    ],
-                    opacity: this.state.ripple.interpolate({
-                      inputRange: [0, MIN_RIPPLE_SCALE, 0.25, 0.5],
-                      outputRange: [0, 0, 1, 0],
-                    }),
-                  },
-                ]}
-              />
-            ) : null}
+            <Animated.View
+              pointerEvents=""none""
+              style={[
+                styles.ripple,
+                {
+                  // Set top and left values so that the ripple's center is same as the tab's center
+                  top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
+                  left:
+                    navigationState.index * tabWidth +
+                    tabWidth / 2 -
+                    SMALL_RIPPLE_SIZE / 2,
+                  height: SMALL_RIPPLE_SIZE,
+                  width: SMALL_RIPPLE_SIZE,
+                  borderRadius: SMALL_RIPPLE_SIZE / 2,
+                  backgroundColor: touchColor,
+                  transform: [
+                    {
+                      translateX: shifting
+                        ? this.state.shifts[navigationState.index]
+                        : 0,
+                    },
+                    { scale: this.state.touch },
+                  ],
+                  opacity: this.state.touch.interpolate({
+                    inputRange: [0, 0.5, 1],
+                    outputRange: [0, 1, 0],
+                  }),
+                },
+              ]}
+            />
             {routes.map((route, index) => {
               const shift = this.state.shifts[index];
               const focused = this.state.tabs[index];
@@ -607,7 +632,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderIcon ? (
-                          renderIcon({ route, focused: true })
+                          renderIcon({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <Icon
                             style={styles.icon}
@@ -625,7 +654,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderIcon ? (
-                            renderIcon({ route, focused: false })
+                            renderIcon({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <Icon
                               style={styles.icon}
@@ -652,7 +685,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderLabel ? (
-                          renderLabel({ route, focused: true })
+                          renderLabel({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <AnimatedText
                             style={[
@@ -662,7 +699,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                               },
                             ]}
                           >
-                            {route.title}
+                            {getLabelText({ route })}
                           </AnimatedText>
                         )}
                       </Animated.View>
@@ -674,7 +711,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderLabel ? (
-                            renderLabel({ route, focused: false })
+                            renderLabel({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <AnimatedText
                               style={[
@@ -684,7 +725,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                                 },
                               ]}
                             >
-                              {route.title}
+                              {getLabelText({ route })}
                             </AnimatedText>
                           )}
                         </Animated.View>

diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;

diff --git a/.gitignore b/.gitignore
index 2e99ad3..eef9203 100644
--- a/.gitignore
+++ b/.gitignore
@@ -95,3 +95,4 @@ docs/backends/support_matrix.csv
 __pycache__
 tags
 .DS_Store
+prof/
diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index ac19aaf..36aed0e 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -602,3 +602,93 @@ def test_multiple_joins(benchmark, num_joins, num_columns):
         name=""t"",
     )
     benchmark(multiple_joins, table, num_joins)
+
+
+@pytest.fixture
+def customers():
+    return ibis.table(
+        dict(
+            customerid=""int32"",
+            name=""string"",
+            address=""string"",
+            citystatezip=""string"",
+            birthdate=""date"",
+            phone=""string"",
+            timezone=""string"",
+            lat=""float64"",
+            long=""float64"",
+        ),
+        name=""customers"",
+    )
+
+
+@pytest.fixture
+def orders():
+    return ibis.table(
+        dict(
+            orderid=""int32"",
+            customerid=""int32"",
+            ordered=""timestamp"",
+            shipped=""timestamp"",
+            items=""string"",
+            total=""float64"",
+        ),
+        name=""orders"",
+    )
+
+
+@pytest.fixture
+def orders_items():
+    return ibis.table(
+        dict(orderid=""int32"", sku=""string"", qty=""int32"", unit_price=""float64""),
+        name=""orders_items"",
+    )
+
+
+@pytest.fixture
+def products():
+    return ibis.table(
+        dict(
+            sku=""string"",
+            desc=""string"",
+            weight_kg=""float64"",
+            cost=""float64"",
+            dims_cm=""string"",
+        ),
+        name=""products"",
+    )
+
+
+@pytest.mark.benchmark(group=""compilation"")
+@pytest.mark.parametrize(
+    ""module"",
+    [
+        pytest.param(
+            mod,
+            marks=pytest.mark.xfail(
+                condition=mod in _XFAIL_COMPILE_BACKENDS,
+                reason=f""{mod} backend doesn't support compiling UnboundTable"",
+            ),
+        )
+        for mod in _backends
+    ],
+)
+def test_compile_with_drops(
+    benchmark, module, customers, orders, orders_items, products
+):
+    expr = (
+        customers.join(orders, ""customerid"")
+        .join(orders_items, ""orderid"")
+        .join(products, ""sku"")
+        .drop(""customerid"", ""qty"", ""total"", ""items"")
+        .drop(""dims_cm"", ""cost"")
+        .mutate(o_date=lambda t: t.shipped.date())
+        .filter(lambda t: t.ordered == t.shipped)
+    )
+
+    try:
+        mod = getattr(ibis, module)
+    except (AttributeError, ImportError) as e:
+        pytest.skip(str(e))
+    else:
+        benchmark(mod.compile, expr)
",5,"[""74e9de5ec97dc013a52aa063dff0f40ac74c407b"", ""ded26d768ff432ad3bde3c0aa1e95ce50726100a"", ""9be725fa3906323d4bc9788f54eccf74109d632b"", ""a52a585d74894b3b4eeb8c784fa089ff95cddad0"", ""e9617f0854030e70365eb264bcb3b58078e79e9e""]","[""cicd"", ""feat"", ""fix"", ""docs"", ""test""]"
"add numberOfLines prop to DataTableTitle (#863)

Closes #848remove deprecated settings

Removes deprecated ZEEBE_HOST environment variable, and removes
unnecessary log level environment variable, since it's already the
default in the log filesetup jest and add m.ts testsadd comments for the Handlerinitialize threejs objects in defaultRef, to fix undefined type errors","diff --git a/src/components/DataTable/DataTableTitle.js b/src/components/DataTable/DataTableTitle.js
index bfcf07e..d764fd5 100644
--- a/src/components/DataTable/DataTableTitle.js
+++ b/src/components/DataTable/DataTableTitle.js
@@ -27,6 +27,10 @@ type Props = React.ElementConfig<typeof TouchableWithoutFeedback> & {|
    */
   sortDirection?: 'ascending' | 'descending',
   /**
+   * The number of lines to show.
+   */
+  numberOfLines?: number,
+  /**
    * Function to execute on press.
    */
   onPress?: () => mixed,
@@ -44,6 +48,10 @@ type State = {
 class DataTableTitle extends React.Component<Props, State> {
   static displayName = 'DataTable.Title';
 
+  static defaultProps = {
+    numberOfLines: 1,
+  };
+
   state = {
     spinAnim: new Animated.Value(
       this.props.sortDirection === 'ascending' ? 0 : 1
@@ -70,6 +78,7 @@ class DataTableTitle extends React.Component<Props, State> {
       sortDirection,
       theme,
       style,
+      numberOfLines,
       ...rest
     } = this.props;
 
@@ -99,7 +108,7 @@ class DataTableTitle extends React.Component<Props, State> {
               styles.cell,
               sortDirection ? styles.sorted : { color: textColor },
             ]}
-            numberOfLines={1}
+            numberOfLines={numberOfLines}
           >
             {children}
           </Text>

diff --git a/Dockerfile b/Dockerfile
index 6762a39..7f380cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -34,7 +34,6 @@ RUN wget -O - https://github.com/jvm-profiling-tools/async-profiler/releases/dow
 FROM ${APP_ENV} as app
 
 ENV ZB_HOME=/usr/local/zeebe \
-    ZEEBE_LOG_LEVEL=info \
     ZEEBE_BROKER_GATEWAY_NETWORK_HOST=0.0.0.0 \
     ZEEBE_STANDALONE_GATEWAY=false
 ENV PATH ""${ZB_HOME}/bin:${PATH}""
diff --git a/docker/utils/startup.sh b/docker/utils/startup.sh
index bc8d2fc..0fcde2b 100755
--- a/docker/utils/startup.sh
+++ b/docker/utils/startup.sh
@@ -1,17 +1,14 @@
 #!/bin/bash -xeu
 
-# legacy support
-# This environment variable was used to set the gatewway cluster host in standalone and embedded mode.
-# Now, there are two dedicated environment variables for the two different deployment scenarios.
-export ZEEBE_HOST=${ZEEBE_HOST:-$(hostname -i)}
-# Legacy support
+HOST=$(hostname -i)
 
 if [ ""$ZEEBE_STANDALONE_GATEWAY"" = ""true"" ]; then
-    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_GATEWAY_NETWORK_HOST=${ZEEBE_GATEWAY_NETWORK_HOST:-${HOST}}
+    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${HOST}}
 
     exec /usr/local/zeebe/bin/gateway
 else
-    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${HOST}}
     export ZEEBE_BROKER_GATEWAY_CLUSTER_HOST=${ZEEBE_BROKER_GATEWAY_CLUSTER_HOST:-${ZEEBE_BROKER_NETWORK_HOST}}
 
     exec /usr/local/zeebe/bin/broker

diff --git a/src/__test__/m.spec.ts b/src/__test__/m.spec.ts
index ff974a6..ba59baf 100644
--- a/src/__test__/m.spec.ts
+++ b/src/__test__/m.spec.ts
@@ -89,9 +89,9 @@ describe('.m', () => {
     );
   });
 
-  it('should attach ns to props', () => {
+  it('should attach ns to props with children with props', () => {
     const vnode = {
-      tag: 'div',
+      tag: 'svg',
       props: {},
       children: [
         'foo',
@@ -105,7 +105,7 @@ describe('.m', () => {
     };
     ns(vnode.tag, vnode.props, vnode.children);
     expect(vnode).toEqual({
-      tag: 'div',
+      tag: 'svg',
       props: { ns: 'http://www.w3.org/2000/svg' },
       children: [
         'foo',
@@ -119,4 +119,28 @@ describe('.m', () => {
       ],
     });
   });
+
+  it('should attach ns to props with children without props', () => {
+    const vnode = {
+      tag: 'svg',
+      props: {},
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    };
+    ns(vnode.tag, vnode.props, vnode.children);
+    expect(vnode).toEqual({
+      tag: 'svg',
+      props: { ns: 'http://www.w3.org/2000/svg' },
+      children: [
+        'foo',
+        {
+          tag: 'div',
+        },
+      ],
+    });
+  });
 });

diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }

diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number
",5,"[""f9a094918b62534614c47aa8a13f33aec751a1e0"", ""e4a11fd5c34942ba12737f1c8c084489428ee274"", ""229b53a632ea97d47c4be11f096bdd828fb415d8"", ""036a0ff49a7dade0e04c9c07071a1ff49133ee24"", ""2561f4ade46fc9d59f289f328cc77733a6443697""]","[""feat"", ""build"", ""test"", ""docs"", ""fix""]"
"remove deprecated settings

Removes deprecated ZEEBE_HOST environment variable, and removes
unnecessary log level environment variable, since it's already the
default in the log fileadded changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284add benchmark for known-slow table expressionallow disabling dynamic queuerun pyspark tests in parallel","diff --git a/Dockerfile b/Dockerfile
index 6762a39..7f380cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -34,7 +34,6 @@ RUN wget -O - https://github.com/jvm-profiling-tools/async-profiler/releases/dow
 FROM ${APP_ENV} as app
 
 ENV ZB_HOME=/usr/local/zeebe \
-    ZEEBE_LOG_LEVEL=info \
     ZEEBE_BROKER_GATEWAY_NETWORK_HOST=0.0.0.0 \
     ZEEBE_STANDALONE_GATEWAY=false
 ENV PATH ""${ZB_HOME}/bin:${PATH}""
diff --git a/docker/utils/startup.sh b/docker/utils/startup.sh
index bc8d2fc..0fcde2b 100755
--- a/docker/utils/startup.sh
+++ b/docker/utils/startup.sh
@@ -1,17 +1,14 @@
 #!/bin/bash -xeu
 
-# legacy support
-# This environment variable was used to set the gatewway cluster host in standalone and embedded mode.
-# Now, there are two dedicated environment variables for the two different deployment scenarios.
-export ZEEBE_HOST=${ZEEBE_HOST:-$(hostname -i)}
-# Legacy support
+HOST=$(hostname -i)
 
 if [ ""$ZEEBE_STANDALONE_GATEWAY"" = ""true"" ]; then
-    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_GATEWAY_NETWORK_HOST=${ZEEBE_GATEWAY_NETWORK_HOST:-${HOST}}
+    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${HOST}}
 
     exec /usr/local/zeebe/bin/gateway
 else
-    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${HOST}}
     export ZEEBE_BROKER_GATEWAY_CLUSTER_HOST=${ZEEBE_BROKER_GATEWAY_CLUSTER_HOST:-${ZEEBE_BROKER_NETWORK_HOST}}
 
     exec /usr/local/zeebe/bin/broker

diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/.gitignore b/.gitignore
index 2e99ad3..eef9203 100644
--- a/.gitignore
+++ b/.gitignore
@@ -95,3 +95,4 @@ docs/backends/support_matrix.csv
 __pycache__
 tags
 .DS_Store
+prof/
diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index ac19aaf..36aed0e 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -602,3 +602,93 @@ def test_multiple_joins(benchmark, num_joins, num_columns):
         name=""t"",
     )
     benchmark(multiple_joins, table, num_joins)
+
+
+@pytest.fixture
+def customers():
+    return ibis.table(
+        dict(
+            customerid=""int32"",
+            name=""string"",
+            address=""string"",
+            citystatezip=""string"",
+            birthdate=""date"",
+            phone=""string"",
+            timezone=""string"",
+            lat=""float64"",
+            long=""float64"",
+        ),
+        name=""customers"",
+    )
+
+
+@pytest.fixture
+def orders():
+    return ibis.table(
+        dict(
+            orderid=""int32"",
+            customerid=""int32"",
+            ordered=""timestamp"",
+            shipped=""timestamp"",
+            items=""string"",
+            total=""float64"",
+        ),
+        name=""orders"",
+    )
+
+
+@pytest.fixture
+def orders_items():
+    return ibis.table(
+        dict(orderid=""int32"", sku=""string"", qty=""int32"", unit_price=""float64""),
+        name=""orders_items"",
+    )
+
+
+@pytest.fixture
+def products():
+    return ibis.table(
+        dict(
+            sku=""string"",
+            desc=""string"",
+            weight_kg=""float64"",
+            cost=""float64"",
+            dims_cm=""string"",
+        ),
+        name=""products"",
+    )
+
+
+@pytest.mark.benchmark(group=""compilation"")
+@pytest.mark.parametrize(
+    ""module"",
+    [
+        pytest.param(
+            mod,
+            marks=pytest.mark.xfail(
+                condition=mod in _XFAIL_COMPILE_BACKENDS,
+                reason=f""{mod} backend doesn't support compiling UnboundTable"",
+            ),
+        )
+        for mod in _backends
+    ],
+)
+def test_compile_with_drops(
+    benchmark, module, customers, orders, orders_items, products
+):
+    expr = (
+        customers.join(orders, ""customerid"")
+        .join(orders_items, ""orderid"")
+        .join(products, ""sku"")
+        .drop(""customerid"", ""qty"", ""total"", ""items"")
+        .drop(""dims_cm"", ""cost"")
+        .mutate(o_date=lambda t: t.shipped.date())
+        .filter(lambda t: t.ordered == t.shipped)
+    )
+
+    try:
+        mod = getattr(ibis, module)
+    except (AttributeError, ImportError) as e:
+        pytest.skip(str(e))
+    else:
+        benchmark(mod.compile, expr)

diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index e23088e..9708157 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -202,11 +202,11 @@ jobs:
         run: poetry install --without dev --without docs --extras ${{ matrix.backend.name }} --extras geospatial
 
       - name: ""run parallel tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name != 'pyspark' && matrix.backend.name != 'impala'
+        if: matrix.backend.name != 'impala'
         run: just ci-check -m ${{ matrix.backend.name }} --numprocesses auto --dist=loadgroup
 
       - name: ""run serial tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name == 'pyspark' || matrix.backend.name == 'impala'
+        if: matrix.backend.name == 'impala'
         run: just ci-check -m ${{ matrix.backend.name }}
         env:
           IBIS_TEST_NN_HOST: localhost
",5,"[""e4a11fd5c34942ba12737f1c8c084489428ee274"", ""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""e9617f0854030e70365eb264bcb3b58078e79e9e"", ""9ef5c0d14193a9abb09b39856f58477d1f4b0d77"", ""4cbbd2552ba0de273e1dfe7d453c5b3efed751a3""]","[""build"", ""docs"", ""test"", ""fix"", ""cicd""]"
"add numberOfLines prop to DataTableTitle (#863)

Closes #848initialize threejs objects in defaultRef, to fix undefined type errorsdo not use scripts and binaries from the libcc repoadd comments for the Handlerensure checksum persist flushes to disk","diff --git a/src/components/DataTable/DataTableTitle.js b/src/components/DataTable/DataTableTitle.js
index bfcf07e..d764fd5 100644
--- a/src/components/DataTable/DataTableTitle.js
+++ b/src/components/DataTable/DataTableTitle.js
@@ -27,6 +27,10 @@ type Props = React.ElementConfig<typeof TouchableWithoutFeedback> & {|
    */
   sortDirection?: 'ascending' | 'descending',
   /**
+   * The number of lines to show.
+   */
+  numberOfLines?: number,
+  /**
    * Function to execute on press.
    */
   onPress?: () => mixed,
@@ -44,6 +48,10 @@ type State = {
 class DataTableTitle extends React.Component<Props, State> {
   static displayName = 'DataTable.Title';
 
+  static defaultProps = {
+    numberOfLines: 1,
+  };
+
   state = {
     spinAnim: new Animated.Value(
       this.props.sortDirection === 'ascending' ? 0 : 1
@@ -70,6 +78,7 @@ class DataTableTitle extends React.Component<Props, State> {
       sortDirection,
       theme,
       style,
+      numberOfLines,
       ...rest
     } = this.props;
 
@@ -99,7 +108,7 @@ class DataTableTitle extends React.Component<Props, State> {
               styles.cell,
               sortDirection ? styles.sorted : { color: textColor },
             ]}
-            numberOfLines={1}
+            numberOfLines={numberOfLines}
           >
             {children}
           </Text>

diff --git a/src/canvas.tsx b/src/canvas.tsx
index a4ebdef..0242035 100644
--- a/src/canvas.tsx
+++ b/src/canvas.tsx
@@ -18,14 +18,14 @@ export type CanvasContext = {
   setManual: (takeOverRenderloop: boolean) => any
   setDefaultCamera: (camera: THREE.Camera) => any
   invalidate: () => any
+  gl: THREE.WebGLRenderer
+  camera: THREE.Camera
+  raycaster: THREE.Raycaster
+  mouse: THREE.Vector2
+  scene: THREE.Scene
   canvas?: React.MutableRefObject<any>
-  gl?: THREE.WebGLRenderer
-  camera?: THREE.Camera
-  raycaster?: THREE.Raycaster
-  mouse?: THREE.Vector2
-  scene?: THREE.Scene
-  size?: { left: number; top: number; width: number; height: number }
   canvasRect?: DOMRectReadOnly
+  size?: { left: number; top: number; width: number; height: number }
   viewport?: { width: number; height: number }
 }
 
@@ -69,14 +69,14 @@ const defaultRef: CanvasContext = {
   setManual: () => {},
   setDefaultCamera: () => {},
   invalidate: () => {},
+  gl: new THREE.WebGLRenderer(),
+  camera: new THREE.Camera(),
+  raycaster: new THREE.Raycaster(),
+  mouse: new THREE.Vector2(),
+  scene: new THREE.Scene(),
   canvas: undefined,
-  gl: undefined,
-  camera: undefined,
-  raycaster: undefined,
-  mouse: undefined,
-  scene: undefined,
-  size: undefined,
   canvasRect: undefined,
+  size: undefined,
   viewport: undefined,
 }
 
diff --git a/types/index.d.ts b/types/index.d.ts
index 1b130ce..2cb2954 100644
--- a/types/index.d.ts
+++ b/types/index.d.ts
@@ -25,19 +25,19 @@ declare module 'canvas' {
     setManual: (takeOverRenderloop: boolean) => any
     setDefaultCamera: (camera: THREE.Camera) => any
     invalidate: () => any
+    gl: THREE.WebGLRenderer
+    camera: THREE.Camera
+    raycaster: THREE.Raycaster
+    mouse: THREE.Vector2
+    scene: THREE.Scene
     canvas?: React.MutableRefObject<any>
-    gl?: THREE.WebGLRenderer
-    camera?: THREE.Camera
-    raycaster?: THREE.Raycaster
-    mouse?: THREE.Vector2
-    scene?: THREE.Scene
+    canvasRect?: DOMRectReadOnly
     size?: {
       left: number
       top: number
       width: number
       height: number
     }
-    canvasRect?: DOMRectReadOnly
     viewport?: {
       width: number
       height: number

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }

diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);
",5,"[""f9a094918b62534614c47aa8a13f33aec751a1e0"", ""2561f4ade46fc9d59f289f328cc77733a6443697"", ""45837af24a33308a70a3454f0f650f9fe728e272"", ""036a0ff49a7dade0e04c9c07071a1ff49133ee24"", ""b7ce2894fd1794064bd6db4ed730bb6cb7728739""]","[""feat"", ""fix"", ""cicd"", ""docs"", ""test""]"
"add props to get color and label from a routeget tenant authorizations in job state

Get the authorized tenants list in the job state to
avoid code duplication in the various job processors.

This also allows us to be more flexible in the future
if we expand the authorizations and how they are used
for getting jobs.docker PG version upgrade

Signed-off-by: Raju Udava <86527202+dstala@users.noreply.github.com>update flushed index before truncatingadd comments for the Handler","diff --git a/src/components/BottomNavigation.js b/src/components/BottomNavigation.js
index 1b72302..7d8ea75 100644
--- a/src/components/BottomNavigation.js
+++ b/src/components/BottomNavigation.js
@@ -24,8 +24,8 @@ const AnimatedPaper = Animated.createAnimatedComponent(Paper);
 
 type Route = {
   key: string,
-  title: string,
-  icon: IconSource,
+  title?: string,
+  icon?: IconSource,
   color?: string,
 };
 
@@ -51,7 +51,7 @@ type Props<T> = {
    * - `key`: a unique key to identify the route
    * - `title`: title of the route to use as the tab label
    * - `icon`: icon to use as the tab icon, can be a string, an image source or a react component
-   * - `color`: color to use as background color for shifting bottom navigation (optional)
+   * - `color`: color to use as background color for shifting bottom navigation
    *
    * Example:
    *
@@ -115,11 +115,27 @@ type Props<T> = {
   /**
    * Callback which returns a React Element to be used as tab icon.
    */
-  renderIcon?: (props: { route: T, focused: boolean }) => React.Node,
+  renderIcon?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
   /**
    * Callback which React Element to be used as tab label.
    */
-  renderLabel?: (props: { route: T, focused: boolean }) => React.Node,
+  renderLabel?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
+  /**
+   * Get label text for the tab, uses `route.title` by default. Use `renderLabel` to replace label component.
+   */
+  getLabelText?: (props: { route: T }) => string,
+  /**
+   * Get color for the tab, uses `route.color` by default.
+   */
+  getColor?: (props: { route: T }) => string,
   /**
    * Function to execute on tab press. It receives the route for the pressed tab, useful for things like scroll to top.
    */
@@ -159,6 +175,10 @@ type State = {
    */
   ripple: Animated.Value,
   /**
+   * Animation for the touch feedback, used to determine it's scale and opacity.
+   */
+  touch: Animated.Value,
+  /**
    * Layout of the tab bar. The width is used to determine the size and position of the ripple.
    */
   layout: { height: number, width: number, measured: boolean },
@@ -173,7 +193,7 @@ const MIN_SHIFT_AMOUNT = 10;
 const MIN_TAB_WIDTH = 96;
 const MAX_TAB_WIDTH = 168;
 const BAR_HEIGHT = 56;
-const SMALL_RIPPLE_SIZE = 72;
+const SMALL_RIPPLE_SIZE = 96;
 const ACTIVE_LABEL_SIZE = 14;
 const INACTIVE_LABEL_SIZE = 12;
 
@@ -251,6 +271,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ),
       index: new Animated.Value(index),
       ripple: new Animated.Value(MIN_RIPPLE_SCALE),
+      touch: new Animated.Value(MIN_RIPPLE_SCALE),
       layout: { height: 0, width: 0, measured: false },
       previous: 0,
     };
@@ -349,6 +370,15 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
   _handleTabPress = (index: number) => {
     const { navigationState } = this.props;
 
+    this.state.touch.setValue(MIN_RIPPLE_SCALE);
+
+    Animated.timing(this.state.touch, {
+      toValue: 1,
+      duration: 300,
+      easing: Easing.in(Easing.sin),
+      useNativeDriver: true,
+    }).start();
+
     if (index !== navigationState.index) {
       this.props.onIndexChange(index);
     }
@@ -376,6 +406,8 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       renderScene,
       renderIcon,
       renderLabel,
+      getLabelText = ({ route }) => route.title,
+      getColor = ({ route }) => route.color,
       barStyle,
       style,
       theme,
@@ -400,7 +432,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ? this.state.index.interpolate({
           inputRange: routes.map((_, i) => i),
           outputRange: routes.map(
-            route => route.color || approxBackgroundColor
+            route => getColor({ route }) || approxBackgroundColor
           ),
         })
       : approxBackgroundColor;
@@ -416,7 +448,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
           .rgb()
           .string();
 
-    const rippleColor = color(textColor)
+    const touchColor = color(textColor)
       .alpha(0.12)
       .rgb()
       .string();
@@ -430,22 +462,10 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
 
     // Since we have a single ripple, we have to reposition it so that it appears to expand from active tab.
     // We need to move it from the left to the active tab and also account for how much that tab has shifted.
-    const rippleShift =
-      navigationState.index * tabWidth +
-      tabWidth / 2 +
-      this._calculateShift(
-        this.state.previous,
-        navigationState.index,
-        routes.length
-      );
 
     return (
       <View
-        style={[
-          styles.container,
-          { backgroundColor: theme.dark ? white : black },
-          style,
-        ]}
+        style={[styles.container, style]}
         onLayout={this._handleLayout}
         pointerEvents={layout.measured ? 'auto' : 'none'}
       >
@@ -485,25 +505,30 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
             style={[styles.items, { maxWidth: maxTabWidth * routes.length }]}
           >
             {shifting ? (
-              // Large ripple with the backround color
               <Animated.View
                 pointerEvents=""none""
                 style={[
                   styles.ripple,
                   {
                     // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - layout.width / 2,
-                    left: rippleShift - layout.width / 2,
-                    height: layout.width,
-                    width: layout.width,
+                    top: BAR_HEIGHT / 2 - layout.width / 8,
+                    left:
+                      navigationState.index * tabWidth +
+                      tabWidth / 2 -
+                      layout.width / 8,
+                    height: layout.width / 4,
+                    width: layout.width / 4,
                     borderRadius: layout.width / 2,
-                    backgroundColor: routes[navigationState.index].color,
+                    backgroundColor: getColor({
+                      route: routes[navigationState.index],
+                    }),
                     transform: [
+                      { translateX: this.state.shifts[navigationState.index] },
                       {
                         // Scale to twice the size  to ensure it covers the whole tab bar
                         scale: this.state.ripple.interpolate({
                           inputRange: [0, 1],
-                          outputRange: [0, 2],
+                          outputRange: [0, 8],
                         }),
                       },
                     ],
@@ -515,36 +540,36 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                 ]}
               />
             ) : null}
-            {shifting ? (
-              // Small subtle ripple on touch
-              <Animated.View
-                pointerEvents=""none""
-                style={[
-                  styles.ripple,
-                  {
-                    // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
-                    left: rippleShift - SMALL_RIPPLE_SIZE / 2,
-                    height: SMALL_RIPPLE_SIZE,
-                    width: SMALL_RIPPLE_SIZE,
-                    borderRadius: SMALL_RIPPLE_SIZE / 2,
-                    backgroundColor: rippleColor,
-                    transform: [
-                      {
-                        scale: this.state.ripple.interpolate({
-                          inputRange: [0, 0.5, 1],
-                          outputRange: [0, 1, 1],
-                        }),
-                      },
-                    ],
-                    opacity: this.state.ripple.interpolate({
-                      inputRange: [0, MIN_RIPPLE_SCALE, 0.25, 0.5],
-                      outputRange: [0, 0, 1, 0],
-                    }),
-                  },
-                ]}
-              />
-            ) : null}
+            <Animated.View
+              pointerEvents=""none""
+              style={[
+                styles.ripple,
+                {
+                  // Set top and left values so that the ripple's center is same as the tab's center
+                  top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
+                  left:
+                    navigationState.index * tabWidth +
+                    tabWidth / 2 -
+                    SMALL_RIPPLE_SIZE / 2,
+                  height: SMALL_RIPPLE_SIZE,
+                  width: SMALL_RIPPLE_SIZE,
+                  borderRadius: SMALL_RIPPLE_SIZE / 2,
+                  backgroundColor: touchColor,
+                  transform: [
+                    {
+                      translateX: shifting
+                        ? this.state.shifts[navigationState.index]
+                        : 0,
+                    },
+                    { scale: this.state.touch },
+                  ],
+                  opacity: this.state.touch.interpolate({
+                    inputRange: [0, 0.5, 1],
+                    outputRange: [0, 1, 0],
+                  }),
+                },
+              ]}
+            />
             {routes.map((route, index) => {
               const shift = this.state.shifts[index];
               const focused = this.state.tabs[index];
@@ -607,7 +632,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderIcon ? (
-                          renderIcon({ route, focused: true })
+                          renderIcon({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <Icon
                             style={styles.icon}
@@ -625,7 +654,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderIcon ? (
-                            renderIcon({ route, focused: false })
+                            renderIcon({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <Icon
                               style={styles.icon}
@@ -652,7 +685,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderLabel ? (
-                          renderLabel({ route, focused: true })
+                          renderLabel({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <AnimatedText
                             style={[
@@ -662,7 +699,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                               },
                             ]}
                           >
-                            {route.title}
+                            {getLabelText({ route })}
                           </AnimatedText>
                         )}
                       </Animated.View>
@@ -674,7 +711,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderLabel ? (
-                            renderLabel({ route, focused: false })
+                            renderLabel({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <AnimatedText
                               style={[
@@ -684,7 +725,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                                 },
                               ]}
                             >
-                              {route.title}
+                              {getLabelText({ route })}
                             </AnimatedText>
                           )}
                         </Animated.View>

diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
index f47f830..68de52f 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobCompleteProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.common.EventHandle;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
@@ -23,7 +22,6 @@ import io.camunda.zeebe.protocol.record.intent.Intent;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.protocol.record.intent.ProcessInstanceIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
@@ -81,9 +79,7 @@ public final class JobCompleteProcessor implements CommandProcessor<JobRecord> {
 
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
index fbb6f77..bc1a46d 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobFailProcessor.java
@@ -11,7 +11,6 @@ import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESS
 import static io.camunda.zeebe.util.StringUtil.limitString;
 import static io.camunda.zeebe.util.buffer.BufferUtil.wrapString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnBehaviors;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnJobActivationBehavior;
@@ -98,10 +97,7 @@ public final class JobFailProcessor implements TypedRecordProcessor<JobRecord> {
     final var retries = failJobCommandRecord.getRetries();
     final var retryBackOff = failJobCommandRecord.getRetryBackoff();
 
-    final List<String> authorizedTenants =
-        (List<String>) record.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord failedJob = jobState.getJob(jobKey, authorizedTenants);
-
+    final JobRecord failedJob = jobState.getJob(jobKey, record.getAuthorizations());
     if (failedJob == null) {
       final String errorMessage = String.format(NO_JOB_FOUND_MESSAGE, jobKey);
       rejectionWriter.appendRejection(record, RejectionType.NOT_FOUND, errorMessage);
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
index 195113d..07fecf5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobThrowErrorProcessor.java
@@ -10,7 +10,6 @@ package io.camunda.zeebe.engine.processing.job;
 import static io.camunda.zeebe.engine.EngineConfiguration.DEFAULT_MAX_ERROR_MESSAGE_SIZE;
 import static io.camunda.zeebe.util.StringUtil.limitString;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.metrics.JobMetrics;
 import io.camunda.zeebe.engine.processing.bpmn.behavior.BpmnEventPublicationBehavior;
 import io.camunda.zeebe.engine.processing.common.Failure;
@@ -34,7 +33,6 @@ import io.camunda.zeebe.protocol.record.value.ErrorType;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
 import io.camunda.zeebe.stream.api.state.KeyGenerator;
 import io.camunda.zeebe.util.Either;
-import java.util.List;
 import java.util.Optional;
 
 public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
@@ -108,9 +106,7 @@ public class JobThrowErrorProcessor implements CommandProcessor<JobRecord> {
       final TypedRecord<JobRecord> command, final CommandControl<JobRecord> commandControl) {
     final long jobKey = command.getKey();
 
-    final List<String> authorizedTenants =
-        (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-    final JobRecord job = jobState.getJob(jobKey, authorizedTenants);
+    final JobRecord job = jobState.getJob(jobKey, command.getAuthorizations());
     if (job == null) {
       commandControl.reject(RejectionType.NOT_FOUND, String.format(NO_JOB_FOUND_MESSAGE, jobKey));
       return;
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
index 49ef2b3..5cdcb97 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/processing/job/JobUpdateRetriesProcessor.java
@@ -7,7 +7,6 @@
  */
 package io.camunda.zeebe.engine.processing.job;
 
-import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.engine.processing.streamprocessor.CommandProcessor;
 import io.camunda.zeebe.engine.state.immutable.JobState;
 import io.camunda.zeebe.engine.state.immutable.ProcessingState;
@@ -15,7 +14,6 @@ import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.protocol.record.RejectionType;
 import io.camunda.zeebe.protocol.record.intent.JobIntent;
 import io.camunda.zeebe.stream.api.records.TypedRecord;
-import java.util.List;
 
 public final class JobUpdateRetriesProcessor implements CommandProcessor<JobRecord> {
 
@@ -38,9 +36,7 @@ public final class JobUpdateRetriesProcessor implements CommandProcessor<JobReco
     final int retries = command.getValue().getRetries();
 
     if (retries > 0) {
-      final List<String> authorizedTenants =
-          (List<String>) command.getAuthorizations().get(Authorization.AUTHORIZED_TENANTS);
-      final JobRecord job = jobState.getJob(key, authorizedTenants);
+      final JobRecord job = jobState.getJob(key, command.getAuthorizations());
 
       if (job != null) {
         // update retries for response sent to client
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
index fbc3312..b0e87b5 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/immutable/JobState.java
@@ -9,6 +9,7 @@ package io.camunda.zeebe.engine.state.immutable;
 
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -30,7 +31,7 @@ public interface JobState {
 
   JobRecord getJob(long key);
 
-  JobRecord getJob(final long key, final List<String> authorizedTenantIds);
+  JobRecord getJob(final long key, final Map<String, Object> authorizations);
 
   long findBackedOffJobs(final long timestamp, final BiPredicate<Long, JobRecord> callback);
 
diff --git a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
index 0791516..0a207f0 100644
--- a/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
+++ b/engine/src/main/java/io/camunda/zeebe/engine/state/instance/DbJobState.java
@@ -7,6 +7,7 @@
  */
 package io.camunda.zeebe.engine.state.instance;
 
+import io.camunda.zeebe.auth.impl.Authorization;
 import io.camunda.zeebe.db.ColumnFamily;
 import io.camunda.zeebe.db.TransactionContext;
 import io.camunda.zeebe.db.ZeebeDb;
@@ -24,6 +25,7 @@ import io.camunda.zeebe.protocol.ZbColumnFamilies;
 import io.camunda.zeebe.protocol.impl.record.value.job.JobRecord;
 import io.camunda.zeebe.util.EnsureUtil;
 import java.util.List;
+import java.util.Map;
 import java.util.function.BiFunction;
 import java.util.function.BiPredicate;
 import org.agrona.DirectBuffer;
@@ -348,9 +350,9 @@ public final class DbJobState implements JobState, MutableJobState {
   }
 
   @Override
-  public JobRecord getJob(final long key, final List<String> authorizedTenantIds) {
+  public JobRecord getJob(final long key, final Map<String, Object> authorizations) {
     final JobRecord jobRecord = getJob(key);
-    if (authorizedTenantIds.contains(jobRecord.getTenantId())) {
+    if (getAuthorizedTenantIds(authorizations).contains(jobRecord.getTenantId())) {
       return jobRecord;
     }
     return null;
@@ -461,4 +463,8 @@ public final class DbJobState implements JobState, MutableJobState {
       backoffColumnFamily.deleteIfExists(backoffJobKey);
     }
   }
+
+  private List<String> getAuthorizedTenantIds(final Map<String, Object> authorizations) {
+    return (List<String>) authorizations.get(Authorization.AUTHORIZED_TENANTS);
+  }
 }

diff --git a/packages/nocodb/docker-compose.yml b/packages/nocodb/docker-compose.yml
index 7fabf79..ba2ab7b 100644
--- a/packages/nocodb/docker-compose.yml
+++ b/packages/nocodb/docker-compose.yml
@@ -1,4 +1,4 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
     # db55:
@@ -96,8 +96,8 @@ services:
     #     - 5495:5432
     #   volumes:
     #     - ./pg-sakila-db:/docker-entrypoint-initdb.d
-    pg96:
-     image: postgres:9.6
+    pg147:
+     image: postgres:14.7
      restart: always
      environment:
        POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
index 19dfab2..97d346b 100644
--- a/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
+++ b/tests/playwright/scripts/docker-compose-pg-pw-quick.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password
diff --git a/tests/playwright/scripts/docker-compose-pg.yml b/tests/playwright/scripts/docker-compose-pg.yml
index 0396579..9fab10e 100644
--- a/tests/playwright/scripts/docker-compose-pg.yml
+++ b/tests/playwright/scripts/docker-compose-pg.yml
@@ -1,8 +1,8 @@
-version: ""2.1""
+version: ""2.2""
 
 services:
-    pg96:
-        image: postgres:9.6
+    pg147:
+        image: postgres:14.7
         restart: always
         environment:
             POSTGRES_PASSWORD: password

diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }
",5,"[""ded26d768ff432ad3bde3c0aa1e95ce50726100a"", ""062daa45cbd5dba6e96e95d8cdcaee89ae30a83c"", ""37b1cbfd3d2c462ef4f2a131e4172c38dc8d9ddf"", ""933ab6bb86372913c992567cf9660009900911a7"", ""036a0ff49a7dade0e04c9c07071a1ff49133ee24""]","[""feat"", ""refactor"", ""build"", ""fix"", ""docs""]"
"Adjust test scenario

With the new version of the FEEL engine, a non-existing variable results in `null`. Previously, the evaluation failed
with an error.

To keep the semantics of the test cases, create the incident by failing the job.[gn] fix include_dirs ordering errorterminated tasks linger for a bit

Signed-off-by: Eliza Weisman <eliza@buoyant.io>fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.licensing","diff --git a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
index c0a3472..6a9389b 100644
--- a/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
+++ b/engine/src/test/java/io/camunda/zeebe/engine/state/ProcessExecutionCleanStateTest.java
@@ -759,7 +759,7 @@ public final class ProcessExecutionCleanStateTest {
         .withXmlResource(
             Bpmn.createExecutableProcess(PROCESS_ID)
                 .startEvent()
-                .serviceTask(""task"", t -> t.zeebeJobType(""test"").zeebeOutputExpression(""x"", ""y""))
+                .serviceTask(""task"", t -> t.zeebeJobType(""test""))
                 .endEvent()
                 .done())
         .deploy();
@@ -768,7 +768,7 @@ public final class ProcessExecutionCleanStateTest {
     final var processInstanceKey =
         engineRule.processInstance().ofBpmnProcessId(PROCESS_ID).create();
 
-    engineRule.job().ofInstance(processInstanceKey).withType(""test"").complete();
+    engineRule.job().ofInstance(processInstanceKey).withType(""test"").withRetries(0).fail();
 
     RecordingExporter.incidentRecords(IncidentIntent.CREATED)
         .withProcessInstanceKey(processInstanceKey)

diff --git a/BUILD.gn b/BUILD.gn
index 11adaa7..ed64b17 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -240,6 +240,14 @@ static_library(""electron_lib"") {
     ""brightray"",
     ""build/node"",
   ]
+  include_dirs = [
+    ""chromium_src"",
+    ""."",
+    ""$target_gen_dir"",
+    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
+    # API of blink, then delete this include dir.
+    ""//third_party/WebKit/Source"",
+  ]
   if (enable_desktop_capturer) {
     deps += [ ""//third_party/webrtc/modules/desktop_capture"" ]
   }
@@ -275,14 +283,6 @@ static_library(""electron_lib"") {
     # Disable warnings for g_settings_list_schemas.
     ""GLIB_DISABLE_DEPRECATION_WARNINGS"",
   ]
-  include_dirs = [
-    ""chromium_src"",
-    ""."",
-    ""$target_gen_dir"",
-    # TODO(nornagon): replace usage of SchemeRegistry by an actually exported
-    # API of blink, then delete this include dir.
-    ""//third_party/WebKit/Source"",
-  ]
   if (is_component_build) {
     defines += [
       # Import V8 symbols from shared library (node.dll / libnode.so)

diff --git a/console/src/main.rs b/console/src/main.rs
index ebfa315..5328d96 100644
--- a/console/src/main.rs
+++ b/console/src/main.rs
@@ -69,6 +69,7 @@ async fn main() -> Result<(), Box<dyn std::error::Error>> {
                 .wrap(Wrap { trim: true });
             f.render_widget(header, chunks[0]);
             tasks.render(f, chunks[1]);
+            tasks.retain_active();
         })?;
     }
 
diff --git a/console/src/tasks.rs b/console/src/tasks.rs
index 7be39a4..eb41495 100644
--- a/console/src/tasks.rs
+++ b/console/src/tasks.rs
@@ -19,6 +19,7 @@ struct Task {
     fields: String,
     kind: &'static str,
     stats: Stats,
+    completed_for: usize,
 }
 
 #[derive(Default, Debug)]
@@ -28,10 +29,15 @@ struct Stats {
     idle: Duration,
     total: Duration,
 }
+
 impl State {
+    // How many updates to retain completed tasks for
+    const RETAIN_COMPLETED_FOR: usize = 6;
+
     pub(crate) fn len(&self) -> usize {
         self.tasks.len()
     }
+
     pub(crate) fn update(&mut self, update: proto::tasks::TaskUpdate) {
         let new_tasks = update.new_tasks.into_iter().filter_map(|task| {
             if task.id.is_none() {
@@ -48,6 +54,7 @@ impl State {
                 fields: task.string_fields,
                 kind,
                 stats: Default::default(),
+                completed_for: 0,
             };
             Some((id, task))
         });
@@ -60,7 +67,10 @@ impl State {
         }
 
         for proto::SpanId { id } in update.completed {
-            if self.tasks.remove(&id).is_none() {
+            if let Some(task) = self.tasks.get_mut(&id) {
+                task.kind = ""!"";
+                task.completed_for = 1;
+            } else {
                 tracing::warn!(?id, ""tried to complete a task that didn't exist"");
             }
         }
@@ -79,7 +89,7 @@ impl State {
         const DUR_PRECISION: usize = 4;
         const POLLS_LEN: usize = 5;
         let rows = self.tasks.values().map(|task| {
-            let row = Row::new(vec![
+            let mut row = Row::new(vec![
                 Cell::from(task.id_hex.as_str()),
                 // TODO(eliza): is there a way to write a `fmt::Debug` impl
                 // directly to tui without doing an allocation?
@@ -105,6 +115,9 @@ impl State {
                 Cell::from(format!(""{:>width$}"", task.stats.polls, width = POLLS_LEN)),
                 Cell::from(task.fields.as_str()),
             ]);
+            if task.completed_for > 0 {
+                row = row.style(Style::default().add_modifier(style::Modifier::DIM));
+            }
             row
         });
         let t = Table::new(rows)
@@ -126,6 +139,16 @@ impl State {
 
         frame.render_widget(t, area)
     }
+
+    pub(crate) fn retain_active(&mut self) {
+        self.tasks.retain(|_, task| {
+            if task.completed_for == 0 {
+                return true;
+            }
+            task.completed_for += 1;
+            task.completed_for <= Self::RETAIN_COMPLETED_FOR
+        })
+    }
 }
 
 impl From<proto::tasks::Stats> for Stats {

diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;
",5,"[""f411e58cd510f8a2b980b2f1932003a0c0e9f8f3"", ""c44cf88a6ec54e5ddd99d8348bcc57b301ec7945"", ""1bcf88670b50155b50071e707f98f30cea0b7a24"", ""9be725fa3906323d4bc9788f54eccf74109d632b"", ""a52a585d74894b3b4eeb8c784fa089ff95cddad0""]","[""test"", ""build"", ""feat"", ""fix"", ""docs""]"
"update flushed index before truncatingbuffer assert and bpmn model api helper class

related to camunda-tngp/camunda-tngp#23skip flaky testadd remote [skip ci]add comments for the Handler","diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/test-util/pom.xml b/test-util/pom.xml
index a097651..b6518ee 100644
--- a/test-util/pom.xml
+++ b/test-util/pom.xml
@@ -20,6 +20,7 @@
     <project.build.sourceEncoding>utf-8</project.build.sourceEncoding>
     <!-- TODO: Move to common parent -->
     <agrona.version>0.4.11</agrona.version>
+    <camunda.version>7.6.0-SNAPSHOT</camunda.version>
   </properties>
 
   <dependencies>
@@ -30,6 +31,13 @@
       <version>${agrona.version}</version>
       <scope>provided</scope>
     </dependency>
+    
+    <dependency>
+      <groupId>org.camunda.bpm.model</groupId>
+      <artifactId>camunda-bpmn-model</artifactId>
+      <version>${camunda.version}</version>
+      <scope>provided</scope>
+    </dependency>
 
     <dependency>
       <groupId>junit</groupId>
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
index 37e3a6f..b8d9b26 100644
--- a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
@@ -14,7 +14,7 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         super(actual, BufferAssert.class);
     }
 
-    public static BufferAssert assertThat(DirectBuffer buffer)
+    public static BufferAssert assertThatBuffer(DirectBuffer buffer)
     {
         return new BufferAssert(buffer);
     }
@@ -41,4 +41,16 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         return hasBytes(expected, 0);
     }
 
+    public BufferAssert hasCapacity(int expectedCapacity)
+    {
+        isNotNull();
+
+        if (expectedCapacity != actual.capacity())
+        {
+            failWithMessage(""Expected capacity "" + expectedCapacity + "" but was "" + actual.capacity());
+        }
+
+        return this;
+    }
+
 }
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
new file mode 100644
index 0000000..6f0d134
--- /dev/null
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
@@ -0,0 +1,121 @@
+package org.camunda.tngp.broker.test.util.bpmn;
+
+import java.util.Collection;
+
+import org.camunda.bpm.model.bpmn.BpmnModelInstance;
+import org.camunda.bpm.model.bpmn.impl.BpmnModelConstants;
+import org.camunda.bpm.model.bpmn.instance.Definitions;
+import org.camunda.bpm.model.xml.Model;
+import org.camunda.bpm.model.xml.instance.DomDocument;
+import org.camunda.bpm.model.xml.instance.ModelElementInstance;
+import org.camunda.bpm.model.xml.type.ModelElementType;
+import org.camunda.bpm.model.xml.validation.ModelElementValidator;
+import org.camunda.bpm.model.xml.validation.ValidationResults;
+
+public class TngpModelInstance implements BpmnModelInstance
+{
+    protected BpmnModelInstance wrappedInstance;
+
+    public TngpModelInstance(BpmnModelInstance wrappedInstance)
+    {
+        this.wrappedInstance = wrappedInstance;
+    }
+
+    @Override
+    public DomDocument getDocument()
+    {
+        return wrappedInstance.getDocument();
+    }
+
+    @Override
+    public ModelElementInstance getDocumentElement()
+    {
+        return wrappedInstance.getDocumentElement();
+    }
+
+    @Override
+    public void setDocumentElement(ModelElementInstance documentElement)
+    {
+        wrappedInstance.setDocumentElement(documentElement);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(Class<T> type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(ModelElementType type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public Model getModel()
+    {
+        return wrappedInstance.getModel();
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T getModelElementById(String id)
+    {
+        return wrappedInstance.getModelElementById(id);
+    }
+
+    @Override
+    public Collection<ModelElementInstance> getModelElementsByType(ModelElementType referencingType)
+    {
+        return wrappedInstance.getModelElementsByType(referencingType);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> Collection<T> getModelElementsByType(Class<T> referencingClass)
+    {
+        return wrappedInstance.getModelElementsByType(referencingClass);
+    }
+
+    @Override
+    public ValidationResults validate(Collection<ModelElementValidator<?>> validators)
+    {
+        return wrappedInstance.validate(validators);
+    }
+
+    @Override
+    public BpmnModelInstance clone()
+    {
+        return wrappedInstance.clone();
+    }
+
+    @Override
+    public Definitions getDefinitions()
+    {
+        return wrappedInstance.getDefinitions();
+    }
+
+    @Override
+    public void setDefinitions(Definitions arg0)
+    {
+        wrappedInstance.setDefinitions(arg0);
+    }
+
+    public TngpModelInstance taskAttributes(String taskId, String taskType, int taskQueueId)
+    {
+        final ModelElementInstance task = wrappedInstance.getModelElementById(taskId);
+
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskType"", taskType);
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskQueueId"", String.valueOf(taskQueueId));
+
+        return this;
+    }
+
+    public static TngpModelInstance wrap(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance);
+    }
+
+    public static TngpModelInstance wrapCopy(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance.clone());
+    }
+}

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method

diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 06c9003..e19c703 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -47,7 +47,10 @@ jobs:
           git config --global user.email 'ibis-squawk-bot[bot]@users.noreply.github.com'
 
       - name: fetch and rebase on top of upstream
-        run: git pull --rebase -X ours https://github.com/ibis-project/ibis master
+        run: |
+          git remote add upstream https://github.com/ibis-project/ibis
+          git fetch upstream
+          git rebase -X ours upstream/master
 
       - uses: tibdex/github-app-token@v1
         id: generate_pr_token

diff --git a/packages/core/src/nodes.rs b/packages/core/src/nodes.rs
index 93d4c8b..80de929 100644
--- a/packages/core/src/nodes.rs
+++ b/packages/core/src/nodes.rs
@@ -357,12 +357,14 @@ pub struct EventHandler<'bump, T = ()> {
 }
 
 impl<T> EventHandler<'_, T> {
+    /// Call this event handler with the appropriate event type
     pub fn call(&self, event: T) {
         if let Some(callback) = self.callback.borrow_mut().as_mut() {
             callback(event);
         }
     }
 
+    /// Forcibly drop the internal handler callback, releasing memory
     pub fn release(&self) {
         self.callback.replace(None);
     }
",5,"[""933ab6bb86372913c992567cf9660009900911a7"", ""6ed56ce9ae743ba9a87e6c9643cc06b1de7b748d"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d"", ""e96487ad7ce90b141219d9032fa2bed68d5dae6a"", ""036a0ff49a7dade0e04c9c07071a1ff49133ee24""]","[""fix"", ""feat"", ""test"", ""cicd"", ""docs""]"
verify checkpoint listeners are notifiedrestructure ClusterTopology to track completed changedo not use scripts and binaries from the libcc repo[gn win] link comctl32.lib to fix component buildallow disabling dynamic queue,"diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }

diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
index 0c4a971..d13bb16 100644
--- a/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
+++ b/packages/nocodb/src/modules/jobs/redis/jobs.service.ts
@@ -33,16 +33,19 @@ export class JobsService implements OnModuleInit {
   }
 
   async add(name: string, data: any) {
-    // resume primary instance queue if there is no worker
-    const workerCount = await this.jobsRedisService.workerCount();
-    const localWorkerPaused = await this.jobsQueue.isPaused(true);
+    // if NC_WORKER_CONTAINER is false, then skip dynamic queue pause/resume
+    if (process.env.NC_WORKER_CONTAINER !== 'false') {
+      // resume primary instance queue if there is no worker
+      const workerCount = await this.jobsRedisService.workerCount();
+      const localWorkerPaused = await this.jobsQueue.isPaused(true);
 
-    // if there is no worker and primary instance queue is paused, resume it
-    // if there is any worker and primary instance queue is not paused, pause it
-    if (workerCount === 0 && localWorkerPaused) {
-      await this.jobsQueue.resume(true);
-    } else if (workerCount > 0 && !localWorkerPaused) {
-      await this.jobsQueue.pause(true);
+      // if there is no worker and primary instance queue is paused, resume it
+      // if there is any worker and primary instance queue is not paused, pause it
+      if (workerCount === 0 && localWorkerPaused) {
+        await this.jobsQueue.resume(true);
+      } else if (workerCount > 0 && !localWorkerPaused) {
+        await this.jobsQueue.pause(true);
+      }
     }
 
     const job = await this.jobsQueue.add(name, data);
",5,"[""e0198f74b81da3663144cfe1d971939319f82a0f"", ""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2"", ""45837af24a33308a70a3454f0f650f9fe728e272"", ""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""9ef5c0d14193a9abb09b39856f58477d1f4b0d77""]","[""test"", ""refactor"", ""cicd"", ""build"", ""fix""]"
"spring version, core versionterminated tasks linger for a bit

Signed-off-by: Eliza Weisman <eliza@buoyant.io>convert `run_tag_values_test_case` to a functiononly run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>skip flaky test","diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 

diff --git a/console/src/main.rs b/console/src/main.rs
index ebfa315..5328d96 100644
--- a/console/src/main.rs
+++ b/console/src/main.rs
@@ -69,6 +69,7 @@ async fn main() -> Result<(), Box<dyn std::error::Error>> {
                 .wrap(Wrap { trim: true });
             f.render_widget(header, chunks[0]);
             tasks.render(f, chunks[1]);
+            tasks.retain_active();
         })?;
     }
 
diff --git a/console/src/tasks.rs b/console/src/tasks.rs
index 7be39a4..eb41495 100644
--- a/console/src/tasks.rs
+++ b/console/src/tasks.rs
@@ -19,6 +19,7 @@ struct Task {
     fields: String,
     kind: &'static str,
     stats: Stats,
+    completed_for: usize,
 }
 
 #[derive(Default, Debug)]
@@ -28,10 +29,15 @@ struct Stats {
     idle: Duration,
     total: Duration,
 }
+
 impl State {
+    // How many updates to retain completed tasks for
+    const RETAIN_COMPLETED_FOR: usize = 6;
+
     pub(crate) fn len(&self) -> usize {
         self.tasks.len()
     }
+
     pub(crate) fn update(&mut self, update: proto::tasks::TaskUpdate) {
         let new_tasks = update.new_tasks.into_iter().filter_map(|task| {
             if task.id.is_none() {
@@ -48,6 +54,7 @@ impl State {
                 fields: task.string_fields,
                 kind,
                 stats: Default::default(),
+                completed_for: 0,
             };
             Some((id, task))
         });
@@ -60,7 +67,10 @@ impl State {
         }
 
         for proto::SpanId { id } in update.completed {
-            if self.tasks.remove(&id).is_none() {
+            if let Some(task) = self.tasks.get_mut(&id) {
+                task.kind = ""!"";
+                task.completed_for = 1;
+            } else {
                 tracing::warn!(?id, ""tried to complete a task that didn't exist"");
             }
         }
@@ -79,7 +89,7 @@ impl State {
         const DUR_PRECISION: usize = 4;
         const POLLS_LEN: usize = 5;
         let rows = self.tasks.values().map(|task| {
-            let row = Row::new(vec![
+            let mut row = Row::new(vec![
                 Cell::from(task.id_hex.as_str()),
                 // TODO(eliza): is there a way to write a `fmt::Debug` impl
                 // directly to tui without doing an allocation?
@@ -105,6 +115,9 @@ impl State {
                 Cell::from(format!(""{:>width$}"", task.stats.polls, width = POLLS_LEN)),
                 Cell::from(task.fields.as_str()),
             ]);
+            if task.completed_for > 0 {
+                row = row.style(Style::default().add_modifier(style::Modifier::DIM));
+            }
             row
         });
         let t = Table::new(rows)
@@ -126,6 +139,16 @@ impl State {
 
         frame.render_widget(t, area)
     }
+
+    pub(crate) fn retain_active(&mut self) {
+        self.tasks.retain(|_, task| {
+            if task.completed_for == 0 {
+                return true;
+            }
+            task.completed_for += 1;
+            task.completed_for <= Self::RETAIN_COMPLETED_FOR
+        })
+    }
 }
 
 impl From<proto::tasks::Stats> for Stats {

diff --git a/query_tests/src/influxrpc/tag_values.rs b/query_tests/src/influxrpc/tag_values.rs
index 01fd411..3570cae 100644
--- a/query_tests/src/influxrpc/tag_values.rs
+++ b/query_tests/src/influxrpc/tag_values.rs
@@ -1,5 +1,5 @@
 use datafusion::logical_plan::{col, lit};
-use predicate::predicate::PredicateBuilder;
+use predicate::predicate::{Predicate, PredicateBuilder};
 use query::{
     exec::stringset::{IntoStringSet, StringSetRef},
     frontend::influxrpc::InfluxRpcPlanner,
@@ -9,39 +9,42 @@ use crate::scenarios::*;
 
 /// runs tag_value(predicate) and compares it to the expected
 /// output
-macro_rules! run_tag_values_test_case {
-    ($DB_SETUP:expr, $TAG_NAME:expr, $PREDICATE:expr, $EXPECTED_VALUES:expr) => {
-        test_helpers::maybe_start_logging();
-        let predicate = $PREDICATE;
-        let tag_name = $TAG_NAME;
-        let expected_values = $EXPECTED_VALUES;
-        for scenario in $DB_SETUP.make().await {
-            let DbScenario {
-                scenario_name, db, ..
-            } = scenario;
-            println!(""Running scenario '{}'"", scenario_name);
-            println!(""Predicate: '{:#?}'"", predicate);
-            let planner = InfluxRpcPlanner::new();
-            let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
-
-            let plan = planner
-                .tag_values(db.as_ref(), &tag_name, predicate.clone())
-                .expect(""built plan successfully"");
-            let names = ctx
-                .to_string_set(plan)
-                .await
-                .expect(""converted plan to strings successfully"");
-
-            assert_eq!(
-                names,
-                to_stringset(&expected_values),
-                ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
-                scenario_name,
-                expected_values,
-                names
-            );
-        }
-    };
+async fn run_tag_values_test_case<D>(
+    db_setup: D,
+    tag_name: &str,
+    predicate: Predicate,
+    expected_tag_values: Vec<&str>,
+) where
+    D: DbSetup,
+{
+    test_helpers::maybe_start_logging();
+
+    for scenario in db_setup.make().await {
+        let DbScenario {
+            scenario_name, db, ..
+        } = scenario;
+        println!(""Running scenario '{}'"", scenario_name);
+        println!(""Predicate: '{:#?}'"", predicate);
+        let planner = InfluxRpcPlanner::new();
+        let ctx = db.executor().new_context(query::exec::ExecutorType::Query);
+
+        let plan = planner
+            .tag_values(db.as_ref(), tag_name, predicate.clone())
+            .expect(""built plan successfully"");
+        let names = ctx
+            .to_string_set(plan)
+            .await
+            .expect(""converted plan to strings successfully"");
+
+        assert_eq!(
+            names,
+            to_stringset(&expected_tag_values),
+            ""Error in  scenario '{}'\n\nexpected:\n{:?}\nactual:\n{:?}"",
+            scenario_name,
+            expected_tag_values,
+            names
+        );
+    }
 }
 
 #[tokio::test]
@@ -50,12 +53,13 @@ async fn list_tag_values_no_tag() {
     // If the tag is not present, expect no values back (not error)
     let tag_name = ""tag_not_in_chunks"";
     let expected_tag_keys = vec![];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -63,12 +67,13 @@ async fn list_tag_values_no_predicate_state_col() {
     let predicate = PredicateBuilder::default().build();
     let tag_name = ""state"";
     let expected_tag_keys = vec![""CA"", ""MA"", ""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -76,12 +81,13 @@ async fn list_tag_values_no_predicate_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().build();
     let expected_tag_keys = vec![""Boston"", ""LA"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -89,12 +95,13 @@ async fn list_tag_values_timestamp_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().timestamp_range(50, 201).build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -104,12 +111,13 @@ async fn list_tag_values_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""Boston""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -120,12 +128,13 @@ async fn list_tag_values_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""MA""))) // state=MA
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -133,12 +142,13 @@ async fn list_tag_values_table_pred_state_col() {
     let tag_name = ""state"";
     let predicate = PredicateBuilder::default().table(""h2o"").build();
     let expected_tag_keys = vec![""CA"", ""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -146,12 +156,13 @@ async fn list_tag_values_table_pred_city_col() {
     let tag_name = ""city"";
     let predicate = PredicateBuilder::default().table(""o2"").build();
     let expected_tag_keys = vec![""Boston"", ""NYC""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -162,12 +173,13 @@ async fn list_tag_values_table_and_timestamp_and_table_pred_state_col() {
         .timestamp_range(50, 201)
         .build();
     let expected_tag_keys = vec![""MA""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -178,12 +190,13 @@ async fn list_tag_values_table_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -195,12 +208,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col() {
         .add_expr(col(""state"").eq(lit(""NY""))) // state=NY
         .build();
     let expected_tag_keys = vec![""NY""];
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]
@@ -213,12 +227,13 @@ async fn list_tag_values_table_and_timestamp_and_state_pred_state_col_no_rows() 
         .build();
     let expected_tag_keys = vec![];
 
-    run_tag_values_test_case!(
+    run_tag_values_test_case(
         TwoMeasurementsManyNulls {},
         tag_name,
         predicate,
-        expected_tag_keys
-    );
+        expected_tag_keys,
+    )
+    .await;
 }
 
 #[tokio::test]

diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method
",5,"[""c55591ba157298a9c5816693c102a89dfd058830"", ""1bcf88670b50155b50071e707f98f30cea0b7a24"", ""1db13ec43727aca872a0f3836e4023ed85db665e"", ""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d""]","[""build"", ""feat"", ""refactor"", ""cicd"", ""test""]"
"support use meta key select multiple elementsmall error msg improvement

refs #1005ensure checksum persist flushes to diskdo not use scripts and binaries from the libcc repoupgrade to Flux v0.42.0

Skips a test that requires special dependencies to pass.","diff --git a/packages/core/src/LogicFlow.tsx b/packages/core/src/LogicFlow.tsx
index ab68624..aeee7b7 100644
--- a/packages/core/src/LogicFlow.tsx
+++ b/packages/core/src/LogicFlow.tsx
@@ -277,9 +277,11 @@ export default class LogicFlow {
   }
   /**
    * 将图形选中
+   * @param id 选择元素ID
+   * @param multiple 是否允许多选，如果为true，不会将上一个选中的元素重置
    */
-  select(id: string) {
-    this.graphModel.selectElementById(id);
+  select(id: string, multiple = false) {
+    this.graphModel.selectElementById(id, multiple);
   }
   /**
    * 将图形定位到画布中心
diff --git a/packages/core/src/model/EditConfigModel.ts b/packages/core/src/model/EditConfigModel.ts
index 67e334a..83e5f16 100644
--- a/packages/core/src/model/EditConfigModel.ts
+++ b/packages/core/src/model/EditConfigModel.ts
@@ -25,6 +25,7 @@ const SilentConfig = {
   edgeTextEdit: false,
   nodeTextDraggable: false,
   edgeTextDraggable: false,
+  metaKeyMultipleSelected: false,
 };
 
 /**
@@ -42,6 +43,7 @@ export default class EditConfigModel {
   @observable edgeTextEdit = true; // 允许连线文本可以编辑
   @observable nodeTextDraggable = false; // 允许节点文本可以拖拽
   @observable edgeTextDraggable = false; // 允许连线文本可以拖拽
+  @observable metaKeyMultipleSelected = false; // 允许meta多选元素
   constructor(data) {
     const keys = [
       'stopZoomGraph',
@@ -55,6 +57,7 @@ export default class EditConfigModel {
       'edgeTextEdit',
       'nodeTextDraggable',
       'edgeTextDraggable',
+      'metaKeyMultipleSelected',
     ];
     const { isSilentMode, textEdit } = data;
     if (isSilentMode) {
diff --git a/packages/core/src/model/GraphModel.ts b/packages/core/src/model/GraphModel.ts
index 9667f4d..310daf4 100644
--- a/packages/core/src/model/GraphModel.ts
+++ b/packages/core/src/model/GraphModel.ts
@@ -34,6 +34,7 @@ class GraphModel {
   height: number;
   topElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
   selectElement: BaseNodeModel | BaseEdgeModel; // 当前位于顶部的元素
+  selectElements = new Map<string, IBaseModel>(); // 多选
   @observable edgeType: string;
   @observable nodes: BaseNodeModel[] = [];
   @observable activeElement: IBaseModel;
@@ -50,7 +51,6 @@ class GraphModel {
   @observable gridSize = 1;
   @observable partial = false; // 是否开启局部渲染
   @observable fakerNode: BaseNodeModel;
-  // @observable selectElements = new Map<string, IBaseModel>(); // 多选还没有做，先不加
   constructor(config) {
     const {
       container,
@@ -456,24 +456,44 @@ class GraphModel {
   }
 
   @action
-  selectNodeById(id) {
-    this.selectElement?.setSelected(false);
+  selectNodeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.nodesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectEdgeById(id) {
-    this.selectElement?.setSelected(false);
+  selectEdgeById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.edgesMap[id]?.model;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
   }
 
   @action
-  selectElementById(id: string) {
-    this.selectElement?.setSelected(false);
+  selectElementById(id: string, multiple = false) {
+    if (!multiple) {
+      this.selectElement?.setSelected(false);
+      this.clearSelectElements();
+    }
     this.selectElement = this.getElement(id) as BaseNodeModel | BaseEdgeModel;
     this.selectElement?.setSelected(true);
+    this.selectElements.set(id, this.selectElement);
+  }
+
+  @action
+  clearSelectElements() {
+    this.selectElements.forEach(element => {
+      element.setSelected(false);
+    });
+    this.selectElements.clear();
   }
 
   /* 修改连线类型 */
diff --git a/packages/core/src/view/edge/BaseEdge.tsx b/packages/core/src/view/edge/BaseEdge.tsx
index d45ea9e..d7c8f38 100644
--- a/packages/core/src/view/edge/BaseEdge.tsx
+++ b/packages/core/src/view/edge/BaseEdge.tsx
@@ -178,7 +178,8 @@ export default class BaseEdge extends Component<IProps> {
   handleClick = (e) => {
     const { model, graphModel, eventCenter } = this.props;
     graphModel.toFront(model.id);
-    graphModel.selectEdgeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectEdgeById(model.id, e.metaKey && metaKeyMultipleSelected);
     // 边数据
     const edgeData = model?.getData();
     const position = graphModel.getPointByClient({
diff --git a/packages/core/src/view/node/BaseNode.tsx b/packages/core/src/view/node/BaseNode.tsx
index 140889c..5ee3975 100644
--- a/packages/core/src/view/node/BaseNode.tsx
+++ b/packages/core/src/view/node/BaseNode.tsx
@@ -275,7 +275,8 @@ export default abstract class BaseNode extends Component<IProps, Istate> {
       }, 400);
     }
     graphModel.toFront(model.id);
-    graphModel.selectNodeById(model.id);
+    const { editConfig: { metaKeyMultipleSelected } } = graphModel;
+    graphModel.selectNodeById(model.id, e.metaKey && metaKeyMultipleSelected);
     this.preStartTime = this.startTime;
   };
   handleContextMenu = (ev: MouseEvent) => {
diff --git a/packages/core/src/view/overlay/CanvasOverlay.tsx b/packages/core/src/view/overlay/CanvasOverlay.tsx
index ef11822..8c79fd2 100644
--- a/packages/core/src/view/overlay/CanvasOverlay.tsx
+++ b/packages/core/src/view/overlay/CanvasOverlay.tsx
@@ -104,9 +104,9 @@ class CanvasOverlay extends Component<IProps, Istate> {
     const target = ev.target as HTMLElement;
     if (target.getAttribute('name') === 'canvas-overlay') {
       const { graphModel, eventCenter } = this.props;
-      const { selectElement, textEditElement } = graphModel;
-      if (selectElement) {
-        selectElement.setSelected(false);
+      const { textEditElement, selectElements } = graphModel;
+      if (selectElements.size > 0) {
+        graphModel.clearSelectElements();
       }
       if (textEditElement) {
         textEditElement.setElementState(ElementState.DEFAULT);
diff --git a/packages/extension/examples/bpmn/index.html b/packages/extension/examples/bpmn/index.html
index 7a68d6f..f7ea87d 100644
--- a/packages/extension/examples/bpmn/index.html
+++ b/packages/extension/examples/bpmn/index.html
@@ -6,6 +6,7 @@
   <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
   <title>LOGIN FLOW</title>
   <link rel=""stylesheet"" href=""/core/dist/style/index.css"">
+  <link rel=""stylesheet"" href=""/extension/lib/style/index.css"">
   <style>
     html,body {
       padding: 0;
@@ -129,11 +130,14 @@
     </div>
   </div>
   <script src=""/core/dist/logic-flow.js""></script>
+  <!-- <script src=""http://0.0.0.0:9090/logic-flow.js""></script> -->
   <script src=""/BpmnElement.js""></script>
   <script src=""/BpmnAdapter.js""></script>
+  <script src=""/Control.js""></script>
   <script src=""/Snapshot.js""></script>
   <script>
     LogicFlow.use(BpmnElement);
+    LogicFlow.use(Control);
     LogicFlow.use(BpmnAdapter);
     LogicFlow.use(Snapshot);
   </script>
diff --git a/packages/extension/examples/bpmn/index.js b/packages/extension/examples/bpmn/index.js
index 21d2da0..6f6aa39 100644
--- a/packages/extension/examples/bpmn/index.js
+++ b/packages/extension/examples/bpmn/index.js
@@ -3,6 +3,10 @@ window.onload = function () {
     container: document.querySelector('#app'),
     // fixme: grid成为了必传的了
     edgeTextDraggable: true,
+    metaKeyMultipleSelected: true,
+    // stopScrollGraph: true,
+    // stopMoveGraph: true,
+    // stopZoomGraph: true,
     grid: {
       type: 'dot',
       size: 20,

diff --git a/internal/pipe/git/errors.go b/internal/pipe/git/errors.go
index a8c15d5..13dfb56 100644
--- a/internal/pipe/git/errors.go
+++ b/internal/pipe/git/errors.go
@@ -11,7 +11,7 @@ type ErrDirty struct {
 }
 
 func (e ErrDirty) Error() string {
-	return fmt.Sprintf(""git is currently in a dirty state:\n%v"", e.status)
+	return fmt.Sprintf(""git is currently in a dirty state, please check in your pipeline what can be changing the following files:\n%v"", e.status)
 }
 
 // ErrWrongRef happens when the HEAD reference is different from the tag being built

diff --git a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
index eed9424..a1ae702 100644
--- a/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
+++ b/snapshot/src/test/java/io/camunda/zeebe/snapshots/impl/SnapshotChecksumTest.java
@@ -10,6 +10,10 @@ package io.camunda.zeebe.snapshots.impl;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import io.camunda.zeebe.snapshots.ImmutableChecksumsSFV;
+import io.camunda.zeebe.test.util.STracer;
+import io.camunda.zeebe.test.util.STracer.Syscall;
+import io.camunda.zeebe.test.util.asserts.strace.FSyncTraceAssert;
+import io.camunda.zeebe.test.util.asserts.strace.STracerAssert;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
@@ -124,6 +128,28 @@ public class SnapshotChecksumTest {
   }
 
   @Test
+  public void shouldFlushOnPersist() throws Exception {
+    // given
+    final var traceFile = temporaryFolder.newFile().toPath();
+    final var expectedChecksum = SnapshotChecksum.calculate(multipleFileSnapshot);
+    final var checksumPath = multipleFileSnapshot.resolveSibling(""checksum"");
+    final var tracer = STracer.traceFor(Syscall.FSYNC, traceFile);
+
+    // when
+    try (tracer) {
+      SnapshotChecksum.persist(checksumPath, expectedChecksum);
+    }
+
+    // then
+    STracerAssert.assertThat(tracer)
+        .fsyncTraces()
+        .hasSize(1)
+        .first(FSyncTraceAssert.factory())
+        .hasPath(checksumPath)
+        .isSuccessful();
+  }
+
+  @Test
   public void shouldDetectCorruptedSnapshot() throws IOException {
     // given
     final var expectedChecksum = SnapshotChecksum.calculate(corruptedSnapshot);

diff --git a/.circleci/config.yml b/.circleci/config.yml
index 1822508..c7c402d 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -169,7 +169,7 @@ mac-build-steps: &mac-build-steps
         name: GN gen
         command: |
           cd src
-          SCCACHE_PATH=""$PWD/libchromiumcontent/tools/sccache/aad2120/mac/sccache""
+          SCCACHE_PATH=""$PWD/electron/external_binaries/sccache""
           echo 'export SCCACHE_WRAPPER=""'""$SCCACHE_PATH""'""' >> $BASH_ENV
           echo 'export CHROMIUM_BUILDTOOLS_PATH=""'""$PWD""'/buildtools""' >> $BASH_ENV
           source $BASH_ENV
diff --git a/vsts-gn.yml b/vsts-gn.yml
index 3c9985b..24ed1f5 100644
--- a/vsts-gn.yml
+++ b/vsts-gn.yml
@@ -31,13 +31,13 @@ phases:
   - bash: |
       cd src
       export CHROMIUM_BUILDTOOLS_PATH=`pwd`/buildtools
-      export SCCACHE_WRAPPER=""`pwd`/electron/external_binaries/sccache""
-      export SCCACHE_HELPER=""`pwd`/libchromiumcontent/script/sccache""
-      ""$SCCACHE_HELPER"" --start-server --azure_container ""$(SCCACHE_AZURE_BLOB_CONTAINER)"" --azure_connection ""$(SCCACHE_AZURE_CONNECTION_STRING)""
-      echo ""##vso[task.setvariable variable=SCCACHE_WRAPPER]$SCCACHE_WRAPPER""
-      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]`pwd`/buildtools""
+      export SCCACHE_BINARY=""`pwd`/electron/external_binaries/sccache""
+      # SCCACHE_AZURE_BLOB_CONTAINER and SCCACHE_AZURE_CONNECTION_STRING are expected to be set.
+      ""$SCCACHE_BINARY"" --start-server
+      echo ""##vso[task.setvariable variable=SCCACHE_BINARY]$SCCACHE_BINARY""
+      echo ""##vso[task.setvariable variable=CHROMIUM_BUILDTOOLS_PATH]$CHROMIUM_BUILDTOOLS_PATH""
       echo ""GN gen for: $GN_CONFIG""
-      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_WRAPPER""'""'
+      gn gen out/Default --args='import(""'$GN_CONFIG'"") cc_wrapper=""'""$SCCACHE_BINARY""'""'
     name: GN_gen
 
   - bash: |
@@ -46,8 +46,8 @@ phases:
     name: Ninja_build
 
   - bash: |
-      ""$SCCACHE_WRAPPER"" -s
-      ""$SCCACHE_WRAPPER"" --stop-server
+      ""$SCCACHE_BINARY"" -s
+      ""$SCCACHE_BINARY"" --stop-server
     name: Check_sccache_stats
 
   - bash: |

diff --git a/go.mod b/go.mod
index ea705da..8c352f7 100644
--- a/go.mod
+++ b/go.mod
@@ -38,7 +38,7 @@ require (
 	github.com/hashicorp/go-msgpack v0.0.0-20150518234257-fa3f63826f7c // indirect
 	github.com/hashicorp/raft v1.0.0 // indirect
 	github.com/hashicorp/vault/api v1.0.2
-	github.com/influxdata/flux v0.41.0
+	github.com/influxdata/flux v0.42.0
 	github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6
 	github.com/influxdata/usage-client v0.0.0-20160829180054-6d3895376368
 	github.com/jessevdk/go-flags v1.4.0
diff --git a/go.sum b/go.sum
index 4bfdf4c..634a0f1 100644
--- a/go.sum
+++ b/go.sum
@@ -206,8 +206,8 @@ github.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NH
 github.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=
 github.com/influxdata/changelog v1.0.0 h1:RstJD6H48zLQj0GdE6E6k/6RPwtUjkyzIe/T1E/xuWU=
 github.com/influxdata/changelog v1.0.0/go.mod h1:uzpGWE/qehT8L426YuXwpMQub+a63vIINhIeEI9mnSM=
-github.com/influxdata/flux v0.41.0 h1:ljbWJmE+aNx8Yoqhb04gWC4sXMV87eYUxz5vjYphLLs=
-github.com/influxdata/flux v0.41.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
+github.com/influxdata/flux v0.42.0 h1:2iEG6hLHdHEJ6LgD8OSnlHS9yoVrLO1/aM4P9ERb94U=
+github.com/influxdata/flux v0.42.0/go.mod h1:QvF9P06HFgYKD28Z556rFLJ0D0bvtcgEtkFALteZ4Lo=
 github.com/influxdata/goreleaser v0.97.0-influx h1:jT5OrcW7WfS0e2QxfwmTBjhLvpIC9CDLRhNgZJyhj8s=
 github.com/influxdata/goreleaser v0.97.0-influx/go.mod h1:MnjA0e0Uq6ISqjG1WxxMAl+3VS1QYjILSWVnMYDxasE=
 github.com/influxdata/influxql v0.0.0-20180925231337-1cbfca8e56b6 h1:CFx+pP90q/qg3spoiZjf8donE4WpAdjeJfPOcoNqkWo=
diff --git a/query/stdlib/testing/testing.go b/query/stdlib/testing/testing.go
index d41574a..85b0673 100644
--- a/query/stdlib/testing/testing.go
+++ b/query/stdlib/testing/testing.go
@@ -98,4 +98,6 @@ var FluxEndToEndSkipList = map[string]string{
 	""http_endpoint"": ""need ability to test side effects in e2e tests: (https://github.com/influxdata/flux/issues/1723)"",
 
 	""holt_winters_panic"": ""Expected output is an empty table which breaks the testing framework (https://github.com/influxdata/influxdb/issues/14749)"",
+
+	""secrets"": ""Cannot inject custom deps into the test framework so the secrets don't lookup correctly"",
 }
",5,"[""e137f9fdbdb6bf3f85c3f7ac9323785e445844c8"", ""a62314d9bb632be6af026686615d14b912250512"", ""b7ce2894fd1794064bd6db4ed730bb6cb7728739"", ""45837af24a33308a70a3454f0f650f9fe728e272"", ""454003841aabeb74396d73541378bfa59c75b5db""]","[""feat"", ""refactor"", ""test"", ""cicd"", ""build""]"
"update wrapping tests for v7use `regexp_instr != 0` instead of `REGEXP` keywordupdated react demo parcel commandexport a modal transition presetadded changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284","diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(

diff --git a/demo/react/package.json b/demo/react/package.json
index be28bf9..32d0952 100644
--- a/demo/react/package.json
+++ b/demo/react/package.json
@@ -12,7 +12,7 @@
   },
   ""scripts"": {
     ""start"": ""parcel serve public/index.html --no-cache --open"",
-    ""build"": ""parcel build -t browser -d dist public/index.html --no-source-maps""
+    ""build"": ""parcel build --target browser --dist-dir dist public/index.html --no-source-maps""
   },
   ""bugs"": {
     ""url"": ""https://github.com/matteobruni/tsparticles/issues""

diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {

diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')
",5,"[""317f4eefecddfb1392ca71d551840f446feee302"", ""06e2be4e2019b6fa714e1fcb34485860ef1ede79"", ""32b92cfa0b74a6c25990e32ac6aab12b8496794c"", ""535708ae50aecb452560a23356fd396f99ef13a2"", ""aca23027da1295c78fdf42ba9687d8ccc88784d7""]","[""test"", ""fix"", ""build"", ""refactor"", ""docs""]"
"add riscv64gc-unknown-linux-gnubuffer assert and bpmn model api helper class

related to camunda-tngp/camunda-tngp#23updated react demo parcel commandupdate flushed index before truncatingadd benchmark for known-slow table expression","diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }

diff --git a/test-util/pom.xml b/test-util/pom.xml
index a097651..b6518ee 100644
--- a/test-util/pom.xml
+++ b/test-util/pom.xml
@@ -20,6 +20,7 @@
     <project.build.sourceEncoding>utf-8</project.build.sourceEncoding>
     <!-- TODO: Move to common parent -->
     <agrona.version>0.4.11</agrona.version>
+    <camunda.version>7.6.0-SNAPSHOT</camunda.version>
   </properties>
 
   <dependencies>
@@ -30,6 +31,13 @@
       <version>${agrona.version}</version>
       <scope>provided</scope>
     </dependency>
+    
+    <dependency>
+      <groupId>org.camunda.bpm.model</groupId>
+      <artifactId>camunda-bpmn-model</artifactId>
+      <version>${camunda.version}</version>
+      <scope>provided</scope>
+    </dependency>
 
     <dependency>
       <groupId>junit</groupId>
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
index 37e3a6f..b8d9b26 100644
--- a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
@@ -14,7 +14,7 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         super(actual, BufferAssert.class);
     }
 
-    public static BufferAssert assertThat(DirectBuffer buffer)
+    public static BufferAssert assertThatBuffer(DirectBuffer buffer)
     {
         return new BufferAssert(buffer);
     }
@@ -41,4 +41,16 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         return hasBytes(expected, 0);
     }
 
+    public BufferAssert hasCapacity(int expectedCapacity)
+    {
+        isNotNull();
+
+        if (expectedCapacity != actual.capacity())
+        {
+            failWithMessage(""Expected capacity "" + expectedCapacity + "" but was "" + actual.capacity());
+        }
+
+        return this;
+    }
+
 }
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
new file mode 100644
index 0000000..6f0d134
--- /dev/null
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
@@ -0,0 +1,121 @@
+package org.camunda.tngp.broker.test.util.bpmn;
+
+import java.util.Collection;
+
+import org.camunda.bpm.model.bpmn.BpmnModelInstance;
+import org.camunda.bpm.model.bpmn.impl.BpmnModelConstants;
+import org.camunda.bpm.model.bpmn.instance.Definitions;
+import org.camunda.bpm.model.xml.Model;
+import org.camunda.bpm.model.xml.instance.DomDocument;
+import org.camunda.bpm.model.xml.instance.ModelElementInstance;
+import org.camunda.bpm.model.xml.type.ModelElementType;
+import org.camunda.bpm.model.xml.validation.ModelElementValidator;
+import org.camunda.bpm.model.xml.validation.ValidationResults;
+
+public class TngpModelInstance implements BpmnModelInstance
+{
+    protected BpmnModelInstance wrappedInstance;
+
+    public TngpModelInstance(BpmnModelInstance wrappedInstance)
+    {
+        this.wrappedInstance = wrappedInstance;
+    }
+
+    @Override
+    public DomDocument getDocument()
+    {
+        return wrappedInstance.getDocument();
+    }
+
+    @Override
+    public ModelElementInstance getDocumentElement()
+    {
+        return wrappedInstance.getDocumentElement();
+    }
+
+    @Override
+    public void setDocumentElement(ModelElementInstance documentElement)
+    {
+        wrappedInstance.setDocumentElement(documentElement);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(Class<T> type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(ModelElementType type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public Model getModel()
+    {
+        return wrappedInstance.getModel();
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T getModelElementById(String id)
+    {
+        return wrappedInstance.getModelElementById(id);
+    }
+
+    @Override
+    public Collection<ModelElementInstance> getModelElementsByType(ModelElementType referencingType)
+    {
+        return wrappedInstance.getModelElementsByType(referencingType);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> Collection<T> getModelElementsByType(Class<T> referencingClass)
+    {
+        return wrappedInstance.getModelElementsByType(referencingClass);
+    }
+
+    @Override
+    public ValidationResults validate(Collection<ModelElementValidator<?>> validators)
+    {
+        return wrappedInstance.validate(validators);
+    }
+
+    @Override
+    public BpmnModelInstance clone()
+    {
+        return wrappedInstance.clone();
+    }
+
+    @Override
+    public Definitions getDefinitions()
+    {
+        return wrappedInstance.getDefinitions();
+    }
+
+    @Override
+    public void setDefinitions(Definitions arg0)
+    {
+        wrappedInstance.setDefinitions(arg0);
+    }
+
+    public TngpModelInstance taskAttributes(String taskId, String taskType, int taskQueueId)
+    {
+        final ModelElementInstance task = wrappedInstance.getModelElementById(taskId);
+
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskType"", taskType);
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskQueueId"", String.valueOf(taskQueueId));
+
+        return this;
+    }
+
+    public static TngpModelInstance wrap(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance);
+    }
+
+    public static TngpModelInstance wrapCopy(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance.clone());
+    }
+}

diff --git a/demo/react/package.json b/demo/react/package.json
index be28bf9..32d0952 100644
--- a/demo/react/package.json
+++ b/demo/react/package.json
@@ -12,7 +12,7 @@
   },
   ""scripts"": {
     ""start"": ""parcel serve public/index.html --no-cache --open"",
-    ""build"": ""parcel build -t browser -d dist public/index.html --no-source-maps""
+    ""build"": ""parcel build --target browser --dist-dir dist public/index.html --no-source-maps""
   },
   ""bugs"": {
     ""url"": ""https://github.com/matteobruni/tsparticles/issues""

diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/.gitignore b/.gitignore
index 2e99ad3..eef9203 100644
--- a/.gitignore
+++ b/.gitignore
@@ -95,3 +95,4 @@ docs/backends/support_matrix.csv
 __pycache__
 tags
 .DS_Store
+prof/
diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index ac19aaf..36aed0e 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -602,3 +602,93 @@ def test_multiple_joins(benchmark, num_joins, num_columns):
         name=""t"",
     )
     benchmark(multiple_joins, table, num_joins)
+
+
+@pytest.fixture
+def customers():
+    return ibis.table(
+        dict(
+            customerid=""int32"",
+            name=""string"",
+            address=""string"",
+            citystatezip=""string"",
+            birthdate=""date"",
+            phone=""string"",
+            timezone=""string"",
+            lat=""float64"",
+            long=""float64"",
+        ),
+        name=""customers"",
+    )
+
+
+@pytest.fixture
+def orders():
+    return ibis.table(
+        dict(
+            orderid=""int32"",
+            customerid=""int32"",
+            ordered=""timestamp"",
+            shipped=""timestamp"",
+            items=""string"",
+            total=""float64"",
+        ),
+        name=""orders"",
+    )
+
+
+@pytest.fixture
+def orders_items():
+    return ibis.table(
+        dict(orderid=""int32"", sku=""string"", qty=""int32"", unit_price=""float64""),
+        name=""orders_items"",
+    )
+
+
+@pytest.fixture
+def products():
+    return ibis.table(
+        dict(
+            sku=""string"",
+            desc=""string"",
+            weight_kg=""float64"",
+            cost=""float64"",
+            dims_cm=""string"",
+        ),
+        name=""products"",
+    )
+
+
+@pytest.mark.benchmark(group=""compilation"")
+@pytest.mark.parametrize(
+    ""module"",
+    [
+        pytest.param(
+            mod,
+            marks=pytest.mark.xfail(
+                condition=mod in _XFAIL_COMPILE_BACKENDS,
+                reason=f""{mod} backend doesn't support compiling UnboundTable"",
+            ),
+        )
+        for mod in _backends
+    ],
+)
+def test_compile_with_drops(
+    benchmark, module, customers, orders, orders_items, products
+):
+    expr = (
+        customers.join(orders, ""customerid"")
+        .join(orders_items, ""orderid"")
+        .join(products, ""sku"")
+        .drop(""customerid"", ""qty"", ""total"", ""items"")
+        .drop(""dims_cm"", ""cost"")
+        .mutate(o_date=lambda t: t.shipped.date())
+        .filter(lambda t: t.ordered == t.shipped)
+    )
+
+    try:
+        mod = getattr(ibis, module)
+    except (AttributeError, ImportError) as e:
+        pytest.skip(str(e))
+    else:
+        benchmark(mod.compile, expr)
",5,"[""173553c0372e66e03bdab19e0e6c2dd44daa14a0"", ""6ed56ce9ae743ba9a87e6c9643cc06b1de7b748d"", ""32b92cfa0b74a6c25990e32ac6aab12b8496794c"", ""933ab6bb86372913c992567cf9660009900911a7"", ""e9617f0854030e70365eb264bcb3b58078e79e9e""]","[""cicd"", ""feat"", ""build"", ""fix"", ""test""]"
"only run Snyk once a day on master

Signed-off-by: Alex Collins <alex_collins@intuit.com>skip flaky testupdate flushed index before truncatingdetach ViewControllers when not activespring version, core version","diff --git a/.github/workflows/snyk.yml b/.github/workflows/snyk.yml
index 675a22b..a4586d0 100644
--- a/.github/workflows/snyk.yml
+++ b/.github/workflows/snyk.yml
@@ -1,5 +1,7 @@
 name: Snyk
-on: push
+on:
+  schedule:
+    - cron: ""30 2 * * *""
 jobs:
   security:
     runs-on: ubuntu-latest

diff --git a/test/browser-pool/browser-pool.test.ts b/test/browser-pool/browser-pool.test.ts
index 9f21322..7a011b5 100644
--- a/test/browser-pool/browser-pool.test.ts
+++ b/test/browser-pool/browser-pool.test.ts
@@ -128,7 +128,8 @@ describe.each([
             expect(page.close).toBeDefined();
         });
 
-        test('should allow early aborting in case of outer timeout', async () => {
+        // TODO: this test is very flaky in the CI
+        test.skip('should allow early aborting in case of outer timeout', async () => {
             const timeout = browserPool.operationTimeoutMillis;
             browserPool.operationTimeoutMillis = 500;
             // @ts-expect-error mocking private method

diff --git a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
index f0c8639..d5c8246 100644
--- a/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
+++ b/journal/src/main/java/io/camunda/zeebe/journal/file/SegmentedJournalWriter.java
@@ -99,8 +99,8 @@ final class SegmentedJournalWriter {
 
     // Truncate down to the current index, such that the last index is `index`, and the next index
     // `index + 1`
-    currentWriter.truncate(index);
     flusher.setLastFlushedIndex(index);
+    currentWriter.truncate(index);
   }
 
   void flush() {

diff --git a/ionic/components/nav/nav-controller.ts b/ionic/components/nav/nav-controller.ts
index becdd99..1cc3c31 100644
--- a/ionic/components/nav/nav-controller.ts
+++ b/ionic/components/nav/nav-controller.ts
@@ -1410,6 +1410,9 @@ export class NavController extends Ion {
       // set the ComponentRef's instance to this ViewController
       view.setInstance(component);
 
+      // remember the ChangeDetectorRef for this ViewController
+      view.setChangeDetector(hostViewRef.changeDetectorRef);
+
       // remember the ElementRef to the ion-page elementRef that was just created
       view.setPageRef(pageElementRef);
 
diff --git a/ionic/components/nav/view-controller.ts b/ionic/components/nav/view-controller.ts
index 3207fa2..069c74d 100644
--- a/ionic/components/nav/view-controller.ts
+++ b/ionic/components/nav/view-controller.ts
@@ -1,4 +1,4 @@
-import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer} from 'angular2/core';
+import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer, ChangeDetectorRef} from 'angular2/core';
 
 import {Navbar} from '../navbar/navbar';
 import {NavController, NavOptions} from './nav-controller';
@@ -33,6 +33,7 @@ export class ViewController {
   private _nbVwRef: ViewContainerRef;
   private _onDismiss: Function = null;
   private _pgRef: ElementRef;
+  private _cd: ChangeDetectorRef;
   protected _nav: NavController;
 
   /**
@@ -166,6 +167,13 @@ export class ViewController {
   /**
    * @private
    */
+  setChangeDetector(cd: ChangeDetectorRef) {
+    this._cd = cd;
+  }
+
+  /**
+   * @private
+   */
   setInstance(instance: any) {
     this.instance = instance;
   }
@@ -467,6 +475,14 @@ export class ViewController {
    * The view is about to enter and become the active view.
    */
   willEnter() {
+    if (this._cd) {
+      // ensure this has been re-attached to the change detector
+      this._cd.reattach();
+
+      // detect changes before we run any user code
+      this._cd.detectChanges();
+    }
+
     ctrlFn(this, 'onPageWillEnter');
   }
 
@@ -496,6 +512,10 @@ export class ViewController {
    */
   didLeave() {
     ctrlFn(this, 'onPageDidLeave');
+
+    // when this is not the active page
+    // we no longer need to detect changes
+    this._cd && this._cd.detach();
   }
 
   /**

diff --git a/backend/pom.xml b/backend/pom.xml
index 5f3e72f..7b1917f 100644
--- a/backend/pom.xml
+++ b/backend/pom.xml
@@ -148,7 +148,7 @@
         <dependency>
             <groupId>io.metersphere</groupId>
             <artifactId>ms-jmeter-core</artifactId>
-            <version>1.0.3</version>
+            <version>1.0.4</version>
         </dependency>
 
         <!--   排除jmeter中的 xstream 解决bug     -->
@@ -430,7 +430,7 @@
                         <artifactItem>
                             <groupId>org.apache.jmeter</groupId>
                             <artifactId>ApacheJMeter_functions</artifactId>
-                            <version>5.4.2</version>
+                            <version>5.4.3</version>
                             <type>jar</type>
                             <overWrite>true</overWrite>
                             <outputDirectory>src/main/resources/jmeter/lib/ext</outputDirectory>
diff --git a/pom.xml b/pom.xml
index 207e439..8c7de0f 100644
--- a/pom.xml
+++ b/pom.xml
@@ -10,7 +10,7 @@
     <parent>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-parent</artifactId>
-        <version>2.6.1</version>
+        <version>2.6.2</version>
         <relativePath/> <!-- lookup parent from repository -->
     </parent>
 
",5,"[""dbb537a26e388a8d7d17faf131abc30c2f7a84e6"", ""e2e8ad25854bd1e7cdbc7f50b50bbd99e04ad47d"", ""933ab6bb86372913c992567cf9660009900911a7"", ""b282e90e2cbb74559aab79eee8443a4d7c85502a"", ""c55591ba157298a9c5816693c102a89dfd058830""]","[""cicd"", ""test"", ""fix"", ""feat"", ""build""]"
"update wrapping tests for v7remove deprecated settings

Removes deprecated ZEEBE_HOST environment variable, and removes
unnecessary log level environment variable, since it's already the
default in the log fileadd props to get color and label from a routeprint errors without stacktraceadd riscv64gc-unknown-linux-gnu","diff --git a/core/src/components/select/test/legacy/wrapping/select.e2e.ts b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
new file mode 100644
index 0000000..e530ebb
--- /dev/null
+++ b/core/src/components/select/test/legacy/wrapping/select.e2e.ts
@@ -0,0 +1,46 @@
+import { expect } from '@playwright/test';
+import { test } from '@utils/test/playwright';
+
+test.describe('select: wrapping', () => {
+  test('should not wrap text by default', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""nowrap"">
+        <ion-select-option value=""nowrap"">Should not wrap when no label exists and no class is added to make the text wrap</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-nowrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should wrap text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-select value=""wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap when no label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
+    `);
+
+    const select = page.locator('ion-select');
+    await expect(select).toHaveScreenshot(`select-wrap-${page.getSnapshotSettings()}.png`);
+  });
+
+  test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
+    skip.rtl();
+
+    await page.setContent(`
+      <ion-item>
+        <ion-label>Really long label should not wrap</ion-label>
+        <ion-select value=""wrap"" class=""ion-text-wrap"">
+          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+        </ion-select>
+      </ion-item>
+    `);
+
+    const select = page.locator('ion-item');
+    await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
+  });
+});
diff --git a/core/src/components/select/test/wrapping/select.e2e.ts b/core/src/components/select/test/wrapping/select.e2e.ts
index 1cf0e62..b0cb528 100644
--- a/core/src/components/select/test/wrapping/select.e2e.ts
+++ b/core/src/components/select/test/wrapping/select.e2e.ts
@@ -31,18 +31,13 @@ test.describe('select: wrapping', () => {
   test('should not wrap label while wrapping text with class', async ({ page, skip }) => {
     skip.rtl();
 
-    // TODO(FW-3787) Make label a property of select
     await page.setContent(`
-      <ion-item>
-        <ion-label>Really long label should not wrap</ion-label>
-        <ion-select value=""wrap"" aria-label=""Should Wrap"" class=""ion-text-wrap"">
-          <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
-        </ion-select>
-        </ion-label>
-      </ion-item>
+      <ion-select value=""wrap"" label=""Really long label should not wrap"" class=""ion-text-wrap"">
+        <ion-select-option value=""wrap"">Should wrap value only when label exists and really long text exists to make it wrap the text</ion-select-option>
+      </ion-select>
     `);
 
-    const select = page.locator('ion-item');
+    const select = page.locator('ion-select');
     await expect(select).toHaveScreenshot(`select-wrap-with-label-${page.getSnapshotSettings()}.png`);
   });
 });

diff --git a/Dockerfile b/Dockerfile
index 6762a39..7f380cd 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -34,7 +34,6 @@ RUN wget -O - https://github.com/jvm-profiling-tools/async-profiler/releases/dow
 FROM ${APP_ENV} as app
 
 ENV ZB_HOME=/usr/local/zeebe \
-    ZEEBE_LOG_LEVEL=info \
     ZEEBE_BROKER_GATEWAY_NETWORK_HOST=0.0.0.0 \
     ZEEBE_STANDALONE_GATEWAY=false
 ENV PATH ""${ZB_HOME}/bin:${PATH}""
diff --git a/docker/utils/startup.sh b/docker/utils/startup.sh
index bc8d2fc..0fcde2b 100755
--- a/docker/utils/startup.sh
+++ b/docker/utils/startup.sh
@@ -1,17 +1,14 @@
 #!/bin/bash -xeu
 
-# legacy support
-# This environment variable was used to set the gatewway cluster host in standalone and embedded mode.
-# Now, there are two dedicated environment variables for the two different deployment scenarios.
-export ZEEBE_HOST=${ZEEBE_HOST:-$(hostname -i)}
-# Legacy support
+HOST=$(hostname -i)
 
 if [ ""$ZEEBE_STANDALONE_GATEWAY"" = ""true"" ]; then
-    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_GATEWAY_NETWORK_HOST=${ZEEBE_GATEWAY_NETWORK_HOST:-${HOST}}
+    export ZEEBE_GATEWAY_CLUSTER_HOST=${ZEEBE_GATEWAY_CLUSTER_HOST:-${HOST}}
 
     exec /usr/local/zeebe/bin/gateway
 else
-    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${ZEEBE_HOST}}
+    export ZEEBE_BROKER_NETWORK_HOST=${ZEEBE_BROKER_NETWORK_HOST:-${HOST}}
     export ZEEBE_BROKER_GATEWAY_CLUSTER_HOST=${ZEEBE_BROKER_GATEWAY_CLUSTER_HOST:-${ZEEBE_BROKER_NETWORK_HOST}}
 
     exec /usr/local/zeebe/bin/broker

diff --git a/src/components/BottomNavigation.js b/src/components/BottomNavigation.js
index 1b72302..7d8ea75 100644
--- a/src/components/BottomNavigation.js
+++ b/src/components/BottomNavigation.js
@@ -24,8 +24,8 @@ const AnimatedPaper = Animated.createAnimatedComponent(Paper);
 
 type Route = {
   key: string,
-  title: string,
-  icon: IconSource,
+  title?: string,
+  icon?: IconSource,
   color?: string,
 };
 
@@ -51,7 +51,7 @@ type Props<T> = {
    * - `key`: a unique key to identify the route
    * - `title`: title of the route to use as the tab label
    * - `icon`: icon to use as the tab icon, can be a string, an image source or a react component
-   * - `color`: color to use as background color for shifting bottom navigation (optional)
+   * - `color`: color to use as background color for shifting bottom navigation
    *
    * Example:
    *
@@ -115,11 +115,27 @@ type Props<T> = {
   /**
    * Callback which returns a React Element to be used as tab icon.
    */
-  renderIcon?: (props: { route: T, focused: boolean }) => React.Node,
+  renderIcon?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
   /**
    * Callback which React Element to be used as tab label.
    */
-  renderLabel?: (props: { route: T, focused: boolean }) => React.Node,
+  renderLabel?: (props: {
+    route: T,
+    focused: boolean,
+    tintColor: string,
+  }) => React.Node,
+  /**
+   * Get label text for the tab, uses `route.title` by default. Use `renderLabel` to replace label component.
+   */
+  getLabelText?: (props: { route: T }) => string,
+  /**
+   * Get color for the tab, uses `route.color` by default.
+   */
+  getColor?: (props: { route: T }) => string,
   /**
    * Function to execute on tab press. It receives the route for the pressed tab, useful for things like scroll to top.
    */
@@ -159,6 +175,10 @@ type State = {
    */
   ripple: Animated.Value,
   /**
+   * Animation for the touch feedback, used to determine it's scale and opacity.
+   */
+  touch: Animated.Value,
+  /**
    * Layout of the tab bar. The width is used to determine the size and position of the ripple.
    */
   layout: { height: number, width: number, measured: boolean },
@@ -173,7 +193,7 @@ const MIN_SHIFT_AMOUNT = 10;
 const MIN_TAB_WIDTH = 96;
 const MAX_TAB_WIDTH = 168;
 const BAR_HEIGHT = 56;
-const SMALL_RIPPLE_SIZE = 72;
+const SMALL_RIPPLE_SIZE = 96;
 const ACTIVE_LABEL_SIZE = 14;
 const INACTIVE_LABEL_SIZE = 12;
 
@@ -251,6 +271,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ),
       index: new Animated.Value(index),
       ripple: new Animated.Value(MIN_RIPPLE_SCALE),
+      touch: new Animated.Value(MIN_RIPPLE_SCALE),
       layout: { height: 0, width: 0, measured: false },
       previous: 0,
     };
@@ -349,6 +370,15 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
   _handleTabPress = (index: number) => {
     const { navigationState } = this.props;
 
+    this.state.touch.setValue(MIN_RIPPLE_SCALE);
+
+    Animated.timing(this.state.touch, {
+      toValue: 1,
+      duration: 300,
+      easing: Easing.in(Easing.sin),
+      useNativeDriver: true,
+    }).start();
+
     if (index !== navigationState.index) {
       this.props.onIndexChange(index);
     }
@@ -376,6 +406,8 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       renderScene,
       renderIcon,
       renderLabel,
+      getLabelText = ({ route }) => route.title,
+      getColor = ({ route }) => route.color,
       barStyle,
       style,
       theme,
@@ -400,7 +432,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
       ? this.state.index.interpolate({
           inputRange: routes.map((_, i) => i),
           outputRange: routes.map(
-            route => route.color || approxBackgroundColor
+            route => getColor({ route }) || approxBackgroundColor
           ),
         })
       : approxBackgroundColor;
@@ -416,7 +448,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
           .rgb()
           .string();
 
-    const rippleColor = color(textColor)
+    const touchColor = color(textColor)
       .alpha(0.12)
       .rgb()
       .string();
@@ -430,22 +462,10 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
 
     // Since we have a single ripple, we have to reposition it so that it appears to expand from active tab.
     // We need to move it from the left to the active tab and also account for how much that tab has shifted.
-    const rippleShift =
-      navigationState.index * tabWidth +
-      tabWidth / 2 +
-      this._calculateShift(
-        this.state.previous,
-        navigationState.index,
-        routes.length
-      );
 
     return (
       <View
-        style={[
-          styles.container,
-          { backgroundColor: theme.dark ? white : black },
-          style,
-        ]}
+        style={[styles.container, style]}
         onLayout={this._handleLayout}
         pointerEvents={layout.measured ? 'auto' : 'none'}
       >
@@ -485,25 +505,30 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
             style={[styles.items, { maxWidth: maxTabWidth * routes.length }]}
           >
             {shifting ? (
-              // Large ripple with the backround color
               <Animated.View
                 pointerEvents=""none""
                 style={[
                   styles.ripple,
                   {
                     // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - layout.width / 2,
-                    left: rippleShift - layout.width / 2,
-                    height: layout.width,
-                    width: layout.width,
+                    top: BAR_HEIGHT / 2 - layout.width / 8,
+                    left:
+                      navigationState.index * tabWidth +
+                      tabWidth / 2 -
+                      layout.width / 8,
+                    height: layout.width / 4,
+                    width: layout.width / 4,
                     borderRadius: layout.width / 2,
-                    backgroundColor: routes[navigationState.index].color,
+                    backgroundColor: getColor({
+                      route: routes[navigationState.index],
+                    }),
                     transform: [
+                      { translateX: this.state.shifts[navigationState.index] },
                       {
                         // Scale to twice the size  to ensure it covers the whole tab bar
                         scale: this.state.ripple.interpolate({
                           inputRange: [0, 1],
-                          outputRange: [0, 2],
+                          outputRange: [0, 8],
                         }),
                       },
                     ],
@@ -515,36 +540,36 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                 ]}
               />
             ) : null}
-            {shifting ? (
-              // Small subtle ripple on touch
-              <Animated.View
-                pointerEvents=""none""
-                style={[
-                  styles.ripple,
-                  {
-                    // Set top and left values so that the ripple's center is same as the tab's center
-                    top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
-                    left: rippleShift - SMALL_RIPPLE_SIZE / 2,
-                    height: SMALL_RIPPLE_SIZE,
-                    width: SMALL_RIPPLE_SIZE,
-                    borderRadius: SMALL_RIPPLE_SIZE / 2,
-                    backgroundColor: rippleColor,
-                    transform: [
-                      {
-                        scale: this.state.ripple.interpolate({
-                          inputRange: [0, 0.5, 1],
-                          outputRange: [0, 1, 1],
-                        }),
-                      },
-                    ],
-                    opacity: this.state.ripple.interpolate({
-                      inputRange: [0, MIN_RIPPLE_SCALE, 0.25, 0.5],
-                      outputRange: [0, 0, 1, 0],
-                    }),
-                  },
-                ]}
-              />
-            ) : null}
+            <Animated.View
+              pointerEvents=""none""
+              style={[
+                styles.ripple,
+                {
+                  // Set top and left values so that the ripple's center is same as the tab's center
+                  top: BAR_HEIGHT / 2 - SMALL_RIPPLE_SIZE / 2,
+                  left:
+                    navigationState.index * tabWidth +
+                    tabWidth / 2 -
+                    SMALL_RIPPLE_SIZE / 2,
+                  height: SMALL_RIPPLE_SIZE,
+                  width: SMALL_RIPPLE_SIZE,
+                  borderRadius: SMALL_RIPPLE_SIZE / 2,
+                  backgroundColor: touchColor,
+                  transform: [
+                    {
+                      translateX: shifting
+                        ? this.state.shifts[navigationState.index]
+                        : 0,
+                    },
+                    { scale: this.state.touch },
+                  ],
+                  opacity: this.state.touch.interpolate({
+                    inputRange: [0, 0.5, 1],
+                    outputRange: [0, 1, 0],
+                  }),
+                },
+              ]}
+            />
             {routes.map((route, index) => {
               const shift = this.state.shifts[index];
               const focused = this.state.tabs[index];
@@ -607,7 +632,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderIcon ? (
-                          renderIcon({ route, focused: true })
+                          renderIcon({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <Icon
                             style={styles.icon}
@@ -625,7 +654,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderIcon ? (
-                            renderIcon({ route, focused: false })
+                            renderIcon({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <Icon
                               style={styles.icon}
@@ -652,7 +685,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                         ]}
                       >
                         {renderLabel ? (
-                          renderLabel({ route, focused: true })
+                          renderLabel({
+                            route,
+                            focused: true,
+                            tintColor: activeColor,
+                          })
                         ) : (
                           <AnimatedText
                             style={[
@@ -662,7 +699,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                               },
                             ]}
                           >
-                            {route.title}
+                            {getLabelText({ route })}
                           </AnimatedText>
                         )}
                       </Animated.View>
@@ -674,7 +711,11 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                           ]}
                         >
                           {renderLabel ? (
-                            renderLabel({ route, focused: false })
+                            renderLabel({
+                              route,
+                              focused: false,
+                              tintColor: inactiveColor,
+                            })
                           ) : (
                             <AnimatedText
                               style={[
@@ -684,7 +725,7 @@ class BottomNavigation<T: Route> extends React.Component<Props<T>, State> {
                                 },
                               ]}
                             >
-                              {route.title}
+                              {getLabelText({ route })}
                             </AnimatedText>
                           )}
                         </Animated.View>

diff --git a/website/api/auth/index.js b/website/api/auth/index.js
index c2f1f8b..87ab9b6 100644
--- a/website/api/auth/index.js
+++ b/website/api/auth/index.js
@@ -36,13 +36,19 @@ module.exports = async function (context, req) {
 
     redirect(context, segment, tokens, '');
   } catch (error) {
+    if (!error.stack) {
+      redirect(context, segment, tokens, toBase64(error));
+      return;
+    }
     context.log(`Error: ${error.stack}`);
-    let buff = Buffer.from(error.stack);
-    let message = buff.toString('base64');
-    redirect(context, segment, tokens, message);
+    redirect(context, segment, tokens, toBase64(error.stack));
   }
 }
 
+function toBase64(str) {
+  return Buffer.from(str).toString('base64');
+}
+
 function redirect(context, segment, tokens, error) {
   const url = `${process.env['DOCS_LOCATION']}/docs/auth?segment=${segment}&access_token=${tokens.access_token}&refresh_token=${tokens.refresh_token}&expires_in=${tokens.expires_in}&error=${error}`;
   context.res = {

diff --git a/.github/workflows/linux-riscv64.yaml b/.github/workflows/linux-riscv64.yaml
new file mode 100644
index 0000000..8da3d41
--- /dev/null
+++ b/.github/workflows/linux-riscv64.yaml
@@ -0,0 +1,53 @@
+name: Linux-riscv64
+
+env:
+  DEBUG: 'napi:*'
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
+on:
+  push:
+    branches:
+      - main
+  pull_request:
+
+jobs:
+  build:
+    name: stable - riscv64-unknown-linux-gnu - node@18
+    runs-on: ubuntu-latest
+
+    steps:
+      - uses: actions/checkout@v3
+
+      - name: Setup node
+        uses: actions/setup-node@v3
+        with:
+          node-version: 18
+          cache: 'yarn'
+
+      - name: Install
+        uses: dtolnay/rust-toolchain@stable
+        with:
+          toolchain: stable
+          targets: riscv64gc-unknown-linux-gnu
+
+      - name: Cache cargo
+        uses: actions/cache@v3
+        with:
+          path: |
+            ~/.cargo/registry
+            ~/.cargo/git
+          key: stable-linux-riscv64-gnu-node@18-cargo-cache
+
+      - name: Install dependencies
+        run: |
+          sudo apt-get update
+          sudo apt-get install -y gcc-riscv64-linux-gnu
+          yarn config set --json supportedArchitectures.cpu '[""current"", ""riscv64""]'
+          yarn config set supportedArchitectures.libc ""glibc""
+          yarn install --immutable --mode=skip-build
+
+      - name: Cross build native tests
+        run: yarn build:test -- --target riscv64gc-unknown-linux-gnu
diff --git a/cli/src/api/templates/ci-template.ts b/cli/src/api/templates/ci-template.ts
index 783aa41..ee1dfdc 100644
--- a/cli/src/api/templates/ci-template.ts
+++ b/cli/src/api/templates/ci-template.ts
@@ -94,6 +94,14 @@ jobs:
           - host: windows-latest
             target: 'aarch64-pc-windows-msvc'
             build: yarn build --platform --target aarch64-pc-windows-msvc
+          - host: ubuntu-latest
+            target: 'riscv64gc-unknown-linux-gnu'
+            setup: |
+              sudo apt-get update
+              sudo apt-get install gcc-riscv64-linux-gnu -y
+            build: |
+              yarn build --platform --target riscv64gc-unknown-linux-gnu
+              riscv64-linux-gnu-strip *.node
 
     name: stable - \${{ matrix.settings.target }} - node@18
     runs-on: \${{ matrix.settings.host }}
diff --git a/cli/src/utils/ci.ts b/cli/src/utils/ci.ts
index 3084bb3..d77148d 100644
--- a/cli/src/utils/ci.ts
+++ b/cli/src/utils/ci.ts
@@ -99,4 +99,13 @@ export const CIConfig: Partial<
     ],
     test: false,
   },
+  'riscv64gc-unknown-linux-gnu': {
+    host: 'ubuntu-latest',
+    build_setup: [
+      'sudo apt-get update',
+      'sudo apt-get install g++-riscv64-linux-gnu gcc-riscv64-linux-gnu -y',
+    ],
+    // No official nodejs docker image for riscv64
+    test: false,
+  },
 }
",5,"[""317f4eefecddfb1392ca71d551840f446feee302"", ""e4a11fd5c34942ba12737f1c8c084489428ee274"", ""ded26d768ff432ad3bde3c0aa1e95ce50726100a"", ""d129eaf9125a967ac86c6c7276bbae6b4d50af36"", ""173553c0372e66e03bdab19e0e6c2dd44daa14a0""]","[""test"", ""build"", ""feat"", ""fix"", ""cicd""]"
"xfail on to_parquet and to_csv that use pyarrow write options[gn win] link comctl32.lib to fix component buildremove appear css animationadded changelog pipe docs

Added the documentation to the new changelog pipe.

Refs #284Add ability to specify release name

Signed-off-by: Matt Stratton <matt.stratton@gmail.com>","diff --git a/ibis/backends/tests/test_export.py b/ibis/backends/tests/test_export.py
index 4d536d7..5bb9775 100644
--- a/ibis/backends/tests/test_export.py
+++ b/ibis/backends/tests/test_export.py
@@ -222,18 +222,23 @@ def test_table_to_parquet(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs""), [({""version"": ""1.0""}), ({""version"": ""2.6""})])
-def test_table_to_parquet_writer_kwargs(kwargs, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.NotSupportedError,
+)
+@pytest.mark.parametrize(""version"", [""1.0"", ""2.6""])
+def test_table_to_parquet_writer_kwargs(version, tmp_path, backend, awards_players):
     outparquet = tmp_path / ""out.parquet""
-    awards_players.to_parquet(outparquet, **kwargs)
+    awards_players.to_parquet(outparquet, version=version)
 
     df = pd.read_parquet(outparquet)
 
     backend.assert_frame_equal(awards_players.to_pandas(), df)
 
-    file = pa.parquet.ParquetFile(outparquet)
+    md = pa.parquet.read_metadata(outparquet)
 
-    assert file.metadata.format_version == kwargs[""version""]
+    assert md.format_version == version
 
 
 @pytest.mark.notimpl(
@@ -316,14 +321,20 @@ def test_table_to_csv(tmp_path, backend, awards_players):
 
 
 @pytest.mark.notimpl([""flink""])
-@pytest.mark.parametrize((""kwargs"", ""delimiter""), [({""write_options"": pcsv.WriteOptions(delimiter="";"")}, "";""), ({""write_options"": pcsv.WriteOptions(delimiter=""\t"")}, ""\t"")])
-def test_table_to_csv_writer_kwargs(kwargs, delimiter, tmp_path, backend, awards_players):
+@pytest.mark.notimpl(
+    [""duckdb""],
+    reason=""cannot inline WriteOptions objects"",
+    raises=sa.exc.ProgrammingError,
+)
+@pytest.mark.parametrize(""delimiter"", ["";"", ""\t""], ids=[""semicolon"", ""tab""])
+def test_table_to_csv_writer_kwargs(delimiter, tmp_path, awards_players):
     outcsv = tmp_path / ""out.csv""
     # avoid pandas NaNonense
     awards_players = awards_players.select(""playerID"", ""awardID"", ""yearID"", ""lgID"")
 
-    awards_players.to_csv(outcsv, **kwargs)
-    pd.read_csv(outcsv, delimiter=delimiter)
+    awards_players.to_csv(outcsv, write_options=pcsv.WriteOptions(delimiter=delimiter))
+    df = pd.read_csv(outcsv, delimiter=delimiter, nrows=1)
+    assert len(df) == 1
 
 
 @pytest.mark.parametrize(

diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/src/popup/Popup.tsx b/src/popup/Popup.tsx
index d485bb6..2abc22a 100644
--- a/src/popup/Popup.tsx
+++ b/src/popup/Popup.tsx
@@ -269,7 +269,6 @@ export class Popup extends React.Component<{ t: TranslationFunction }, PopupStat
         <CSSTransition
           classNames='fade'
           in={!!currentTabUrl}
-          appear
           timeout={500}
           exit={false}
           mountOnEnter

diff --git a/docs/115-release.md b/docs/115-release.md
index 21c670a..cb893ef 100644
--- a/docs/115-release.md
+++ b/docs/115-release.md
@@ -34,6 +34,22 @@ release:
   name_template: ""{{.ProjectName}}-v{{.Version}}""
 ```
 
+## Customize the changelog
+
+You can customize how the changelog is generated using the
+`changelog` section in the config file:
+
+```yaml
+# .goreleaser.yml
+changelog:
+  filters:
+    # commit messages containing the words listed here will be removed from
+    # the changelog
+    exclude:
+      - docs
+      - typo
+```
+
 ## Custom release notes
 
 You can specify a file containing your custom release notes, and
@@ -42,8 +58,10 @@ GoReleaser will then skip its own release notes generation,
 using the contents of your file instead.
 You can use Markdown to format the contents of your file.
 
-On Unix systems you can also generate the release notes in-line by using [process substitution](https://en.wikipedia.org/wiki/Process_substitution).
-To list all commits since the last tag, but skip ones starting with `Merge` or `docs`, you could run this command:
+On Unix systems you can also generate the release notes in-line by using
+[process substitution](https://en.wikipedia.org/wiki/Process_substitution).
+To list all commits since the last tag, but skip ones starting with `Merge` or
+`docs`, you could run this command:
 
 ```sh
 goreleaser --release-notes <(git log --pretty=oneline --abbrev-commit $(git describe --tags --abbrev=0)^.. | grep -v '^[^ ]* \(Merge\|docs\)')

diff --git a/config/config.go b/config/config.go
index ee2922d..f37c4c1 100644
--- a/config/config.go
+++ b/config/config.go
@@ -116,9 +116,10 @@ type Archive struct {
 
 // Release config used for the GitHub release
 type Release struct {
-	GitHub     Repo `yaml:"",omitempty""`
-	Draft      bool `yaml:"",omitempty""`
-	Prerelease bool `yaml:"",omitempty""`
+	GitHub       Repo   `yaml:"",omitempty""`
+	Draft        bool   `yaml:"",omitempty""`
+	Prerelease   bool   `yaml:"",omitempty""`
+	NameTemplate string `yaml:"",omitempty`
 
 	// Capture all undefined fields and should be empty after loading
 	XXX map[string]interface{} `yaml:"",inline""`
diff --git a/internal/name/name.go b/internal/name/name.go
index ca5dbec..e53a0a2 100644
--- a/internal/name/name.go
+++ b/internal/name/name.go
@@ -67,6 +67,18 @@ func ForChecksums(ctx *context.Context) (string, error) {
 	)
 }
 
+// ForTitle returns the release title based upon its template
+func ForTitle(ctx *context.Context) (string, error) {
+	return apply{
+		nameData{
+			ProjectName: ctx.Config.ProjectName,
+			Tag: ctx.Git.CurrentTag,
+			Version: ctx.Version,
+		}
+		ctx.Config.Release.NameTemplate,
+	}
+}
+
 func apply(data nameData, templateStr string) (string, error) {
 	var out bytes.Buffer
 	t, err := template.New(data.ProjectName).Parse(templateStr)
diff --git a/pipeline/defaults/defaults.go b/pipeline/defaults/defaults.go
index e94ee24..9dbfce8 100644
--- a/pipeline/defaults/defaults.go
+++ b/pipeline/defaults/defaults.go
@@ -14,6 +14,9 @@ import (
 // NameTemplate default name_template for the archive.
 const NameTemplate = ""{{ .Binary }}_{{ .Version }}_{{ .Os }}_{{ .Arch }}{{ if .Arm }}v{{ .Arm }}{{ end }}""
 
+// ReleaseNameTemplate is the default name for the release.
+const ReleaseNameTemplate = ""{{ .Version }}""
+
 // SnapshotNameTemplate represents the default format for snapshot release names.
 const SnapshotNameTemplate = ""SNAPSHOT-{{ .Commit }}""
 
@@ -31,6 +34,9 @@ func (Pipe) Description() string {
 // Run the pipe
 func (Pipe) Run(ctx *context.Context) error {
 	ctx.Config.Dist = ""dist""
+	if ctx.Config.Release.NameTemplate == """" {
+		ctx.Config.Release.NameTemplate = ReleaseNameTemplate
+	}
 	if ctx.Config.Snapshot.NameTemplate == """" {
 		ctx.Config.Snapshot.NameTemplate = SnapshotNameTemplate
 	}
",5,"[""bedc7950b24c37809e36a585b7985d5aa5e3e458"", ""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""47ef9104e4a89e80d7cc6c1950bc080841da4a7b"", ""aca23027da1295c78fdf42ba9687d8ccc88784d7"", ""f823cf28652987d43c8324b4f5b203240032383a""]","[""test"", ""build"", ""refactor"", ""docs"", ""feat""]"
"[gn win] link comctl32.lib to fix component buildadd a branch name to Slack notifications (#14793)add hardware back button

Closes #5071licensinguse `regexp_instr != 0` instead of `REGEXP` keyword","diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'

diff --git a/ionic/components/app/app.ts b/ionic/components/app/app.ts
index 04d8c57..08aab92 100644
--- a/ionic/components/app/app.ts
+++ b/ionic/components/app/app.ts
@@ -3,8 +3,7 @@ import {Title} from 'angular2/platform/browser';
 
 import {Config} from '../../config/config';
 import {ClickBlock} from '../../util/click-block';
-import {Nav} from '../nav/nav';
-import {Tabs} from '../tabs/tabs';
+import {Platform} from '../../platform/platform';
 
 
 /**
@@ -23,8 +22,20 @@ export class IonicApp {
 
   constructor(
     private _config: Config,
-    private _clickBlock: ClickBlock
-  ) {}
+    private _clickBlock: ClickBlock,
+    platform: Platform
+  ) {
+    platform.backButton.subscribe(() => {
+      let activeNav = this.getActiveNav();
+      if (activeNav) {
+        if (activeNav.length() === 1) {
+          platform.exitApp();
+        } else {
+          activeNav.pop();
+        }
+      }
+    });
+  }
 
   /**
    * Sets the document title.
@@ -102,7 +113,7 @@ export class IonicApp {
   /**
    * @private
    */
-  getActiveNav(): Nav | Tabs {
+  getActiveNav(): any {
     var nav = this._rootNav || null;
     var activeChildNav;
 

diff --git a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
index d1b1821..bd1fb44 100644
--- a/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
+++ b/broker/src/test/java/io/camunda/zeebe/broker/exporter/util/ExternalExporter.java
@@ -1,3 +1,10 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
 package io.camunda.zeebe.broker.exporter.util;
 
 import io.camunda.zeebe.exporter.api.Exporter;

diff --git a/ibis/backends/snowflake/registry.py b/ibis/backends/snowflake/registry.py
index 305304f..3d5db1b 100644
--- a/ibis/backends/snowflake/registry.py
+++ b/ibis/backends/snowflake/registry.py
@@ -408,7 +408,9 @@ operation_registry.update(
         ops.DateFromYMD: fixed_arity(sa.func.date_from_parts, 3),
         ops.StringToTimestamp: fixed_arity(sa.func.to_timestamp_tz, 2),
         ops.RegexExtract: _regex_extract,
-        ops.RegexSearch: fixed_arity(sa.sql.operators.custom_op(""REGEXP""), 2),
+        ops.RegexSearch: fixed_arity(
+            lambda arg, pattern: sa.func.regexp_instr(arg, pattern) != 0, 2
+        ),
         ops.RegexReplace: fixed_arity(sa.func.regexp_replace, 3),
         ops.ExtractMicrosecond: fixed_arity(
             lambda arg: sa.cast(
",5,"[""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da"", ""68278b00450f2679761a2999500f6d87a579376b"", ""a52a585d74894b3b4eeb8c784fa089ff95cddad0"", ""06e2be4e2019b6fa714e1fcb34485860ef1ede79""]","[""build"", ""cicd"", ""feat"", ""docs"", ""fix""]"
verify checkpoint listeners are notified[gn win] link comctl32.lib to fix component buildrestructure ClusterTopology to track completed changerepository creationremove ubuntu-latest from job title where that is the only os,"diff --git a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
index c44f724..8b3ad83 100644
--- a/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
+++ b/backup/src/test/java/io/camunda/zeebe/backup/processing/CheckpointRecordsProcessorTest.java
@@ -27,6 +27,7 @@ import io.camunda.zeebe.protocol.impl.record.value.management.CheckpointRecord;
 import io.camunda.zeebe.protocol.record.RecordType;
 import io.camunda.zeebe.protocol.record.intent.management.CheckpointIntent;
 import java.nio.file.Path;
+import java.util.concurrent.atomic.AtomicLong;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -175,4 +176,69 @@ final class CheckpointRecordsProcessorTest {
     assertThat(state.getCheckpointId()).isEqualTo(checkpointId);
     assertThat(state.getCheckpointPosition()).isEqualTo(checkpointPosition);
   }
+
+  @Test
+  void shouldNotifyListenerWhenNewCheckpointCreated() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 2;
+    final long checkpointPosition = 20;
+    final CheckpointRecord value = new CheckpointRecord().setCheckpointId(checkpointId);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition, 0, CheckpointIntent.CREATE, RecordType.COMMAND, value);
+
+    // when
+    processor.process(record, resultBuilder);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerWhenReplayed() {
+    // given
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+
+    final long checkpointId = 3;
+    final long checkpointPosition = 10;
+    final CheckpointRecord value =
+        new CheckpointRecord()
+            .setCheckpointId(checkpointId)
+            .setCheckpointPosition(checkpointPosition);
+    final MockTypedCheckpointRecord record =
+        new MockTypedCheckpointRecord(
+            checkpointPosition + 1,
+            checkpointPosition,
+            CheckpointIntent.CREATED,
+            RecordType.EVENT,
+            value);
+
+    // when
+    processor.replay(record);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
+
+  @Test
+  void shouldNotifyListenerOnInit() {
+    // given
+    final var context = new Context(zeebedb, zeebedb.createContext());
+    processor = new CheckpointRecordsProcessor(backupManager);
+    final long checkpointId = 3;
+    final long checkpointPosition = 30;
+    state.setCheckpointInfo(checkpointId, checkpointPosition);
+
+    // when
+    final AtomicLong checkpoint = new AtomicLong();
+    processor.addCheckpointListener(checkpoint::set);
+    processor.init(context);
+
+    // then
+    assertThat(checkpoint).hasValue(checkpointId);
+  }
 }

diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
index e4ffc70..07707fe 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/changes/TopologyChangeCoordinatorImpl.java
@@ -150,12 +150,12 @@ public class TopologyChangeCoordinatorImpl implements TopologyChangeCoordinator 
       final ClusterTopology updatedTopology,
       final TopologyChangeAppliersImpl topologyChangeSimulator,
       final ActorFuture<ClusterTopology> simulationCompleted) {
-    if (!updatedTopology.changes().hasPendingChanges()) {
+    if (!updatedTopology.hasPendingChanges()) {
       simulationCompleted.complete(updatedTopology);
       return;
     }
 
-    final var operation = updatedTopology.changes().nextPendingOperation();
+    final var operation = updatedTopology.nextPendingOperation();
     final OperationApplier applier = topologyChangeSimulator.getApplier(operation);
     final var result = applier.init(updatedTopology);
     if (result.isLeft()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
index a521721..1f89665 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/serializer/ProtoBufSerializer.java
@@ -23,7 +23,6 @@ import io.camunda.zeebe.topology.protocol.Requests.ChangeStatus;
 import io.camunda.zeebe.topology.protocol.Topology;
 import io.camunda.zeebe.topology.protocol.Topology.CompletedChange;
 import io.camunda.zeebe.topology.protocol.Topology.MemberState;
-import io.camunda.zeebe.topology.protocol.Topology.PendingChange;
 import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterChangePlan.CompletedOperation;
 import io.camunda.zeebe.topology.state.ClusterTopology;
@@ -98,10 +97,17 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             .map(e -> Map.entry(MemberId.from(e.getKey()), decodeMemberState(e.getValue())))
             .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
 
-    final var changes = decodeChangePlan(encodedClusterTopology.getChanges());
+    final Optional<io.camunda.zeebe.topology.state.CompletedChange> completedChange =
+        encodedClusterTopology.hasLastChange()
+            ? Optional.of(decodeCompletedChange(encodedClusterTopology.getLastChange()))
+            : Optional.empty();
+    final Optional<ClusterChangePlan> currentChange =
+        encodedClusterTopology.hasCurrentChange()
+            ? Optional.of(decodeChangePlan(encodedClusterTopology.getCurrentChange()))
+            : Optional.empty();
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        encodedClusterTopology.getVersion(), members, changes);
+        encodedClusterTopology.getVersion(), members, completedChange, currentChange);
   }
 
   private Topology.ClusterTopology encodeClusterTopology(
@@ -110,12 +116,19 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
         clusterTopology.members().entrySet().stream()
             .collect(Collectors.toMap(e -> e.getKey().id(), e -> encodeMemberState(e.getValue())));
 
-    final var encodedChangePlan = encodeChangePlan(clusterTopology.changes());
-    return Topology.ClusterTopology.newBuilder()
-        .setVersion(clusterTopology.version())
-        .putAllMembers(members)
-        .setChanges(encodedChangePlan)
-        .build();
+    final var builder =
+        Topology.ClusterTopology.newBuilder()
+            .setVersion(clusterTopology.version())
+            .putAllMembers(members);
+
+    clusterTopology
+        .lastChange()
+        .ifPresent(lastChange -> builder.setLastChange(encodeCompletedChange(lastChange)));
+    clusterTopology
+        .changes()
+        .ifPresent(changePlan -> builder.setCurrentChange(encodeChangePlan(changePlan)));
+
+    return builder.build();
   }
 
   private io.camunda.zeebe.topology.state.MemberState decodeMemberState(
@@ -207,17 +220,28 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private Topology.ClusterChangePlan encodeChangePlan(final ClusterChangePlan changes) {
-    final var builder = Topology.ClusterChangePlan.newBuilder().setVersion(changes.version());
-    if (changes.ongoingChange().isPresent()) {
-      builder.setPendingChange(encodePendingChange(changes.ongoingChange().get()));
-    } else if (changes.lastChange().isPresent()) {
-      builder.setCompletedChange(encodeCompletedChange(changes.lastChange().get()));
-    }
+    final var builder =
+        Topology.ClusterChangePlan.newBuilder()
+            .setVersion(changes.version())
+            .setId(changes.id())
+            .setStatus(fromTopologyChangeStatus(changes.status()))
+            .setStartedAt(
+                Timestamp.newBuilder()
+                    .setSeconds(changes.startedAt().getEpochSecond())
+                    .setNanos(changes.startedAt().getNano())
+                    .build());
+    changes
+        .pendingOperations()
+        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
+    changes
+        .completedOperations()
+        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
+
     return builder.build();
   }
 
   private CompletedChange encodeCompletedChange(
-      final ClusterChangePlan.CompletedChange completedChange) {
+      final io.camunda.zeebe.topology.state.CompletedChange completedChange) {
     final var builder = Topology.CompletedChange.newBuilder();
     builder
         .setId(completedChange.id())
@@ -236,27 +260,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
     return builder.build();
   }
 
-  private Topology.PendingChange encodePendingChange(
-      final ClusterChangePlan.PendingChange pendingChange) {
-    final var builder = Topology.PendingChange.newBuilder();
-    builder
-        .setId(pendingChange.id())
-        .setStatus(fromTopologyChangeStatus(pendingChange.status()))
-        .setStartedAt(
-            Timestamp.newBuilder()
-                .setSeconds(pendingChange.startedAt().getEpochSecond())
-                .setNanos(pendingChange.startedAt().getNano())
-                .build());
-    pendingChange
-        .pendingOperations()
-        .forEach(operation -> builder.addPendingOperations(encodeOperation(operation)));
-    pendingChange
-        .completedOperations()
-        .forEach(operation -> builder.addCompletedOperations(encodeCompletedOperation(operation)));
-
-    return builder.build();
-  }
-
   private Topology.TopologyChangeOperation encodeOperation(
       final io.camunda.zeebe.topology.state.TopologyChangeOperation operation) {
     final var builder =
@@ -298,22 +301,31 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
   }
 
   private ClusterChangePlan decodeChangePlan(final Topology.ClusterChangePlan clusterChangePlan) {
+
     final var version = clusterChangePlan.getVersion();
-    final Optional<ClusterChangePlan.PendingChange> pendingChange =
-        clusterChangePlan.hasPendingChange()
-            ? Optional.of(decodePendingChange(clusterChangePlan.getPendingChange()))
-            : Optional.empty();
-    final Optional<ClusterChangePlan.CompletedChange> completedChange =
-        clusterChangePlan.hasCompletedChange()
-            ? Optional.of(decodeCompletedChange(clusterChangePlan.getCompletedChange()))
-            : Optional.empty();
+    final var pendingOperations =
+        clusterChangePlan.getPendingOperationsList().stream()
+            .map(this::decodeOperation)
+            .collect(Collectors.toList());
+    final var completedOperations =
+        clusterChangePlan.getCompletedOperationsList().stream()
+            .map(this::decodeCompletedOperation)
+            .collect(Collectors.toList());
 
-    return new ClusterChangePlan(version, completedChange, pendingChange);
+    return new ClusterChangePlan(
+        clusterChangePlan.getId(),
+        clusterChangePlan.getVersion(),
+        toChangeStatus(clusterChangePlan.getStatus()),
+        Instant.ofEpochSecond(
+            clusterChangePlan.getStartedAt().getSeconds(),
+            clusterChangePlan.getStartedAt().getNanos()),
+        completedOperations,
+        pendingOperations);
   }
 
-  private ClusterChangePlan.CompletedChange decodeCompletedChange(
+  private io.camunda.zeebe.topology.state.CompletedChange decodeCompletedChange(
       final CompletedChange completedChange) {
-    return new ClusterChangePlan.CompletedChange(
+    return new io.camunda.zeebe.topology.state.CompletedChange(
         completedChange.getId(),
         toChangeStatus(completedChange.getStatus()),
         Instant.ofEpochSecond(
@@ -323,25 +335,6 @@ public class ProtoBufSerializer implements ClusterTopologySerializer, TopologyRe
             completedChange.getCompletedAt().getNanos()));
   }
 
-  private ClusterChangePlan.PendingChange decodePendingChange(final PendingChange pendingChange) {
-    final var pendingOperations =
-        pendingChange.getPendingOperationsList().stream()
-            .map(this::decodeOperation)
-            .collect(Collectors.toList());
-    final var completedOperations =
-        pendingChange.getCompletedOperationsList().stream()
-            .map(this::decodeCompletedOperation)
-            .collect(Collectors.toList());
-
-    return new ClusterChangePlan.PendingChange(
-        pendingChange.getId(),
-        toChangeStatus(pendingChange.getStatus()),
-        Instant.ofEpochSecond(
-            pendingChange.getStartedAt().getSeconds(), pendingChange.getStartedAt().getNanos()),
-        completedOperations,
-        pendingOperations);
-  }
-
   private TopologyChangeOperation decodeOperation(
       final Topology.TopologyChangeOperation topologyChangeOperation) {
     if (topologyChangeOperation.hasPartitionJoin()) {
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
index 49ed70f..97a29ba 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterChangePlan.java
@@ -11,7 +11,6 @@ import io.atomix.cluster.MemberId;
 import java.time.Instant;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Optional;
 
 /**
  * Represents the ongoing cluster topology changes. The pendingOperations are executed sequentially.
@@ -23,50 +22,32 @@ import java.util.Optional;
  * gossip update out of order.
  */
 public record ClusterChangePlan(
-    int version, Optional<CompletedChange> lastChange, Optional<PendingChange> ongoingChange) {
-  public static ClusterChangePlan empty() {
-    return new ClusterChangePlan(0, Optional.empty(), Optional.empty());
-  }
+    long id,
+    int version,
+    Status status,
+    Instant startedAt,
+    List<CompletedOperation> completedOperations,
+    List<TopologyChangeOperation> pendingOperations) {
 
   public static ClusterChangePlan init(
       final long id, final List<TopologyChangeOperation> operations) {
     return new ClusterChangePlan(
-        1,
-        Optional.empty(),
-        Optional.of(
-            new PendingChange(
-                id, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations))));
+        id, 1, Status.IN_PROGRESS, Instant.now(), List.of(), List.copyOf(operations));
   }
 
   /** To be called when the first operation is completed. */
   ClusterChangePlan advance() {
     // List#subList hold on to the original list. Make a copy to prevent a potential memory leak.
-    final PendingChange pendingChange = ongoingChange.orElseThrow();
-    final List<TopologyChangeOperation> pendingOperations = pendingChange.pendingOperations();
     final var nextPendingOperations =
         List.copyOf(pendingOperations.subList(1, pendingOperations.size()));
-    final var newCompletedOperations = new ArrayList<>(pendingChange.completedOperations());
+    final var newCompletedOperations = new ArrayList<>(completedOperations);
     newCompletedOperations.add(new CompletedOperation(pendingOperations.get(0), Instant.now()));
     return new ClusterChangePlan(
-        version + 1,
-        lastChange,
-        Optional.of(
-            new PendingChange(
-                pendingChange.id(),
-                pendingChange.status(),
-                pendingChange.startedAt(),
-                newCompletedOperations,
-                nextPendingOperations)));
+        id, version + 1, status, startedAt(), newCompletedOperations, nextPendingOperations);
   }
 
-  ClusterChangePlan completed() {
-    final var pendingChange = ongoingChange.orElseThrow();
-    return new ClusterChangePlan(
-        0, // reset version
-        Optional.of(
-            new CompletedChange(
-                pendingChange.id(), Status.COMPLETED, pendingChange.startedAt(), Instant.now())),
-        Optional.empty());
+  CompletedChange completed() {
+    return new CompletedChange(id, Status.COMPLETED, startedAt(), Instant.now());
   }
 
   public ClusterChangePlan merge(final ClusterChangePlan other) {
@@ -81,35 +62,22 @@ public record ClusterChangePlan(
   }
 
   public boolean hasPendingChangesFor(final MemberId memberId) {
-    if (ongoingChange.isEmpty()) {
-      return false;
-    }
-    final var pendingOperations = ongoingChange.get().pendingOperations();
     return !pendingOperations.isEmpty() && pendingOperations.get(0).memberId().equals(memberId);
   }
 
   public TopologyChangeOperation nextPendingOperation() {
-    return ongoingChange.orElseThrow().pendingOperations().get(0);
+    return pendingOperations().get(0);
   }
 
   public boolean hasPendingChanges() {
-    return ongoingChange.isPresent() && !ongoingChange.get().pendingOperations().isEmpty();
+    return !pendingOperations().isEmpty();
   }
 
-  public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
-
-  public record PendingChange(
-      long id,
-      Status status,
-      Instant startedAt,
-      List<CompletedOperation> completedOperations,
-      List<TopologyChangeOperation> pendingOperations) {}
-
   public record CompletedOperation(TopologyChangeOperation operation, Instant completedAt) {}
 
   public enum Status {
     IN_PROGRESS,
     COMPLETED,
-    FAILED
+    FAILED;
   }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
index 544118a..3494832 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/ClusterTopology.java
@@ -12,6 +12,8 @@ import io.atomix.cluster.MemberId;
 import io.camunda.zeebe.topology.state.MemberState.State;
 import java.util.List;
 import java.util.Map;
+import java.util.Map.Entry;
+import java.util.NoSuchElementException;
 import java.util.Objects;
 import java.util.Optional;
 import java.util.function.UnaryOperator;
@@ -32,12 +34,15 @@ import java.util.stream.Stream;
  * <p>This class is immutable. Each mutable methods returns a new instance with the updated state.
  */
 public record ClusterTopology(
-    long version, Map<MemberId, MemberState> members, ClusterChangePlan changes) {
+    long version,
+    Map<MemberId, MemberState> members,
+    Optional<CompletedChange> lastChange,
+    Optional<ClusterChangePlan> changes) {
 
   private static final int UNINITIALIZED_VERSION = -1;
 
   public static ClusterTopology uninitialized() {
-    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(UNINITIALIZED_VERSION, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public boolean isUninitialized() {
@@ -45,7 +50,7 @@ public record ClusterTopology(
   }
 
   public static ClusterTopology init() {
-    return new ClusterTopology(0, Map.of(), ClusterChangePlan.empty());
+    return new ClusterTopology(0, Map.of(), Optional.empty(), Optional.empty());
   }
 
   public ClusterTopology addMember(final MemberId memberId, final MemberState state) {
@@ -58,7 +63,7 @@ public record ClusterTopology(
 
     final var newMembers =
         ImmutableMap.<MemberId, MemberState>builder().putAll(members).put(memberId, state).build();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   /**
@@ -96,7 +101,7 @@ public record ClusterTopology(
     }
 
     final var newMembers = mapBuilder.buildKeepingLast();
-    return new ClusterTopology(version, newMembers, changes);
+    return new ClusterTopology(version, newMembers, lastChange, changes);
   }
 
   public ClusterTopology startTopologyChange(final List<TopologyChangeOperation> operations) {
@@ -110,7 +115,10 @@ public record ClusterTopology(
     } else {
       final long newVersion = version + 1;
       return new ClusterTopology(
-          newVersion, members, ClusterChangePlan.init(newVersion, operations));
+          newVersion,
+          members,
+          lastChange,
+          Optional.of(ClusterChangePlan.init(newVersion, operations)));
     }
   }
 
@@ -130,20 +138,28 @@ public record ClusterTopology(
     } else {
       final var mergedMembers =
           Stream.concat(members.entrySet().stream(), other.members().entrySet().stream())
-              .collect(
-                  Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, MemberState::merge));
+              .collect(Collectors.toMap(Entry::getKey, Entry::getValue, MemberState::merge));
 
-      final var mergedChanges = changes.merge(other.changes);
-      return new ClusterTopology(version, ImmutableMap.copyOf(mergedMembers), mergedChanges);
+      final Optional<ClusterChangePlan> mergedChanges =
+          Stream.of(changes, other.changes)
+              .flatMap(Optional::stream)
+              .reduce(ClusterChangePlan::merge);
+
+      return new ClusterTopology(
+          version, ImmutableMap.copyOf(mergedMembers), lastChange, mergedChanges);
     }
   }
 
+  public boolean hasPendingChanges() {
+    return changes.isPresent() && changes.orElseThrow().hasPendingChanges();
+  }
+
   /**
    * @return true if the next operation in pending changes is applicable for the given memberId,
    *     otherwise returns false.
    */
   private boolean hasPendingChangesFor(final MemberId memberId) {
-    return changes.hasPendingChangesFor(memberId);
+    return changes.isPresent() && changes.get().hasPendingChangesFor(memberId);
   }
 
   /**
@@ -157,7 +173,7 @@ public record ClusterTopology(
     if (!hasPendingChangesFor(memberId)) {
       return Optional.empty();
     }
-    return Optional.of(changes.nextPendingOperation());
+    return Optional.of(changes.orElseThrow().nextPendingOperation());
   }
 
   /**
@@ -179,7 +195,9 @@ public record ClusterTopology(
       throw new IllegalStateException(
           ""Expected to advance the topology change, but there is no pending change"");
     }
-    final ClusterTopology result = new ClusterTopology(version, members, changes.advance());
+    final ClusterTopology result =
+        new ClusterTopology(
+            version, members, lastChange, Optional.of(changes.orElseThrow().advance()));
 
     if (!result.hasPendingChanges()) {
       // The last change has been applied. Clean up the members that are marked as LEFT in the
@@ -194,7 +212,9 @@ public record ClusterTopology(
               .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 
       // Increment the version so that other members can merge by overwriting their local topology.
-      return new ClusterTopology(result.version() + 1, currentMembers, changes.completed());
+      final var completedChange = changes.orElseThrow().completed();
+      return new ClusterTopology(
+          result.version() + 1, currentMembers, Optional.of(completedChange), Optional.empty());
     }
 
     return result;
@@ -208,10 +228,6 @@ public record ClusterTopology(
     return members().get(memberId);
   }
 
-  public boolean hasPendingChanges() {
-    return changes.hasPendingChanges();
-  }
-
   public int clusterSize() {
     return (int)
         members.entrySet().stream()
@@ -226,4 +242,11 @@ public record ClusterTopology(
     return (int)
         members.values().stream().flatMap(m -> m.partitions().keySet().stream()).distinct().count();
   }
+
+  public TopologyChangeOperation nextPendingOperation() {
+    if (!hasPendingChanges()) {
+      throw new NoSuchElementException();
+    }
+    return changes.orElseThrow().nextPendingOperation();
+  }
 }
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
new file mode 100644
index 0000000..7031e88
--- /dev/null
+++ b/topology/src/main/java/io/camunda/zeebe/topology/state/CompletedChange.java
@@ -0,0 +1,13 @@
+/*
+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under
+ * one or more contributor license agreements. See the NOTICE file distributed
+ * with this work for additional information regarding copyright ownership.
+ * Licensed under the Zeebe Community License 1.1. You may not use this file
+ * except in compliance with the Zeebe Community License 1.1.
+ */
+package io.camunda.zeebe.topology.state;
+
+import io.camunda.zeebe.topology.state.ClusterChangePlan.Status;
+import java.time.Instant;
+
+public record CompletedChange(long id, Status status, Instant startedAt, Instant completedAt) {}
diff --git a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
index 5861c7c..ef94a1f 100644
--- a/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
+++ b/topology/src/main/java/io/camunda/zeebe/topology/util/TopologyUtil.java
@@ -10,13 +10,13 @@ package io.camunda.zeebe.topology.util;
 import io.atomix.cluster.MemberId;
 import io.atomix.primitive.partition.PartitionId;
 import io.atomix.primitive.partition.PartitionMetadata;
-import io.camunda.zeebe.topology.state.ClusterChangePlan;
 import io.camunda.zeebe.topology.state.ClusterTopology;
 import io.camunda.zeebe.topology.state.MemberState;
 import io.camunda.zeebe.topology.state.PartitionState;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Optional;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -42,7 +42,7 @@ public final class TopologyUtil {
     }
 
     return new io.camunda.zeebe.topology.state.ClusterTopology(
-        0, Map.copyOf(memberStates), ClusterChangePlan.empty());
+        0, Map.copyOf(memberStates), Optional.empty(), Optional.empty());
   }
 
   public static Set<PartitionMetadata> getPartitionDistributionFrom(

diff --git a/server/src/services/repository.service.ts b/server/src/services/repository.service.ts
index 3869c98..d675b30 100644
--- a/server/src/services/repository.service.ts
+++ b/server/src/services/repository.service.ts
@@ -19,6 +19,8 @@ export class RepositoryService {
       return;
     }
 
+    await this.createTeam(this.github, this.getTeamName(course), course.id);
+
     const studentRepo = getCustomRepository(StudentRepository);
     const students = await studentRepo.findActiveByCourseId(this.courseId);
 
@@ -31,8 +33,8 @@ export class RepositoryService {
         if (mentorGithubId) {
           await this.inviteMentor(mentorGithubId, course);
         }
-        await this.addTeamToRepository(this.github, course, student.githubId);
       }
+      await this.addTeamToRepository(this.github, course, student.githubId);
       if (record?.repository) {
         result.push({ repository: record.repository });
       }

diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index 4dea4c9..006290a 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -122,7 +122,7 @@ jobs:
           path: junit.xml
 
   test_postgres:
-    name: PostgreSQL ubuntu-latest deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
+    name: PostgreSQL deps-${{ (matrix.deps && """") || ""un"" }}bounded python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -204,7 +204,7 @@ jobs:
           path: junit.xml
 
   test_pyspark:
-    name: PySpark ${{ matrix.pyspark.version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: PySpark ${{ matrix.pyspark.version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -279,7 +279,7 @@ jobs:
           path: junit.xml
 
   test_impala:
-    name: Impala ubuntu-latest python-${{ matrix.python-version }}
+    name: Impala python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     env:
       IBIS_TEST_NN_HOST: localhost
@@ -386,7 +386,7 @@ jobs:
           path: junit.xml
 
   test_mysql_clickhouse:
-    name: ${{ matrix.backend.title }} ubuntu-latest python-${{ matrix.python-version }}
+    name: ${{ matrix.backend.title }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
@@ -460,7 +460,7 @@ jobs:
           path: junit.xml
 
   test_datafusion:
-    name: DataFusion ${{ matrix.datafusion-version }} ubuntu-latest python-${{ matrix.python-version }}
+    name: DataFusion ${{ matrix.datafusion-version }} python-${{ matrix.python-version }}
     runs-on: ubuntu-latest
     strategy:
       fail-fast: false
",5,"[""e0198f74b81da3663144cfe1d971939319f82a0f"", ""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""3cca5c314ad6feeffbfe1f14cf49ebd0fd9a95a2"", ""87d5d4e55ab7149b593d29410f1fe426ba2447d4"", ""74e9de5ec97dc013a52aa063dff0f40ac74c407b""]","[""test"", ""build"", ""refactor"", ""fix"", ""cicd""]"
"buffer assert and bpmn model api helper class

related to camunda-tngp/camunda-tngp#23fix build orderingrepository creationadd a branch name to Slack notifications (#14793)add benchmark for known-slow table expression","diff --git a/test-util/pom.xml b/test-util/pom.xml
index a097651..b6518ee 100644
--- a/test-util/pom.xml
+++ b/test-util/pom.xml
@@ -20,6 +20,7 @@
     <project.build.sourceEncoding>utf-8</project.build.sourceEncoding>
     <!-- TODO: Move to common parent -->
     <agrona.version>0.4.11</agrona.version>
+    <camunda.version>7.6.0-SNAPSHOT</camunda.version>
   </properties>
 
   <dependencies>
@@ -30,6 +31,13 @@
       <version>${agrona.version}</version>
       <scope>provided</scope>
     </dependency>
+    
+    <dependency>
+      <groupId>org.camunda.bpm.model</groupId>
+      <artifactId>camunda-bpmn-model</artifactId>
+      <version>${camunda.version}</version>
+      <scope>provided</scope>
+    </dependency>
 
     <dependency>
       <groupId>junit</groupId>
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
index 37e3a6f..b8d9b26 100644
--- a/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/BufferAssert.java
@@ -14,7 +14,7 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         super(actual, BufferAssert.class);
     }
 
-    public static BufferAssert assertThat(DirectBuffer buffer)
+    public static BufferAssert assertThatBuffer(DirectBuffer buffer)
     {
         return new BufferAssert(buffer);
     }
@@ -41,4 +41,16 @@ public class BufferAssert extends AbstractAssert<BufferAssert, DirectBuffer>
         return hasBytes(expected, 0);
     }
 
+    public BufferAssert hasCapacity(int expectedCapacity)
+    {
+        isNotNull();
+
+        if (expectedCapacity != actual.capacity())
+        {
+            failWithMessage(""Expected capacity "" + expectedCapacity + "" but was "" + actual.capacity());
+        }
+
+        return this;
+    }
+
 }
diff --git a/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
new file mode 100644
index 0000000..6f0d134
--- /dev/null
+++ b/test-util/src/main/java/org/camunda/tngp/broker/test/util/bpmn/TngpModelInstance.java
@@ -0,0 +1,121 @@
+package org.camunda.tngp.broker.test.util.bpmn;
+
+import java.util.Collection;
+
+import org.camunda.bpm.model.bpmn.BpmnModelInstance;
+import org.camunda.bpm.model.bpmn.impl.BpmnModelConstants;
+import org.camunda.bpm.model.bpmn.instance.Definitions;
+import org.camunda.bpm.model.xml.Model;
+import org.camunda.bpm.model.xml.instance.DomDocument;
+import org.camunda.bpm.model.xml.instance.ModelElementInstance;
+import org.camunda.bpm.model.xml.type.ModelElementType;
+import org.camunda.bpm.model.xml.validation.ModelElementValidator;
+import org.camunda.bpm.model.xml.validation.ValidationResults;
+
+public class TngpModelInstance implements BpmnModelInstance
+{
+    protected BpmnModelInstance wrappedInstance;
+
+    public TngpModelInstance(BpmnModelInstance wrappedInstance)
+    {
+        this.wrappedInstance = wrappedInstance;
+    }
+
+    @Override
+    public DomDocument getDocument()
+    {
+        return wrappedInstance.getDocument();
+    }
+
+    @Override
+    public ModelElementInstance getDocumentElement()
+    {
+        return wrappedInstance.getDocumentElement();
+    }
+
+    @Override
+    public void setDocumentElement(ModelElementInstance documentElement)
+    {
+        wrappedInstance.setDocumentElement(documentElement);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(Class<T> type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T newInstance(ModelElementType type)
+    {
+        return wrappedInstance.newInstance(type);
+    }
+
+    @Override
+    public Model getModel()
+    {
+        return wrappedInstance.getModel();
+    }
+
+    @Override
+    public <T extends ModelElementInstance> T getModelElementById(String id)
+    {
+        return wrappedInstance.getModelElementById(id);
+    }
+
+    @Override
+    public Collection<ModelElementInstance> getModelElementsByType(ModelElementType referencingType)
+    {
+        return wrappedInstance.getModelElementsByType(referencingType);
+    }
+
+    @Override
+    public <T extends ModelElementInstance> Collection<T> getModelElementsByType(Class<T> referencingClass)
+    {
+        return wrappedInstance.getModelElementsByType(referencingClass);
+    }
+
+    @Override
+    public ValidationResults validate(Collection<ModelElementValidator<?>> validators)
+    {
+        return wrappedInstance.validate(validators);
+    }
+
+    @Override
+    public BpmnModelInstance clone()
+    {
+        return wrappedInstance.clone();
+    }
+
+    @Override
+    public Definitions getDefinitions()
+    {
+        return wrappedInstance.getDefinitions();
+    }
+
+    @Override
+    public void setDefinitions(Definitions arg0)
+    {
+        wrappedInstance.setDefinitions(arg0);
+    }
+
+    public TngpModelInstance taskAttributes(String taskId, String taskType, int taskQueueId)
+    {
+        final ModelElementInstance task = wrappedInstance.getModelElementById(taskId);
+
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskType"", taskType);
+        task.setAttributeValueNs(BpmnModelConstants.CAMUNDA_NS, ""taskQueueId"", String.valueOf(taskQueueId));
+
+        return this;
+    }
+
+    public static TngpModelInstance wrap(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance);
+    }
+
+    public static TngpModelInstance wrapCopy(BpmnModelInstance modelInstance)
+    {
+        return new TngpModelInstance(modelInstance.clone());
+    }
+}

diff --git a/scripts/build.mjs b/scripts/build.mjs
index 204854f..b3cf067 100644
--- a/scripts/build.mjs
+++ b/scripts/build.mjs
@@ -3,8 +3,8 @@ import { write } from 'fsxx';
 import { info, success } from './helpers.mjs';
 
 await $`rm -rf dist/*`;
-await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 await $`unbuild`;
+await $`esbuild src/react/react.ts --legal-comments=none --minify --outfile=dist/code-size-measurement.js`;
 
 const packages = [
   'jsx-runtime',

diff --git a/server/src/services/repository.service.ts b/server/src/services/repository.service.ts
index 3869c98..d675b30 100644
--- a/server/src/services/repository.service.ts
+++ b/server/src/services/repository.service.ts
@@ -19,6 +19,8 @@ export class RepositoryService {
       return;
     }
 
+    await this.createTeam(this.github, this.getTeamName(course), course.id);
+
     const studentRepo = getCustomRepository(StudentRepository);
     const students = await studentRepo.findActiveByCourseId(this.courseId);
 
@@ -31,8 +33,8 @@ export class RepositoryService {
         if (mentorGithubId) {
           await this.inviteMentor(mentorGithubId, course);
         }
-        await this.addTeamToRepository(this.github, course, student.githubId);
       }
+      await this.addTeamToRepository(this.github, course, student.githubId);
       if (record?.repository) {
         result.push({ repository: record.repository });
       }

diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'

diff --git a/.gitignore b/.gitignore
index 2e99ad3..eef9203 100644
--- a/.gitignore
+++ b/.gitignore
@@ -95,3 +95,4 @@ docs/backends/support_matrix.csv
 __pycache__
 tags
 .DS_Store
+prof/
diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index ac19aaf..36aed0e 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -602,3 +602,93 @@ def test_multiple_joins(benchmark, num_joins, num_columns):
         name=""t"",
     )
     benchmark(multiple_joins, table, num_joins)
+
+
+@pytest.fixture
+def customers():
+    return ibis.table(
+        dict(
+            customerid=""int32"",
+            name=""string"",
+            address=""string"",
+            citystatezip=""string"",
+            birthdate=""date"",
+            phone=""string"",
+            timezone=""string"",
+            lat=""float64"",
+            long=""float64"",
+        ),
+        name=""customers"",
+    )
+
+
+@pytest.fixture
+def orders():
+    return ibis.table(
+        dict(
+            orderid=""int32"",
+            customerid=""int32"",
+            ordered=""timestamp"",
+            shipped=""timestamp"",
+            items=""string"",
+            total=""float64"",
+        ),
+        name=""orders"",
+    )
+
+
+@pytest.fixture
+def orders_items():
+    return ibis.table(
+        dict(orderid=""int32"", sku=""string"", qty=""int32"", unit_price=""float64""),
+        name=""orders_items"",
+    )
+
+
+@pytest.fixture
+def products():
+    return ibis.table(
+        dict(
+            sku=""string"",
+            desc=""string"",
+            weight_kg=""float64"",
+            cost=""float64"",
+            dims_cm=""string"",
+        ),
+        name=""products"",
+    )
+
+
+@pytest.mark.benchmark(group=""compilation"")
+@pytest.mark.parametrize(
+    ""module"",
+    [
+        pytest.param(
+            mod,
+            marks=pytest.mark.xfail(
+                condition=mod in _XFAIL_COMPILE_BACKENDS,
+                reason=f""{mod} backend doesn't support compiling UnboundTable"",
+            ),
+        )
+        for mod in _backends
+    ],
+)
+def test_compile_with_drops(
+    benchmark, module, customers, orders, orders_items, products
+):
+    expr = (
+        customers.join(orders, ""customerid"")
+        .join(orders_items, ""orderid"")
+        .join(products, ""sku"")
+        .drop(""customerid"", ""qty"", ""total"", ""items"")
+        .drop(""dims_cm"", ""cost"")
+        .mutate(o_date=lambda t: t.shipped.date())
+        .filter(lambda t: t.ordered == t.shipped)
+    )
+
+    try:
+        mod = getattr(ibis, module)
+    except (AttributeError, ImportError) as e:
+        pytest.skip(str(e))
+    else:
+        benchmark(mod.compile, expr)
",5,"[""6ed56ce9ae743ba9a87e6c9643cc06b1de7b748d"", ""c323d59c607cabc91f17a78528d998f376f30b10"", ""87d5d4e55ab7149b593d29410f1fe426ba2447d4"", ""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da"", ""e9617f0854030e70365eb264bcb3b58078e79e9e""]","[""feat"", ""build"", ""fix"", ""cicd"", ""test""]"
"[gn win] link comctl32.lib to fix component buildadd benchmark for known-slow table expressionadded suported tuple typesadd hardware back button

Closes #5071add remote [skip ci]","diff --git a/BUILD.gn b/BUILD.gn
index 571f528..7924a3d 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -676,8 +676,9 @@ if (is_mac) {
       ]
 
       libs = [
-        ""wtsapi32.lib"",
+        ""comctl32.lib"",
         ""uiautomationcore.lib"",
+        ""wtsapi32.lib"",
       ]
 
       configs += [ ""//build/config/win:windowed"" ]

diff --git a/.gitignore b/.gitignore
index 2e99ad3..eef9203 100644
--- a/.gitignore
+++ b/.gitignore
@@ -95,3 +95,4 @@ docs/backends/support_matrix.csv
 __pycache__
 tags
 .DS_Store
+prof/
diff --git a/ibis/tests/benchmarks/test_benchmarks.py b/ibis/tests/benchmarks/test_benchmarks.py
index ac19aaf..36aed0e 100644
--- a/ibis/tests/benchmarks/test_benchmarks.py
+++ b/ibis/tests/benchmarks/test_benchmarks.py
@@ -602,3 +602,93 @@ def test_multiple_joins(benchmark, num_joins, num_columns):
         name=""t"",
     )
     benchmark(multiple_joins, table, num_joins)
+
+
+@pytest.fixture
+def customers():
+    return ibis.table(
+        dict(
+            customerid=""int32"",
+            name=""string"",
+            address=""string"",
+            citystatezip=""string"",
+            birthdate=""date"",
+            phone=""string"",
+            timezone=""string"",
+            lat=""float64"",
+            long=""float64"",
+        ),
+        name=""customers"",
+    )
+
+
+@pytest.fixture
+def orders():
+    return ibis.table(
+        dict(
+            orderid=""int32"",
+            customerid=""int32"",
+            ordered=""timestamp"",
+            shipped=""timestamp"",
+            items=""string"",
+            total=""float64"",
+        ),
+        name=""orders"",
+    )
+
+
+@pytest.fixture
+def orders_items():
+    return ibis.table(
+        dict(orderid=""int32"", sku=""string"", qty=""int32"", unit_price=""float64""),
+        name=""orders_items"",
+    )
+
+
+@pytest.fixture
+def products():
+    return ibis.table(
+        dict(
+            sku=""string"",
+            desc=""string"",
+            weight_kg=""float64"",
+            cost=""float64"",
+            dims_cm=""string"",
+        ),
+        name=""products"",
+    )
+
+
+@pytest.mark.benchmark(group=""compilation"")
+@pytest.mark.parametrize(
+    ""module"",
+    [
+        pytest.param(
+            mod,
+            marks=pytest.mark.xfail(
+                condition=mod in _XFAIL_COMPILE_BACKENDS,
+                reason=f""{mod} backend doesn't support compiling UnboundTable"",
+            ),
+        )
+        for mod in _backends
+    ],
+)
+def test_compile_with_drops(
+    benchmark, module, customers, orders, orders_items, products
+):
+    expr = (
+        customers.join(orders, ""customerid"")
+        .join(orders_items, ""orderid"")
+        .join(products, ""sku"")
+        .drop(""customerid"", ""qty"", ""total"", ""items"")
+        .drop(""dims_cm"", ""cost"")
+        .mutate(o_date=lambda t: t.shipped.date())
+        .filter(lambda t: t.ordered == t.shipped)
+    )
+
+    try:
+        mod = getattr(ibis, module)
+    except (AttributeError, ImportError) as e:
+        pytest.skip(str(e))
+    else:
+        benchmark(mod.compile, expr)

diff --git a/src/List/Tuple.ts b/src/List/Tuple.ts
index 4c59caa..6e45503 100644
--- a/src/List/Tuple.ts
+++ b/src/List/Tuple.ts
@@ -1,15 +1,17 @@
-/** A [[Tuple]]
+import {NonNullable} from '../Object/NonNullable'
+
+/** A [[Tuple]] (supported)
  * @param A its type
- * @returns **`any[]`**
+ * @returns **`A[]`**
  * @example
  * ```ts
- * type list0 = [1, 2, 3]
- * type list1 = number[]
+ * type tuple0 = [1, 20, 42]
+ * type tuple1 = ['at', 420]
  * ```
  */
-export type Tuple = [
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-    any?, any?, any?, any?, any?, any?, any?, any?, any?, any?,
-]
+export type Tuple<A = any> = NonNullable<[
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+    A?, A?, A?, A?, A?, A?, A?, A?, A?, A?,
+]>

diff --git a/ionic/components/app/app.ts b/ionic/components/app/app.ts
index 04d8c57..08aab92 100644
--- a/ionic/components/app/app.ts
+++ b/ionic/components/app/app.ts
@@ -3,8 +3,7 @@ import {Title} from 'angular2/platform/browser';
 
 import {Config} from '../../config/config';
 import {ClickBlock} from '../../util/click-block';
-import {Nav} from '../nav/nav';
-import {Tabs} from '../tabs/tabs';
+import {Platform} from '../../platform/platform';
 
 
 /**
@@ -23,8 +22,20 @@ export class IonicApp {
 
   constructor(
     private _config: Config,
-    private _clickBlock: ClickBlock
-  ) {}
+    private _clickBlock: ClickBlock,
+    platform: Platform
+  ) {
+    platform.backButton.subscribe(() => {
+      let activeNav = this.getActiveNav();
+      if (activeNav) {
+        if (activeNav.length() === 1) {
+          platform.exitApp();
+        } else {
+          activeNav.pop();
+        }
+      }
+    });
+  }
 
   /**
    * Sets the document title.
@@ -102,7 +113,7 @@ export class IonicApp {
   /**
    * @private
    */
-  getActiveNav(): Nav | Tabs {
+  getActiveNav(): any {
     var nav = this._rootNav || null;
     var activeChildNav;
 

diff --git a/.github/workflows/ibis-rebase-nightly.yml b/.github/workflows/ibis-rebase-nightly.yml
index 06c9003..e19c703 100644
--- a/.github/workflows/ibis-rebase-nightly.yml
+++ b/.github/workflows/ibis-rebase-nightly.yml
@@ -47,7 +47,10 @@ jobs:
           git config --global user.email 'ibis-squawk-bot[bot]@users.noreply.github.com'
 
       - name: fetch and rebase on top of upstream
-        run: git pull --rebase -X ours https://github.com/ibis-project/ibis master
+        run: |
+          git remote add upstream https://github.com/ibis-project/ibis
+          git fetch upstream
+          git rebase -X ours upstream/master
 
       - uses: tibdex/github-app-token@v1
         id: generate_pr_token
",5,"[""5b81fde8a72cf2e69a10e9f5c4f0bea0a2b8c3e0"", ""e9617f0854030e70365eb264bcb3b58078e79e9e"", ""2954a0955ce9af6acb345ed1e8328e145ad30475"", ""68278b00450f2679761a2999500f6d87a579376b"", ""e96487ad7ce90b141219d9032fa2bed68d5dae6a""]","[""build"", ""test"", ""refactor"", ""feat"", ""cicd""]"
"run pyspark tests in parallelexport a modal transition presetnginx forward L7 headers from LB

Signed-off-by: rjshrjndrn <rjshrjndrn@gmail.com>enable user to re-order attachment in modal view

re #383

Signed-off-by: Pranav C <pranavxc@gmail.com>fix default value for `cache.enabled`

Previously it was required to have the `cache.enabled` explicitly enabled
even with ts-morph provider, otherwise CLI cache commands would fail to run.","diff --git a/.github/workflows/ibis-backends.yml b/.github/workflows/ibis-backends.yml
index e23088e..9708157 100644
--- a/.github/workflows/ibis-backends.yml
+++ b/.github/workflows/ibis-backends.yml
@@ -202,11 +202,11 @@ jobs:
         run: poetry install --without dev --without docs --extras ${{ matrix.backend.name }} --extras geospatial
 
       - name: ""run parallel tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name != 'pyspark' && matrix.backend.name != 'impala'
+        if: matrix.backend.name != 'impala'
         run: just ci-check -m ${{ matrix.backend.name }} --numprocesses auto --dist=loadgroup
 
       - name: ""run serial tests: ${{ matrix.backend.name }}""
-        if: matrix.backend.name == 'pyspark' || matrix.backend.name == 'impala'
+        if: matrix.backend.name == 'impala'
         run: just ci-check -m ${{ matrix.backend.name }}
         env:
           IBIS_TEST_NN_HOST: localhost

diff --git a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
index f1066a1..ae93dca 100644
--- a/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
+++ b/packages/stack/src/TransitionConfigs/TransitionPresets.tsx
@@ -79,3 +79,8 @@ export const DefaultTransition = Platform.select({
       ? FadeFromBottomAndroid
       : WipeFromBottomAndroid,
 });
+
+export const ModalTransition = Platform.select({
+  ios: ModalSlideFromBottomIOS,
+  default: DefaultTransition,
+});
diff --git a/packages/stack/src/views/Stack/Stack.tsx b/packages/stack/src/views/Stack/Stack.tsx
index cf1719c..47c1abf 100755
--- a/packages/stack/src/views/Stack/Stack.tsx
+++ b/packages/stack/src/views/Stack/Stack.tsx
@@ -14,7 +14,7 @@ import { Props as HeaderContainerProps } from '../Header/HeaderContainer';
 import StackItem from './StackItem';
 import {
   DefaultTransition,
-  ModalSlideFromBottomIOS,
+  ModalTransition,
 } from '../../TransitionConfigs/TransitionPresets';
 import { forNoAnimation } from '../../TransitionConfigs/HeaderStyleInterpolators';
 import {
@@ -301,9 +301,7 @@ export default class Stack extends React.Component<Props, State> {
     const focusedOptions = descriptors[focusedRoute.key].options;
 
     let defaultTransitionPreset =
-      mode === 'modal' && Platform.OS === 'ios'
-        ? ModalSlideFromBottomIOS
-        : DefaultTransition;
+      mode === 'modal' ? ModalTransition : DefaultTransition;
 
     if (headerMode === 'screen') {
       defaultTransitionPreset = {

diff --git a/scripts/helmcharts/vars.yaml b/scripts/helmcharts/vars.yaml
index 5c02f57..163b7d2 100644
--- a/scripts/helmcharts/vars.yaml
+++ b/scripts/helmcharts/vars.yaml
@@ -54,6 +54,10 @@ ingress-nginx: &ingress-nginx
       default-ssl-certificate: ""app/openreplay-ssl""
     config:
       enable-real-ip: true
+      # Enable LB forwarded protocol
+      # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers
+      # https://github.com/nginxinc/kubernetes-ingress/issues/1284#issuecomment-872869354
+      # use-forwarded-headers: true
       # Ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#max-worker-connections
       max-worker-connections: 0
       # SSL redirection

diff --git a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
index 7e9d06c..cbc5775 100644
--- a/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
+++ b/packages/nc-gui/components/project/spreadsheet/components/editableCell/editableAttachmentCell.vue
@@ -18,13 +18,16 @@
     </div>
 
     <div class=""d-flex align-center img-container"">
-      <div v-for=""(item,i) in localState"" :key=""i"" class=""thumbnail align-center justify-center d-flex"">
+      <div
+        v-for=""(item,i) in localState""
+        :key=""item.url""
+        class=""thumbnail align-center justify-center d-flex""
+      >
         <v-tooltip bottom>
           <template #activator=""{on}"">
             <!--            <img alt=""#"" v-if=""isImage(item.title)"" :src=""item.url"" v-on=""on"" @click=""selectImage(item.url,i)"">-->
             <v-img
               v-if=""isImage(item.title)""
-              :key=""item.url""
               lazy-src=""https://via.placeholder.com/60.png?text=Loading...""
               alt=""#""
               max-height=""33px""
@@ -89,7 +92,11 @@
 
           <div class=""d-flex flex-wrap h-100"">
             <v-container fluid style=""max-height:calc(90vh - 80px);overflow-y: auto"">
-              <v-row>
+              <draggable
+                v-model=""localState""
+                class=""row""
+                @update=""onOrderUpdate""
+              >
                 <v-col v-for=""(item,i) in localState"" :key=""i"" cols=""4"">
                   <v-card
                     class=""modal-thumbnail-card align-center justify-center d-flex""
@@ -125,7 +132,7 @@
                     {{ item.title }}
                   </p>
                 </v-col>
-              </v-row>
+              </draggable>
             </v-container>
           </div>
         </v-card-text>
@@ -216,9 +223,12 @@
 
 <script>
 import FileSaver from 'file-saver'
+import draggable from 'vuedraggable'
 import { isImage } from '@/components/project/spreadsheet/helpers/imageExt'
+
 export default {
   name: 'EditableAttachmentCell',
+  components: { draggable },
   props: ['dbAlias', 'value', 'active', 'isLocked', 'meta', 'column'],
   data: () => ({
     carousel: null,
@@ -301,6 +311,10 @@ export default {
       this.$emit('input', JSON.stringify(this.localState))
       this.$emit('update')
     },
+    onOrderUpdate() {
+      this.$emit('input', JSON.stringify(this.localState))
+      this.$emit('update')
+    },
     removeItem(i) {
       this.localState.splice(i, 1)
       this.$emit('input', JSON.stringify(this.localState))
@@ -394,18 +408,19 @@ export default {
   top: 5px;
   right: 5px
 }
-.modal-thumbnail-card{
+
+.modal-thumbnail-card {
 
   .download-icon {
     position: absolute;
     bottom: 5px;
     right: 5px;
-    opacity:0;
-    transition:.4s opacity;
+    opacity: 0;
+    transition: .4s opacity;
   }
 
-  &:hover .download-icon{
-    opacity:1
+  &:hover .download-icon {
+    opacity: 1
   }
 }
 

diff --git a/packages/core/src/utils/Configuration.ts b/packages/core/src/utils/Configuration.ts
index 95516ba..a869a32 100644
--- a/packages/core/src/utils/Configuration.ts
+++ b/packages/core/src/utils/Configuration.ts
@@ -183,7 +183,7 @@ export class Configuration<D extends IDatabaseDriver = IDatabaseDriver> {
       this.options.cache.adapter = NullCacheAdapter;
     }
 
-    if ('enabled' in this.options.cache) {
+    if (!('enabled' in this.options.cache)) {
       this.options.cache.enabled = this.getMetadataProvider().useCache();
     }
 
",5,"[""4cbbd2552ba0de273e1dfe7d453c5b3efed751a3"", ""535708ae50aecb452560a23356fd396f99ef13a2"", ""e12d9e77a6fd531a22325337838a841b1c67f00d"", ""fd8e563cc19ca4684885d4692acee6bebcca4ada"", ""9be725fa3906323d4bc9788f54eccf74109d632b""]","[""cicd"", ""refactor"", ""docs"", ""feat"", ""fix""]"
add a branch name to Slack notifications (#14793)autostart feature fixeddetach ViewControllers when not activeFix typomake it mode less,"diff --git a/.circleci/config.yml b/.circleci/config.yml
index d0c7bd1..cd5d2cc 100644
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -50,7 +50,7 @@ step-maybe-notify-slack-failure: &step-maybe-notify-slack-failure
     name: Send a Slack notification on failure
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build failed for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
@@ -61,7 +61,7 @@ step-maybe-notify-slack-success: &step-maybe-notify-slack-success
     name: Send a Slack notification on success
     command: |
       if [ ""$NOTIFY_SLACK"" == ""true"" ]; then
-        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build.""
+        export MESSAGE=""Build succeeded for *<$CIRCLE_BUILD_URL|$CIRCLE_JOB>* nightly build from *$CIRCLE_BRANCH*.""
         curl -g -H ""Content-Type: application/json"" -X POST \
         -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$CIRCLE_JOB nightly build results\"",\""title_link\"": \""$CIRCLE_BUILD_URL\""}]}"" $SLACK_WEBHOOK
       fi
diff --git a/vsts.yml b/vsts.yml
index c02d13a..2e72426 100644
--- a/vsts.yml
+++ b/vsts.yml
@@ -128,7 +128,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build failed for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""#FC5C3C\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Failure'
@@ -136,7 +136,7 @@ jobs:
 
   - bash: |
       export BUILD_URL=""${SYSTEM_TEAMFOUNDATIONCOLLECTIONURI}${SYSTEM_TEAMPROJECT}/_build/results?buildId=${BUILD_BUILDID}""
-      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build.""
+      export MESSAGE=""Build succeeded for *<$BUILD_URL|$BUILD_DEFINITIONNAME>* nightly build from *$BUILD_SOURCEBRANCHNAME*.""
       curl -g -H ""Content-Type: application/json"" -X POST \
       -d ""{\""text\"": \""$MESSAGE\"", \""attachments\"": [{\""color\"": \""good\"",\""title\"": \""$BUILD_DEFINITIONNAME nightly build results\"",\""title_link\"": \""$BUILD_URL\""}]}"" $(slack_webhook)
     displayName: 'Post Slack Notification on Success'

diff --git a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
index 8017a14..24ed3d0 100644
--- a/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Interactivity/Modes/ModesOptionsEditor.ts
@@ -3,7 +3,6 @@ import type { IModes } from ""tsparticles/dist/Options/Interfaces/Interactivity/M
 import { ColorUtils, EditorGroup, IHsl, IRgb, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 import { ParticlesOptionsEditor } from ""../../Particles/ParticlesOptionsEditor"";
-import { IParticles } from ""tsparticles/dist/Options/Interfaces/Particles/IParticles"";
 
 export class ModesOptionsEditor extends EditorBase {
     public group!: EditorGroup;
diff --git a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
index 8cdc539..c3999f3 100644
--- a/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
+++ b/core/editor/src/ts/Sections/Options/Particles/Stroke/StrokeOptionsEditor.ts
@@ -1,7 +1,6 @@
 import { Container } from ""tsparticles/dist/Core/Container"";
 import { IStroke } from ""tsparticles/dist/Options/Interfaces/Particles/IStroke"";
 import { ColorOptionsEditor } from ""../Color/ColorOptionsEditor"";
-import { IAnimatableColor } from ""tsparticles/dist/Options/Interfaces/Particles/IAnimatableColor"";
 import { EditorGroup, SingleOrMultiple, EditorType } from ""object-gui"";
 import { EditorBase } from ""../../../../EditorBase"";
 
diff --git a/core/main/src/Core/Container.ts b/core/main/src/Core/Container.ts
index bc634f2..7c3773b 100644
--- a/core/main/src/Core/Container.ts
+++ b/core/main/src/Core/Container.ts
@@ -309,7 +309,7 @@ export class Container {
             return;
         }
 
-        this.firstStart = false;
+        this.firstStart = true;
         this.started = false;
         this.eventListeners.removeListeners();
         this.pause();

diff --git a/ionic/components/nav/nav-controller.ts b/ionic/components/nav/nav-controller.ts
index becdd99..1cc3c31 100644
--- a/ionic/components/nav/nav-controller.ts
+++ b/ionic/components/nav/nav-controller.ts
@@ -1410,6 +1410,9 @@ export class NavController extends Ion {
       // set the ComponentRef's instance to this ViewController
       view.setInstance(component);
 
+      // remember the ChangeDetectorRef for this ViewController
+      view.setChangeDetector(hostViewRef.changeDetectorRef);
+
       // remember the ElementRef to the ion-page elementRef that was just created
       view.setPageRef(pageElementRef);
 
diff --git a/ionic/components/nav/view-controller.ts b/ionic/components/nav/view-controller.ts
index 3207fa2..069c74d 100644
--- a/ionic/components/nav/view-controller.ts
+++ b/ionic/components/nav/view-controller.ts
@@ -1,4 +1,4 @@
-import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer} from 'angular2/core';
+import {Output, EventEmitter, Type, TemplateRef, ViewContainerRef, ElementRef, Renderer, ChangeDetectorRef} from 'angular2/core';
 
 import {Navbar} from '../navbar/navbar';
 import {NavController, NavOptions} from './nav-controller';
@@ -33,6 +33,7 @@ export class ViewController {
   private _nbVwRef: ViewContainerRef;
   private _onDismiss: Function = null;
   private _pgRef: ElementRef;
+  private _cd: ChangeDetectorRef;
   protected _nav: NavController;
 
   /**
@@ -166,6 +167,13 @@ export class ViewController {
   /**
    * @private
    */
+  setChangeDetector(cd: ChangeDetectorRef) {
+    this._cd = cd;
+  }
+
+  /**
+   * @private
+   */
   setInstance(instance: any) {
     this.instance = instance;
   }
@@ -467,6 +475,14 @@ export class ViewController {
    * The view is about to enter and become the active view.
    */
   willEnter() {
+    if (this._cd) {
+      // ensure this has been re-attached to the change detector
+      this._cd.reattach();
+
+      // detect changes before we run any user code
+      this._cd.detectChanges();
+    }
+
     ctrlFn(this, 'onPageWillEnter');
   }
 
@@ -496,6 +512,10 @@ export class ViewController {
    */
   didLeave() {
     ctrlFn(this, 'onPageDidLeave');
+
+    // when this is not the active page
+    // we no longer need to detect changes
+    this._cd && this._cd.detach();
   }
 
   /**

diff --git a/README.md b/README.md
index a8ef3bf..2947cd9 100644
--- a/README.md
+++ b/README.md
@@ -69,7 +69,7 @@ Follow the instructions on the `rustup` site for your operating system.
 
 [`rustup`]: https://rustup.rs/
 
-By default, `rustup` will install the latest stable verison of Rust. InfluxDB IOx is currently
+By default, `rustup` will install the latest stable version of Rust. InfluxDB IOx is currently
 using a nightly version of Rust to get performance benefits from the unstable `simd` feature. The
 exact nightly version is specified in the `rust-toolchain` file. When you're in the directory
 containing this repository's code, `rustup` will look in the `rust-toolchain` file and

diff --git a/core/src/components/slides/slides.tsx b/core/src/components/slides/slides.tsx
index 48fd53f..d5c2f75 100644
--- a/core/src/components/slides/slides.tsx
+++ b/core/src/components/slides/slides.tsx
@@ -1,7 +1,6 @@
 import { Component, Element, Event, EventEmitter, Method, Prop, Watch } from '@stencil/core';
 
 import { Mode } from '../../interface.js';
-import { createThemedClasses } from '../../utils/theme.js';
 
 import { Swiper } from './vendor/swiper.js';
 
@@ -15,6 +14,7 @@ import { Swiper } from './vendor/swiper.js';
   shadow: true
 })
 export class Slides {
+
   private container!: HTMLElement;
   private swiper: any;
 
@@ -391,12 +391,6 @@ export class Slides {
     return { ...swiperOptions, ...this.options, ...eventOptions };
   }
 
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'slides')
-    };
-  }
-
   render() {
     return (
       <div class=""swiper-container"" ref={el => this.container = el as HTMLElement }>
diff --git a/core/src/components/thumbnail/thumbnail.ios.scss b/core/src/components/thumbnail/thumbnail.ios.scss
deleted file mode 100644
index e3add45..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.ios.vars"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-ios-width};
-  --border-radius: #{$thumbnail-ios-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.ios.vars.scss b/core/src/components/thumbnail/thumbnail.ios.vars.scss
deleted file mode 100644
index 85d53e5..0000000
--- a/core/src/components/thumbnail/thumbnail.ios.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.ios"";
-
-// iOS Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-ios-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-ios-height:                  $thumbnail-ios-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-ios-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.md.scss b/core/src/components/thumbnail/thumbnail.md.scss
deleted file mode 100644
index 0fbb2ca..0000000
--- a/core/src/components/thumbnail/thumbnail.md.scss
+++ /dev/null
@@ -1,10 +0,0 @@
-@import ""./thumbnail"";
-@import ""./thumbnail.md.vars"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-:host {
-  --size: #{$thumbnail-md-width};
-  --border-radius: #{$thumbnail-md-border-radius};
-}
diff --git a/core/src/components/thumbnail/thumbnail.md.vars.scss b/core/src/components/thumbnail/thumbnail.md.vars.scss
deleted file mode 100644
index 94e48b2..0000000
--- a/core/src/components/thumbnail/thumbnail.md.vars.scss
+++ /dev/null
@@ -1,13 +0,0 @@
-@import ""../../themes/ionic.globals.md"";
-
-// Material Design Thumbnail
-// --------------------------------------------------
-
-/// @prop - Width of the thumbnail
-$thumbnail-md-width:                   48px !default;
-
-/// @prop - Height of the thumbnail
-$thumbnail-md-height:                  $thumbnail-md-width !default;
-
-/// @prop - Border radius of the thumbnail
-$thumbnail-md-border-radius:           0 !default;
diff --git a/core/src/components/thumbnail/thumbnail.scss b/core/src/components/thumbnail/thumbnail.scss
index 8ac3a22..8af268d 100644
--- a/core/src/components/thumbnail/thumbnail.scss
+++ b/core/src/components/thumbnail/thumbnail.scss
@@ -9,6 +9,8 @@
    * @prop --border-radius: Border radius of the thumbnail
    * @prop --size: Size of the thumbnail
    */
+  --size: 48px;
+  --border-radius: 0;
 
   @include border-radius(var(--border-radius));
 
diff --git a/core/src/components/thumbnail/thumbnail.tsx b/core/src/components/thumbnail/thumbnail.tsx
index 50ff2c2..de76593 100644
--- a/core/src/components/thumbnail/thumbnail.tsx
+++ b/core/src/components/thumbnail/thumbnail.tsx
@@ -1,25 +1,11 @@
 import { Component } from '@stencil/core';
 
-import { Mode } from '../../interface';
-import { createThemedClasses } from '../../utils/theme';
-
 @Component({
   tag: 'ion-thumbnail',
-  styleUrls: {
-    ios: 'thumbnail.ios.scss',
-    md: 'thumbnail.md.scss'
-  },
+  styleUrl: 'thumbnail.scss',
   shadow: true
 })
 export class Thumbnail {
-  mode!: Mode;
-
-  hostData() {
-    return {
-      class: createThemedClasses(this.mode, 'thumbnail')
-    };
-  }
-
   render() {
     return <slot></slot>;
   }
",5,"[""c5fa7b80438fbd74f4c341f0d3c9bd9e0f4910da"", ""bed78248c941d57ad4cc20a455147e186e97c7a1"", ""b282e90e2cbb74559aab79eee8443a4d7c85502a"", ""bf83c9155e9bee6925aa7102fab53fb803d52533"", ""771857b1df9470ebc15357e8879118a72c649d5b""]","[""cicd"", ""fix"", ""feat"", ""docs"", ""refactor""]"
